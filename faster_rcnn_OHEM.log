 rpn_cls_loss = 0.034219 (* 1 = 0.034219 loss)
I1018 08:34:29.353929  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0206528 (* 1 = 0.0206528 loss)
I1018 08:34:29.353932  9916 solver.cpp:571] Iteration 76880, lr = 0.0001
I1018 08:34:31.785673  9916 solver.cpp:242] Iteration 76900, loss = 0.0581966
I1018 08:34:31.785702  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0352728 (* 1 = 0.0352728 loss)
I1018 08:34:31.785707  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0229238 (* 1 = 0.0229238 loss)
I1018 08:34:31.785711  9916 solver.cpp:571] Iteration 76900, lr = 0.0001
I1018 08:34:34.238533  9916 solver.cpp:242] Iteration 76920, loss = 0.0769047
I1018 08:34:34.238560  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.069002 (* 1 = 0.069002 loss)
I1018 08:34:34.238564  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00790273 (* 1 = 0.00790273 loss)
I1018 08:34:34.238569  9916 solver.cpp:571] Iteration 76920, lr = 0.0001
I1018 08:34:36.679720  9916 solver.cpp:242] Iteration 76940, loss = 0.162235
I1018 08:34:36.679747  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.122973 (* 1 = 0.122973 loss)
I1018 08:34:36.679752  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.039262 (* 1 = 0.039262 loss)
I1018 08:34:36.679756  9916 solver.cpp:571] Iteration 76940, lr = 0.0001
I1018 08:34:39.121661  9916 solver.cpp:242] Iteration 76960, loss = 0.0650662
I1018 08:34:39.121696  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0517182 (* 1 = 0.0517182 loss)
I1018 08:34:39.121703  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.013348 (* 1 = 0.013348 loss)
I1018 08:34:39.121709  9916 solver.cpp:571] Iteration 76960, lr = 0.0001
I1018 08:34:41.509557  9916 solver.cpp:242] Iteration 76980, loss = 0.178103
I1018 08:34:41.509583  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.160442 (* 1 = 0.160442 loss)
I1018 08:34:41.509588  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0176615 (* 1 = 0.0176615 loss)
I1018 08:34:41.509591  9916 solver.cpp:571] Iteration 76980, lr = 0.0001
speed: 0.122s / iter
I1018 08:34:43.897807  9916 solver.cpp:242] Iteration 77000, loss = 0.127233
I1018 08:34:43.897835  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.118862 (* 1 = 0.118862 loss)
I1018 08:34:43.897840  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00837091 (* 1 = 0.00837091 loss)
I1018 08:34:43.897842  9916 solver.cpp:571] Iteration 77000, lr = 0.0001
I1018 08:34:46.361007  9916 solver.cpp:242] Iteration 77020, loss = 0.204391
I1018 08:34:46.361034  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.152085 (* 1 = 0.152085 loss)
I1018 08:34:46.361039  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0523054 (* 1 = 0.0523054 loss)
I1018 08:34:46.361042  9916 solver.cpp:571] Iteration 77020, lr = 0.0001
I1018 08:34:48.795454  9916 solver.cpp:242] Iteration 77040, loss = 0.109365
I1018 08:34:48.795482  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0907014 (* 1 = 0.0907014 loss)
I1018 08:34:48.795487  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.018664 (* 1 = 0.018664 loss)
I1018 08:34:48.795490  9916 solver.cpp:571] Iteration 77040, lr = 0.0001
I1018 08:34:51.274664  9916 solver.cpp:242] Iteration 77060, loss = 0.0636006
I1018 08:34:51.274693  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.055902 (* 1 = 0.055902 loss)
I1018 08:34:51.274698  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00769855 (* 1 = 0.00769855 loss)
I1018 08:34:51.274701  9916 solver.cpp:571] Iteration 77060, lr = 0.0001
I1018 08:34:53.693804  9916 solver.cpp:242] Iteration 77080, loss = 0.048167
I1018 08:34:53.693832  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0260128 (* 1 = 0.0260128 loss)
I1018 08:34:53.693836  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0221542 (* 1 = 0.0221542 loss)
I1018 08:34:53.693840  9916 solver.cpp:571] Iteration 77080, lr = 0.0001
I1018 08:34:56.089696  9916 solver.cpp:242] Iteration 77100, loss = 0.0870541
I1018 08:34:56.089725  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.085354 (* 1 = 0.085354 loss)
I1018 08:34:56.089730  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0017001 (* 1 = 0.0017001 loss)
I1018 08:34:56.089732  9916 solver.cpp:571] Iteration 77100, lr = 0.0001
I1018 08:34:58.528206  9916 solver.cpp:242] Iteration 77120, loss = 0.0800036
I1018 08:34:58.528234  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0674505 (* 1 = 0.0674505 loss)
I1018 08:34:58.528239  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0125532 (* 1 = 0.0125532 loss)
I1018 08:34:58.528241  9916 solver.cpp:571] Iteration 77120, lr = 0.0001
I1018 08:35:00.968354  9916 solver.cpp:242] Iteration 77140, loss = 0.0983628
I1018 08:35:00.968381  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0898375 (* 1 = 0.0898375 loss)
I1018 08:35:00.968386  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0085253 (* 1 = 0.0085253 loss)
I1018 08:35:00.968390  9916 solver.cpp:571] Iteration 77140, lr = 0.0001
I1018 08:35:03.400372  9916 solver.cpp:242] Iteration 77160, loss = 0.197282
I1018 08:35:03.400398  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.171783 (* 1 = 0.171783 loss)
I1018 08:35:03.400403  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0254984 (* 1 = 0.0254984 loss)
I1018 08:35:03.400408  9916 solver.cpp:571] Iteration 77160, lr = 0.0001
I1018 08:35:05.873850  9916 solver.cpp:242] Iteration 77180, loss = 0.113473
I1018 08:35:05.873878  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0935415 (* 1 = 0.0935415 loss)
I1018 08:35:05.873883  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0199315 (* 1 = 0.0199315 loss)
I1018 08:35:05.873888  9916 solver.cpp:571] Iteration 77180, lr = 0.0001
speed: 0.122s / iter
I1018 08:35:08.299412  9916 solver.cpp:242] Iteration 77200, loss = 0.112156
I1018 08:35:08.299439  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0656643 (* 1 = 0.0656643 loss)
I1018 08:35:08.299444  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0464921 (* 1 = 0.0464921 loss)
I1018 08:35:08.299448  9916 solver.cpp:571] Iteration 77200, lr = 0.0001
I1018 08:35:10.785718  9916 solver.cpp:242] Iteration 77220, loss = 0.186534
I1018 08:35:10.785745  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.161276 (* 1 = 0.161276 loss)
I1018 08:35:10.785750  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0252579 (* 1 = 0.0252579 loss)
I1018 08:35:10.785754  9916 solver.cpp:571] Iteration 77220, lr = 0.0001
I1018 08:35:13.199198  9916 solver.cpp:242] Iteration 77240, loss = 0.08848
I1018 08:35:13.199226  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0812755 (* 1 = 0.0812755 loss)
I1018 08:35:13.199231  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00720453 (* 1 = 0.00720453 loss)
I1018 08:35:13.199235  9916 solver.cpp:571] Iteration 77240, lr = 0.0001
I1018 08:35:15.681180  9916 solver.cpp:242] Iteration 77260, loss = 0.108673
I1018 08:35:15.681207  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0234041 (* 1 = 0.0234041 loss)
I1018 08:35:15.681213  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.085269 (* 1 = 0.085269 loss)
I1018 08:35:15.681216  9916 solver.cpp:571] Iteration 77260, lr = 0.0001
I1018 08:35:18.090340  9916 solver.cpp:242] Iteration 77280, loss = 0.634602
I1018 08:35:18.090368  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.587042 (* 1 = 0.587042 loss)
I1018 08:35:18.090373  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0475602 (* 1 = 0.0475602 loss)
I1018 08:35:18.090376  9916 solver.cpp:571] Iteration 77280, lr = 0.0001
I1018 08:35:20.538125  9916 solver.cpp:242] Iteration 77300, loss = 0.0280347
I1018 08:35:20.538152  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0258942 (* 1 = 0.0258942 loss)
I1018 08:35:20.538157  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00214052 (* 1 = 0.00214052 loss)
I1018 08:35:20.538161  9916 solver.cpp:571] Iteration 77300, lr = 0.0001
I1018 08:35:22.974314  9916 solver.cpp:242] Iteration 77320, loss = 0.0686852
I1018 08:35:22.974342  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0644714 (* 1 = 0.0644714 loss)
I1018 08:35:22.974347  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00421384 (* 1 = 0.00421384 loss)
I1018 08:35:22.974350  9916 solver.cpp:571] Iteration 77320, lr = 0.0001
I1018 08:35:25.383033  9916 solver.cpp:242] Iteration 77340, loss = 0.0645531
I1018 08:35:25.383059  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0531101 (* 1 = 0.0531101 loss)
I1018 08:35:25.383064  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.011443 (* 1 = 0.011443 loss)
I1018 08:35:25.383069  9916 solver.cpp:571] Iteration 77340, lr = 0.0001
I1018 08:35:27.790130  9916 solver.cpp:242] Iteration 77360, loss = 0.0738841
I1018 08:35:27.790158  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0651902 (* 1 = 0.0651902 loss)
I1018 08:35:27.790163  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00869389 (* 1 = 0.00869389 loss)
I1018 08:35:27.790165  9916 solver.cpp:571] Iteration 77360, lr = 0.0001
I1018 08:35:30.213733  9916 solver.cpp:242] Iteration 77380, loss = 0.169295
I1018 08:35:30.213760  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.141189 (* 1 = 0.141189 loss)
I1018 08:35:30.213765  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0281065 (* 1 = 0.0281065 loss)
I1018 08:35:30.213769  9916 solver.cpp:571] Iteration 77380, lr = 0.0001
speed: 0.122s / iter
I1018 08:35:32.708981  9916 solver.cpp:242] Iteration 77400, loss = 0.0391318
I1018 08:35:32.709009  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0279383 (* 1 = 0.0279383 loss)
I1018 08:35:32.709014  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0111935 (* 1 = 0.0111935 loss)
I1018 08:35:32.709017  9916 solver.cpp:571] Iteration 77400, lr = 0.0001
I1018 08:35:35.189528  9916 solver.cpp:242] Iteration 77420, loss = 0.272972
I1018 08:35:35.189554  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.215788 (* 1 = 0.215788 loss)
I1018 08:35:35.189559  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0571832 (* 1 = 0.0571832 loss)
I1018 08:35:35.189563  9916 solver.cpp:571] Iteration 77420, lr = 0.0001
I1018 08:35:37.608561  9916 solver.cpp:242] Iteration 77440, loss = 0.125627
I1018 08:35:37.608588  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0763941 (* 1 = 0.0763941 loss)
I1018 08:35:37.608593  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0492326 (* 1 = 0.0492326 loss)
I1018 08:35:37.608597  9916 solver.cpp:571] Iteration 77440, lr = 0.0001
I1018 08:35:40.078809  9916 solver.cpp:242] Iteration 77460, loss = 0.151723
I1018 08:35:40.078836  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.139707 (* 1 = 0.139707 loss)
I1018 08:35:40.078841  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0120159 (* 1 = 0.0120159 loss)
I1018 08:35:40.078845  9916 solver.cpp:571] Iteration 77460, lr = 0.0001
I1018 08:35:42.556131  9916 solver.cpp:242] Iteration 77480, loss = 0.0064902
I1018 08:35:42.556159  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.00592556 (* 1 = 0.00592556 loss)
I1018 08:35:42.556164  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.000564639 (* 1 = 0.000564639 loss)
I1018 08:35:42.556169  9916 solver.cpp:571] Iteration 77480, lr = 0.0001
I1018 08:35:45.029306  9916 solver.cpp:242] Iteration 77500, loss = 0.174087
I1018 08:35:45.029333  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.100262 (* 1 = 0.100262 loss)
I1018 08:35:45.029338  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0738249 (* 1 = 0.0738249 loss)
I1018 08:35:45.029342  9916 solver.cpp:571] Iteration 77500, lr = 0.0001
I1018 08:35:47.469959  9916 solver.cpp:242] Iteration 77520, loss = 0.332186
I1018 08:35:47.469986  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.176877 (* 1 = 0.176877 loss)
I1018 08:35:47.469991  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.15531 (* 1 = 0.15531 loss)
I1018 08:35:47.469995  9916 solver.cpp:571] Iteration 77520, lr = 0.0001
I1018 08:35:49.889228  9916 solver.cpp:242] Iteration 77540, loss = 0.0523665
I1018 08:35:49.889255  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0451817 (* 1 = 0.0451817 loss)
I1018 08:35:49.889261  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00718481 (* 1 = 0.00718481 loss)
I1018 08:35:49.889263  9916 solver.cpp:571] Iteration 77540, lr = 0.0001
I1018 08:35:52.327311  9916 solver.cpp:242] Iteration 77560, loss = 0.0419693
I1018 08:35:52.327342  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0195435 (* 1 = 0.0195435 loss)
I1018 08:35:52.327347  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0224259 (* 1 = 0.0224259 loss)
I1018 08:35:52.327350  9916 solver.cpp:571] Iteration 77560, lr = 0.0001
I1018 08:35:54.813575  9916 solver.cpp:242] Iteration 77580, loss = 0.12437
I1018 08:35:54.813602  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.115485 (* 1 = 0.115485 loss)
I1018 08:35:54.813607  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00888509 (* 1 = 0.00888509 loss)
I1018 08:35:54.813611  9916 solver.cpp:571] Iteration 77580, lr = 0.0001
speed: 0.122s / iter
I1018 08:35:57.298460  9916 solver.cpp:242] Iteration 77600, loss = 0.132604
I1018 08:35:57.298488  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.111095 (* 1 = 0.111095 loss)
I1018 08:35:57.298492  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0215092 (* 1 = 0.0215092 loss)
I1018 08:35:57.298496  9916 solver.cpp:571] Iteration 77600, lr = 0.0001
I1018 08:35:59.798797  9916 solver.cpp:242] Iteration 77620, loss = 0.0914025
I1018 08:35:59.798825  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0755215 (* 1 = 0.0755215 loss)
I1018 08:35:59.798830  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.015881 (* 1 = 0.015881 loss)
I1018 08:35:59.798835  9916 solver.cpp:571] Iteration 77620, lr = 0.0001
I1018 08:36:02.261560  9916 solver.cpp:242] Iteration 77640, loss = 0.0996342
I1018 08:36:02.261589  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0679675 (* 1 = 0.0679675 loss)
I1018 08:36:02.261592  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0316668 (* 1 = 0.0316668 loss)
I1018 08:36:02.261596  9916 solver.cpp:571] Iteration 77640, lr = 0.0001
I1018 08:36:04.718128  9916 solver.cpp:242] Iteration 77660, loss = 0.805467
I1018 08:36:04.718158  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.252316 (* 1 = 0.252316 loss)
I1018 08:36:04.718161  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.553151 (* 1 = 0.553151 loss)
I1018 08:36:04.718165  9916 solver.cpp:571] Iteration 77660, lr = 0.0001
I1018 08:36:07.164294  9916 solver.cpp:242] Iteration 77680, loss = 0.0595398
I1018 08:36:07.164320  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.028817 (* 1 = 0.028817 loss)
I1018 08:36:07.164325  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0307227 (* 1 = 0.0307227 loss)
I1018 08:36:07.164330  9916 solver.cpp:571] Iteration 77680, lr = 0.0001
I1018 08:36:09.643539  9916 solver.cpp:242] Iteration 77700, loss = 0.124224
I1018 08:36:09.643568  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.111474 (* 1 = 0.111474 loss)
I1018 08:36:09.643573  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0127497 (* 1 = 0.0127497 loss)
I1018 08:36:09.643575  9916 solver.cpp:571] Iteration 77700, lr = 0.0001
I1018 08:36:12.098554  9916 solver.cpp:242] Iteration 77720, loss = 0.366684
I1018 08:36:12.098582  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.219985 (* 1 = 0.219985 loss)
I1018 08:36:12.098585  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.146699 (* 1 = 0.146699 loss)
I1018 08:36:12.098589  9916 solver.cpp:571] Iteration 77720, lr = 0.0001
I1018 08:36:14.576496  9916 solver.cpp:242] Iteration 77740, loss = 0.0625749
I1018 08:36:14.576524  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0576614 (* 1 = 0.0576614 loss)
I1018 08:36:14.576529  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00491354 (* 1 = 0.00491354 loss)
I1018 08:36:14.576532  9916 solver.cpp:571] Iteration 77740, lr = 0.0001
I1018 08:36:17.030207  9916 solver.cpp:242] Iteration 77760, loss = 0.111491
I1018 08:36:17.030236  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0795952 (* 1 = 0.0795952 loss)
I1018 08:36:17.030239  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.031896 (* 1 = 0.031896 loss)
I1018 08:36:17.030243  9916 solver.cpp:571] Iteration 77760, lr = 0.0001
I1018 08:36:19.472877  9916 solver.cpp:242] Iteration 77780, loss = 0.0283331
I1018 08:36:19.472903  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0180234 (* 1 = 0.0180234 loss)
I1018 08:36:19.472908  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0103097 (* 1 = 0.0103097 loss)
I1018 08:36:19.472911  9916 solver.cpp:571] Iteration 77780, lr = 0.0001
speed: 0.122s / iter
I1018 08:36:21.902981  9916 solver.cpp:242] Iteration 77800, loss = 0.151033
I1018 08:36:21.903009  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.119327 (* 1 = 0.119327 loss)
I1018 08:36:21.903014  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0317059 (* 1 = 0.0317059 loss)
I1018 08:36:21.903017  9916 solver.cpp:571] Iteration 77800, lr = 0.0001
I1018 08:36:24.332315  9916 solver.cpp:242] Iteration 77820, loss = 0.0852998
I1018 08:36:24.332342  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0819565 (* 1 = 0.0819565 loss)
I1018 08:36:24.332347  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00334323 (* 1 = 0.00334323 loss)
I1018 08:36:24.332351  9916 solver.cpp:571] Iteration 77820, lr = 0.0001
I1018 08:36:26.792090  9916 solver.cpp:242] Iteration 77840, loss = 0.0899412
I1018 08:36:26.792117  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0853825 (* 1 = 0.0853825 loss)
I1018 08:36:26.792122  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00455872 (* 1 = 0.00455872 loss)
I1018 08:36:26.792125  9916 solver.cpp:571] Iteration 77840, lr = 0.0001
I1018 08:36:29.215456  9916 solver.cpp:242] Iteration 77860, loss = 0.0634744
I1018 08:36:29.215502  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0461873 (* 1 = 0.0461873 loss)
I1018 08:36:29.215509  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0172871 (* 1 = 0.0172871 loss)
I1018 08:36:29.215515  9916 solver.cpp:571] Iteration 77860, lr = 0.0001
I1018 08:36:31.691444  9916 solver.cpp:242] Iteration 77880, loss = 0.0194014
I1018 08:36:31.691473  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.016904 (* 1 = 0.016904 loss)
I1018 08:36:31.691478  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00249738 (* 1 = 0.00249738 loss)
I1018 08:36:31.691480  9916 solver.cpp:571] Iteration 77880, lr = 0.0001
I1018 08:36:34.125026  9916 solver.cpp:242] Iteration 77900, loss = 0.11963
I1018 08:36:34.125053  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.109677 (* 1 = 0.109677 loss)
I1018 08:36:34.125058  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00995349 (* 1 = 0.00995349 loss)
I1018 08:36:34.125062  9916 solver.cpp:571] Iteration 77900, lr = 0.0001
I1018 08:36:36.569358  9916 solver.cpp:242] Iteration 77920, loss = 0.0618613
I1018 08:36:36.569386  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0603146 (* 1 = 0.0603146 loss)
I1018 08:36:36.569391  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00154675 (* 1 = 0.00154675 loss)
I1018 08:36:36.569394  9916 solver.cpp:571] Iteration 77920, lr = 0.0001
I1018 08:36:39.032821  9916 solver.cpp:242] Iteration 77940, loss = 0.13452
I1018 08:36:39.032848  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.111177 (* 1 = 0.111177 loss)
I1018 08:36:39.032853  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0233432 (* 1 = 0.0233432 loss)
I1018 08:36:39.032857  9916 solver.cpp:571] Iteration 77940, lr = 0.0001
I1018 08:36:41.497931  9916 solver.cpp:242] Iteration 77960, loss = 0.234134
I1018 08:36:41.497957  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.170272 (* 1 = 0.170272 loss)
I1018 08:36:41.497962  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0638624 (* 1 = 0.0638624 loss)
I1018 08:36:41.497967  9916 solver.cpp:571] Iteration 77960, lr = 0.0001
I1018 08:36:43.918100  9916 solver.cpp:242] Iteration 77980, loss = 0.0101048
I1018 08:36:43.918128  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.00684583 (* 1 = 0.00684583 loss)
I1018 08:36:43.918131  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00325901 (* 1 = 0.00325901 loss)
I1018 08:36:43.918135  9916 solver.cpp:571] Iteration 77980, lr = 0.0001
speed: 0.122s / iter
I1018 08:36:46.332509  9916 solver.cpp:242] Iteration 78000, loss = 0.0529077
I1018 08:36:46.332535  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0259262 (* 1 = 0.0259262 loss)
I1018 08:36:46.332540  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0269815 (* 1 = 0.0269815 loss)
I1018 08:36:46.332545  9916 solver.cpp:571] Iteration 78000, lr = 0.0001
I1018 08:36:48.802959  9916 solver.cpp:242] Iteration 78020, loss = 0.0624461
I1018 08:36:48.802988  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0406479 (* 1 = 0.0406479 loss)
I1018 08:36:48.802992  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0217983 (* 1 = 0.0217983 loss)
I1018 08:36:48.802996  9916 solver.cpp:571] Iteration 78020, lr = 0.0001
I1018 08:36:51.290712  9916 solver.cpp:242] Iteration 78040, loss = 0.0569119
I1018 08:36:51.290740  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0306271 (* 1 = 0.0306271 loss)
I1018 08:36:51.290745  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0262848 (* 1 = 0.0262848 loss)
I1018 08:36:51.290748  9916 solver.cpp:571] Iteration 78040, lr = 0.0001
I1018 08:36:53.752993  9916 solver.cpp:242] Iteration 78060, loss = 0.147226
I1018 08:36:53.753021  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0788847 (* 1 = 0.0788847 loss)
I1018 08:36:53.753026  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0683418 (* 1 = 0.0683418 loss)
I1018 08:36:53.753029  9916 solver.cpp:571] Iteration 78060, lr = 0.0001
I1018 08:36:56.165869  9916 solver.cpp:242] Iteration 78080, loss = 0.140453
I1018 08:36:56.165897  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0950949 (* 1 = 0.0950949 loss)
I1018 08:36:56.165902  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0453582 (* 1 = 0.0453582 loss)
I1018 08:36:56.165905  9916 solver.cpp:571] Iteration 78080, lr = 0.0001
I1018 08:36:58.573528  9916 solver.cpp:242] Iteration 78100, loss = 0.0515285
I1018 08:36:58.573554  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0409345 (* 1 = 0.0409345 loss)
I1018 08:36:58.573559  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0105941 (* 1 = 0.0105941 loss)
I1018 08:36:58.573563  9916 solver.cpp:571] Iteration 78100, lr = 0.0001
I1018 08:37:01.006649  9916 solver.cpp:242] Iteration 78120, loss = 0.307519
I1018 08:37:01.006676  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.213811 (* 1 = 0.213811 loss)
I1018 08:37:01.006681  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0937082 (* 1 = 0.0937082 loss)
I1018 08:37:01.006685  9916 solver.cpp:571] Iteration 78120, lr = 0.0001
I1018 08:37:03.489759  9916 solver.cpp:242] Iteration 78140, loss = 0.081236
I1018 08:37:03.489786  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0445115 (* 1 = 0.0445115 loss)
I1018 08:37:03.489791  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0367245 (* 1 = 0.0367245 loss)
I1018 08:37:03.489794  9916 solver.cpp:571] Iteration 78140, lr = 0.0001
I1018 08:37:05.904703  9916 solver.cpp:242] Iteration 78160, loss = 0.0460415
I1018 08:37:05.904731  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0356647 (* 1 = 0.0356647 loss)
I1018 08:37:05.904736  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0103768 (* 1 = 0.0103768 loss)
I1018 08:37:05.904739  9916 solver.cpp:571] Iteration 78160, lr = 0.0001
I1018 08:37:08.382973  9916 solver.cpp:242] Iteration 78180, loss = 0.240836
I1018 08:37:08.383000  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.214176 (* 1 = 0.214176 loss)
I1018 08:37:08.383005  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.02666 (* 1 = 0.02666 loss)
I1018 08:37:08.383009  9916 solver.cpp:571] Iteration 78180, lr = 0.0001
speed: 0.122s / iter
I1018 08:37:10.805327  9916 solver.cpp:242] Iteration 78200, loss = 0.0277546
I1018 08:37:10.805354  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.00911849 (* 1 = 0.00911849 loss)
I1018 08:37:10.805358  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0186361 (* 1 = 0.0186361 loss)
I1018 08:37:10.805362  9916 solver.cpp:571] Iteration 78200, lr = 0.0001
I1018 08:37:13.163416  9916 solver.cpp:242] Iteration 78220, loss = 0.0337597
I1018 08:37:13.163444  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0206287 (* 1 = 0.0206287 loss)
I1018 08:37:13.163449  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.013131 (* 1 = 0.013131 loss)
I1018 08:37:13.163452  9916 solver.cpp:571] Iteration 78220, lr = 0.0001
I1018 08:37:15.643887  9916 solver.cpp:242] Iteration 78240, loss = 0.0238946
I1018 08:37:15.643913  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0172267 (* 1 = 0.0172267 loss)
I1018 08:37:15.643918  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00666784 (* 1 = 0.00666784 loss)
I1018 08:37:15.643923  9916 solver.cpp:571] Iteration 78240, lr = 0.0001
I1018 08:37:18.076357  9916 solver.cpp:242] Iteration 78260, loss = 0.0359453
I1018 08:37:18.076386  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0288574 (* 1 = 0.0288574 loss)
I1018 08:37:18.076391  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00708792 (* 1 = 0.00708792 loss)
I1018 08:37:18.076395  9916 solver.cpp:571] Iteration 78260, lr = 0.0001
I1018 08:37:20.493015  9916 solver.cpp:242] Iteration 78280, loss = 0.13044
I1018 08:37:20.493041  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0656442 (* 1 = 0.0656442 loss)
I1018 08:37:20.493046  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0647958 (* 1 = 0.0647958 loss)
I1018 08:37:20.493051  9916 solver.cpp:571] Iteration 78280, lr = 0.0001
I1018 08:37:22.948321  9916 solver.cpp:242] Iteration 78300, loss = 0.0590239
I1018 08:37:22.948349  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0413436 (* 1 = 0.0413436 loss)
I1018 08:37:22.948354  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0176803 (* 1 = 0.0176803 loss)
I1018 08:37:22.948357  9916 solver.cpp:571] Iteration 78300, lr = 0.0001
I1018 08:37:25.394979  9916 solver.cpp:242] Iteration 78320, loss = 0.312735
I1018 08:37:25.395007  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.250156 (* 1 = 0.250156 loss)
I1018 08:37:25.395012  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.062579 (* 1 = 0.062579 loss)
I1018 08:37:25.395016  9916 solver.cpp:571] Iteration 78320, lr = 0.0001
I1018 08:37:27.843979  9916 solver.cpp:242] Iteration 78340, loss = 0.167199
I1018 08:37:27.844007  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.134321 (* 1 = 0.134321 loss)
I1018 08:37:27.844012  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0328783 (* 1 = 0.0328783 loss)
I1018 08:37:27.844014  9916 solver.cpp:571] Iteration 78340, lr = 0.0001
I1018 08:37:30.282083  9916 solver.cpp:242] Iteration 78360, loss = 0.101504
I1018 08:37:30.282110  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0659013 (* 1 = 0.0659013 loss)
I1018 08:37:30.282115  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0356025 (* 1 = 0.0356025 loss)
I1018 08:37:30.282119  9916 solver.cpp:571] Iteration 78360, lr = 0.0001
I1018 08:37:32.756955  9916 solver.cpp:242] Iteration 78380, loss = 0.152396
I1018 08:37:32.756983  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.138012 (* 1 = 0.138012 loss)
I1018 08:37:32.756988  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.014384 (* 1 = 0.014384 loss)
I1018 08:37:32.756991  9916 solver.cpp:571] Iteration 78380, lr = 0.0001
speed: 0.122s / iter
I1018 08:37:35.239941  9916 solver.cpp:242] Iteration 78400, loss = 0.0349545
I1018 08:37:35.239969  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0180376 (* 1 = 0.0180376 loss)
I1018 08:37:35.239974  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0169169 (* 1 = 0.0169169 loss)
I1018 08:37:35.239977  9916 solver.cpp:571] Iteration 78400, lr = 0.0001
I1018 08:37:37.680093  9916 solver.cpp:242] Iteration 78420, loss = 0.073121
I1018 08:37:37.680120  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0633369 (* 1 = 0.0633369 loss)
I1018 08:37:37.680124  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00978412 (* 1 = 0.00978412 loss)
I1018 08:37:37.680129  9916 solver.cpp:571] Iteration 78420, lr = 0.0001
I1018 08:37:40.122792  9916 solver.cpp:242] Iteration 78440, loss = 0.122909
I1018 08:37:40.122819  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.095506 (* 1 = 0.095506 loss)
I1018 08:37:40.122824  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0274028 (* 1 = 0.0274028 loss)
I1018 08:37:40.122828  9916 solver.cpp:571] Iteration 78440, lr = 0.0001
I1018 08:37:42.554455  9916 solver.cpp:242] Iteration 78460, loss = 0.115933
I1018 08:37:42.554482  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0678755 (* 1 = 0.0678755 loss)
I1018 08:37:42.554487  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0480577 (* 1 = 0.0480577 loss)
I1018 08:37:42.554491  9916 solver.cpp:571] Iteration 78460, lr = 0.0001
I1018 08:37:44.986322  9916 solver.cpp:242] Iteration 78480, loss = 0.15357
I1018 08:37:44.986349  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.14118 (* 1 = 0.14118 loss)
I1018 08:37:44.986354  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.01239 (* 1 = 0.01239 loss)
I1018 08:37:44.986357  9916 solver.cpp:571] Iteration 78480, lr = 0.0001
I1018 08:37:47.376577  9916 solver.cpp:242] Iteration 78500, loss = 0.0498078
I1018 08:37:47.376605  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.038069 (* 1 = 0.038069 loss)
I1018 08:37:47.376610  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0117388 (* 1 = 0.0117388 loss)
I1018 08:37:47.376612  9916 solver.cpp:571] Iteration 78500, lr = 0.0001
I1018 08:37:49.861274  9916 solver.cpp:242] Iteration 78520, loss = 0.144475
I1018 08:37:49.861304  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.126958 (* 1 = 0.126958 loss)
I1018 08:37:49.861309  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0175168 (* 1 = 0.0175168 loss)
I1018 08:37:49.861312  9916 solver.cpp:571] Iteration 78520, lr = 0.0001
I1018 08:37:52.254708  9916 solver.cpp:242] Iteration 78540, loss = 0.0996443
I1018 08:37:52.254735  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0691407 (* 1 = 0.0691407 loss)
I1018 08:37:52.254740  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0305036 (* 1 = 0.0305036 loss)
I1018 08:37:52.254743  9916 solver.cpp:571] Iteration 78540, lr = 0.0001
I1018 08:37:54.641144  9916 solver.cpp:242] Iteration 78560, loss = 0.222279
I1018 08:37:54.641170  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.174654 (* 1 = 0.174654 loss)
I1018 08:37:54.641175  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0476251 (* 1 = 0.0476251 loss)
I1018 08:37:54.641180  9916 solver.cpp:571] Iteration 78560, lr = 0.0001
I1018 08:37:57.127223  9916 solver.cpp:242] Iteration 78580, loss = 0.277013
I1018 08:37:57.127249  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.262471 (* 1 = 0.262471 loss)
I1018 08:37:57.127254  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0145419 (* 1 = 0.0145419 loss)
I1018 08:37:57.127259  9916 solver.cpp:571] Iteration 78580, lr = 0.0001
speed: 0.122s / iter
I1018 08:37:59.543517  9916 solver.cpp:242] Iteration 78600, loss = 0.170374
I1018 08:37:59.543545  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.124295 (* 1 = 0.124295 loss)
I1018 08:37:59.543550  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0460786 (* 1 = 0.0460786 loss)
I1018 08:37:59.543553  9916 solver.cpp:571] Iteration 78600, lr = 0.0001
I1018 08:38:01.989375  9916 solver.cpp:242] Iteration 78620, loss = 0.0485246
I1018 08:38:01.989403  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0335444 (* 1 = 0.0335444 loss)
I1018 08:38:01.989408  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0149802 (* 1 = 0.0149802 loss)
I1018 08:38:01.989413  9916 solver.cpp:571] Iteration 78620, lr = 0.0001
I1018 08:38:04.454347  9916 solver.cpp:242] Iteration 78640, loss = 0.109764
I1018 08:38:04.454375  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0946477 (* 1 = 0.0946477 loss)
I1018 08:38:04.454380  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0151164 (* 1 = 0.0151164 loss)
I1018 08:38:04.454383  9916 solver.cpp:571] Iteration 78640, lr = 0.0001
I1018 08:38:06.940201  9916 solver.cpp:242] Iteration 78660, loss = 0.181998
I1018 08:38:06.940228  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.14968 (* 1 = 0.14968 loss)
I1018 08:38:06.940233  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0323181 (* 1 = 0.0323181 loss)
I1018 08:38:06.940237  9916 solver.cpp:571] Iteration 78660, lr = 0.0001
I1018 08:38:09.369704  9916 solver.cpp:242] Iteration 78680, loss = 0.0557773
I1018 08:38:09.369730  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.053563 (* 1 = 0.053563 loss)
I1018 08:38:09.369735  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00221428 (* 1 = 0.00221428 loss)
I1018 08:38:09.369740  9916 solver.cpp:571] Iteration 78680, lr = 0.0001
I1018 08:38:11.766373  9916 solver.cpp:242] Iteration 78700, loss = 0.0862381
I1018 08:38:11.766402  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0572013 (* 1 = 0.0572013 loss)
I1018 08:38:11.766405  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0290368 (* 1 = 0.0290368 loss)
I1018 08:38:11.766409  9916 solver.cpp:571] Iteration 78700, lr = 0.0001
I1018 08:38:14.192369  9916 solver.cpp:242] Iteration 78720, loss = 0.154318
I1018 08:38:14.192395  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.114584 (* 1 = 0.114584 loss)
I1018 08:38:14.192400  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0397341 (* 1 = 0.0397341 loss)
I1018 08:38:14.192404  9916 solver.cpp:571] Iteration 78720, lr = 0.0001
I1018 08:38:16.697789  9916 solver.cpp:242] Iteration 78740, loss = 0.222246
I1018 08:38:16.697816  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.185289 (* 1 = 0.185289 loss)
I1018 08:38:16.697821  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0369575 (* 1 = 0.0369575 loss)
I1018 08:38:16.697824  9916 solver.cpp:571] Iteration 78740, lr = 0.0001
I1018 08:38:19.143182  9916 solver.cpp:242] Iteration 78760, loss = 0.17838
I1018 08:38:19.143208  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.124269 (* 1 = 0.124269 loss)
I1018 08:38:19.143213  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0541114 (* 1 = 0.0541114 loss)
I1018 08:38:19.143216  9916 solver.cpp:571] Iteration 78760, lr = 0.0001
I1018 08:38:21.596846  9916 solver.cpp:242] Iteration 78780, loss = 0.0505551
I1018 08:38:21.596874  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0281572 (* 1 = 0.0281572 loss)
I1018 08:38:21.596879  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0223979 (* 1 = 0.0223979 loss)
I1018 08:38:21.596882  9916 solver.cpp:571] Iteration 78780, lr = 0.0001
speed: 0.122s / iter
I1018 08:38:24.034530  9916 solver.cpp:242] Iteration 78800, loss = 0.263344
I1018 08:38:24.034559  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.197314 (* 1 = 0.197314 loss)
I1018 08:38:24.034562  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.06603 (* 1 = 0.06603 loss)
I1018 08:38:24.034566  9916 solver.cpp:571] Iteration 78800, lr = 0.0001
I1018 08:38:26.441382  9916 solver.cpp:242] Iteration 78820, loss = 0.161414
I1018 08:38:26.441409  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0923912 (* 1 = 0.0923912 loss)
I1018 08:38:26.441413  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0690225 (* 1 = 0.0690225 loss)
I1018 08:38:26.441417  9916 solver.cpp:571] Iteration 78820, lr = 0.0001
I1018 08:38:28.894834  9916 solver.cpp:242] Iteration 78840, loss = 0.0646335
I1018 08:38:28.894861  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0608751 (* 1 = 0.0608751 loss)
I1018 08:38:28.894866  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0037584 (* 1 = 0.0037584 loss)
I1018 08:38:28.894870  9916 solver.cpp:571] Iteration 78840, lr = 0.0001
I1018 08:38:31.352061  9916 solver.cpp:242] Iteration 78860, loss = 0.0441945
I1018 08:38:31.352088  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0171433 (* 1 = 0.0171433 loss)
I1018 08:38:31.352093  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0270512 (* 1 = 0.0270512 loss)
I1018 08:38:31.352097  9916 solver.cpp:571] Iteration 78860, lr = 0.0001
I1018 08:38:33.715090  9916 solver.cpp:242] Iteration 78880, loss = 0.0536057
I1018 08:38:33.715116  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0456694 (* 1 = 0.0456694 loss)
I1018 08:38:33.715121  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00793629 (* 1 = 0.00793629 loss)
I1018 08:38:33.715126  9916 solver.cpp:571] Iteration 78880, lr = 0.0001
I1018 08:38:36.143846  9916 solver.cpp:242] Iteration 78900, loss = 0.133212
I1018 08:38:36.143873  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.11781 (* 1 = 0.11781 loss)
I1018 08:38:36.143878  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0154022 (* 1 = 0.0154022 loss)
I1018 08:38:36.143882  9916 solver.cpp:571] Iteration 78900, lr = 0.0001
I1018 08:38:38.564198  9916 solver.cpp:242] Iteration 78920, loss = 0.0860044
I1018 08:38:38.564225  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0733941 (* 1 = 0.0733941 loss)
I1018 08:38:38.564230  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0126103 (* 1 = 0.0126103 loss)
I1018 08:38:38.564234  9916 solver.cpp:571] Iteration 78920, lr = 0.0001
I1018 08:38:41.022855  9916 solver.cpp:242] Iteration 78940, loss = 0.0406142
I1018 08:38:41.022883  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0244532 (* 1 = 0.0244532 loss)
I1018 08:38:41.022887  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0161611 (* 1 = 0.0161611 loss)
I1018 08:38:41.022891  9916 solver.cpp:571] Iteration 78940, lr = 0.0001
I1018 08:38:43.486289  9916 solver.cpp:242] Iteration 78960, loss = 0.0352125
I1018 08:38:43.486315  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0320999 (* 1 = 0.0320999 loss)
I1018 08:38:43.486320  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00311267 (* 1 = 0.00311267 loss)
I1018 08:38:43.486325  9916 solver.cpp:571] Iteration 78960, lr = 0.0001
I1018 08:38:45.962388  9916 solver.cpp:242] Iteration 78980, loss = 0.242469
I1018 08:38:45.962415  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.195866 (* 1 = 0.195866 loss)
I1018 08:38:45.962420  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0466039 (* 1 = 0.0466039 loss)
I1018 08:38:45.962424  9916 solver.cpp:571] Iteration 78980, lr = 0.0001
speed: 0.122s / iter
I1018 08:38:48.422402  9916 solver.cpp:242] Iteration 79000, loss = 0.0939311
I1018 08:38:48.422430  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0257042 (* 1 = 0.0257042 loss)
I1018 08:38:48.422435  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0682269 (* 1 = 0.0682269 loss)
I1018 08:38:48.422440  9916 solver.cpp:571] Iteration 79000, lr = 0.0001
I1018 08:38:50.889087  9916 solver.cpp:242] Iteration 79020, loss = 0.128434
I1018 08:38:50.889114  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.031535 (* 1 = 0.031535 loss)
I1018 08:38:50.889119  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0968993 (* 1 = 0.0968993 loss)
I1018 08:38:50.889122  9916 solver.cpp:571] Iteration 79020, lr = 0.0001
I1018 08:38:53.334239  9916 solver.cpp:242] Iteration 79040, loss = 0.139058
I1018 08:38:53.334265  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.113702 (* 1 = 0.113702 loss)
I1018 08:38:53.334270  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0253557 (* 1 = 0.0253557 loss)
I1018 08:38:53.334275  9916 solver.cpp:571] Iteration 79040, lr = 0.0001
I1018 08:38:55.794834  9916 solver.cpp:242] Iteration 79060, loss = 0.186774
I1018 08:38:55.794863  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.115378 (* 1 = 0.115378 loss)
I1018 08:38:55.794868  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.071396 (* 1 = 0.071396 loss)
I1018 08:38:55.794872  9916 solver.cpp:571] Iteration 79060, lr = 0.0001
I1018 08:38:58.260514  9916 solver.cpp:242] Iteration 79080, loss = 0.11142
I1018 08:38:58.260541  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.091968 (* 1 = 0.091968 loss)
I1018 08:38:58.260545  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0194519 (* 1 = 0.0194519 loss)
I1018 08:38:58.260550  9916 solver.cpp:571] Iteration 79080, lr = 0.0001
I1018 08:39:00.742738  9916 solver.cpp:242] Iteration 79100, loss = 0.0550088
I1018 08:39:00.742765  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0501493 (* 1 = 0.0501493 loss)
I1018 08:39:00.742769  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00485946 (* 1 = 0.00485946 loss)
I1018 08:39:00.742774  9916 solver.cpp:571] Iteration 79100, lr = 0.0001
I1018 08:39:03.214575  9916 solver.cpp:242] Iteration 79120, loss = 0.0347847
I1018 08:39:03.214607  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0251946 (* 1 = 0.0251946 loss)
I1018 08:39:03.214613  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00959012 (* 1 = 0.00959012 loss)
I1018 08:39:03.214617  9916 solver.cpp:571] Iteration 79120, lr = 0.0001
I1018 08:39:05.684792  9916 solver.cpp:242] Iteration 79140, loss = 0.0625251
I1018 08:39:05.684818  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0509041 (* 1 = 0.0509041 loss)
I1018 08:39:05.684823  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0116209 (* 1 = 0.0116209 loss)
I1018 08:39:05.684828  9916 solver.cpp:571] Iteration 79140, lr = 0.0001
I1018 08:39:08.126185  9916 solver.cpp:242] Iteration 79160, loss = 0.281587
I1018 08:39:08.126214  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.258743 (* 1 = 0.258743 loss)
I1018 08:39:08.126219  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.022845 (* 1 = 0.022845 loss)
I1018 08:39:08.126222  9916 solver.cpp:571] Iteration 79160, lr = 0.0001
I1018 08:39:10.629597  9916 solver.cpp:242] Iteration 79180, loss = 0.14882
I1018 08:39:10.629626  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0792207 (* 1 = 0.0792207 loss)
I1018 08:39:10.629629  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0695997 (* 1 = 0.0695997 loss)
I1018 08:39:10.629633  9916 solver.cpp:571] Iteration 79180, lr = 0.0001
speed: 0.122s / iter
I1018 08:39:13.091830  9916 solver.cpp:242] Iteration 79200, loss = 0.0707664
I1018 08:39:13.091857  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0687464 (* 1 = 0.0687464 loss)
I1018 08:39:13.091862  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00201999 (* 1 = 0.00201999 loss)
I1018 08:39:13.091866  9916 solver.cpp:571] Iteration 79200, lr = 0.0001
I1018 08:39:15.531951  9916 solver.cpp:242] Iteration 79220, loss = 0.742002
I1018 08:39:15.531978  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.467334 (* 1 = 0.467334 loss)
I1018 08:39:15.531983  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.274668 (* 1 = 0.274668 loss)
I1018 08:39:15.531986  9916 solver.cpp:571] Iteration 79220, lr = 0.0001
I1018 08:39:17.905195  9916 solver.cpp:242] Iteration 79240, loss = 0.249341
I1018 08:39:17.905223  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0164135 (* 1 = 0.0164135 loss)
I1018 08:39:17.905228  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.232927 (* 1 = 0.232927 loss)
I1018 08:39:17.905232  9916 solver.cpp:571] Iteration 79240, lr = 0.0001
I1018 08:39:20.360433  9916 solver.cpp:242] Iteration 79260, loss = 0.144275
I1018 08:39:20.360460  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0973966 (* 1 = 0.0973966 loss)
I1018 08:39:20.360466  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0468788 (* 1 = 0.0468788 loss)
I1018 08:39:20.360468  9916 solver.cpp:571] Iteration 79260, lr = 0.0001
I1018 08:39:22.813825  9916 solver.cpp:242] Iteration 79280, loss = 0.548934
I1018 08:39:22.813854  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.458222 (* 1 = 0.458222 loss)
I1018 08:39:22.813859  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0907122 (* 1 = 0.0907122 loss)
I1018 08:39:22.813863  9916 solver.cpp:571] Iteration 79280, lr = 0.0001
I1018 08:39:25.273470  9916 solver.cpp:242] Iteration 79300, loss = 0.0832853
I1018 08:39:25.273497  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0246268 (* 1 = 0.0246268 loss)
I1018 08:39:25.273502  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0586585 (* 1 = 0.0586585 loss)
I1018 08:39:25.273505  9916 solver.cpp:571] Iteration 79300, lr = 0.0001
I1018 08:39:27.761301  9916 solver.cpp:242] Iteration 79320, loss = 0.0636901
I1018 08:39:27.761328  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0616405 (* 1 = 0.0616405 loss)
I1018 08:39:27.761333  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00204968 (* 1 = 0.00204968 loss)
I1018 08:39:27.761337  9916 solver.cpp:571] Iteration 79320, lr = 0.0001
I1018 08:39:30.204215  9916 solver.cpp:242] Iteration 79340, loss = 0.128651
I1018 08:39:30.204241  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.112133 (* 1 = 0.112133 loss)
I1018 08:39:30.204246  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0165174 (* 1 = 0.0165174 loss)
I1018 08:39:30.204249  9916 solver.cpp:571] Iteration 79340, lr = 0.0001
I1018 08:39:32.672368  9916 solver.cpp:242] Iteration 79360, loss = 0.127462
I1018 08:39:32.672394  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.108564 (* 1 = 0.108564 loss)
I1018 08:39:32.672399  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0188981 (* 1 = 0.0188981 loss)
I1018 08:39:32.672404  9916 solver.cpp:571] Iteration 79360, lr = 0.0001
I1018 08:39:35.100704  9916 solver.cpp:242] Iteration 79380, loss = 0.157922
I1018 08:39:35.100733  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.109124 (* 1 = 0.109124 loss)
I1018 08:39:35.100738  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0487983 (* 1 = 0.0487983 loss)
I1018 08:39:35.100741  9916 solver.cpp:571] Iteration 79380, lr = 0.0001
speed: 0.122s / iter
I1018 08:39:37.563266  9916 solver.cpp:242] Iteration 79400, loss = 0.0766244
I1018 08:39:37.563293  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0571956 (* 1 = 0.0571956 loss)
I1018 08:39:37.563298  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0194289 (* 1 = 0.0194289 loss)
I1018 08:39:37.563302  9916 solver.cpp:571] Iteration 79400, lr = 0.0001
I1018 08:39:39.996065  9916 solver.cpp:242] Iteration 79420, loss = 0.0140446
I1018 08:39:39.996093  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0138565 (* 1 = 0.0138565 loss)
I1018 08:39:39.996098  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.000188124 (* 1 = 0.000188124 loss)
I1018 08:39:39.996101  9916 solver.cpp:571] Iteration 79420, lr = 0.0001
I1018 08:39:42.410976  9916 solver.cpp:242] Iteration 79440, loss = 0.0347836
I1018 08:39:42.411005  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0098068 (* 1 = 0.0098068 loss)
I1018 08:39:42.411010  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0249768 (* 1 = 0.0249768 loss)
I1018 08:39:42.411012  9916 solver.cpp:571] Iteration 79440, lr = 0.0001
I1018 08:39:44.879179  9916 solver.cpp:242] Iteration 79460, loss = 0.083768
I1018 08:39:44.879205  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0673376 (* 1 = 0.0673376 loss)
I1018 08:39:44.879210  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0164304 (* 1 = 0.0164304 loss)
I1018 08:39:44.879215  9916 solver.cpp:571] Iteration 79460, lr = 0.0001
I1018 08:39:47.336220  9916 solver.cpp:242] Iteration 79480, loss = 0.0574341
I1018 08:39:47.336246  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0161347 (* 1 = 0.0161347 loss)
I1018 08:39:47.336251  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0412994 (* 1 = 0.0412994 loss)
I1018 08:39:47.336256  9916 solver.cpp:571] Iteration 79480, lr = 0.0001
I1018 08:39:49.775887  9916 solver.cpp:242] Iteration 79500, loss = 0.057739
I1018 08:39:49.775914  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.048435 (* 1 = 0.048435 loss)
I1018 08:39:49.775919  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00930404 (* 1 = 0.00930404 loss)
I1018 08:39:49.775923  9916 solver.cpp:571] Iteration 79500, lr = 0.0001
I1018 08:39:52.242143  9916 solver.cpp:242] Iteration 79520, loss = 0.156601
I1018 08:39:52.242171  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.102751 (* 1 = 0.102751 loss)
I1018 08:39:52.242175  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0538507 (* 1 = 0.0538507 loss)
I1018 08:39:52.242179  9916 solver.cpp:571] Iteration 79520, lr = 0.0001
I1018 08:39:54.714982  9916 solver.cpp:242] Iteration 79540, loss = 0.339446
I1018 08:39:54.715009  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.266257 (* 1 = 0.266257 loss)
I1018 08:39:54.715014  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0731887 (* 1 = 0.0731887 loss)
I1018 08:39:54.715018  9916 solver.cpp:571] Iteration 79540, lr = 0.0001
I1018 08:39:57.158241  9916 solver.cpp:242] Iteration 79560, loss = 0.220984
I1018 08:39:57.158269  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.172268 (* 1 = 0.172268 loss)
I1018 08:39:57.158274  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0487158 (* 1 = 0.0487158 loss)
I1018 08:39:57.158278  9916 solver.cpp:571] Iteration 79560, lr = 0.0001
I1018 08:39:59.578857  9916 solver.cpp:242] Iteration 79580, loss = 0.196926
I1018 08:39:59.578886  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.136513 (* 1 = 0.136513 loss)
I1018 08:39:59.578891  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0604127 (* 1 = 0.0604127 loss)
I1018 08:39:59.578893  9916 solver.cpp:571] Iteration 79580, lr = 0.0001
speed: 0.122s / iter
I1018 08:40:02.035524  9916 solver.cpp:242] Iteration 79600, loss = 0.107299
I1018 08:40:02.035552  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0914314 (* 1 = 0.0914314 loss)
I1018 08:40:02.035557  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0158671 (* 1 = 0.0158671 loss)
I1018 08:40:02.035560  9916 solver.cpp:571] Iteration 79600, lr = 0.0001
I1018 08:40:04.451424  9916 solver.cpp:242] Iteration 79620, loss = 0.0563814
I1018 08:40:04.451452  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0367375 (* 1 = 0.0367375 loss)
I1018 08:40:04.451457  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0196438 (* 1 = 0.0196438 loss)
I1018 08:40:04.451460  9916 solver.cpp:571] Iteration 79620, lr = 0.0001
I1018 08:40:06.910817  9916 solver.cpp:242] Iteration 79640, loss = 0.144455
I1018 08:40:06.910845  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.115241 (* 1 = 0.115241 loss)
I1018 08:40:06.910850  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0292135 (* 1 = 0.0292135 loss)
I1018 08:40:06.910853  9916 solver.cpp:571] Iteration 79640, lr = 0.0001
I1018 08:40:09.396181  9916 solver.cpp:242] Iteration 79660, loss = 0.0374601
I1018 08:40:09.396209  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0248872 (* 1 = 0.0248872 loss)
I1018 08:40:09.396214  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0125729 (* 1 = 0.0125729 loss)
I1018 08:40:09.396217  9916 solver.cpp:571] Iteration 79660, lr = 0.0001
I1018 08:40:11.851665  9916 solver.cpp:242] Iteration 79680, loss = 0.0268648
I1018 08:40:11.851691  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.024412 (* 1 = 0.024412 loss)
I1018 08:40:11.851696  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00245282 (* 1 = 0.00245282 loss)
I1018 08:40:11.851701  9916 solver.cpp:571] Iteration 79680, lr = 0.0001
I1018 08:40:14.314945  9916 solver.cpp:242] Iteration 79700, loss = 0.12529
I1018 08:40:14.314972  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.114768 (* 1 = 0.114768 loss)
I1018 08:40:14.314977  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0105221 (* 1 = 0.0105221 loss)
I1018 08:40:14.314981  9916 solver.cpp:571] Iteration 79700, lr = 0.0001
I1018 08:40:16.798600  9916 solver.cpp:242] Iteration 79720, loss = 0.0753752
I1018 08:40:16.798629  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.045203 (* 1 = 0.045203 loss)
I1018 08:40:16.798634  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0301722 (* 1 = 0.0301722 loss)
I1018 08:40:16.798637  9916 solver.cpp:571] Iteration 79720, lr = 0.0001
I1018 08:40:19.281194  9916 solver.cpp:242] Iteration 79740, loss = 0.0831144
I1018 08:40:19.281222  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0759882 (* 1 = 0.0759882 loss)
I1018 08:40:19.281227  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00712626 (* 1 = 0.00712626 loss)
I1018 08:40:19.281230  9916 solver.cpp:571] Iteration 79740, lr = 0.0001
I1018 08:40:21.728425  9916 solver.cpp:242] Iteration 79760, loss = 0.0258061
I1018 08:40:21.728456  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0249336 (* 1 = 0.0249336 loss)
I1018 08:40:21.728461  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.000872498 (* 1 = 0.000872498 loss)
I1018 08:40:21.728466  9916 solver.cpp:571] Iteration 79760, lr = 0.0001
I1018 08:40:24.204690  9916 solver.cpp:242] Iteration 79780, loss = 0.102308
I1018 08:40:24.204718  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0829946 (* 1 = 0.0829946 loss)
I1018 08:40:24.204723  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0193138 (* 1 = 0.0193138 loss)
I1018 08:40:24.204727  9916 solver.cpp:571] Iteration 79780, lr = 0.0001
speed: 0.122s / iter
I1018 08:40:26.674387  9916 solver.cpp:242] Iteration 79800, loss = 0.0435437
I1018 08:40:26.674415  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0296327 (* 1 = 0.0296327 loss)
I1018 08:40:26.674420  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.013911 (* 1 = 0.013911 loss)
I1018 08:40:26.674423  9916 solver.cpp:571] Iteration 79800, lr = 0.0001
I1018 08:40:29.126080  9916 solver.cpp:242] Iteration 79820, loss = 0.0942632
I1018 08:40:29.126108  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0760301 (* 1 = 0.0760301 loss)
I1018 08:40:29.126113  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.018233 (* 1 = 0.018233 loss)
I1018 08:40:29.126117  9916 solver.cpp:571] Iteration 79820, lr = 0.0001
I1018 08:40:31.628669  9916 solver.cpp:242] Iteration 79840, loss = 0.0428339
I1018 08:40:31.628697  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0372808 (* 1 = 0.0372808 loss)
I1018 08:40:31.628701  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00555309 (* 1 = 0.00555309 loss)
I1018 08:40:31.628705  9916 solver.cpp:571] Iteration 79840, lr = 0.0001
I1018 08:40:34.102629  9916 solver.cpp:242] Iteration 79860, loss = 0.027067
I1018 08:40:34.102658  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0186285 (* 1 = 0.0186285 loss)
I1018 08:40:34.102663  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00843849 (* 1 = 0.00843849 loss)
I1018 08:40:34.102666  9916 solver.cpp:571] Iteration 79860, lr = 0.0001
I1018 08:40:36.611726  9916 solver.cpp:242] Iteration 79880, loss = 0.110531
I1018 08:40:36.611752  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0443389 (* 1 = 0.0443389 loss)
I1018 08:40:36.611757  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.066192 (* 1 = 0.066192 loss)
I1018 08:40:36.611760  9916 solver.cpp:571] Iteration 79880, lr = 0.0001
I1018 08:40:39.120573  9916 solver.cpp:242] Iteration 79900, loss = 0.0425059
I1018 08:40:39.120601  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0377726 (* 1 = 0.0377726 loss)
I1018 08:40:39.120606  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00473327 (* 1 = 0.00473327 loss)
I1018 08:40:39.120609  9916 solver.cpp:571] Iteration 79900, lr = 0.0001
I1018 08:40:41.573371  9916 solver.cpp:242] Iteration 79920, loss = 0.0347341
I1018 08:40:41.573400  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0330635 (* 1 = 0.0330635 loss)
I1018 08:40:41.573405  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00167059 (* 1 = 0.00167059 loss)
I1018 08:40:41.573407  9916 solver.cpp:571] Iteration 79920, lr = 0.0001
I1018 08:40:43.977504  9916 solver.cpp:242] Iteration 79940, loss = 0.122165
I1018 08:40:43.977532  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.117315 (* 1 = 0.117315 loss)
I1018 08:40:43.977537  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.00484959 (* 1 = 0.00484959 loss)
I1018 08:40:43.977541  9916 solver.cpp:571] Iteration 79940, lr = 0.0001
I1018 08:40:46.452139  9916 solver.cpp:242] Iteration 79960, loss = 0.169441
I1018 08:40:46.452167  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.124851 (* 1 = 0.124851 loss)
I1018 08:40:46.452172  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0445894 (* 1 = 0.0445894 loss)
I1018 08:40:46.452175  9916 solver.cpp:571] Iteration 79960, lr = 0.0001
I1018 08:40:48.932422  9916 solver.cpp:242] Iteration 79980, loss = 0.178941
I1018 08:40:48.932449  9916 solver.cpp:258]     Train net output #0: rpn_cls_loss = 0.0855194 (* 1 = 0.0855194 loss)
I1018 08:40:48.932454  9916 solver.cpp:258]     Train net output #1: rpn_loss_bbox = 0.0934214 (* 1 = 0.0934214 loss)
I1018 08:40:48.932457  9916 solver.cpp:571] Iteration 79980, lr = 0.0001
speed: 0.122s / iter
Wrote snapshot to: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000.caffemodel
done solving
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Stage 2 RPN, generate proposals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RPN model: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000.caffemodel
Using config:
{'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_alt_opt',
 'GPU_ID': 0,
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/bsl/py-faster-rcnn-master',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 2000,
          'RPN_PRE_NMS_TOP_N': -1,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'selective_search',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': 'stage2',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for proposal generation
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1018 08:40:52.470888 11016 net.cpp:50] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
input: "data"
input: "im_info"
state {
  phase: TEST
}
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}
input_shape {
  dim: 1
  dim: 3
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rois"
  top: "scores"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16"
  }
}
I1018 08:40:52.470971 11016 net.cpp:435] Input 0 -> data
I1018 08:40:52.470983 11016 net.cpp:435] Input 1 -> im_info
I1018 08:40:52.470990 11016 layer_factory.hpp:76] Creating layer conv1_1
I1018 08:40:52.470999 11016 net.cpp:110] Creating Layer conv1_1
I1018 08:40:52.471002 11016 net.cpp:477] conv1_1 <- data
I1018 08:40:52.471005 11016 net.cpp:433] conv1_1 -> conv1_1
I1018 08:40:52.475594 11016 net.cpp:155] Setting up conv1_1
I1018 08:40:52.475610 11016 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 08:40:52.475620 11016 layer_factory.hpp:76] Creating layer relu1_1
I1018 08:40:52.475625 11016 net.cpp:110] Creating Layer relu1_1
I1018 08:40:52.475627 11016 net.cpp:477] relu1_1 <- conv1_1
I1018 08:40:52.475630 11016 net.cpp:419] relu1_1 -> conv1_1 (in-place)
I1018 08:40:52.475638 11016 net.cpp:155] Setting up relu1_1
I1018 08:40:52.475641 11016 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 08:40:52.475642 11016 layer_factory.hpp:76] Creating layer conv1_2
I1018 08:40:52.475647 11016 net.cpp:110] Creating Layer conv1_2
I1018 08:40:52.475649 11016 net.cpp:477] conv1_2 <- conv1_1
I1018 08:40:52.475652 11016 net.cpp:433] conv1_2 -> conv1_2
I1018 08:40:52.475708 11016 net.cpp:155] Setting up conv1_2
I1018 08:40:52.475713 11016 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 08:40:52.475718 11016 layer_factory.hpp:76] Creating layer relu1_2
I1018 08:40:52.475721 11016 net.cpp:110] Creating Layer relu1_2
I1018 08:40:52.475723 11016 net.cpp:477] relu1_2 <- conv1_2
I1018 08:40:52.475726 11016 net.cpp:419] relu1_2 -> conv1_2 (in-place)
I1018 08:40:52.475729 11016 net.cpp:155] Setting up relu1_2
I1018 08:40:52.475731 11016 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 08:40:52.475733 11016 layer_factory.hpp:76] Creating layer pool1
I1018 08:40:52.475739 11016 net.cpp:110] Creating Layer pool1
I1018 08:40:52.475739 11016 net.cpp:477] pool1 <- conv1_2
I1018 08:40:52.475742 11016 net.cpp:433] pool1 -> pool1
I1018 08:40:52.475749 11016 net.cpp:155] Setting up pool1
I1018 08:40:52.475750 11016 net.cpp:163] Top shape: 1 64 112 112 (802816)
I1018 08:40:52.475752 11016 layer_factory.hpp:76] Creating layer conv2_1
I1018 08:40:52.475757 11016 net.cpp:110] Creating Layer conv2_1
I1018 08:40:52.475759 11016 net.cpp:477] conv2_1 <- pool1
I1018 08:40:52.475762 11016 net.cpp:433] conv2_1 -> conv2_1
I1018 08:40:52.476265 11016 net.cpp:155] Setting up conv2_1
I1018 08:40:52.476272 11016 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 08:40:52.476279 11016 layer_factory.hpp:76] Creating layer relu2_1
I1018 08:40:52.476282 11016 net.cpp:110] Creating Layer relu2_1
I1018 08:40:52.476284 11016 net.cpp:477] relu2_1 <- conv2_1
I1018 08:40:52.476287 11016 net.cpp:419] relu2_1 -> conv2_1 (in-place)
I1018 08:40:52.476291 11016 net.cpp:155] Setting up relu2_1
I1018 08:40:52.476294 11016 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 08:40:52.476295 11016 layer_factory.hpp:76] Creating layer conv2_2
I1018 08:40:52.476299 11016 net.cpp:110] Creating Layer conv2_2
I1018 08:40:52.476300 11016 net.cpp:477] conv2_2 <- conv2_1
I1018 08:40:52.476303 11016 net.cpp:433] conv2_2 -> conv2_2
I1018 08:40:52.476387 11016 net.cpp:155] Setting up conv2_2
I1018 08:40:52.476392 11016 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 08:40:52.476395 11016 layer_factory.hpp:76] Creating layer relu2_2
I1018 08:40:52.476398 11016 net.cpp:110] Creating Layer relu2_2
I1018 08:40:52.476400 11016 net.cpp:477] relu2_2 <- conv2_2
I1018 08:40:52.476403 11016 net.cpp:419] relu2_2 -> conv2_2 (in-place)
I1018 08:40:52.476407 11016 net.cpp:155] Setting up relu2_2
I1018 08:40:52.476408 11016 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 08:40:52.476410 11016 layer_factory.hpp:76] Creating layer pool2
I1018 08:40:52.476413 11016 net.cpp:110] Creating Layer pool2
I1018 08:40:52.476415 11016 net.cpp:477] pool2 <- conv2_2
I1018 08:40:52.476418 11016 net.cpp:433] pool2 -> pool2
I1018 08:40:52.476423 11016 net.cpp:155] Setting up pool2
I1018 08:40:52.476424 11016 net.cpp:163] Top shape: 1 128 56 56 (401408)
I1018 08:40:52.476426 11016 layer_factory.hpp:76] Creating layer conv3_1
I1018 08:40:52.476430 11016 net.cpp:110] Creating Layer conv3_1
I1018 08:40:52.476433 11016 net.cpp:477] conv3_1 <- pool2
I1018 08:40:52.476434 11016 net.cpp:433] conv3_1 -> conv3_1
I1018 08:40:52.476826 11016 net.cpp:155] Setting up conv3_1
I1018 08:40:52.476833 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.476838 11016 layer_factory.hpp:76] Creating layer relu3_1
I1018 08:40:52.476842 11016 net.cpp:110] Creating Layer relu3_1
I1018 08:40:52.476845 11016 net.cpp:477] relu3_1 <- conv3_1
I1018 08:40:52.476847 11016 net.cpp:419] relu3_1 -> conv3_1 (in-place)
I1018 08:40:52.476851 11016 net.cpp:155] Setting up relu3_1
I1018 08:40:52.476853 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.476855 11016 layer_factory.hpp:76] Creating layer conv3_2
I1018 08:40:52.476858 11016 net.cpp:110] Creating Layer conv3_2
I1018 08:40:52.476861 11016 net.cpp:477] conv3_2 <- conv3_1
I1018 08:40:52.476863 11016 net.cpp:433] conv3_2 -> conv3_2
I1018 08:40:52.477538 11016 net.cpp:155] Setting up conv3_2
I1018 08:40:52.477545 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.477550 11016 layer_factory.hpp:76] Creating layer relu3_2
I1018 08:40:52.477553 11016 net.cpp:110] Creating Layer relu3_2
I1018 08:40:52.477555 11016 net.cpp:477] relu3_2 <- conv3_2
I1018 08:40:52.477558 11016 net.cpp:419] relu3_2 -> conv3_2 (in-place)
I1018 08:40:52.477561 11016 net.cpp:155] Setting up relu3_2
I1018 08:40:52.477565 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.477566 11016 layer_factory.hpp:76] Creating layer conv3_3
I1018 08:40:52.477569 11016 net.cpp:110] Creating Layer conv3_3
I1018 08:40:52.477571 11016 net.cpp:477] conv3_3 <- conv3_2
I1018 08:40:52.477574 11016 net.cpp:433] conv3_3 -> conv3_3
I1018 08:40:52.478255 11016 net.cpp:155] Setting up conv3_3
I1018 08:40:52.478261 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.478266 11016 layer_factory.hpp:76] Creating layer relu3_3
I1018 08:40:52.478269 11016 net.cpp:110] Creating Layer relu3_3
I1018 08:40:52.478271 11016 net.cpp:477] relu3_3 <- conv3_3
I1018 08:40:52.478274 11016 net.cpp:419] relu3_3 -> conv3_3 (in-place)
I1018 08:40:52.478277 11016 net.cpp:155] Setting up relu3_3
I1018 08:40:52.478279 11016 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 08:40:52.478281 11016 layer_factory.hpp:76] Creating layer pool3
I1018 08:40:52.478287 11016 net.cpp:110] Creating Layer pool3
I1018 08:40:52.478289 11016 net.cpp:477] pool3 <- conv3_3
I1018 08:40:52.478292 11016 net.cpp:433] pool3 -> pool3
I1018 08:40:52.478296 11016 net.cpp:155] Setting up pool3
I1018 08:40:52.478299 11016 net.cpp:163] Top shape: 1 256 28 28 (200704)
I1018 08:40:52.478302 11016 layer_factory.hpp:76] Creating layer conv4_1
I1018 08:40:52.478304 11016 net.cpp:110] Creating Layer conv4_1
I1018 08:40:52.478305 11016 net.cpp:477] conv4_1 <- pool3
I1018 08:40:52.478308 11016 net.cpp:433] conv4_1 -> conv4_1
I1018 08:40:52.479915 11016 net.cpp:155] Setting up conv4_1
I1018 08:40:52.479933 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.479938 11016 layer_factory.hpp:76] Creating layer relu4_1
I1018 08:40:52.479943 11016 net.cpp:110] Creating Layer relu4_1
I1018 08:40:52.479946 11016 net.cpp:477] relu4_1 <- conv4_1
I1018 08:40:52.479949 11016 net.cpp:419] relu4_1 -> conv4_1 (in-place)
I1018 08:40:52.479954 11016 net.cpp:155] Setting up relu4_1
I1018 08:40:52.479956 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.479959 11016 layer_factory.hpp:76] Creating layer conv4_2
I1018 08:40:52.479964 11016 net.cpp:110] Creating Layer conv4_2
I1018 08:40:52.479965 11016 net.cpp:477] conv4_2 <- conv4_1
I1018 08:40:52.479969 11016 net.cpp:433] conv4_2 -> conv4_2
I1018 08:40:52.482990 11016 net.cpp:155] Setting up conv4_2
I1018 08:40:52.483011 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.483022 11016 layer_factory.hpp:76] Creating layer relu4_2
I1018 08:40:52.483029 11016 net.cpp:110] Creating Layer relu4_2
I1018 08:40:52.483032 11016 net.cpp:477] relu4_2 <- conv4_2
I1018 08:40:52.483036 11016 net.cpp:419] relu4_2 -> conv4_2 (in-place)
I1018 08:40:52.483042 11016 net.cpp:155] Setting up relu4_2
I1018 08:40:52.483044 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.483047 11016 layer_factory.hpp:76] Creating layer conv4_3
I1018 08:40:52.483050 11016 net.cpp:110] Creating Layer conv4_3
I1018 08:40:52.483052 11016 net.cpp:477] conv4_3 <- conv4_2
I1018 08:40:52.483055 11016 net.cpp:433] conv4_3 -> conv4_3
I1018 08:40:52.486069 11016 net.cpp:155] Setting up conv4_3
I1018 08:40:52.486090 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.486098 11016 layer_factory.hpp:76] Creating layer relu4_3
I1018 08:40:52.486104 11016 net.cpp:110] Creating Layer relu4_3
I1018 08:40:52.486107 11016 net.cpp:477] relu4_3 <- conv4_3
I1018 08:40:52.486110 11016 net.cpp:419] relu4_3 -> conv4_3 (in-place)
I1018 08:40:52.486115 11016 net.cpp:155] Setting up relu4_3
I1018 08:40:52.486119 11016 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 08:40:52.486120 11016 layer_factory.hpp:76] Creating layer pool4
I1018 08:40:52.486124 11016 net.cpp:110] Creating Layer pool4
I1018 08:40:52.486125 11016 net.cpp:477] pool4 <- conv4_3
I1018 08:40:52.486129 11016 net.cpp:433] pool4 -> pool4
I1018 08:40:52.486135 11016 net.cpp:155] Setting up pool4
I1018 08:40:52.486137 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.486140 11016 layer_factory.hpp:76] Creating layer conv5_1
I1018 08:40:52.486143 11016 net.cpp:110] Creating Layer conv5_1
I1018 08:40:52.486145 11016 net.cpp:477] conv5_1 <- pool4
I1018 08:40:52.486150 11016 net.cpp:433] conv5_1 -> conv5_1
I1018 08:40:52.489246 11016 net.cpp:155] Setting up conv5_1
I1018 08:40:52.489267 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.489274 11016 layer_factory.hpp:76] Creating layer relu5_1
I1018 08:40:52.489281 11016 net.cpp:110] Creating Layer relu5_1
I1018 08:40:52.489284 11016 net.cpp:477] relu5_1 <- conv5_1
I1018 08:40:52.489287 11016 net.cpp:419] relu5_1 -> conv5_1 (in-place)
I1018 08:40:52.489292 11016 net.cpp:155] Setting up relu5_1
I1018 08:40:52.489295 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.489297 11016 layer_factory.hpp:76] Creating layer conv5_2
I1018 08:40:52.489301 11016 net.cpp:110] Creating Layer conv5_2
I1018 08:40:52.489303 11016 net.cpp:477] conv5_2 <- conv5_1
I1018 08:40:52.489306 11016 net.cpp:433] conv5_2 -> conv5_2
I1018 08:40:52.492336 11016 net.cpp:155] Setting up conv5_2
I1018 08:40:52.492359 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.492367 11016 layer_factory.hpp:76] Creating layer relu5_2
I1018 08:40:52.492372 11016 net.cpp:110] Creating Layer relu5_2
I1018 08:40:52.492375 11016 net.cpp:477] relu5_2 <- conv5_2
I1018 08:40:52.492379 11016 net.cpp:419] relu5_2 -> conv5_2 (in-place)
I1018 08:40:52.492385 11016 net.cpp:155] Setting up relu5_2
I1018 08:40:52.492388 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.492389 11016 layer_factory.hpp:76] Creating layer conv5_3
I1018 08:40:52.492393 11016 net.cpp:110] Creating Layer conv5_3
I1018 08:40:52.492395 11016 net.cpp:477] conv5_3 <- conv5_2
I1018 08:40:52.492399 11016 net.cpp:433] conv5_3 -> conv5_3
I1018 08:40:52.495596 11016 net.cpp:155] Setting up conv5_3
I1018 08:40:52.495621 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.495628 11016 layer_factory.hpp:76] Creating layer relu5_3
I1018 08:40:52.495635 11016 net.cpp:110] Creating Layer relu5_3
I1018 08:40:52.495638 11016 net.cpp:477] relu5_3 <- conv5_3
I1018 08:40:52.495642 11016 net.cpp:419] relu5_3 -> conv5_3 (in-place)
I1018 08:40:52.495647 11016 net.cpp:155] Setting up relu5_3
I1018 08:40:52.495651 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.495652 11016 layer_factory.hpp:76] Creating layer rpn_conv/3x3
I1018 08:40:52.495657 11016 net.cpp:110] Creating Layer rpn_conv/3x3
I1018 08:40:52.495659 11016 net.cpp:477] rpn_conv/3x3 <- conv5_3
I1018 08:40:52.495662 11016 net.cpp:433] rpn_conv/3x3 -> rpn/output
I1018 08:40:52.498674 11016 net.cpp:155] Setting up rpn_conv/3x3
I1018 08:40:52.498697 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.498704 11016 layer_factory.hpp:76] Creating layer rpn_relu/3x3
I1018 08:40:52.498711 11016 net.cpp:110] Creating Layer rpn_relu/3x3
I1018 08:40:52.498714 11016 net.cpp:477] rpn_relu/3x3 <- rpn/output
I1018 08:40:52.498718 11016 net.cpp:419] rpn_relu/3x3 -> rpn/output (in-place)
I1018 08:40:52.498724 11016 net.cpp:155] Setting up rpn_relu/3x3
I1018 08:40:52.498726 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.498728 11016 layer_factory.hpp:76] Creating layer rpn/output_rpn_relu/3x3_0_split
I1018 08:40:52.498741 11016 net.cpp:110] Creating Layer rpn/output_rpn_relu/3x3_0_split
I1018 08:40:52.498744 11016 net.cpp:477] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I1018 08:40:52.498745 11016 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I1018 08:40:52.498749 11016 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I1018 08:40:52.498764 11016 net.cpp:155] Setting up rpn/output_rpn_relu/3x3_0_split
I1018 08:40:52.498766 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.498769 11016 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 08:40:52.498771 11016 layer_factory.hpp:76] Creating layer rpn_cls_score
I1018 08:40:52.498775 11016 net.cpp:110] Creating Layer rpn_cls_score
I1018 08:40:52.498777 11016 net.cpp:477] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I1018 08:40:52.498781 11016 net.cpp:433] rpn_cls_score -> rpn_cls_score
I1018 08:40:52.498832 11016 net.cpp:155] Setting up rpn_cls_score
I1018 08:40:52.498836 11016 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1018 08:40:52.498839 11016 layer_factory.hpp:76] Creating layer rpn_bbox_pred
I1018 08:40:52.498842 11016 net.cpp:110] Creating Layer rpn_bbox_pred
I1018 08:40:52.498845 11016 net.cpp:477] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I1018 08:40:52.498847 11016 net.cpp:433] rpn_bbox_pred -> rpn_bbox_pred
I1018 08:40:52.498898 11016 net.cpp:155] Setting up rpn_bbox_pred
I1018 08:40:52.498913 11016 net.cpp:163] Top shape: 1 36 14 14 (7056)
I1018 08:40:52.498916 11016 layer_factory.hpp:76] Creating layer rpn_cls_score_reshape
I1018 08:40:52.498921 11016 net.cpp:110] Creating Layer rpn_cls_score_reshape
I1018 08:40:52.498924 11016 net.cpp:477] rpn_cls_score_reshape <- rpn_cls_score
I1018 08:40:52.498926 11016 net.cpp:433] rpn_cls_score_reshape -> rpn_cls_score_reshape
I1018 08:40:52.498932 11016 net.cpp:155] Setting up rpn_cls_score_reshape
I1018 08:40:52.498935 11016 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1018 08:40:52.498937 11016 layer_factory.hpp:76] Creating layer rpn_cls_prob
I1018 08:40:52.498941 11016 net.cpp:110] Creating Layer rpn_cls_prob
I1018 08:40:52.498944 11016 net.cpp:477] rpn_cls_prob <- rpn_cls_score_reshape
I1018 08:40:52.498946 11016 net.cpp:433] rpn_cls_prob -> rpn_cls_prob
I1018 08:40:52.498961 11016 net.cpp:155] Setting up rpn_cls_prob
I1018 08:40:52.498965 11016 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1018 08:40:52.498966 11016 layer_factory.hpp:76] Creating layer rpn_cls_prob_reshape
I1018 08:40:52.498970 11016 net.cpp:110] Creating Layer rpn_cls_prob_reshape
I1018 08:40:52.498971 11016 net.cpp:477] rpn_cls_prob_reshape <- rpn_cls_prob
I1018 08:40:52.498975 11016 net.cpp:433] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I1018 08:40:52.498978 11016 net.cpp:155] Setting up rpn_cls_prob_reshape
I1018 08:40:52.498981 11016 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1018 08:40:52.498983 11016 layer_factory.hpp:76] Creating layer proposal
I1018 08:40:52.499824 11016 net.cpp:110] Creating Layer proposal
I1018 08:40:52.499831 11016 net.cpp:477] proposal <- rpn_cls_prob_reshape
I1018 08:40:52.499835 11016 net.cpp:477] proposal <- rpn_bbox_pred
I1018 08:40:52.499837 11016 net.cpp:477] proposal <- im_info
I1018 08:40:52.499841 11016 net.cpp:433] proposal -> rois
I1018 08:40:52.499845 11016 net.cpp:433] proposal -> scores
I1018 08:40:52.500407 11016 net.cpp:155] Setting up proposal
I1018 08:40:52.500416 11016 net.cpp:163] Top shape: 1 5 (5)
I1018 08:40:52.500418 11016 net.cpp:163] Top shape: 1 1 1 1 (1)
I1018 08:40:52.500421 11016 net.cpp:240] proposal does not need backward computation.
I1018 08:40:52.500423 11016 net.cpp:240] rpn_cls_prob_reshape does not need backward computation.
I1018 08:40:52.500425 11016 net.cpp:240] rpn_cls_prob does not need backward computation.
I1018 08:40:52.500427 11016 net.cpp:240] rpn_cls_score_reshape does not need backward computation.
I1018 08:40:52.500429 11016 net.cpp:240] rpn_bbox_pred does not need backward computation.
I1018 08:40:52.500432 11016 net.cpp:240] rpn_cls_score does not need backward computation.
I1018 08:40:52.500433 11016 net.cpp:240] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I1018 08:40:52.500435 11016 net.cpp:240] rpn_relu/3x3 does not need backward computation.
I1018 08:40:52.500437 11016 net.cpp:240] rpn_conv/3x3 does not need backward computation.
I1018 08:40:52.500439 11016 net.cpp:240] relu5_3 does not need backward computation.
I1018 08:40:52.500442 11016 net.cpp:240] conv5_3 does not need backward computation.
I1018 08:40:52.500444 11016 net.cpp:240] relu5_2 does not need backward computation.
I1018 08:40:52.500447 11016 net.cpp:240] conv5_2 does not need backward computation.
I1018 08:40:52.500448 11016 net.cpp:240] relu5_1 does not need backward computation.
I1018 08:40:52.500450 11016 net.cpp:240] conv5_1 does not need backward computation.
I1018 08:40:52.500452 11016 net.cpp:240] pool4 does not need backward computation.
I1018 08:40:52.500454 11016 net.cpp:240] relu4_3 does not need backward computation.
I1018 08:40:52.500457 11016 net.cpp:240] conv4_3 does not need backward computation.
I1018 08:40:52.500458 11016 net.cpp:240] relu4_2 does not need backward computation.
I1018 08:40:52.500460 11016 net.cpp:240] conv4_2 does not need backward computation.
I1018 08:40:52.500463 11016 net.cpp:240] relu4_1 does not need backward computation.
I1018 08:40:52.500464 11016 net.cpp:240] conv4_1 does not need backward computation.
I1018 08:40:52.500466 11016 net.cpp:240] pool3 does not need backward computation.
I1018 08:40:52.500468 11016 net.cpp:240] relu3_3 does not need backward computation.
I1018 08:40:52.500470 11016 net.cpp:240] conv3_3 does not need backward computation.
I1018 08:40:52.500473 11016 net.cpp:240] relu3_2 does not need backward computation.
I1018 08:40:52.500474 11016 net.cpp:240] conv3_2 does not need backward computation.
I1018 08:40:52.500476 11016 net.cpp:240] relu3_1 does not need backward computation.
I1018 08:40:52.500478 11016 net.cpp:240] conv3_1 does not need backward computation.
I1018 08:40:52.500481 11016 net.cpp:240] pool2 does not need backward computation.
I1018 08:40:52.500483 11016 net.cpp:240] relu2_2 does not need backward computation.
I1018 08:40:52.500484 11016 net.cpp:240] conv2_2 does not need backward computation.
I1018 08:40:52.500488 11016 net.cpp:240] relu2_1 does not need backward computation.
I1018 08:40:52.500489 11016 net.cpp:240] conv2_1 does not need backward computation.
I1018 08:40:52.500491 11016 net.cpp:240] pool1 does not need backward computation.
I1018 08:40:52.500494 11016 net.cpp:240] relu1_2 does not need backward computation.
I1018 08:40:52.500495 11016 net.cpp:240] conv1_2 does not need backward computation.
I1018 08:40:52.500497 11016 net.cpp:240] relu1_1 does not need backward computation.
I1018 08:40:52.500499 11016 net.cpp:240] conv1_1 does not need backward computation.
I1018 08:40:52.500501 11016 net.cpp:283] This network produces output rois
I1018 08:40:52.500504 11016 net.cpp:283] This network produces output scores
I1018 08:40:52.500517 11016 net.cpp:297] Network initialization done.
I1018 08:40:52.500519 11016 net.cpp:298] Memory required for data: 116091608
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 546596435
Output will be saved to `/home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval`
im_proposals: 1/5011 0.151s
im_proposals: 2/5011 0.155s
im_proposals: 3/5011 0.141s
im_proposals: 4/5011 0.138s
im_proposals: 5/5011 0.136s
im_proposals: 6/5011 0.132s
im_proposals: 7/5011 0.129s
im_proposals: 8/5011 0.128s
im_proposals: 9/5011 0.128s
im_proposals: 10/5011 0.128s
im_proposals: 11/5011 0.128s
im_proposals: 12/5011 0.128s
im_proposals: 13/5011 0.127s
im_proposals: 14/5011 0.129s
im_proposals: 15/5011 0.129s
im_proposals: 16/5011 0.128s
im_proposals: 17/5011 0.127s
im_proposals: 18/5011 0.127s
im_proposals: 19/5011 0.127s
im_proposals: 20/5011 0.127s
im_proposals: 21/5011 0.127s
im_proposals: 22/5011 0.127s
im_proposals: 23/5011 0.127s
im_proposals: 24/5011 0.127s
im_proposals: 25/5011 0.127s
im_proposals: 26/5011 0.127s
im_proposals: 27/5011 0.126s
im_proposals: 28/5011 0.127s
im_proposals: 29/5011 0.127s
im_proposals: 30/5011 0.127s
im_proposals: 31/5011 0.127s
im_proposals: 32/5011 0.125s
im_proposals: 33/5011 0.126s
im_proposals: 34/5011 0.125s
im_proposals: 35/5011 0.126s
im_proposals: 36/5011 0.125s
im_proposals: 37/5011 0.126s
im_proposals: 38/5011 0.125s
im_proposals: 39/5011 0.125s
im_proposals: 40/5011 0.126s
im_proposals: 41/5011 0.126s
im_proposals: 42/5011 0.125s
im_proposals: 43/5011 0.126s
im_proposals: 44/5011 0.126s
im_proposals: 45/5011 0.126s
im_proposals: 46/5011 0.126s
im_proposals: 47/5011 0.126s
im_proposals: 48/5011 0.126s
im_proposals: 49/5011 0.126s
im_proposals: 50/5011 0.126s
im_proposals: 51/5011 0.126s
im_proposals: 52/5011 0.126s
im_proposals: 53/5011 0.126s
im_proposals: 54/5011 0.126s
im_proposals: 55/5011 0.126s
im_proposals: 56/5011 0.126s
im_proposals: 57/5011 0.126s
im_proposals: 58/5011 0.125s
im_proposals: 59/5011 0.125s
im_proposals: 60/5011 0.125s
im_proposals: 61/5011 0.125s
im_proposals: 62/5011 0.125s
im_proposals: 63/5011 0.125s
im_proposals: 64/5011 0.125s
im_proposals: 65/5011 0.125s
im_proposals: 66/5011 0.125s
im_proposals: 67/5011 0.125s
im_proposals: 68/5011 0.125s
im_proposals: 69/5011 0.124s
im_proposals: 70/5011 0.124s
im_proposals: 71/5011 0.124s
im_proposals: 72/5011 0.124s
im_proposals: 73/5011 0.124s
im_proposals: 74/5011 0.125s
im_proposals: 75/5011 0.125s
im_proposals: 76/5011 0.125s
im_proposals: 77/5011 0.125s
im_proposals: 78/5011 0.125s
im_proposals: 79/5011 0.125s
im_proposals: 80/5011 0.125s
im_proposals: 81/5011 0.125s
im_proposals: 82/5011 0.124s
im_proposals: 83/5011 0.124s
im_proposals: 84/5011 0.124s
im_proposals: 85/5011 0.124s
im_proposals: 86/5011 0.124s
im_proposals: 87/5011 0.124s
im_proposals: 88/5011 0.124s
im_proposals: 89/5011 0.124s
im_proposals: 90/5011 0.124s
im_proposals: 91/5011 0.124s
im_proposals: 92/5011 0.124s
im_proposals: 93/5011 0.124s
im_proposals: 94/5011 0.124s
im_proposals: 95/5011 0.124s
im_proposals: 96/5011 0.124s
im_proposals: 97/5011 0.124s
im_proposals: 98/5011 0.124s
im_proposals: 99/5011 0.124s
im_proposals: 100/5011 0.124s
im_proposals: 101/5011 0.124s
im_proposals: 102/5011 0.124s
im_proposals: 103/5011 0.124s
im_proposals: 104/5011 0.124s
im_proposals: 105/5011 0.124s
im_proposals: 106/5011 0.124s
im_proposals: 107/5011 0.124s
im_proposals: 108/5011 0.124s
im_proposals: 109/5011 0.124s
im_proposals: 110/5011 0.124s
im_proposals: 111/5011 0.124s
im_proposals: 112/5011 0.124s
im_proposals: 113/5011 0.124s
im_proposals: 114/5011 0.124s
im_proposals: 115/5011 0.124s
im_proposals: 116/5011 0.124s
im_proposals: 117/5011 0.124s
im_proposals: 118/5011 0.124s
im_proposals: 119/5011 0.124s
im_proposals: 120/5011 0.124s
im_proposals: 121/5011 0.124s
im_proposals: 122/5011 0.124s
im_proposals: 123/5011 0.124s
im_proposals: 124/5011 0.124s
im_proposals: 125/5011 0.124s
im_proposals: 126/5011 0.124s
im_proposals: 127/5011 0.124s
im_proposals: 128/5011 0.124s
im_proposals: 129/5011 0.124s
im_proposals: 130/5011 0.124s
im_proposals: 131/5011 0.124s
im_proposals: 132/5011 0.124s
im_proposals: 133/5011 0.124s
im_proposals: 134/5011 0.124s
im_proposals: 135/5011 0.124s
im_proposals: 136/5011 0.124s
im_proposals: 137/5011 0.124s
im_proposals: 138/5011 0.124s
im_proposals: 139/5011 0.124s
im_proposals: 140/5011 0.124s
im_proposals: 141/5011 0.124s
im_proposals: 142/5011 0.124s
im_proposals: 143/5011 0.124s
im_proposals: 144/5011 0.124s
im_proposals: 145/5011 0.124s
im_proposals: 146/5011 0.124s
im_proposals: 147/5011 0.124s
im_proposals: 148/5011 0.124s
im_proposals: 149/5011 0.124s
im_proposals: 150/5011 0.124s
im_proposals: 151/5011 0.124s
im_proposals: 152/5011 0.124s
im_proposals: 153/5011 0.124s
im_proposals: 154/5011 0.124s
im_proposals: 155/5011 0.124s
im_proposals: 156/5011 0.124s
im_proposals: 157/5011 0.124s
im_proposals: 158/5011 0.124s
im_proposals: 159/5011 0.124s
im_proposals: 160/5011 0.124s
im_proposals: 161/5011 0.124s
im_proposals: 162/5011 0.124s
im_proposals: 163/5011 0.124s
im_proposals: 164/5011 0.124s
im_proposals: 165/5011 0.124s
im_proposals: 166/5011 0.124s
im_proposals: 167/5011 0.124s
im_proposals: 168/5011 0.125s
im_proposals: 169/5011 0.125s
im_proposals: 170/5011 0.125s
im_proposals: 171/5011 0.125s
im_proposals: 172/5011 0.125s
im_proposals: 173/5011 0.125s
im_proposals: 174/5011 0.125s
im_proposals: 175/5011 0.125s
im_proposals: 176/5011 0.125s
im_proposals: 177/5011 0.125s
im_proposals: 178/5011 0.125s
im_proposals: 179/5011 0.125s
im_proposals: 180/5011 0.125s
im_proposals: 181/5011 0.125s
im_proposals: 182/5011 0.125s
im_proposals: 183/5011 0.125s
im_proposals: 184/5011 0.125s
im_proposals: 185/5011 0.125s
im_proposals: 186/5011 0.125s
im_proposals: 187/5011 0.125s
im_proposals: 188/5011 0.125s
im_proposals: 189/5011 0.125s
im_proposals: 190/5011 0.125s
im_proposals: 191/5011 0.125s
im_proposals: 192/5011 0.125s
im_proposals: 193/5011 0.125s
im_proposals: 194/5011 0.125s
im_proposals: 195/5011 0.125s
im_proposals: 196/5011 0.125s
im_proposals: 197/5011 0.125s
im_proposals: 198/5011 0.125s
im_proposals: 199/5011 0.125s
im_proposals: 200/5011 0.125s
im_proposals: 201/5011 0.125s
im_proposals: 202/5011 0.125s
im_proposals: 203/5011 0.125s
im_proposals: 204/5011 0.125s
im_proposals: 205/5011 0.125s
im_proposals: 206/5011 0.125s
im_proposals: 207/5011 0.125s
im_proposals: 208/5011 0.125s
im_proposals: 209/5011 0.125s
im_proposals: 210/5011 0.125s
im_proposals: 211/5011 0.125s
im_proposals: 212/5011 0.125s
im_proposals: 213/5011 0.125s
im_proposals: 214/5011 0.125s
im_proposals: 215/5011 0.125s
im_proposals: 216/5011 0.125s
im_proposals: 217/5011 0.125s
im_proposals: 218/5011 0.125s
im_proposals: 219/5011 0.125s
im_proposals: 220/5011 0.125s
im_proposals: 221/5011 0.125s
im_proposals: 222/5011 0.125s
im_proposals: 223/5011 0.125s
im_proposals: 224/5011 0.125s
im_proposals: 225/5011 0.125s
im_proposals: 226/5011 0.125s
im_proposals: 227/5011 0.125s
im_proposals: 228/5011 0.125s
im_proposals: 229/5011 0.125s
im_proposals: 230/5011 0.125s
im_proposals: 231/5011 0.125s
im_proposals: 232/5011 0.125s
im_proposals: 233/5011 0.125s
im_proposals: 234/5011 0.125s
im_proposals: 235/5011 0.125s
im_proposals: 236/5011 0.125s
im_proposals: 237/5011 0.125s
im_proposals: 238/5011 0.125s
im_proposals: 239/5011 0.125s
im_proposals: 240/5011 0.125s
im_proposals: 241/5011 0.125s
im_proposals: 242/5011 0.125s
im_proposals: 243/5011 0.125s
im_proposals: 244/5011 0.125s
im_proposals: 245/5011 0.125s
im_proposals: 246/5011 0.125s
im_proposals: 247/5011 0.125s
im_proposals: 248/5011 0.125s
im_proposals: 249/5011 0.125s
im_proposals: 250/5011 0.125s
im_proposals: 251/5011 0.125s
im_proposals: 252/5011 0.125s
im_proposals: 253/5011 0.125s
im_proposals: 254/5011 0.125s
im_proposals: 255/5011 0.125s
im_proposals: 256/5011 0.125s
im_proposals: 257/5011 0.125s
im_proposals: 258/5011 0.125s
im_proposals: 259/5011 0.125s
im_proposals: 260/5011 0.125s
im_proposals: 261/5011 0.125s
im_proposals: 262/5011 0.125s
im_proposals: 263/5011 0.125s
im_proposals: 264/5011 0.125s
im_proposals: 265/5011 0.125s
im_proposals: 266/5011 0.125s
im_proposals: 267/5011 0.125s
im_proposals: 268/5011 0.125s
im_proposals: 269/5011 0.125s
im_proposals: 270/5011 0.125s
im_proposals: 271/5011 0.125s
im_proposals: 272/5011 0.125s
im_proposals: 273/5011 0.125s
im_proposals: 274/5011 0.125s
im_proposals: 275/5011 0.125s
im_proposals: 276/5011 0.125s
im_proposals: 277/5011 0.125s
im_proposals: 278/5011 0.125s
im_proposals: 279/5011 0.125s
im_proposals: 280/5011 0.125s
im_proposals: 281/5011 0.125s
im_proposals: 282/5011 0.125s
im_proposals: 283/5011 0.125s
im_proposals: 284/5011 0.125s
im_proposals: 285/5011 0.125s
im_proposals: 286/5011 0.125s
im_proposals: 287/5011 0.125s
im_proposals: 288/5011 0.125s
im_proposals: 289/5011 0.125s
im_proposals: 290/5011 0.125s
im_proposals: 291/5011 0.125s
im_proposals: 292/5011 0.125s
im_proposals: 293/5011 0.125s
im_proposals: 294/5011 0.125s
im_proposals: 295/5011 0.125s
im_proposals: 296/5011 0.125s
im_proposals: 297/5011 0.125s
im_proposals: 298/5011 0.125s
im_proposals: 299/5011 0.125s
im_proposals: 300/5011 0.125s
im_proposals: 301/5011 0.125s
im_proposals: 302/5011 0.125s
im_proposals: 303/5011 0.125s
im_proposals: 304/5011 0.125s
im_proposals: 305/5011 0.125s
im_proposals: 306/5011 0.125s
im_proposals: 307/5011 0.125s
im_proposals: 308/5011 0.125s
im_proposals: 309/5011 0.125s
im_proposals: 310/5011 0.125s
im_proposals: 311/5011 0.125s
im_proposals: 312/5011 0.125s
im_proposals: 313/5011 0.125s
im_proposals: 314/5011 0.125s
im_proposals: 315/5011 0.125s
im_proposals: 316/5011 0.125s
im_proposals: 317/5011 0.125s
im_proposals: 318/5011 0.125s
im_proposals: 319/5011 0.125s
im_proposals: 320/5011 0.125s
im_proposals: 321/5011 0.125s
im_proposals: 322/5011 0.125s
im_proposals: 323/5011 0.125s
im_proposals: 324/5011 0.125s
im_proposals: 325/5011 0.125s
im_proposals: 326/5011 0.125s
im_proposals: 327/5011 0.125s
im_proposals: 328/5011 0.125s
im_proposals: 329/5011 0.125s
im_proposals: 330/5011 0.125s
im_proposals: 331/5011 0.125s
im_proposals: 332/5011 0.125s
im_proposals: 333/5011 0.125s
im_proposals: 334/5011 0.125s
im_proposals: 335/5011 0.125s
im_proposals: 336/5011 0.125s
im_proposals: 337/5011 0.125s
im_proposals: 338/5011 0.125s
im_proposals: 339/5011 0.125s
im_proposals: 340/5011 0.125s
im_proposals: 341/5011 0.125s
im_proposals: 342/5011 0.125s
im_proposals: 343/5011 0.125s
im_proposals: 344/5011 0.125s
im_proposals: 345/5011 0.125s
im_proposals: 346/5011 0.125s
im_proposals: 347/5011 0.125s
im_proposals: 348/5011 0.125s
im_proposals: 349/5011 0.125s
im_proposals: 350/5011 0.125s
im_proposals: 351/5011 0.125s
im_proposals: 352/5011 0.126s
im_proposals: 353/5011 0.126s
im_proposals: 354/5011 0.126s
im_proposals: 355/5011 0.126s
im_proposals: 356/5011 0.125s
im_proposals: 357/5011 0.126s
im_proposals: 358/5011 0.126s
im_proposals: 359/5011 0.125s
im_proposals: 360/5011 0.126s
im_proposals: 361/5011 0.126s
im_proposals: 362/5011 0.126s
im_proposals: 363/5011 0.126s
im_proposals: 364/5011 0.126s
im_proposals: 365/5011 0.126s
im_proposals: 366/5011 0.126s
im_proposals: 367/5011 0.126s
im_proposals: 368/5011 0.126s
im_proposals: 369/5011 0.126s
im_proposals: 370/5011 0.126s
im_proposals: 371/5011 0.126s
im_proposals: 372/5011 0.126s
im_proposals: 373/5011 0.126s
im_proposals: 374/5011 0.126s
im_proposals: 375/5011 0.126s
im_proposals: 376/5011 0.126s
im_proposals: 377/5011 0.126s
im_proposals: 378/5011 0.126s
im_proposals: 379/5011 0.126s
im_proposals: 380/5011 0.126s
im_proposals: 381/5011 0.126s
im_proposals: 382/5011 0.126s
im_proposals: 383/5011 0.126s
im_proposals: 384/5011 0.126s
im_proposals: 385/5011 0.126s
im_proposals: 386/5011 0.126s
im_proposals: 387/5011 0.126s
im_proposals: 388/5011 0.126s
im_proposals: 389/5011 0.126s
im_proposals: 390/5011 0.126s
im_proposals: 391/5011 0.126s
im_proposals: 392/5011 0.126s
im_proposals: 393/5011 0.126s
im_proposals: 394/5011 0.126s
im_proposals: 395/5011 0.126s
im_proposals: 396/5011 0.126s
im_proposals: 397/5011 0.126s
im_proposals: 398/5011 0.126s
im_proposals: 399/5011 0.126s
im_proposals: 400/5011 0.126s
im_proposals: 401/5011 0.126s
im_proposals: 402/5011 0.126s
im_proposals: 403/5011 0.126s
im_proposals: 404/5011 0.126s
im_proposals: 405/5011 0.126s
im_proposals: 406/5011 0.126s
im_proposals: 407/5011 0.126s
im_proposals: 408/5011 0.126s
im_proposals: 409/5011 0.126s
im_proposals: 410/5011 0.126s
im_proposals: 411/5011 0.126s
im_proposals: 412/5011 0.126s
im_proposals: 413/5011 0.126s
im_proposals: 414/5011 0.126s
im_proposals: 415/5011 0.126s
im_proposals: 416/5011 0.126s
im_proposals: 417/5011 0.126s
im_proposals: 418/5011 0.126s
im_proposals: 419/5011 0.126s
im_proposals: 420/5011 0.126s
im_proposals: 421/5011 0.126s
im_proposals: 422/5011 0.126s
im_proposals: 423/5011 0.126s
im_proposals: 424/5011 0.126s
im_proposals: 425/5011 0.126s
im_proposals: 426/5011 0.126s
im_proposals: 427/5011 0.126s
im_proposals: 428/5011 0.126s
im_proposals: 429/5011 0.126s
im_proposals: 430/5011 0.126s
im_proposals: 431/5011 0.126s
im_proposals: 432/5011 0.126s
im_proposals: 433/5011 0.126s
im_proposals: 434/5011 0.126s
im_proposals: 435/5011 0.126s
im_proposals: 436/5011 0.126s
im_proposals: 437/5011 0.126s
im_proposals: 438/5011 0.126s
im_proposals: 439/5011 0.126s
im_proposals: 440/5011 0.126s
im_proposals: 441/5011 0.126s
im_proposals: 442/5011 0.126s
im_proposals: 443/5011 0.126s
im_proposals: 444/5011 0.126s
im_proposals: 445/5011 0.126s
im_proposals: 446/5011 0.126s
im_proposals: 447/5011 0.126s
im_proposals: 448/5011 0.126s
im_proposals: 449/5011 0.126s
im_proposals: 450/5011 0.126s
im_proposals: 451/5011 0.126s
im_proposals: 452/5011 0.126s
im_proposals: 453/5011 0.126s
im_proposals: 454/5011 0.126s
im_proposals: 455/5011 0.126s
im_proposals: 456/5011 0.126s
im_proposals: 457/5011 0.126s
im_proposals: 458/5011 0.126s
im_proposals: 459/5011 0.126s
im_proposals: 460/5011 0.126s
im_proposals: 461/5011 0.126s
im_proposals: 462/5011 0.126s
im_proposals: 463/5011 0.126s
im_proposals: 464/5011 0.126s
im_proposals: 465/5011 0.126s
im_proposals: 466/5011 0.126s
im_proposals: 467/5011 0.126s
im_proposals: 468/5011 0.126s
im_proposals: 469/5011 0.126s
im_proposals: 470/5011 0.126s
im_proposals: 471/5011 0.126s
im_proposals: 472/5011 0.126s
im_proposals: 473/5011 0.126s
im_proposals: 474/5011 0.126s
im_proposals: 475/5011 0.126s
im_proposals: 476/5011 0.126s
im_proposals: 477/5011 0.126s
im_proposals: 478/5011 0.126s
im_proposals: 479/5011 0.126s
im_proposals: 480/5011 0.126s
im_proposals: 481/5011 0.126s
im_proposals: 482/5011 0.126s
im_proposals: 483/5011 0.126s
im_proposals: 484/5011 0.126s
im_proposals: 485/5011 0.126s
im_proposals: 486/5011 0.126s
im_proposals: 487/5011 0.126s
im_proposals: 488/5011 0.126s
im_proposals: 489/5011 0.126s
im_proposals: 490/5011 0.126s
im_proposals: 491/5011 0.126s
im_proposals: 492/5011 0.126s
im_proposals: 493/5011 0.126s
im_proposals: 494/5011 0.126s
im_proposals: 495/5011 0.126s
im_proposals: 496/5011 0.126s
im_proposals: 497/5011 0.126s
im_proposals: 498/5011 0.126s
im_proposals: 499/5011 0.126s
im_proposals: 500/5011 0.126s
im_proposals: 501/5011 0.126s
im_proposals: 502/5011 0.125s
im_proposals: 503/5011 0.125s
im_proposals: 504/5011 0.125s
im_proposals: 505/5011 0.126s
im_proposals: 506/5011 0.125s
im_proposals: 507/5011 0.126s
im_proposals: 508/5011 0.126s
im_proposals: 509/5011 0.126s
im_proposals: 510/5011 0.126s
im_proposals: 511/5011 0.126s
im_proposals: 512/5011 0.126s
im_proposals: 513/5011 0.125s
im_proposals: 514/5011 0.125s
im_proposals: 515/5011 0.125s
im_proposals: 516/5011 0.126s
im_proposals: 517/5011 0.125s
im_proposals: 518/5011 0.125s
im_proposals: 519/5011 0.125s
im_proposals: 520/5011 0.126s
im_proposals: 521/5011 0.126s
im_proposals: 522/5011 0.126s
im_proposals: 523/5011 0.126s
im_proposals: 524/5011 0.126s
im_proposals: 525/5011 0.126s
im_proposals: 526/5011 0.126s
im_proposals: 527/5011 0.126s
im_proposals: 528/5011 0.126s
im_proposals: 529/5011 0.126s
im_proposals: 530/5011 0.126s
im_proposals: 531/5011 0.126s
im_proposals: 532/5011 0.126s
im_proposals: 533/5011 0.126s
im_proposals: 534/5011 0.126s
im_proposals: 535/5011 0.126s
im_proposals: 536/5011 0.126s
im_proposals: 537/5011 0.126s
im_proposals: 538/5011 0.126s
im_proposals: 539/5011 0.126s
im_proposals: 540/5011 0.126s
im_proposals: 541/5011 0.126s
im_proposals: 542/5011 0.126s
im_proposals: 543/5011 0.126s
im_proposals: 544/5011 0.126s
im_proposals: 545/5011 0.126s
im_proposals: 546/5011 0.126s
im_proposals: 547/5011 0.126s
im_proposals: 548/5011 0.126s
im_proposals: 549/5011 0.126s
im_proposals: 550/5011 0.126s
im_proposals: 551/5011 0.126s
im_proposals: 552/5011 0.126s
im_proposals: 553/5011 0.126s
im_proposals: 554/5011 0.126s
im_proposals: 555/5011 0.126s
im_proposals: 556/5011 0.126s
im_proposals: 557/5011 0.126s
im_proposals: 558/5011 0.126s
im_proposals: 559/5011 0.126s
im_proposals: 560/5011 0.126s
im_proposals: 561/5011 0.126s
im_proposals: 562/5011 0.126s
im_proposals: 563/5011 0.126s
im_proposals: 564/5011 0.126s
im_proposals: 565/5011 0.126s
im_proposals: 566/5011 0.126s
im_proposals: 567/5011 0.126s
im_proposals: 568/5011 0.126s
im_proposals: 569/5011 0.126s
im_proposals: 570/5011 0.126s
im_proposals: 571/5011 0.126s
im_proposals: 572/5011 0.126s
im_proposals: 573/5011 0.126s
im_proposals: 574/5011 0.126s
im_proposals: 575/5011 0.126s
im_proposals: 576/5011 0.126s
im_proposals: 577/5011 0.126s
im_proposals: 578/5011 0.126s
im_proposals: 579/5011 0.126s
im_proposals: 580/5011 0.126s
im_proposals: 581/5011 0.126s
im_proposals: 582/5011 0.126s
im_proposals: 583/5011 0.126s
im_proposals: 584/5011 0.126s
im_proposals: 585/5011 0.126s
im_proposals: 586/5011 0.126s
im_proposals: 587/5011 0.126s
im_proposals: 588/5011 0.126s
im_proposals: 589/5011 0.126s
im_proposals: 590/5011 0.126s
im_proposals: 591/5011 0.126s
im_proposals: 592/5011 0.126s
im_proposals: 593/5011 0.126s
im_proposals: 594/5011 0.126s
im_proposals: 595/5011 0.126s
im_proposals: 596/5011 0.126s
im_proposals: 597/5011 0.126s
im_proposals: 598/5011 0.126s
im_proposals: 599/5011 0.126s
im_proposals: 600/5011 0.126s
im_proposals: 601/5011 0.126s
im_proposals: 602/5011 0.126s
im_proposals: 603/5011 0.126s
im_proposals: 604/5011 0.126s
im_proposals: 605/5011 0.126s
im_proposals: 606/5011 0.126s
im_proposals: 607/5011 0.126s
im_proposals: 608/5011 0.126s
im_proposals: 609/5011 0.126s
im_proposals: 610/5011 0.126s
im_proposals: 611/5011 0.126s
im_proposals: 612/5011 0.126s
im_proposals: 613/5011 0.126s
im_proposals: 614/5011 0.126s
im_proposals: 615/5011 0.126s
im_proposals: 616/5011 0.126s
im_proposals: 617/5011 0.126s
im_proposals: 618/5011 0.126s
im_proposals: 619/5011 0.126s
im_proposals: 620/5011 0.126s
im_proposals: 621/5011 0.126s
im_proposals: 622/5011 0.126s
im_proposals: 623/5011 0.126s
im_proposals: 624/5011 0.126s
im_proposals: 625/5011 0.126s
im_proposals: 626/5011 0.126s
im_proposals: 627/5011 0.126s
im_proposals: 628/5011 0.126s
im_proposals: 629/5011 0.126s
im_proposals: 630/5011 0.126s
im_proposals: 631/5011 0.126s
im_proposals: 632/5011 0.126s
im_proposals: 633/5011 0.126s
im_proposals: 634/5011 0.126s
im_proposals: 635/5011 0.126s
im_proposals: 636/5011 0.126s
im_proposals: 637/5011 0.126s
im_proposals: 638/5011 0.126s
im_proposals: 639/5011 0.126s
im_proposals: 640/5011 0.126s
im_proposals: 641/5011 0.126s
im_proposals: 642/5011 0.126s
im_proposals: 643/5011 0.126s
im_proposals: 644/5011 0.126s
im_proposals: 645/5011 0.126s
im_proposals: 646/5011 0.126s
im_proposals: 647/5011 0.126s
im_proposals: 648/5011 0.126s
im_proposals: 649/5011 0.126s
im_proposals: 650/5011 0.126s
im_proposals: 651/5011 0.126s
im_proposals: 652/5011 0.126s
im_proposals: 653/5011 0.126s
im_proposals: 654/5011 0.126s
im_proposals: 655/5011 0.126s
im_proposals: 656/5011 0.126s
im_proposals: 657/5011 0.126s
im_proposals: 658/5011 0.126s
im_proposals: 659/5011 0.126s
im_proposals: 660/5011 0.126s
im_proposals: 661/5011 0.126s
im_proposals: 662/5011 0.126s
im_proposals: 663/5011 0.126s
im_proposals: 664/5011 0.126s
im_proposals: 665/5011 0.126s
im_proposals: 666/5011 0.126s
im_proposals: 667/5011 0.126s
im_proposals: 668/5011 0.126s
im_proposals: 669/5011 0.126s
im_proposals: 670/5011 0.126s
im_proposals: 671/5011 0.126s
im_proposals: 672/5011 0.126s
im_proposals: 673/5011 0.126s
im_proposals: 674/5011 0.126s
im_proposals: 675/5011 0.126s
im_proposals: 676/5011 0.126s
im_proposals: 677/5011 0.126s
im_proposals: 678/5011 0.126s
im_proposals: 679/5011 0.126s
im_proposals: 680/5011 0.126s
im_proposals: 681/5011 0.126s
im_proposals: 682/5011 0.126s
im_proposals: 683/5011 0.126s
im_proposals: 684/5011 0.126s
im_proposals: 685/5011 0.126s
im_proposals: 686/5011 0.126s
im_proposals: 687/5011 0.126s
im_proposals: 688/5011 0.126s
im_proposals: 689/5011 0.126s
im_proposals: 690/5011 0.126s
im_proposals: 691/5011 0.126s
im_proposals: 692/5011 0.126s
im_proposals: 693/5011 0.126s
im_proposals: 694/5011 0.126s
im_proposals: 695/5011 0.126s
im_proposals: 696/5011 0.126s
im_proposals: 697/5011 0.126s
im_proposals: 698/5011 0.126s
im_proposals: 699/5011 0.126s
im_proposals: 700/5011 0.126s
im_proposals: 701/5011 0.126s
im_proposals: 702/5011 0.126s
im_proposals: 703/5011 0.126s
im_proposals: 704/5011 0.126s
im_proposals: 705/5011 0.126s
im_proposals: 706/5011 0.126s
im_proposals: 707/5011 0.126s
im_proposals: 708/5011 0.126s
im_proposals: 709/5011 0.126s
im_proposals: 710/5011 0.126s
im_proposals: 711/5011 0.126s
im_proposals: 712/5011 0.126s
im_proposals: 713/5011 0.126s
im_proposals: 714/5011 0.126s
im_proposals: 715/5011 0.126s
im_proposals: 716/5011 0.126s
im_proposals: 717/5011 0.126s
im_proposals: 718/5011 0.126s
im_proposals: 719/5011 0.126s
im_proposals: 720/5011 0.126s
im_proposals: 721/5011 0.126s
im_proposals: 722/5011 0.126s
im_proposals: 723/5011 0.126s
im_proposals: 724/5011 0.126s
im_proposals: 725/5011 0.126s
im_proposals: 726/5011 0.126s
im_proposals: 727/5011 0.126s
im_proposals: 728/5011 0.126s
im_proposals: 729/5011 0.126s
im_proposals: 730/5011 0.126s
im_proposals: 731/5011 0.126s
im_proposals: 732/5011 0.126s
im_proposals: 733/5011 0.126s
im_proposals: 734/5011 0.126s
im_proposals: 735/5011 0.126s
im_proposals: 736/5011 0.126s
im_proposals: 737/5011 0.126s
im_proposals: 738/5011 0.126s
im_proposals: 739/5011 0.126s
im_proposals: 740/5011 0.126s
im_proposals: 741/5011 0.126s
im_proposals: 742/5011 0.126s
im_proposals: 743/5011 0.126s
im_proposals: 744/5011 0.126s
im_proposals: 745/5011 0.126s
im_proposals: 746/5011 0.126s
im_proposals: 747/5011 0.126s
im_proposals: 748/5011 0.126s
im_proposals: 749/5011 0.126s
im_proposals: 750/5011 0.126s
im_proposals: 751/5011 0.126s
im_proposals: 752/5011 0.126s
im_proposals: 753/5011 0.126s
im_proposals: 754/5011 0.126s
im_proposals: 755/5011 0.126s
im_proposals: 756/5011 0.126s
im_proposals: 757/5011 0.126s
im_proposals: 758/5011 0.126s
im_proposals: 759/5011 0.126s
im_proposals: 760/5011 0.126s
im_proposals: 761/5011 0.126s
im_proposals: 762/5011 0.126s
im_proposals: 763/5011 0.126s
im_proposals: 764/5011 0.126s
im_proposals: 765/5011 0.126s
im_proposals: 766/5011 0.126s
im_proposals: 767/5011 0.126s
im_proposals: 768/5011 0.126s
im_proposals: 769/5011 0.126s
im_proposals: 770/5011 0.126s
im_proposals: 771/5011 0.126s
im_proposals: 772/5011 0.126s
im_proposals: 773/5011 0.126s
im_proposals: 774/5011 0.126s
im_proposals: 775/5011 0.126s
im_proposals: 776/5011 0.126s
im_proposals: 777/5011 0.126s
im_proposals: 778/5011 0.126s
im_proposals: 779/5011 0.126s
im_proposals: 780/5011 0.126s
im_proposals: 781/5011 0.126s
im_proposals: 782/5011 0.126s
im_proposals: 783/5011 0.126s
im_proposals: 784/5011 0.126s
im_proposals: 785/5011 0.126s
im_proposals: 786/5011 0.126s
im_proposals: 787/5011 0.126s
im_proposals: 788/5011 0.126s
im_proposals: 789/5011 0.126s
im_proposals: 790/5011 0.126s
im_proposals: 791/5011 0.126s
im_proposals: 792/5011 0.126s
im_proposals: 793/5011 0.126s
im_proposals: 794/5011 0.126s
im_proposals: 795/5011 0.126s
im_proposals: 796/5011 0.126s
im_proposals: 797/5011 0.126s
im_proposals: 798/5011 0.126s
im_proposals: 799/5011 0.126s
im_proposals: 800/5011 0.126s
im_proposals: 801/5011 0.126s
im_proposals: 802/5011 0.126s
im_proposals: 803/5011 0.126s
im_proposals: 804/5011 0.126s
im_proposals: 805/5011 0.126s
im_proposals: 806/5011 0.126s
im_proposals: 807/5011 0.126s
im_proposals: 808/5011 0.126s
im_proposals: 809/5011 0.126s
im_proposals: 810/5011 0.126s
im_proposals: 811/5011 0.126s
im_proposals: 812/5011 0.126s
im_proposals: 813/5011 0.126s
im_proposals: 814/5011 0.126s
im_proposals: 815/5011 0.126s
im_proposals: 816/5011 0.126s
im_proposals: 817/5011 0.126s
im_proposals: 818/5011 0.126s
im_proposals: 819/5011 0.126s
im_proposals: 820/5011 0.126s
im_proposals: 821/5011 0.126s
im_proposals: 822/5011 0.126s
im_proposals: 823/5011 0.126s
im_proposals: 824/5011 0.126s
im_proposals: 825/5011 0.126s
im_proposals: 826/5011 0.126s
im_proposals: 827/5011 0.126s
im_proposals: 828/5011 0.126s
im_proposals: 829/5011 0.126s
im_proposals: 830/5011 0.126s
im_proposals: 831/5011 0.126s
im_proposals: 832/5011 0.126s
im_proposals: 833/5011 0.126s
im_proposals: 834/5011 0.126s
im_proposals: 835/5011 0.126s
im_proposals: 836/5011 0.126s
im_proposals: 837/5011 0.126s
im_proposals: 838/5011 0.126s
im_proposals: 839/5011 0.126s
im_proposals: 840/5011 0.126s
im_proposals: 841/5011 0.126s
im_proposals: 842/5011 0.126s
im_proposals: 843/5011 0.126s
im_proposals: 844/5011 0.126s
im_proposals: 845/5011 0.126s
im_proposals: 846/5011 0.126s
im_proposals: 847/5011 0.126s
im_proposals: 848/5011 0.126s
im_proposals: 849/5011 0.126s
im_proposals: 850/5011 0.126s
im_proposals: 851/5011 0.126s
im_proposals: 852/5011 0.126s
im_proposals: 853/5011 0.126s
im_proposals: 854/5011 0.126s
im_proposals: 855/5011 0.126s
im_proposals: 856/5011 0.126s
im_proposals: 857/5011 0.126s
im_proposals: 858/5011 0.126s
im_proposals: 859/5011 0.126s
im_proposals: 860/5011 0.126s
im_proposals: 861/5011 0.126s
im_proposals: 862/5011 0.126s
im_proposals: 863/5011 0.126s
im_proposals: 864/5011 0.126s
im_proposals: 865/5011 0.126s
im_proposals: 866/5011 0.126s
im_proposals: 867/5011 0.126s
im_proposals: 868/5011 0.126s
im_proposals: 869/5011 0.126s
im_proposals: 870/5011 0.126s
im_proposals: 871/5011 0.126s
im_proposals: 872/5011 0.126s
im_proposals: 873/5011 0.126s
im_proposals: 874/5011 0.126s
im_proposals: 875/5011 0.126s
im_proposals: 876/5011 0.126s
im_proposals: 877/5011 0.126s
im_proposals: 878/5011 0.126s
im_proposals: 879/5011 0.126s
im_proposals: 880/5011 0.126s
im_proposals: 881/5011 0.126s
im_proposals: 882/5011 0.126s
im_proposals: 883/5011 0.126s
im_proposals: 884/5011 0.126s
im_proposals: 885/5011 0.126s
im_proposals: 886/5011 0.126s
im_proposals: 887/5011 0.126s
im_proposals: 888/5011 0.126s
im_proposals: 889/5011 0.126s
im_proposals: 890/5011 0.126s
im_proposals: 891/5011 0.126s
im_proposals: 892/5011 0.126s
im_proposals: 893/5011 0.126s
im_proposals: 894/5011 0.126s
im_proposals: 895/5011 0.126s
im_proposals: 896/5011 0.126s
im_proposals: 897/5011 0.126s
im_proposals: 898/5011 0.126s
im_proposals: 899/5011 0.126s
im_proposals: 900/5011 0.126s
im_proposals: 901/5011 0.126s
im_proposals: 902/5011 0.126s
im_proposals: 903/5011 0.126s
im_proposals: 904/5011 0.126s
im_proposals: 905/5011 0.126s
im_proposals: 906/5011 0.126s
im_proposals: 907/5011 0.126s
im_proposals: 908/5011 0.126s
im_proposals: 909/5011 0.126s
im_proposals: 910/5011 0.126s
im_proposals: 911/5011 0.126s
im_proposals: 912/5011 0.126s
im_proposals: 913/5011 0.126s
im_proposals: 914/5011 0.126s
im_proposals: 915/5011 0.126s
im_proposals: 916/5011 0.126s
im_proposals: 917/5011 0.126s
im_proposals: 918/5011 0.126s
im_proposals: 919/5011 0.126s
im_proposals: 920/5011 0.126s
im_proposals: 921/5011 0.126s
im_proposals: 922/5011 0.126s
im_proposals: 923/5011 0.126s
im_proposals: 924/5011 0.126s
im_proposals: 925/5011 0.126s
im_proposals: 926/5011 0.125s
im_proposals: 927/5011 0.125s
im_proposals: 928/5011 0.125s
im_proposals: 929/5011 0.125s
im_proposals: 930/5011 0.125s
im_proposals: 931/5011 0.125s
im_proposals: 932/5011 0.126s
im_proposals: 933/5011 0.125s
im_proposals: 934/5011 0.125s
im_proposals: 935/5011 0.125s
im_proposals: 936/5011 0.125s
im_proposals: 937/5011 0.125s
im_proposals: 938/5011 0.125s
im_proposals: 939/5011 0.125s
im_proposals: 940/5011 0.125s
im_proposals: 941/5011 0.125s
im_proposals: 942/5011 0.125s
im_proposals: 943/5011 0.126s
im_proposals: 944/5011 0.126s
im_proposals: 945/5011 0.126s
im_proposals: 946/5011 0.126s
im_proposals: 947/5011 0.126s
im_proposals: 948/5011 0.126s
im_proposals: 949/5011 0.126s
im_proposals: 950/5011 0.126s
im_proposals: 951/5011 0.126s
im_proposals: 952/5011 0.126s
im_proposals: 953/5011 0.126s
im_proposals: 954/5011 0.126s
im_proposals: 955/5011 0.126s
im_proposals: 956/5011 0.126s
im_proposals: 957/5011 0.126s
im_proposals: 958/5011 0.126s
im_proposals: 959/5011 0.126s
im_proposals: 960/5011 0.126s
im_proposals: 961/5011 0.126s
im_proposals: 962/5011 0.126s
im_proposals: 963/5011 0.126s
im_proposals: 964/5011 0.126s
im_proposals: 965/5011 0.126s
im_proposals: 966/5011 0.126s
im_proposals: 967/5011 0.126s
im_proposals: 968/5011 0.126s
im_proposals: 969/5011 0.126s
im_proposals: 970/5011 0.126s
im_proposals: 971/5011 0.126s
im_proposals: 972/5011 0.126s
im_proposals: 973/5011 0.126s
im_proposals: 974/5011 0.126s
im_proposals: 975/5011 0.126s
im_proposals: 976/5011 0.126s
im_proposals: 977/5011 0.126s
im_proposals: 978/5011 0.126s
im_proposals: 979/5011 0.126s
im_proposals: 980/5011 0.126s
im_proposals: 981/5011 0.126s
im_proposals: 982/5011 0.126s
im_proposals: 983/5011 0.126s
im_proposals: 984/5011 0.126s
im_proposals: 985/5011 0.126s
im_proposals: 986/5011 0.126s
im_proposals: 987/5011 0.126s
im_proposals: 988/5011 0.126s
im_proposals: 989/5011 0.126s
im_proposals: 990/5011 0.126s
im_proposals: 991/5011 0.126s
im_proposals: 992/5011 0.126s
im_proposals: 993/5011 0.126s
im_proposals: 994/5011 0.126s
im_proposals: 995/5011 0.126s
im_proposals: 996/5011 0.126s
im_proposals: 997/5011 0.126s
im_proposals: 998/5011 0.126s
im_proposals: 999/5011 0.126s
im_proposals: 1000/5011 0.126s
im_proposals: 1001/5011 0.126s
im_proposals: 1002/5011 0.126s
im_proposals: 1003/5011 0.126s
im_proposals: 1004/5011 0.126s
im_proposals: 1005/5011 0.126s
im_proposals: 1006/5011 0.126s
im_proposals: 1007/5011 0.126s
im_proposals: 1008/5011 0.126s
im_proposals: 1009/5011 0.126s
im_proposals: 1010/5011 0.126s
im_proposals: 1011/5011 0.126s
im_proposals: 1012/5011 0.126s
im_proposals: 1013/5011 0.126s
im_proposals: 1014/5011 0.126s
im_proposals: 1015/5011 0.126s
im_proposals: 1016/5011 0.126s
im_proposals: 1017/5011 0.126s
im_proposals: 1018/5011 0.126s
im_proposals: 1019/5011 0.126s
im_proposals: 1020/5011 0.126s
im_proposals: 1021/5011 0.126s
im_proposals: 1022/5011 0.126s
im_proposals: 1023/5011 0.126s
im_proposals: 1024/5011 0.126s
im_proposals: 1025/5011 0.126s
im_proposals: 1026/5011 0.126s
im_proposals: 1027/5011 0.126s
im_proposals: 1028/5011 0.126s
im_proposals: 1029/5011 0.126s
im_proposals: 1030/5011 0.126s
im_proposals: 1031/5011 0.126s
im_proposals: 1032/5011 0.126s
im_proposals: 1033/5011 0.126s
im_proposals: 1034/5011 0.126s
im_proposals: 1035/5011 0.126s
im_proposals: 1036/5011 0.126s
im_proposals: 1037/5011 0.126s
im_proposals: 1038/5011 0.126s
im_proposals: 1039/5011 0.126s
im_proposals: 1040/5011 0.126s
im_proposals: 1041/5011 0.126s
im_proposals: 1042/5011 0.126s
im_proposals: 1043/5011 0.126s
im_proposals: 1044/5011 0.126s
im_proposals: 1045/5011 0.126s
im_proposals: 1046/5011 0.126s
im_proposals: 1047/5011 0.126s
im_proposals: 1048/5011 0.126s
im_proposals: 1049/5011 0.126s
im_proposals: 1050/5011 0.126s
im_proposals: 1051/5011 0.126s
im_proposals: 1052/5011 0.126s
im_proposals: 1053/5011 0.126s
im_proposals: 1054/5011 0.126s
im_proposals: 1055/5011 0.126s
im_proposals: 1056/5011 0.126s
im_proposals: 1057/5011 0.126s
im_proposals: 1058/5011 0.126s
im_proposals: 1059/5011 0.126s
im_proposals: 1060/5011 0.126s
im_proposals: 1061/5011 0.126s
im_proposals: 1062/5011 0.126s
im_proposals: 1063/5011 0.126s
im_proposals: 1064/5011 0.126s
im_proposals: 1065/5011 0.126s
im_proposals: 1066/5011 0.126s
im_proposals: 1067/5011 0.126s
im_proposals: 1068/5011 0.126s
im_proposals: 1069/5011 0.126s
im_proposals: 1070/5011 0.126s
im_proposals: 1071/5011 0.126s
im_proposals: 1072/5011 0.126s
im_proposals: 1073/5011 0.126s
im_proposals: 1074/5011 0.126s
im_proposals: 1075/5011 0.126s
im_proposals: 1076/5011 0.126s
im_proposals: 1077/5011 0.126s
im_proposals: 1078/5011 0.126s
im_proposals: 1079/5011 0.126s
im_proposals: 1080/5011 0.126s
im_proposals: 1081/5011 0.126s
im_proposals: 1082/5011 0.126s
im_proposals: 1083/5011 0.126s
im_proposals: 1084/5011 0.126s
im_proposals: 1085/5011 0.126s
im_proposals: 1086/5011 0.126s
im_proposals: 1087/5011 0.126s
im_proposals: 1088/5011 0.126s
im_proposals: 1089/5011 0.126s
im_proposals: 1090/5011 0.126s
im_proposals: 1091/5011 0.126s
im_proposals: 1092/5011 0.126s
im_proposals: 1093/5011 0.126s
im_proposals: 1094/5011 0.126s
im_proposals: 1095/5011 0.126s
im_proposals: 1096/5011 0.126s
im_proposals: 1097/5011 0.126s
im_proposals: 1098/5011 0.126s
im_proposals: 1099/5011 0.126s
im_proposals: 1100/5011 0.126s
im_proposals: 1101/5011 0.126s
im_proposals: 1102/5011 0.126s
im_proposals: 1103/5011 0.126s
im_proposals: 1104/5011 0.126s
im_proposals: 1105/5011 0.126s
im_proposals: 1106/5011 0.126s
im_proposals: 1107/5011 0.126s
im_proposals: 1108/5011 0.126s
im_proposals: 1109/5011 0.126s
im_proposals: 1110/5011 0.126s
im_proposals: 1111/5011 0.126s
im_proposals: 1112/5011 0.126s
im_proposals: 1113/5011 0.126s
im_proposals: 1114/5011 0.126s
im_proposals: 1115/5011 0.126s
im_proposals: 1116/5011 0.126s
im_proposals: 1117/5011 0.126s
im_proposals: 1118/5011 0.126s
im_proposals: 1119/5011 0.126s
im_proposals: 1120/5011 0.126s
im_proposals: 1121/5011 0.126s
im_proposals: 1122/5011 0.126s
im_proposals: 1123/5011 0.126s
im_proposals: 1124/5011 0.126s
im_proposals: 1125/5011 0.126s
im_proposals: 1126/5011 0.126s
im_proposals: 1127/5011 0.126s
im_proposals: 1128/5011 0.126s
im_proposals: 1129/5011 0.126s
im_proposals: 1130/5011 0.126s
im_proposals: 1131/5011 0.126s
im_proposals: 1132/5011 0.126s
im_proposals: 1133/5011 0.126s
im_proposals: 1134/5011 0.126s
im_proposals: 1135/5011 0.126s
im_proposals: 1136/5011 0.126s
im_proposals: 1137/5011 0.126s
im_proposals: 1138/5011 0.126s
im_proposals: 1139/5011 0.126s
im_proposals: 1140/5011 0.126s
im_proposals: 1141/5011 0.126s
im_proposals: 1142/5011 0.126s
im_proposals: 1143/5011 0.126s
im_proposals: 1144/5011 0.126s
im_proposals: 1145/5011 0.126s
im_proposals: 1146/5011 0.126s
im_proposals: 1147/5011 0.126s
im_proposals: 1148/5011 0.126s
im_proposals: 1149/5011 0.126s
im_proposals: 1150/5011 0.126s
im_proposals: 1151/5011 0.126s
im_proposals: 1152/5011 0.126s
im_proposals: 1153/5011 0.126s
im_proposals: 1154/5011 0.126s
im_proposals: 1155/5011 0.126s
im_proposals: 1156/5011 0.126s
im_proposals: 1157/5011 0.126s
im_proposals: 1158/5011 0.126s
im_proposals: 1159/5011 0.126s
im_proposals: 1160/5011 0.126s
im_proposals: 1161/5011 0.126s
im_proposals: 1162/5011 0.126s
im_proposals: 1163/5011 0.126s
im_proposals: 1164/5011 0.126s
im_proposals: 1165/5011 0.126s
im_proposals: 1166/5011 0.126s
im_proposals: 1167/5011 0.126s
im_proposals: 1168/5011 0.126s
im_proposals: 1169/5011 0.126s
im_proposals: 1170/5011 0.126s
im_proposals: 1171/5011 0.126s
im_proposals: 1172/5011 0.126s
im_proposals: 1173/5011 0.126s
im_proposals: 1174/5011 0.126s
im_proposals: 1175/5011 0.126s
im_proposals: 1176/5011 0.126s
im_proposals: 1177/5011 0.126s
im_proposals: 1178/5011 0.126s
im_proposals: 1179/5011 0.126s
im_proposals: 1180/5011 0.126s
im_proposals: 1181/5011 0.126s
im_proposals: 1182/5011 0.126s
im_proposals: 1183/5011 0.126s
im_proposals: 1184/5011 0.126s
im_proposals: 1185/5011 0.126s
im_proposals: 1186/5011 0.126s
im_proposals: 1187/5011 0.126s
im_proposals: 1188/5011 0.126s
im_proposals: 1189/5011 0.126s
im_proposals: 1190/5011 0.126s
im_proposals: 1191/5011 0.126s
im_proposals: 1192/5011 0.126s
im_proposals: 1193/5011 0.126s
im_proposals: 1194/5011 0.126s
im_proposals: 1195/5011 0.126s
im_proposals: 1196/5011 0.126s
im_proposals: 1197/5011 0.126s
im_proposals: 1198/5011 0.126s
im_proposals: 1199/5011 0.126s
im_proposals: 1200/5011 0.126s
im_proposals: 1201/5011 0.126s
im_proposals: 1202/5011 0.126s
im_proposals: 1203/5011 0.126s
im_proposals: 1204/5011 0.126s
im_proposals: 1205/5011 0.126s
im_proposals: 1206/5011 0.126s
im_proposals: 1207/5011 0.126s
im_proposals: 1208/5011 0.126s
im_proposals: 1209/5011 0.126s
im_proposals: 1210/5011 0.126s
im_proposals: 1211/5011 0.126s
im_proposals: 1212/5011 0.126s
im_proposals: 1213/5011 0.126s
im_proposals: 1214/5011 0.126s
im_proposals: 1215/5011 0.126s
im_proposals: 1216/5011 0.126s
im_proposals: 1217/5011 0.126s
im_proposals: 1218/5011 0.126s
im_proposals: 1219/5011 0.126s
im_proposals: 1220/5011 0.126s
im_proposals: 1221/5011 0.126s
im_proposals: 1222/5011 0.126s
im_proposals: 1223/5011 0.126s
im_proposals: 1224/5011 0.126s
im_proposals: 1225/5011 0.126s
im_proposals: 1226/5011 0.126s
im_proposals: 1227/5011 0.126s
im_proposals: 1228/5011 0.126s
im_proposals: 1229/5011 0.126s
im_proposals: 1230/5011 0.126s
im_proposals: 1231/5011 0.126s
im_proposals: 1232/5011 0.126s
im_proposals: 1233/5011 0.126s
im_proposals: 1234/5011 0.126s
im_proposals: 1235/5011 0.126s
im_proposals: 1236/5011 0.126s
im_proposals: 1237/5011 0.126s
im_proposals: 1238/5011 0.126s
im_proposals: 1239/5011 0.126s
im_proposals: 1240/5011 0.126s
im_proposals: 1241/5011 0.126s
im_proposals: 1242/5011 0.126s
im_proposals: 1243/5011 0.126s
im_proposals: 1244/5011 0.126s
im_proposals: 1245/5011 0.126s
im_proposals: 1246/5011 0.126s
im_proposals: 1247/5011 0.126s
im_proposals: 1248/5011 0.126s
im_proposals: 1249/5011 0.126s
im_proposals: 1250/5011 0.125s
im_proposals: 1251/5011 0.125s
im_proposals: 1252/5011 0.125s
im_proposals: 1253/5011 0.125s
im_proposals: 1254/5011 0.125s
im_proposals: 1255/5011 0.125s
im_proposals: 1256/5011 0.125s
im_proposals: 1257/5011 0.125s
im_proposals: 1258/5011 0.125s
im_proposals: 1259/5011 0.125s
im_proposals: 1260/5011 0.125s
im_proposals: 1261/5011 0.125s
im_proposals: 1262/5011 0.125s
im_proposals: 1263/5011 0.126s
im_proposals: 1264/5011 0.125s
im_proposals: 1265/5011 0.126s
im_proposals: 1266/5011 0.126s
im_proposals: 1267/5011 0.126s
im_proposals: 1268/5011 0.126s
im_proposals: 1269/5011 0.126s
im_proposals: 1270/5011 0.126s
im_proposals: 1271/5011 0.126s
im_proposals: 1272/5011 0.125s
im_proposals: 1273/5011 0.126s
im_proposals: 1274/5011 0.126s
im_proposals: 1275/5011 0.126s
im_proposals: 1276/5011 0.125s
im_proposals: 1277/5011 0.125s
im_proposals: 1278/5011 0.125s
im_proposals: 1279/5011 0.125s
im_proposals: 1280/5011 0.125s
im_proposals: 1281/5011 0.125s
im_proposals: 1282/5011 0.125s
im_proposals: 1283/5011 0.125s
im_proposals: 1284/5011 0.125s
im_proposals: 1285/5011 0.125s
im_proposals: 1286/5011 0.125s
im_proposals: 1287/5011 0.126s
im_proposals: 1288/5011 0.126s
im_proposals: 1289/5011 0.126s
im_proposals: 1290/5011 0.125s
im_proposals: 1291/5011 0.125s
im_proposals: 1292/5011 0.126s
im_proposals: 1293/5011 0.126s
im_proposals: 1294/5011 0.126s
im_proposals: 1295/5011 0.126s
im_proposals: 1296/5011 0.126s
im_proposals: 1297/5011 0.126s
im_proposals: 1298/5011 0.126s
im_proposals: 1299/5011 0.126s
im_proposals: 1300/5011 0.126s
im_proposals: 1301/5011 0.126s
im_proposals: 1302/5011 0.126s
im_proposals: 1303/5011 0.126s
im_proposals: 1304/5011 0.126s
im_proposals: 1305/5011 0.126s
im_proposals: 1306/5011 0.126s
im_proposals: 1307/5011 0.126s
im_proposals: 1308/5011 0.126s
im_proposals: 1309/5011 0.126s
im_proposals: 1310/5011 0.126s
im_proposals: 1311/5011 0.126s
im_proposals: 1312/5011 0.126s
im_proposals: 1313/5011 0.126s
im_proposals: 1314/5011 0.126s
im_proposals: 1315/5011 0.126s
im_proposals: 1316/5011 0.126s
im_proposals: 1317/5011 0.126s
im_proposals: 1318/5011 0.126s
im_proposals: 1319/5011 0.126s
im_proposals: 1320/5011 0.126s
im_proposals: 1321/5011 0.126s
im_proposals: 1322/5011 0.126s
im_proposals: 1323/5011 0.126s
im_proposals: 1324/5011 0.126s
im_proposals: 1325/5011 0.126s
im_proposals: 1326/5011 0.126s
im_proposals: 1327/5011 0.126s
im_proposals: 1328/5011 0.126s
im_proposals: 1329/5011 0.126s
im_proposals: 1330/5011 0.126s
im_proposals: 1331/5011 0.126s
im_proposals: 1332/5011 0.126s
im_proposals: 1333/5011 0.126s
im_proposals: 1334/5011 0.126s
im_proposals: 1335/5011 0.126s
im_proposals: 1336/5011 0.126s
im_proposals: 1337/5011 0.126s
im_proposals: 1338/5011 0.126s
im_proposals: 1339/5011 0.126s
im_proposals: 1340/5011 0.126s
im_proposals: 1341/5011 0.126s
im_proposals: 1342/5011 0.126s
im_proposals: 1343/5011 0.126s
im_proposals: 1344/5011 0.126s
im_proposals: 1345/5011 0.126s
im_proposals: 1346/5011 0.126s
im_proposals: 1347/5011 0.126s
im_proposals: 1348/5011 0.126s
im_proposals: 1349/5011 0.126s
im_proposals: 1350/5011 0.126s
im_proposals: 1351/5011 0.126s
im_proposals: 1352/5011 0.126s
im_proposals: 1353/5011 0.126s
im_proposals: 1354/5011 0.126s
im_proposals: 1355/5011 0.126s
im_proposals: 1356/5011 0.126s
im_proposals: 1357/5011 0.126s
im_proposals: 1358/5011 0.126s
im_proposals: 1359/5011 0.126s
im_proposals: 1360/5011 0.126s
im_proposals: 1361/5011 0.126s
im_proposals: 1362/5011 0.126s
im_proposals: 1363/5011 0.126s
im_proposals: 1364/5011 0.126s
im_proposals: 1365/5011 0.126s
im_proposals: 1366/5011 0.126s
im_proposals: 1367/5011 0.126s
im_proposals: 1368/5011 0.126s
im_proposals: 1369/5011 0.126s
im_proposals: 1370/5011 0.126s
im_proposals: 1371/5011 0.126s
im_proposals: 1372/5011 0.126s
im_proposals: 1373/5011 0.126s
im_proposals: 1374/5011 0.126s
im_proposals: 1375/5011 0.126s
im_proposals: 1376/5011 0.126s
im_proposals: 1377/5011 0.126s
im_proposals: 1378/5011 0.126s
im_proposals: 1379/5011 0.126s
im_proposals: 1380/5011 0.126s
im_proposals: 1381/5011 0.126s
im_proposals: 1382/5011 0.126s
im_proposals: 1383/5011 0.126s
im_proposals: 1384/5011 0.126s
im_proposals: 1385/5011 0.126s
im_proposals: 1386/5011 0.126s
im_proposals: 1387/5011 0.126s
im_proposals: 1388/5011 0.126s
im_proposals: 1389/5011 0.126s
im_proposals: 1390/5011 0.126s
im_proposals: 1391/5011 0.126s
im_proposals: 1392/5011 0.126s
im_proposals: 1393/5011 0.126s
im_proposals: 1394/5011 0.126s
im_proposals: 1395/5011 0.126s
im_proposals: 1396/5011 0.126s
im_proposals: 1397/5011 0.126s
im_proposals: 1398/5011 0.126s
im_proposals: 1399/5011 0.126s
im_proposals: 1400/5011 0.126s
im_proposals: 1401/5011 0.126s
im_proposals: 1402/5011 0.126s
im_proposals: 1403/5011 0.126s
im_proposals: 1404/5011 0.126s
im_proposals: 1405/5011 0.126s
im_proposals: 1406/5011 0.126s
im_proposals: 1407/5011 0.126s
im_proposals: 1408/5011 0.126s
im_proposals: 1409/5011 0.126s
im_proposals: 1410/5011 0.126s
im_proposals: 1411/5011 0.126s
im_proposals: 1412/5011 0.126s
im_proposals: 1413/5011 0.126s
im_proposals: 1414/5011 0.126s
im_proposals: 1415/5011 0.126s
im_proposals: 1416/5011 0.126s
im_proposals: 1417/5011 0.126s
im_proposals: 1418/5011 0.126s
im_proposals: 1419/5011 0.126s
im_proposals: 1420/5011 0.126s
im_proposals: 1421/5011 0.126s
im_proposals: 1422/5011 0.126s
im_proposals: 1423/5011 0.126s
im_proposals: 1424/5011 0.126s
im_proposals: 1425/5011 0.126s
im_proposals: 1426/5011 0.126s
im_proposals: 1427/5011 0.126s
im_proposals: 1428/5011 0.126s
im_proposals: 1429/5011 0.126s
im_proposals: 1430/5011 0.126s
im_proposals: 1431/5011 0.126s
im_proposals: 1432/5011 0.126s
im_proposals: 1433/5011 0.126s
im_proposals: 1434/5011 0.126s
im_proposals: 1435/5011 0.126s
im_proposals: 1436/5011 0.126s
im_proposals: 1437/5011 0.126s
im_proposals: 1438/5011 0.126s
im_proposals: 1439/5011 0.126s
im_proposals: 1440/5011 0.126s
im_proposals: 1441/5011 0.126s
im_proposals: 1442/5011 0.126s
im_proposals: 1443/5011 0.126s
im_proposals: 1444/5011 0.126s
im_proposals: 1445/5011 0.126s
im_proposals: 1446/5011 0.126s
im_proposals: 1447/5011 0.126s
im_proposals: 1448/5011 0.126s
im_proposals: 1449/5011 0.126s
im_proposals: 1450/5011 0.126s
im_proposals: 1451/5011 0.126s
im_proposals: 1452/5011 0.126s
im_proposals: 1453/5011 0.126s
im_proposals: 1454/5011 0.126s
im_proposals: 1455/5011 0.126s
im_proposals: 1456/5011 0.126s
im_proposals: 1457/5011 0.126s
im_proposals: 1458/5011 0.126s
im_proposals: 1459/5011 0.126s
im_proposals: 1460/5011 0.126s
im_proposals: 1461/5011 0.126s
im_proposals: 1462/5011 0.126s
im_proposals: 1463/5011 0.126s
im_proposals: 1464/5011 0.126s
im_proposals: 1465/5011 0.126s
im_proposals: 1466/5011 0.126s
im_proposals: 1467/5011 0.126s
im_proposals: 1468/5011 0.126s
im_proposals: 1469/5011 0.126s
im_proposals: 1470/5011 0.126s
im_proposals: 1471/5011 0.126s
im_proposals: 1472/5011 0.126s
im_proposals: 1473/5011 0.126s
im_proposals: 1474/5011 0.126s
im_proposals: 1475/5011 0.126s
im_proposals: 1476/5011 0.126s
im_proposals: 1477/5011 0.126s
im_proposals: 1478/5011 0.126s
im_proposals: 1479/5011 0.126s
im_proposals: 1480/5011 0.126s
im_proposals: 1481/5011 0.126s
im_proposals: 1482/5011 0.126s
im_proposals: 1483/5011 0.126s
im_proposals: 1484/5011 0.126s
im_proposals: 1485/5011 0.126s
im_proposals: 1486/5011 0.126s
im_proposals: 1487/5011 0.126s
im_proposals: 1488/5011 0.126s
im_proposals: 1489/5011 0.126s
im_proposals: 1490/5011 0.126s
im_proposals: 1491/5011 0.126s
im_proposals: 1492/5011 0.126s
im_proposals: 1493/5011 0.126s
im_proposals: 1494/5011 0.126s
im_proposals: 1495/5011 0.126s
im_proposals: 1496/5011 0.126s
im_proposals: 1497/5011 0.126s
im_proposals: 1498/5011 0.126s
im_proposals: 1499/5011 0.126s
im_proposals: 1500/5011 0.126s
im_proposals: 1501/5011 0.126s
im_proposals: 1502/5011 0.126s
im_proposals: 1503/5011 0.126s
im_proposals: 1504/5011 0.126s
im_proposals: 1505/5011 0.126s
im_proposals: 1506/5011 0.126s
im_proposals: 1507/5011 0.126s
im_proposals: 1508/5011 0.126s
im_proposals: 1509/5011 0.126s
im_proposals: 1510/5011 0.126s
im_proposals: 1511/5011 0.126s
im_proposals: 1512/5011 0.126s
im_proposals: 1513/5011 0.126s
im_proposals: 1514/5011 0.126s
im_proposals: 1515/5011 0.126s
im_proposals: 1516/5011 0.126s
im_proposals: 1517/5011 0.126s
im_proposals: 1518/5011 0.126s
im_proposals: 1519/5011 0.126s
im_proposals: 1520/5011 0.126s
im_proposals: 1521/5011 0.126s
im_proposals: 1522/5011 0.126s
im_proposals: 1523/5011 0.126s
im_proposals: 1524/5011 0.126s
im_proposals: 1525/5011 0.126s
im_proposals: 1526/5011 0.126s
im_proposals: 1527/5011 0.126s
im_proposals: 1528/5011 0.126s
im_proposals: 1529/5011 0.126s
im_proposals: 1530/5011 0.126s
im_proposals: 1531/5011 0.126s
im_proposals: 1532/5011 0.126s
im_proposals: 1533/5011 0.126s
im_proposals: 1534/5011 0.126s
im_proposals: 1535/5011 0.126s
im_proposals: 1536/5011 0.126s
im_proposals: 1537/5011 0.126s
im_proposals: 1538/5011 0.126s
im_proposals: 1539/5011 0.126s
im_proposals: 1540/5011 0.126s
im_proposals: 1541/5011 0.126s
im_proposals: 1542/5011 0.126s
im_proposals: 1543/5011 0.126s
im_proposals: 1544/5011 0.126s
im_proposals: 1545/5011 0.126s
im_proposals: 1546/5011 0.126s
im_proposals: 1547/5011 0.126s
im_proposals: 1548/5011 0.126s
im_proposals: 1549/5011 0.126s
im_proposals: 1550/5011 0.126s
im_proposals: 1551/5011 0.126s
im_proposals: 1552/5011 0.126s
im_proposals: 1553/5011 0.126s
im_proposals: 1554/5011 0.126s
im_proposals: 1555/5011 0.126s
im_proposals: 1556/5011 0.126s
im_proposals: 1557/5011 0.126s
im_proposals: 1558/5011 0.126s
im_proposals: 1559/5011 0.126s
im_proposals: 1560/5011 0.126s
im_proposals: 1561/5011 0.126s
im_proposals: 1562/5011 0.126s
im_proposals: 1563/5011 0.126s
im_proposals: 1564/5011 0.126s
im_proposals: 1565/5011 0.126s
im_proposals: 1566/5011 0.126s
im_proposals: 1567/5011 0.126s
im_proposals: 1568/5011 0.126s
im_proposals: 1569/5011 0.126s
im_proposals: 1570/5011 0.126s
im_proposals: 1571/5011 0.126s
im_proposals: 1572/5011 0.126s
im_proposals: 1573/5011 0.126s
im_proposals: 1574/5011 0.126s
im_proposals: 1575/5011 0.126s
im_proposals: 1576/5011 0.126s
im_proposals: 1577/5011 0.126s
im_proposals: 1578/5011 0.126s
im_proposals: 1579/5011 0.126s
im_proposals: 1580/5011 0.126s
im_proposals: 1581/5011 0.126s
im_proposals: 1582/5011 0.126s
im_proposals: 1583/5011 0.126s
im_proposals: 1584/5011 0.126s
im_proposals: 1585/5011 0.126s
im_proposals: 1586/5011 0.126s
im_proposals: 1587/5011 0.126s
im_proposals: 1588/5011 0.126s
im_proposals: 1589/5011 0.126s
im_proposals: 1590/5011 0.126s
im_proposals: 1591/5011 0.126s
im_proposals: 1592/5011 0.126s
im_proposals: 1593/5011 0.126s
im_proposals: 1594/5011 0.126s
im_proposals: 1595/5011 0.126s
im_proposals: 1596/5011 0.126s
im_proposals: 1597/5011 0.126s
im_proposals: 1598/5011 0.126s
im_proposals: 1599/5011 0.126s
im_proposals: 1600/5011 0.126s
im_proposals: 1601/5011 0.126s
im_proposals: 1602/5011 0.126s
im_proposals: 1603/5011 0.126s
im_proposals: 1604/5011 0.126s
im_proposals: 1605/5011 0.126s
im_proposals: 1606/5011 0.126s
im_proposals: 1607/5011 0.126s
im_proposals: 1608/5011 0.126s
im_proposals: 1609/5011 0.126s
im_proposals: 1610/5011 0.126s
im_proposals: 1611/5011 0.126s
im_proposals: 1612/5011 0.126s
im_proposals: 1613/5011 0.126s
im_proposals: 1614/5011 0.126s
im_proposals: 1615/5011 0.126s
im_proposals: 1616/5011 0.126s
im_proposals: 1617/5011 0.126s
im_proposals: 1618/5011 0.126s
im_proposals: 1619/5011 0.126s
im_proposals: 1620/5011 0.126s
im_proposals: 1621/5011 0.126s
im_proposals: 1622/5011 0.126s
im_proposals: 1623/5011 0.126s
im_proposals: 1624/5011 0.126s
im_proposals: 1625/5011 0.126s
im_proposals: 1626/5011 0.126s
im_proposals: 1627/5011 0.126s
im_proposals: 1628/5011 0.126s
im_proposals: 1629/5011 0.126s
im_proposals: 1630/5011 0.126s
im_proposals: 1631/5011 0.126s
im_proposals: 1632/5011 0.126s
im_proposals: 1633/5011 0.126s
im_proposals: 1634/5011 0.126s
im_proposals: 1635/5011 0.126s
im_proposals: 1636/5011 0.126s
im_proposals: 1637/5011 0.126s
im_proposals: 1638/5011 0.126s
im_proposals: 1639/5011 0.126s
im_proposals: 1640/5011 0.126s
im_proposals: 1641/5011 0.126s
im_proposals: 1642/5011 0.126s
im_proposals: 1643/5011 0.126s
im_proposals: 1644/5011 0.126s
im_proposals: 1645/5011 0.126s
im_proposals: 1646/5011 0.126s
im_proposals: 1647/5011 0.126s
im_proposals: 1648/5011 0.126s
im_proposals: 1649/5011 0.126s
im_proposals: 1650/5011 0.126s
im_proposals: 1651/5011 0.126s
im_proposals: 1652/5011 0.126s
im_proposals: 1653/5011 0.126s
im_proposals: 1654/5011 0.126s
im_proposals: 1655/5011 0.126s
im_proposals: 1656/5011 0.126s
im_proposals: 1657/5011 0.126s
im_proposals: 1658/5011 0.126s
im_proposals: 1659/5011 0.126s
im_proposals: 1660/5011 0.126s
im_proposals: 1661/5011 0.126s
im_proposals: 1662/5011 0.126s
im_proposals: 1663/5011 0.126s
im_proposals: 1664/5011 0.126s
im_proposals: 1665/5011 0.126s
im_proposals: 1666/5011 0.126s
im_proposals: 1667/5011 0.126s
im_proposals: 1668/5011 0.126s
im_proposals: 1669/5011 0.126s
im_proposals: 1670/5011 0.126s
im_proposals: 1671/5011 0.126s
im_proposals: 1672/5011 0.126s
im_proposals: 1673/5011 0.126s
im_proposals: 1674/5011 0.126s
im_proposals: 1675/5011 0.126s
im_proposals: 1676/5011 0.126s
im_proposals: 1677/5011 0.126s
im_proposals: 1678/5011 0.126s
im_proposals: 1679/5011 0.126s
im_proposals: 1680/5011 0.126s
im_proposals: 1681/5011 0.126s
im_proposals: 1682/5011 0.126s
im_proposals: 1683/5011 0.126s
im_proposals: 1684/5011 0.126s
im_proposals: 1685/5011 0.126s
im_proposals: 1686/5011 0.126s
im_proposals: 1687/5011 0.126s
im_proposals: 1688/5011 0.126s
im_proposals: 1689/5011 0.126s
im_proposals: 1690/5011 0.126s
im_proposals: 1691/5011 0.126s
im_proposals: 1692/5011 0.126s
im_proposals: 1693/5011 0.126s
im_proposals: 1694/5011 0.126s
im_proposals: 1695/5011 0.126s
im_proposals: 1696/5011 0.126s
im_proposals: 1697/5011 0.126s
im_proposals: 1698/5011 0.126s
im_proposals: 1699/5011 0.126s
im_proposals: 1700/5011 0.126s
im_proposals: 1701/5011 0.126s
im_proposals: 1702/5011 0.126s
im_proposals: 1703/5011 0.126s
im_proposals: 1704/5011 0.126s
im_proposals: 1705/5011 0.126s
im_proposals: 1706/5011 0.126s
im_proposals: 1707/5011 0.126s
im_proposals: 1708/5011 0.126s
im_proposals: 1709/5011 0.126s
im_proposals: 1710/5011 0.126s
im_proposals: 1711/5011 0.126s
im_proposals: 1712/5011 0.126s
im_proposals: 1713/5011 0.126s
im_proposals: 1714/5011 0.126s
im_proposals: 1715/5011 0.126s
im_proposals: 1716/5011 0.126s
im_proposals: 1717/5011 0.126s
im_proposals: 1718/5011 0.126s
im_proposals: 1719/5011 0.126s
im_proposals: 1720/5011 0.126s
im_proposals: 1721/5011 0.126s
im_proposals: 1722/5011 0.126s
im_proposals: 1723/5011 0.126s
im_proposals: 1724/5011 0.126s
im_proposals: 1725/5011 0.126s
im_proposals: 1726/5011 0.126s
im_proposals: 1727/5011 0.126s
im_proposals: 1728/5011 0.126s
im_proposals: 1729/5011 0.126s
im_proposals: 1730/5011 0.126s
im_proposals: 1731/5011 0.126s
im_proposals: 1732/5011 0.126s
im_proposals: 1733/5011 0.126s
im_proposals: 1734/5011 0.126s
im_proposals: 1735/5011 0.126s
im_proposals: 1736/5011 0.126s
im_proposals: 1737/5011 0.126s
im_proposals: 1738/5011 0.126s
im_proposals: 1739/5011 0.126s
im_proposals: 1740/5011 0.126s
im_proposals: 1741/5011 0.126s
im_proposals: 1742/5011 0.126s
im_proposals: 1743/5011 0.126s
im_proposals: 1744/5011 0.126s
im_proposals: 1745/5011 0.126s
im_proposals: 1746/5011 0.126s
im_proposals: 1747/5011 0.126s
im_proposals: 1748/5011 0.126s
im_proposals: 1749/5011 0.126s
im_proposals: 1750/5011 0.126s
im_proposals: 1751/5011 0.126s
im_proposals: 1752/5011 0.126s
im_proposals: 1753/5011 0.126s
im_proposals: 1754/5011 0.126s
im_proposals: 1755/5011 0.126s
im_proposals: 1756/5011 0.126s
im_proposals: 1757/5011 0.126s
im_proposals: 1758/5011 0.126s
im_proposals: 1759/5011 0.126s
im_proposals: 1760/5011 0.126s
im_proposals: 1761/5011 0.126s
im_proposals: 1762/5011 0.126s
im_proposals: 1763/5011 0.126s
im_proposals: 1764/5011 0.126s
im_proposals: 1765/5011 0.126s
im_proposals: 1766/5011 0.126s
im_proposals: 1767/5011 0.126s
im_proposals: 1768/5011 0.126s
im_proposals: 1769/5011 0.126s
im_proposals: 1770/5011 0.126s
im_proposals: 1771/5011 0.126s
im_proposals: 1772/5011 0.126s
im_proposals: 1773/5011 0.126s
im_proposals: 1774/5011 0.126s
im_proposals: 1775/5011 0.126s
im_proposals: 1776/5011 0.126s
im_proposals: 1777/5011 0.126s
im_proposals: 1778/5011 0.126s
im_proposals: 1779/5011 0.126s
im_proposals: 1780/5011 0.126s
im_proposals: 1781/5011 0.126s
im_proposals: 1782/5011 0.126s
im_proposals: 1783/5011 0.126s
im_proposals: 1784/5011 0.126s
im_proposals: 1785/5011 0.126s
im_proposals: 1786/5011 0.126s
im_proposals: 1787/5011 0.126s
im_proposals: 1788/5011 0.126s
im_proposals: 1789/5011 0.126s
im_proposals: 1790/5011 0.126s
im_proposals: 1791/5011 0.126s
im_proposals: 1792/5011 0.126s
im_proposals: 1793/5011 0.126s
im_proposals: 1794/5011 0.126s
im_proposals: 1795/5011 0.126s
im_proposals: 1796/5011 0.126s
im_proposals: 1797/5011 0.126s
im_proposals: 1798/5011 0.126s
im_proposals: 1799/5011 0.126s
im_proposals: 1800/5011 0.126s
im_proposals: 1801/5011 0.126s
im_proposals: 1802/5011 0.126s
im_proposals: 1803/5011 0.126s
im_proposals: 1804/5011 0.126s
im_proposals: 1805/5011 0.126s
im_proposals: 1806/5011 0.126s
im_proposals: 1807/5011 0.126s
im_proposals: 1808/5011 0.126s
im_proposals: 1809/5011 0.126s
im_proposals: 1810/5011 0.126s
im_proposals: 1811/5011 0.126s
im_proposals: 1812/5011 0.126s
im_proposals: 1813/5011 0.126s
im_proposals: 1814/5011 0.126s
im_proposals: 1815/5011 0.126s
im_proposals: 1816/5011 0.126s
im_proposals: 1817/5011 0.126s
im_proposals: 1818/5011 0.126s
im_proposals: 1819/5011 0.126s
im_proposals: 1820/5011 0.126s
im_proposals: 1821/5011 0.126s
im_proposals: 1822/5011 0.126s
im_proposals: 1823/5011 0.126s
im_proposals: 1824/5011 0.126s
im_proposals: 1825/5011 0.126s
im_proposals: 1826/5011 0.126s
im_proposals: 1827/5011 0.126s
im_proposals: 1828/5011 0.126s
im_proposals: 1829/5011 0.126s
im_proposals: 1830/5011 0.126s
im_proposals: 1831/5011 0.126s
im_proposals: 1832/5011 0.126s
im_proposals: 1833/5011 0.126s
im_proposals: 1834/5011 0.126s
im_proposals: 1835/5011 0.126s
im_proposals: 1836/5011 0.126s
im_proposals: 1837/5011 0.126s
im_proposals: 1838/5011 0.126s
im_proposals: 1839/5011 0.126s
im_proposals: 1840/5011 0.126s
im_proposals: 1841/5011 0.126s
im_proposals: 1842/5011 0.126s
im_proposals: 1843/5011 0.126s
im_proposals: 1844/5011 0.126s
im_proposals: 1845/5011 0.126s
im_proposals: 1846/5011 0.126s
im_proposals: 1847/5011 0.126s
im_proposals: 1848/5011 0.126s
im_proposals: 1849/5011 0.126s
im_proposals: 1850/5011 0.126s
im_proposals: 1851/5011 0.126s
im_proposals: 1852/5011 0.126s
im_proposals: 1853/5011 0.126s
im_proposals: 1854/5011 0.126s
im_proposals: 1855/5011 0.126s
im_proposals: 1856/5011 0.126s
im_proposals: 1857/5011 0.126s
im_proposals: 1858/5011 0.126s
im_proposals: 1859/5011 0.126s
im_proposals: 1860/5011 0.126s
im_proposals: 1861/5011 0.126s
im_proposals: 1862/5011 0.126s
im_proposals: 1863/5011 0.126s
im_proposals: 1864/5011 0.126s
im_proposals: 1865/5011 0.126s
im_proposals: 1866/5011 0.126s
im_proposals: 1867/5011 0.126s
im_proposals: 1868/5011 0.126s
im_proposals: 1869/5011 0.126s
im_proposals: 1870/5011 0.126s
im_proposals: 1871/5011 0.126s
im_proposals: 1872/5011 0.126s
im_proposals: 1873/5011 0.126s
im_proposals: 1874/5011 0.126s
im_proposals: 1875/5011 0.126s
im_proposals: 1876/5011 0.126s
im_proposals: 1877/5011 0.126s
im_proposals: 1878/5011 0.126s
im_proposals: 1879/5011 0.126s
im_proposals: 1880/5011 0.126s
im_proposals: 1881/5011 0.126s
im_proposals: 1882/5011 0.126s
im_proposals: 1883/5011 0.126s
im_proposals: 1884/5011 0.126s
im_proposals: 1885/5011 0.126s
im_proposals: 1886/5011 0.126s
im_proposals: 1887/5011 0.126s
im_proposals: 1888/5011 0.126s
im_proposals: 1889/5011 0.126s
im_proposals: 1890/5011 0.126s
im_proposals: 1891/5011 0.126s
im_proposals: 1892/5011 0.126s
im_proposals: 1893/5011 0.126s
im_proposals: 1894/5011 0.126s
im_proposals: 1895/5011 0.126s
im_proposals: 1896/5011 0.126s
im_proposals: 1897/5011 0.126s
im_proposals: 1898/5011 0.126s
im_proposals: 1899/5011 0.126s
im_proposals: 1900/5011 0.126s
im_proposals: 1901/5011 0.126s
im_proposals: 1902/5011 0.126s
im_proposals: 1903/5011 0.126s
im_proposals: 1904/5011 0.126s
im_proposals: 1905/5011 0.126s
im_proposals: 1906/5011 0.126s
im_proposals: 1907/5011 0.126s
im_proposals: 1908/5011 0.126s
im_proposals: 1909/5011 0.126s
im_proposals: 1910/5011 0.126s
im_proposals: 1911/5011 0.126s
im_proposals: 1912/5011 0.126s
im_proposals: 1913/5011 0.126s
im_proposals: 1914/5011 0.126s
im_proposals: 1915/5011 0.126s
im_proposals: 1916/5011 0.126s
im_proposals: 1917/5011 0.126s
im_proposals: 1918/5011 0.126s
im_proposals: 1919/5011 0.126s
im_proposals: 1920/5011 0.126s
im_proposals: 1921/5011 0.126s
im_proposals: 1922/5011 0.126s
im_proposals: 1923/5011 0.126s
im_proposals: 1924/5011 0.126s
im_proposals: 1925/5011 0.126s
im_proposals: 1926/5011 0.126s
im_proposals: 1927/5011 0.126s
im_proposals: 1928/5011 0.126s
im_proposals: 1929/5011 0.126s
im_proposals: 1930/5011 0.126s
im_proposals: 1931/5011 0.126s
im_proposals: 1932/5011 0.126s
im_proposals: 1933/5011 0.126s
im_proposals: 1934/5011 0.126s
im_proposals: 1935/5011 0.126s
im_proposals: 1936/5011 0.126s
im_proposals: 1937/5011 0.126s
im_proposals: 1938/5011 0.126s
im_proposals: 1939/5011 0.126s
im_proposals: 1940/5011 0.126s
im_proposals: 1941/5011 0.126s
im_proposals: 1942/5011 0.126s
im_proposals: 1943/5011 0.126s
im_proposals: 1944/5011 0.126s
im_proposals: 1945/5011 0.126s
im_proposals: 1946/5011 0.126s
im_proposals: 1947/5011 0.126s
im_proposals: 1948/5011 0.126s
im_proposals: 1949/5011 0.126s
im_proposals: 1950/5011 0.126s
im_proposals: 1951/5011 0.126s
im_proposals: 1952/5011 0.126s
im_proposals: 1953/5011 0.126s
im_proposals: 1954/5011 0.126s
im_proposals: 1955/5011 0.126s
im_proposals: 1956/5011 0.126s
im_proposals: 1957/5011 0.126s
im_proposals: 1958/5011 0.126s
im_proposals: 1959/5011 0.126s
im_proposals: 1960/5011 0.126s
im_proposals: 1961/5011 0.126s
im_proposals: 1962/5011 0.126s
im_proposals: 1963/5011 0.126s
im_proposals: 1964/5011 0.126s
im_proposals: 1965/5011 0.126s
im_proposals: 1966/5011 0.126s
im_proposals: 1967/5011 0.126s
im_proposals: 1968/5011 0.126s
im_proposals: 1969/5011 0.126s
im_proposals: 1970/5011 0.126s
im_proposals: 1971/5011 0.126s
im_proposals: 1972/5011 0.126s
im_proposals: 1973/5011 0.126s
im_proposals: 1974/5011 0.126s
im_proposals: 1975/5011 0.126s
im_proposals: 1976/5011 0.126s
im_proposals: 1977/5011 0.126s
im_proposals: 1978/5011 0.126s
im_proposals: 1979/5011 0.126s
im_proposals: 1980/5011 0.126s
im_proposals: 1981/5011 0.126s
im_proposals: 1982/5011 0.126s
im_proposals: 1983/5011 0.126s
im_proposals: 1984/5011 0.126s
im_proposals: 1985/5011 0.126s
im_proposals: 1986/5011 0.126s
im_proposals: 1987/5011 0.126s
im_proposals: 1988/5011 0.126s
im_proposals: 1989/5011 0.126s
im_proposals: 1990/5011 0.126s
im_proposals: 1991/5011 0.126s
im_proposals: 1992/5011 0.126s
im_proposals: 1993/5011 0.126s
im_proposals: 1994/5011 0.126s
im_proposals: 1995/5011 0.126s
im_proposals: 1996/5011 0.126s
im_proposals: 1997/5011 0.126s
im_proposals: 1998/5011 0.126s
im_proposals: 1999/5011 0.126s
im_proposals: 2000/5011 0.126s
im_proposals: 2001/5011 0.126s
im_proposals: 2002/5011 0.126s
im_proposals: 2003/5011 0.126s
im_proposals: 2004/5011 0.126s
im_proposals: 2005/5011 0.126s
im_proposals: 2006/5011 0.126s
im_proposals: 2007/5011 0.126s
im_proposals: 2008/5011 0.126s
im_proposals: 2009/5011 0.126s
im_proposals: 2010/5011 0.126s
im_proposals: 2011/5011 0.126s
im_proposals: 2012/5011 0.126s
im_proposals: 2013/5011 0.126s
im_proposals: 2014/5011 0.126s
im_proposals: 2015/5011 0.126s
im_proposals: 2016/5011 0.126s
im_proposals: 2017/5011 0.126s
im_proposals: 2018/5011 0.126s
im_proposals: 2019/5011 0.126s
im_proposals: 2020/5011 0.126s
im_proposals: 2021/5011 0.126s
im_proposals: 2022/5011 0.126s
im_proposals: 2023/5011 0.126s
im_proposals: 2024/5011 0.126s
im_proposals: 2025/5011 0.126s
im_proposals: 2026/5011 0.126s
im_proposals: 2027/5011 0.126s
im_proposals: 2028/5011 0.126s
im_proposals: 2029/5011 0.126s
im_proposals: 2030/5011 0.126s
im_proposals: 2031/5011 0.126s
im_proposals: 2032/5011 0.126s
im_proposals: 2033/5011 0.126s
im_proposals: 2034/5011 0.126s
im_proposals: 2035/5011 0.126s
im_proposals: 2036/5011 0.126s
im_proposals: 2037/5011 0.126s
im_proposals: 2038/5011 0.126s
im_proposals: 2039/5011 0.126s
im_proposals: 2040/5011 0.126s
im_proposals: 2041/5011 0.126s
im_proposals: 2042/5011 0.126s
im_proposals: 2043/5011 0.126s
im_proposals: 2044/5011 0.126s
im_proposals: 2045/5011 0.126s
im_proposals: 2046/5011 0.126s
im_proposals: 2047/5011 0.126s
im_proposals: 2048/5011 0.126s
im_proposals: 2049/5011 0.126s
im_proposals: 2050/5011 0.126s
im_proposals: 2051/5011 0.126s
im_proposals: 2052/5011 0.126s
im_proposals: 2053/5011 0.126s
im_proposals: 2054/5011 0.126s
im_proposals: 2055/5011 0.126s
im_proposals: 2056/5011 0.126s
im_proposals: 2057/5011 0.126s
im_proposals: 2058/5011 0.126s
im_proposals: 2059/5011 0.126s
im_proposals: 2060/5011 0.126s
im_proposals: 2061/5011 0.126s
im_proposals: 2062/5011 0.126s
im_proposals: 2063/5011 0.126s
im_proposals: 2064/5011 0.126s
im_proposals: 2065/5011 0.126s
im_proposals: 2066/5011 0.126s
im_proposals: 2067/5011 0.126s
im_proposals: 2068/5011 0.126s
im_proposals: 2069/5011 0.126s
im_proposals: 2070/5011 0.126s
im_proposals: 2071/5011 0.126s
im_proposals: 2072/5011 0.126s
im_proposals: 2073/5011 0.126s
im_proposals: 2074/5011 0.126s
im_proposals: 2075/5011 0.126s
im_proposals: 2076/5011 0.126s
im_proposals: 2077/5011 0.126s
im_proposals: 2078/5011 0.126s
im_proposals: 2079/5011 0.126s
im_proposals: 2080/5011 0.126s
im_proposals: 2081/5011 0.126s
im_proposals: 2082/5011 0.126s
im_proposals: 2083/5011 0.126s
im_proposals: 2084/5011 0.126s
im_proposals: 2085/5011 0.126s
im_proposals: 2086/5011 0.126s
im_proposals: 2087/5011 0.126s
im_proposals: 2088/5011 0.126s
im_proposals: 2089/5011 0.126s
im_proposals: 2090/5011 0.126s
im_proposals: 2091/5011 0.126s
im_proposals: 2092/5011 0.126s
im_proposals: 2093/5011 0.126s
im_proposals: 2094/5011 0.126s
im_proposals: 2095/5011 0.126s
im_proposals: 2096/5011 0.126s
im_proposals: 2097/5011 0.126s
im_proposals: 2098/5011 0.126s
im_proposals: 2099/5011 0.126s
im_proposals: 2100/5011 0.126s
im_proposals: 2101/5011 0.126s
im_proposals: 2102/5011 0.126s
im_proposals: 2103/5011 0.126s
im_proposals: 2104/5011 0.126s
im_proposals: 2105/5011 0.126s
im_proposals: 2106/5011 0.126s
im_proposals: 2107/5011 0.126s
im_proposals: 2108/5011 0.126s
im_proposals: 2109/5011 0.126s
im_proposals: 2110/5011 0.126s
im_proposals: 2111/5011 0.126s
im_proposals: 2112/5011 0.126s
im_proposals: 2113/5011 0.126s
im_proposals: 2114/5011 0.126s
im_proposals: 2115/5011 0.126s
im_proposals: 2116/5011 0.126s
im_proposals: 2117/5011 0.126s
im_proposals: 2118/5011 0.126s
im_proposals: 2119/5011 0.126s
im_proposals: 2120/5011 0.126s
im_proposals: 2121/5011 0.126s
im_proposals: 2122/5011 0.126s
im_proposals: 2123/5011 0.126s
im_proposals: 2124/5011 0.126s
im_proposals: 2125/5011 0.126s
im_proposals: 2126/5011 0.126s
im_proposals: 2127/5011 0.126s
im_proposals: 2128/5011 0.126s
im_proposals: 2129/5011 0.126s
im_proposals: 2130/5011 0.126s
im_proposals: 2131/5011 0.126s
im_proposals: 2132/5011 0.126s
im_proposals: 2133/5011 0.126s
im_proposals: 2134/5011 0.126s
im_proposals: 2135/5011 0.126s
im_proposals: 2136/5011 0.126s
im_proposals: 2137/5011 0.126s
im_proposals: 2138/5011 0.126s
im_proposals: 2139/5011 0.126s
im_proposals: 2140/5011 0.126s
im_proposals: 2141/5011 0.126s
im_proposals: 2142/5011 0.126s
im_proposals: 2143/5011 0.126s
im_proposals: 2144/5011 0.126s
im_proposals: 2145/5011 0.126s
im_proposals: 2146/5011 0.126s
im_proposals: 2147/5011 0.126s
im_proposals: 2148/5011 0.126s
im_proposals: 2149/5011 0.126s
im_proposals: 2150/5011 0.126s
im_proposals: 2151/5011 0.126s
im_proposals: 2152/5011 0.126s
im_proposals: 2153/5011 0.126s
im_proposals: 2154/5011 0.126s
im_proposals: 2155/5011 0.126s
im_proposals: 2156/5011 0.126s
im_proposals: 2157/5011 0.126s
im_proposals: 2158/5011 0.126s
im_proposals: 2159/5011 0.126s
im_proposals: 2160/5011 0.126s
im_proposals: 2161/5011 0.126s
im_proposals: 2162/5011 0.126s
im_proposals: 2163/5011 0.126s
im_proposals: 2164/5011 0.126s
im_proposals: 2165/5011 0.126s
im_proposals: 2166/5011 0.126s
im_proposals: 2167/5011 0.126s
im_proposals: 2168/5011 0.126s
im_proposals: 2169/5011 0.126s
im_proposals: 2170/5011 0.126s
im_proposals: 2171/5011 0.126s
im_proposals: 2172/5011 0.126s
im_proposals: 2173/5011 0.126s
im_proposals: 2174/5011 0.126s
im_proposals: 2175/5011 0.126s
im_proposals: 2176/5011 0.126s
im_proposals: 2177/5011 0.126s
im_proposals: 2178/5011 0.126s
im_proposals: 2179/5011 0.126s
im_proposals: 2180/5011 0.126s
im_proposals: 2181/5011 0.126s
im_proposals: 2182/5011 0.126s
im_proposals: 2183/5011 0.126s
im_proposals: 2184/5011 0.126s
im_proposals: 2185/5011 0.126s
im_proposals: 2186/5011 0.126s
im_proposals: 2187/5011 0.126s
im_proposals: 2188/5011 0.126s
im_proposals: 2189/5011 0.126s
im_proposals: 2190/5011 0.126s
im_proposals: 2191/5011 0.126s
im_proposals: 2192/5011 0.126s
im_proposals: 2193/5011 0.126s
im_proposals: 2194/5011 0.126s
im_proposals: 2195/5011 0.126s
im_proposals: 2196/5011 0.126s
im_proposals: 2197/5011 0.126s
im_proposals: 2198/5011 0.126s
im_proposals: 2199/5011 0.126s
im_proposals: 2200/5011 0.126s
im_proposals: 2201/5011 0.126s
im_proposals: 2202/5011 0.126s
im_proposals: 2203/5011 0.126s
im_proposals: 2204/5011 0.126s
im_proposals: 2205/5011 0.126s
im_proposals: 2206/5011 0.126s
im_proposals: 2207/5011 0.126s
im_proposals: 2208/5011 0.126s
im_proposals: 2209/5011 0.126s
im_proposals: 2210/5011 0.126s
im_proposals: 2211/5011 0.126s
im_proposals: 2212/5011 0.126s
im_proposals: 2213/5011 0.126s
im_proposals: 2214/5011 0.126s
im_proposals: 2215/5011 0.126s
im_proposals: 2216/5011 0.126s
im_proposals: 2217/5011 0.126s
im_proposals: 2218/5011 0.126s
im_proposals: 2219/5011 0.126s
im_proposals: 2220/5011 0.126s
im_proposals: 2221/5011 0.126s
im_proposals: 2222/5011 0.126s
im_proposals: 2223/5011 0.126s
im_proposals: 2224/5011 0.126s
im_proposals: 2225/5011 0.126s
im_proposals: 2226/5011 0.126s
im_proposals: 2227/5011 0.126s
im_proposals: 2228/5011 0.126s
im_proposals: 2229/5011 0.126s
im_proposals: 2230/5011 0.126s
im_proposals: 2231/5011 0.126s
im_proposals: 2232/5011 0.126s
im_proposals: 2233/5011 0.126s
im_proposals: 2234/5011 0.126s
im_proposals: 2235/5011 0.126s
im_proposals: 2236/5011 0.126s
im_proposals: 2237/5011 0.126s
im_proposals: 2238/5011 0.126s
im_proposals: 2239/5011 0.126s
im_proposals: 2240/5011 0.126s
im_proposals: 2241/5011 0.126s
im_proposals: 2242/5011 0.126s
im_proposals: 2243/5011 0.126s
im_proposals: 2244/5011 0.126s
im_proposals: 2245/5011 0.126s
im_proposals: 2246/5011 0.126s
im_proposals: 2247/5011 0.126s
im_proposals: 2248/5011 0.126s
im_proposals: 2249/5011 0.126s
im_proposals: 2250/5011 0.126s
im_proposals: 2251/5011 0.126s
im_proposals: 2252/5011 0.126s
im_proposals: 2253/5011 0.126s
im_proposals: 2254/5011 0.126s
im_proposals: 2255/5011 0.126s
im_proposals: 2256/5011 0.126s
im_proposals: 2257/5011 0.126s
im_proposals: 2258/5011 0.126s
im_proposals: 2259/5011 0.126s
im_proposals: 2260/5011 0.126s
im_proposals: 2261/5011 0.126s
im_proposals: 2262/5011 0.126s
im_proposals: 2263/5011 0.126s
im_proposals: 2264/5011 0.126s
im_proposals: 2265/5011 0.126s
im_proposals: 2266/5011 0.126s
im_proposals: 2267/5011 0.126s
im_proposals: 2268/5011 0.126s
im_proposals: 2269/5011 0.126s
im_proposals: 2270/5011 0.126s
im_proposals: 2271/5011 0.126s
im_proposals: 2272/5011 0.126s
im_proposals: 2273/5011 0.126s
im_proposals: 2274/5011 0.126s
im_proposals: 2275/5011 0.126s
im_proposals: 2276/5011 0.126s
im_proposals: 2277/5011 0.126s
im_proposals: 2278/5011 0.126s
im_proposals: 2279/5011 0.126s
im_proposals: 2280/5011 0.126s
im_proposals: 2281/5011 0.126s
im_proposals: 2282/5011 0.126s
im_proposals: 2283/5011 0.126s
im_proposals: 2284/5011 0.126s
im_proposals: 2285/5011 0.126s
im_proposals: 2286/5011 0.126s
im_proposals: 2287/5011 0.126s
im_proposals: 2288/5011 0.126s
im_proposals: 2289/5011 0.126s
im_proposals: 2290/5011 0.126s
im_proposals: 2291/5011 0.126s
im_proposals: 2292/5011 0.126s
im_proposals: 2293/5011 0.126s
im_proposals: 2294/5011 0.126s
im_proposals: 2295/5011 0.126s
im_proposals: 2296/5011 0.126s
im_proposals: 2297/5011 0.126s
im_proposals: 2298/5011 0.126s
im_proposals: 2299/5011 0.126s
im_proposals: 2300/5011 0.126s
im_proposals: 2301/5011 0.126s
im_proposals: 2302/5011 0.126s
im_proposals: 2303/5011 0.126s
im_proposals: 2304/5011 0.126s
im_proposals: 2305/5011 0.126s
im_proposals: 2306/5011 0.126s
im_proposals: 2307/5011 0.126s
im_proposals: 2308/5011 0.126s
im_proposals: 2309/5011 0.126s
im_proposals: 2310/5011 0.126s
im_proposals: 2311/5011 0.126s
im_proposals: 2312/5011 0.126s
im_proposals: 2313/5011 0.126s
im_proposals: 2314/5011 0.126s
im_proposals: 2315/5011 0.126s
im_proposals: 2316/5011 0.126s
im_proposals: 2317/5011 0.126s
im_proposals: 2318/5011 0.126s
im_proposals: 2319/5011 0.126s
im_proposals: 2320/5011 0.126s
im_proposals: 2321/5011 0.126s
im_proposals: 2322/5011 0.126s
im_proposals: 2323/5011 0.126s
im_proposals: 2324/5011 0.126s
im_proposals: 2325/5011 0.126s
im_proposals: 2326/5011 0.126s
im_proposals: 2327/5011 0.126s
im_proposals: 2328/5011 0.126s
im_proposals: 2329/5011 0.126s
im_proposals: 2330/5011 0.126s
im_proposals: 2331/5011 0.126s
im_proposals: 2332/5011 0.126s
im_proposals: 2333/5011 0.126s
im_proposals: 2334/5011 0.126s
im_proposals: 2335/5011 0.126s
im_proposals: 2336/5011 0.126s
im_proposals: 2337/5011 0.126s
im_proposals: 2338/5011 0.126s
im_proposals: 2339/5011 0.126s
im_proposals: 2340/5011 0.126s
im_proposals: 2341/5011 0.126s
im_proposals: 2342/5011 0.126s
im_proposals: 2343/5011 0.126s
im_proposals: 2344/5011 0.126s
im_proposals: 2345/5011 0.126s
im_proposals: 2346/5011 0.126s
im_proposals: 2347/5011 0.126s
im_proposals: 2348/5011 0.126s
im_proposals: 2349/5011 0.126s
im_proposals: 2350/5011 0.126s
im_proposals: 2351/5011 0.126s
im_proposals: 2352/5011 0.126s
im_proposals: 2353/5011 0.126s
im_proposals: 2354/5011 0.126s
im_proposals: 2355/5011 0.126s
im_proposals: 2356/5011 0.126s
im_proposals: 2357/5011 0.126s
im_proposals: 2358/5011 0.126s
im_proposals: 2359/5011 0.126s
im_proposals: 2360/5011 0.126s
im_proposals: 2361/5011 0.126s
im_proposals: 2362/5011 0.126s
im_proposals: 2363/5011 0.126s
im_proposals: 2364/5011 0.126s
im_proposals: 2365/5011 0.126s
im_proposals: 2366/5011 0.126s
im_proposals: 2367/5011 0.126s
im_proposals: 2368/5011 0.126s
im_proposals: 2369/5011 0.126s
im_proposals: 2370/5011 0.126s
im_proposals: 2371/5011 0.126s
im_proposals: 2372/5011 0.126s
im_proposals: 2373/5011 0.126s
im_proposals: 2374/5011 0.126s
im_proposals: 2375/5011 0.126s
im_proposals: 2376/5011 0.126s
im_proposals: 2377/5011 0.126s
im_proposals: 2378/5011 0.126s
im_proposals: 2379/5011 0.126s
im_proposals: 2380/5011 0.126s
im_proposals: 2381/5011 0.126s
im_proposals: 2382/5011 0.126s
im_proposals: 2383/5011 0.126s
im_proposals: 2384/5011 0.126s
im_proposals: 2385/5011 0.126s
im_proposals: 2386/5011 0.126s
im_proposals: 2387/5011 0.126s
im_proposals: 2388/5011 0.126s
im_proposals: 2389/5011 0.126s
im_proposals: 2390/5011 0.126s
im_proposals: 2391/5011 0.126s
im_proposals: 2392/5011 0.126s
im_proposals: 2393/5011 0.126s
im_proposals: 2394/5011 0.126s
im_proposals: 2395/5011 0.126s
im_proposals: 2396/5011 0.126s
im_proposals: 2397/5011 0.126s
im_proposals: 2398/5011 0.126s
im_proposals: 2399/5011 0.126s
im_proposals: 2400/5011 0.126s
im_proposals: 2401/5011 0.126s
im_proposals: 2402/5011 0.126s
im_proposals: 2403/5011 0.126s
im_proposals: 2404/5011 0.126s
im_proposals: 2405/5011 0.126s
im_proposals: 2406/5011 0.126s
im_proposals: 2407/5011 0.126s
im_proposals: 2408/5011 0.126s
im_proposals: 2409/5011 0.126s
im_proposals: 2410/5011 0.126s
im_proposals: 2411/5011 0.126s
im_proposals: 2412/5011 0.126s
im_proposals: 2413/5011 0.126s
im_proposals: 2414/5011 0.126s
im_proposals: 2415/5011 0.126s
im_proposals: 2416/5011 0.126s
im_proposals: 2417/5011 0.126s
im_proposals: 2418/5011 0.126s
im_proposals: 2419/5011 0.126s
im_proposals: 2420/5011 0.126s
im_proposals: 2421/5011 0.126s
im_proposals: 2422/5011 0.126s
im_proposals: 2423/5011 0.126s
im_proposals: 2424/5011 0.126s
im_proposals: 2425/5011 0.126s
im_proposals: 2426/5011 0.126s
im_proposals: 2427/5011 0.126s
im_proposals: 2428/5011 0.126s
im_proposals: 2429/5011 0.126s
im_proposals: 2430/5011 0.126s
im_proposals: 2431/5011 0.126s
im_proposals: 2432/5011 0.126s
im_proposals: 2433/5011 0.126s
im_proposals: 2434/5011 0.126s
im_proposals: 2435/5011 0.126s
im_proposals: 2436/5011 0.126s
im_proposals: 2437/5011 0.126s
im_proposals: 2438/5011 0.126s
im_proposals: 2439/5011 0.126s
im_proposals: 2440/5011 0.126s
im_proposals: 2441/5011 0.126s
im_proposals: 2442/5011 0.126s
im_proposals: 2443/5011 0.126s
im_proposals: 2444/5011 0.126s
im_proposals: 2445/5011 0.126s
im_proposals: 2446/5011 0.126s
im_proposals: 2447/5011 0.126s
im_proposals: 2448/5011 0.126s
im_proposals: 2449/5011 0.126s
im_proposals: 2450/5011 0.126s
im_proposals: 2451/5011 0.126s
im_proposals: 2452/5011 0.126s
im_proposals: 2453/5011 0.126s
im_proposals: 2454/5011 0.126s
im_proposals: 2455/5011 0.126s
im_proposals: 2456/5011 0.126s
im_proposals: 2457/5011 0.126s
im_proposals: 2458/5011 0.126s
im_proposals: 2459/5011 0.126s
im_proposals: 2460/5011 0.126s
im_proposals: 2461/5011 0.126s
im_proposals: 2462/5011 0.126s
im_proposals: 2463/5011 0.126s
im_proposals: 2464/5011 0.126s
im_proposals: 2465/5011 0.126s
im_proposals: 2466/5011 0.126s
im_proposals: 2467/5011 0.126s
im_proposals: 2468/5011 0.126s
im_proposals: 2469/5011 0.126s
im_proposals: 2470/5011 0.126s
im_proposals: 2471/5011 0.126s
im_proposals: 2472/5011 0.126s
im_proposals: 2473/5011 0.126s
im_proposals: 2474/5011 0.126s
im_proposals: 2475/5011 0.126s
im_proposals: 2476/5011 0.126s
im_proposals: 2477/5011 0.126s
im_proposals: 2478/5011 0.126s
im_proposals: 2479/5011 0.126s
im_proposals: 2480/5011 0.126s
im_proposals: 2481/5011 0.126s
im_proposals: 2482/5011 0.126s
im_proposals: 2483/5011 0.126s
im_proposals: 2484/5011 0.126s
im_proposals: 2485/5011 0.126s
im_proposals: 2486/5011 0.126s
im_proposals: 2487/5011 0.126s
im_proposals: 2488/5011 0.126s
im_proposals: 2489/5011 0.126s
im_proposals: 2490/5011 0.126s
im_proposals: 2491/5011 0.126s
im_proposals: 2492/5011 0.126s
im_proposals: 2493/5011 0.126s
im_proposals: 2494/5011 0.126s
im_proposals: 2495/5011 0.126s
im_proposals: 2496/5011 0.126s
im_proposals: 2497/5011 0.126s
im_proposals: 2498/5011 0.126s
im_proposals: 2499/5011 0.126s
im_proposals: 2500/5011 0.126s
im_proposals: 2501/5011 0.126s
im_proposals: 2502/5011 0.126s
im_proposals: 2503/5011 0.126s
im_proposals: 2504/5011 0.126s
im_proposals: 2505/5011 0.126s
im_proposals: 2506/5011 0.126s
im_proposals: 2507/5011 0.126s
im_proposals: 2508/5011 0.126s
im_proposals: 2509/5011 0.126s
im_proposals: 2510/5011 0.126s
im_proposals: 2511/5011 0.126s
im_proposals: 2512/5011 0.126s
im_proposals: 2513/5011 0.126s
im_proposals: 2514/5011 0.126s
im_proposals: 2515/5011 0.126s
im_proposals: 2516/5011 0.126s
im_proposals: 2517/5011 0.126s
im_proposals: 2518/5011 0.126s
im_proposals: 2519/5011 0.126s
im_proposals: 2520/5011 0.126s
im_proposals: 2521/5011 0.126s
im_proposals: 2522/5011 0.126s
im_proposals: 2523/5011 0.126s
im_proposals: 2524/5011 0.126s
im_proposals: 2525/5011 0.126s
im_proposals: 2526/5011 0.126s
im_proposals: 2527/5011 0.126s
im_proposals: 2528/5011 0.126s
im_proposals: 2529/5011 0.126s
im_proposals: 2530/5011 0.126s
im_proposals: 2531/5011 0.126s
im_proposals: 2532/5011 0.126s
im_proposals: 2533/5011 0.126s
im_proposals: 2534/5011 0.126s
im_proposals: 2535/5011 0.126s
im_proposals: 2536/5011 0.126s
im_proposals: 2537/5011 0.126s
im_proposals: 2538/5011 0.126s
im_proposals: 2539/5011 0.126s
im_proposals: 2540/5011 0.126s
im_proposals: 2541/5011 0.126s
im_proposals: 2542/5011 0.126s
im_proposals: 2543/5011 0.126s
im_proposals: 2544/5011 0.126s
im_proposals: 2545/5011 0.126s
im_proposals: 2546/5011 0.126s
im_proposals: 2547/5011 0.126s
im_proposals: 2548/5011 0.126s
im_proposals: 2549/5011 0.126s
im_proposals: 2550/5011 0.126s
im_proposals: 2551/5011 0.126s
im_proposals: 2552/5011 0.126s
im_proposals: 2553/5011 0.126s
im_proposals: 2554/5011 0.126s
im_proposals: 2555/5011 0.126s
im_proposals: 2556/5011 0.126s
im_proposals: 2557/5011 0.126s
im_proposals: 2558/5011 0.126s
im_proposals: 2559/5011 0.126s
im_proposals: 2560/5011 0.126s
im_proposals: 2561/5011 0.126s
im_proposals: 2562/5011 0.126s
im_proposals: 2563/5011 0.126s
im_proposals: 2564/5011 0.126s
im_proposals: 2565/5011 0.126s
im_proposals: 2566/5011 0.126s
im_proposals: 2567/5011 0.126s
im_proposals: 2568/5011 0.126s
im_proposals: 2569/5011 0.126s
im_proposals: 2570/5011 0.126s
im_proposals: 2571/5011 0.126s
im_proposals: 2572/5011 0.126s
im_proposals: 2573/5011 0.126s
im_proposals: 2574/5011 0.126s
im_proposals: 2575/5011 0.126s
im_proposals: 2576/5011 0.126s
im_proposals: 2577/5011 0.126s
im_proposals: 2578/5011 0.126s
im_proposals: 2579/5011 0.126s
im_proposals: 2580/5011 0.126s
im_proposals: 2581/5011 0.126s
im_proposals: 2582/5011 0.126s
im_proposals: 2583/5011 0.126s
im_proposals: 2584/5011 0.126s
im_proposals: 2585/5011 0.126s
im_proposals: 2586/5011 0.126s
im_proposals: 2587/5011 0.126s
im_proposals: 2588/5011 0.126s
im_proposals: 2589/5011 0.126s
im_proposals: 2590/5011 0.126s
im_proposals: 2591/5011 0.126s
im_proposals: 2592/5011 0.126s
im_proposals: 2593/5011 0.126s
im_proposals: 2594/5011 0.126s
im_proposals: 2595/5011 0.126s
im_proposals: 2596/5011 0.126s
im_proposals: 2597/5011 0.126s
im_proposals: 2598/5011 0.126s
im_proposals: 2599/5011 0.126s
im_proposals: 2600/5011 0.126s
im_proposals: 2601/5011 0.126s
im_proposals: 2602/5011 0.126s
im_proposals: 2603/5011 0.126s
im_proposals: 2604/5011 0.126s
im_proposals: 2605/5011 0.126s
im_proposals: 2606/5011 0.126s
im_proposals: 2607/5011 0.126s
im_proposals: 2608/5011 0.126s
im_proposals: 2609/5011 0.126s
im_proposals: 2610/5011 0.126s
im_proposals: 2611/5011 0.126s
im_proposals: 2612/5011 0.126s
im_proposals: 2613/5011 0.126s
im_proposals: 2614/5011 0.126s
im_proposals: 2615/5011 0.126s
im_proposals: 2616/5011 0.126s
im_proposals: 2617/5011 0.126s
im_proposals: 2618/5011 0.126s
im_proposals: 2619/5011 0.126s
im_proposals: 2620/5011 0.126s
im_proposals: 2621/5011 0.126s
im_proposals: 2622/5011 0.126s
im_proposals: 2623/5011 0.126s
im_proposals: 2624/5011 0.126s
im_proposals: 2625/5011 0.126s
im_proposals: 2626/5011 0.126s
im_proposals: 2627/5011 0.126s
im_proposals: 2628/5011 0.126s
im_proposals: 2629/5011 0.126s
im_proposals: 2630/5011 0.126s
im_proposals: 2631/5011 0.126s
im_proposals: 2632/5011 0.126s
im_proposals: 2633/5011 0.126s
im_proposals: 2634/5011 0.126s
im_proposals: 2635/5011 0.126s
im_proposals: 2636/5011 0.126s
im_proposals: 2637/5011 0.126s
im_proposals: 2638/5011 0.126s
im_proposals: 2639/5011 0.126s
im_proposals: 2640/5011 0.126s
im_proposals: 2641/5011 0.126s
im_proposals: 2642/5011 0.126s
im_proposals: 2643/5011 0.126s
im_proposals: 2644/5011 0.126s
im_proposals: 2645/5011 0.126s
im_proposals: 2646/5011 0.126s
im_proposals: 2647/5011 0.126s
im_proposals: 2648/5011 0.126s
im_proposals: 2649/5011 0.126s
im_proposals: 2650/5011 0.126s
im_proposals: 2651/5011 0.126s
im_proposals: 2652/5011 0.126s
im_proposals: 2653/5011 0.126s
im_proposals: 2654/5011 0.126s
im_proposals: 2655/5011 0.126s
im_proposals: 2656/5011 0.126s
im_proposals: 2657/5011 0.126s
im_proposals: 2658/5011 0.126s
im_proposals: 2659/5011 0.126s
im_proposals: 2660/5011 0.126s
im_proposals: 2661/5011 0.126s
im_proposals: 2662/5011 0.126s
im_proposals: 2663/5011 0.126s
im_proposals: 2664/5011 0.126s
im_proposals: 2665/5011 0.126s
im_proposals: 2666/5011 0.126s
im_proposals: 2667/5011 0.126s
im_proposals: 2668/5011 0.126s
im_proposals: 2669/5011 0.126s
im_proposals: 2670/5011 0.126s
im_proposals: 2671/5011 0.126s
im_proposals: 2672/5011 0.126s
im_proposals: 2673/5011 0.126s
im_proposals: 2674/5011 0.126s
im_proposals: 2675/5011 0.126s
im_proposals: 2676/5011 0.126s
im_proposals: 2677/5011 0.126s
im_proposals: 2678/5011 0.126s
im_proposals: 2679/5011 0.126s
im_proposals: 2680/5011 0.126s
im_proposals: 2681/5011 0.126s
im_proposals: 2682/5011 0.126s
im_proposals: 2683/5011 0.126s
im_proposals: 2684/5011 0.126s
im_proposals: 2685/5011 0.126s
im_proposals: 2686/5011 0.126s
im_proposals: 2687/5011 0.126s
im_proposals: 2688/5011 0.126s
im_proposals: 2689/5011 0.126s
im_proposals: 2690/5011 0.126s
im_proposals: 2691/5011 0.126s
im_proposals: 2692/5011 0.126s
im_proposals: 2693/5011 0.126s
im_proposals: 2694/5011 0.126s
im_proposals: 2695/5011 0.126s
im_proposals: 2696/5011 0.126s
im_proposals: 2697/5011 0.126s
im_proposals: 2698/5011 0.126s
im_proposals: 2699/5011 0.126s
im_proposals: 2700/5011 0.126s
im_proposals: 2701/5011 0.126s
im_proposals: 2702/5011 0.126s
im_proposals: 2703/5011 0.126s
im_proposals: 2704/5011 0.126s
im_proposals: 2705/5011 0.126s
im_proposals: 2706/5011 0.126s
im_proposals: 2707/5011 0.126s
im_proposals: 2708/5011 0.126s
im_proposals: 2709/5011 0.126s
im_proposals: 2710/5011 0.126s
im_proposals: 2711/5011 0.126s
im_proposals: 2712/5011 0.126s
im_proposals: 2713/5011 0.126s
im_proposals: 2714/5011 0.126s
im_proposals: 2715/5011 0.126s
im_proposals: 2716/5011 0.126s
im_proposals: 2717/5011 0.126s
im_proposals: 2718/5011 0.126s
im_proposals: 2719/5011 0.126s
im_proposals: 2720/5011 0.126s
im_proposals: 2721/5011 0.126s
im_proposals: 2722/5011 0.126s
im_proposals: 2723/5011 0.126s
im_proposals: 2724/5011 0.126s
im_proposals: 2725/5011 0.126s
im_proposals: 2726/5011 0.126s
im_proposals: 2727/5011 0.126s
im_proposals: 2728/5011 0.126s
im_proposals: 2729/5011 0.126s
im_proposals: 2730/5011 0.126s
im_proposals: 2731/5011 0.126s
im_proposals: 2732/5011 0.126s
im_proposals: 2733/5011 0.126s
im_proposals: 2734/5011 0.126s
im_proposals: 2735/5011 0.126s
im_proposals: 2736/5011 0.126s
im_proposals: 2737/5011 0.126s
im_proposals: 2738/5011 0.126s
im_proposals: 2739/5011 0.126s
im_proposals: 2740/5011 0.126s
im_proposals: 2741/5011 0.126s
im_proposals: 2742/5011 0.126s
im_proposals: 2743/5011 0.126s
im_proposals: 2744/5011 0.126s
im_proposals: 2745/5011 0.126s
im_proposals: 2746/5011 0.126s
im_proposals: 2747/5011 0.126s
im_proposals: 2748/5011 0.126s
im_proposals: 2749/5011 0.126s
im_proposals: 2750/5011 0.126s
im_proposals: 2751/5011 0.126s
im_proposals: 2752/5011 0.126s
im_proposals: 2753/5011 0.126s
im_proposals: 2754/5011 0.126s
im_proposals: 2755/5011 0.126s
im_proposals: 2756/5011 0.126s
im_proposals: 2757/5011 0.126s
im_proposals: 2758/5011 0.126s
im_proposals: 2759/5011 0.126s
im_proposals: 2760/5011 0.126s
im_proposals: 2761/5011 0.126s
im_proposals: 2762/5011 0.126s
im_proposals: 2763/5011 0.126s
im_proposals: 2764/5011 0.126s
im_proposals: 2765/5011 0.126s
im_proposals: 2766/5011 0.126s
im_proposals: 2767/5011 0.126s
im_proposals: 2768/5011 0.126s
im_proposals: 2769/5011 0.126s
im_proposals: 2770/5011 0.126s
im_proposals: 2771/5011 0.126s
im_proposals: 2772/5011 0.126s
im_proposals: 2773/5011 0.126s
im_proposals: 2774/5011 0.126s
im_proposals: 2775/5011 0.126s
im_proposals: 2776/5011 0.126s
im_proposals: 2777/5011 0.126s
im_proposals: 2778/5011 0.126s
im_proposals: 2779/5011 0.126s
im_proposals: 2780/5011 0.126s
im_proposals: 2781/5011 0.126s
im_proposals: 2782/5011 0.126s
im_proposals: 2783/5011 0.126s
im_proposals: 2784/5011 0.126s
im_proposals: 2785/5011 0.126s
im_proposals: 2786/5011 0.126s
im_proposals: 2787/5011 0.126s
im_proposals: 2788/5011 0.126s
im_proposals: 2789/5011 0.126s
im_proposals: 2790/5011 0.126s
im_proposals: 2791/5011 0.126s
im_proposals: 2792/5011 0.126s
im_proposals: 2793/5011 0.126s
im_proposals: 2794/5011 0.126s
im_proposals: 2795/5011 0.126s
im_proposals: 2796/5011 0.126s
im_proposals: 2797/5011 0.126s
im_proposals: 2798/5011 0.126s
im_proposals: 2799/5011 0.126s
im_proposals: 2800/5011 0.126s
im_proposals: 2801/5011 0.126s
im_proposals: 2802/5011 0.126s
im_proposals: 2803/5011 0.126s
im_proposals: 2804/5011 0.126s
im_proposals: 2805/5011 0.126s
im_proposals: 2806/5011 0.126s
im_proposals: 2807/5011 0.126s
im_proposals: 2808/5011 0.126s
im_proposals: 2809/5011 0.126s
im_proposals: 2810/5011 0.126s
im_proposals: 2811/5011 0.126s
im_proposals: 2812/5011 0.126s
im_proposals: 2813/5011 0.126s
im_proposals: 2814/5011 0.126s
im_proposals: 2815/5011 0.126s
im_proposals: 2816/5011 0.126s
im_proposals: 2817/5011 0.126s
im_proposals: 2818/5011 0.126s
im_proposals: 2819/5011 0.126s
im_proposals: 2820/5011 0.126s
im_proposals: 2821/5011 0.126s
im_proposals: 2822/5011 0.126s
im_proposals: 2823/5011 0.126s
im_proposals: 2824/5011 0.126s
im_proposals: 2825/5011 0.126s
im_proposals: 2826/5011 0.126s
im_proposals: 2827/5011 0.126s
im_proposals: 2828/5011 0.126s
im_proposals: 2829/5011 0.126s
im_proposals: 2830/5011 0.126s
im_proposals: 2831/5011 0.126s
im_proposals: 2832/5011 0.126s
im_proposals: 2833/5011 0.126s
im_proposals: 2834/5011 0.126s
im_proposals: 2835/5011 0.126s
im_proposals: 2836/5011 0.126s
im_proposals: 2837/5011 0.126s
im_proposals: 2838/5011 0.126s
im_proposals: 2839/5011 0.126s
im_proposals: 2840/5011 0.126s
im_proposals: 2841/5011 0.126s
im_proposals: 2842/5011 0.126s
im_proposals: 2843/5011 0.126s
im_proposals: 2844/5011 0.126s
im_proposals: 2845/5011 0.126s
im_proposals: 2846/5011 0.126s
im_proposals: 2847/5011 0.126s
im_proposals: 2848/5011 0.126s
im_proposals: 2849/5011 0.126s
im_proposals: 2850/5011 0.126s
im_proposals: 2851/5011 0.126s
im_proposals: 2852/5011 0.126s
im_proposals: 2853/5011 0.126s
im_proposals: 2854/5011 0.126s
im_proposals: 2855/5011 0.126s
im_proposals: 2856/5011 0.126s
im_proposals: 2857/5011 0.126s
im_proposals: 2858/5011 0.126s
im_proposals: 2859/5011 0.126s
im_proposals: 2860/5011 0.126s
im_proposals: 2861/5011 0.126s
im_proposals: 2862/5011 0.126s
im_proposals: 2863/5011 0.126s
im_proposals: 2864/5011 0.126s
im_proposals: 2865/5011 0.126s
im_proposals: 2866/5011 0.126s
im_proposals: 2867/5011 0.126s
im_proposals: 2868/5011 0.126s
im_proposals: 2869/5011 0.126s
im_proposals: 2870/5011 0.126s
im_proposals: 2871/5011 0.126s
im_proposals: 2872/5011 0.126s
im_proposals: 2873/5011 0.126s
im_proposals: 2874/5011 0.126s
im_proposals: 2875/5011 0.126s
im_proposals: 2876/5011 0.126s
im_proposals: 2877/5011 0.126s
im_proposals: 2878/5011 0.126s
im_proposals: 2879/5011 0.126s
im_proposals: 2880/5011 0.126s
im_proposals: 2881/5011 0.126s
im_proposals: 2882/5011 0.126s
im_proposals: 2883/5011 0.126s
im_proposals: 2884/5011 0.126s
im_proposals: 2885/5011 0.126s
im_proposals: 2886/5011 0.126s
im_proposals: 2887/5011 0.126s
im_proposals: 2888/5011 0.126s
im_proposals: 2889/5011 0.126s
im_proposals: 2890/5011 0.126s
im_proposals: 2891/5011 0.126s
im_proposals: 2892/5011 0.126s
im_proposals: 2893/5011 0.126s
im_proposals: 2894/5011 0.126s
im_proposals: 2895/5011 0.126s
im_proposals: 2896/5011 0.126s
im_proposals: 2897/5011 0.126s
im_proposals: 2898/5011 0.126s
im_proposals: 2899/5011 0.126s
im_proposals: 2900/5011 0.126s
im_proposals: 2901/5011 0.126s
im_proposals: 2902/5011 0.126s
im_proposals: 2903/5011 0.126s
im_proposals: 2904/5011 0.126s
im_proposals: 2905/5011 0.126s
im_proposals: 2906/5011 0.126s
im_proposals: 2907/5011 0.126s
im_proposals: 2908/5011 0.126s
im_proposals: 2909/5011 0.126s
im_proposals: 2910/5011 0.126s
im_proposals: 2911/5011 0.126s
im_proposals: 2912/5011 0.126s
im_proposals: 2913/5011 0.126s
im_proposals: 2914/5011 0.126s
im_proposals: 2915/5011 0.126s
im_proposals: 2916/5011 0.126s
im_proposals: 2917/5011 0.126s
im_proposals: 2918/5011 0.126s
im_proposals: 2919/5011 0.126s
im_proposals: 2920/5011 0.126s
im_proposals: 2921/5011 0.126s
im_proposals: 2922/5011 0.126s
im_proposals: 2923/5011 0.126s
im_proposals: 2924/5011 0.126s
im_proposals: 2925/5011 0.126s
im_proposals: 2926/5011 0.126s
im_proposals: 2927/5011 0.126s
im_proposals: 2928/5011 0.126s
im_proposals: 2929/5011 0.126s
im_proposals: 2930/5011 0.126s
im_proposals: 2931/5011 0.126s
im_proposals: 2932/5011 0.126s
im_proposals: 2933/5011 0.126s
im_proposals: 2934/5011 0.126s
im_proposals: 2935/5011 0.126s
im_proposals: 2936/5011 0.126s
im_proposals: 2937/5011 0.126s
im_proposals: 2938/5011 0.126s
im_proposals: 2939/5011 0.126s
im_proposals: 2940/5011 0.126s
im_proposals: 2941/5011 0.126s
im_proposals: 2942/5011 0.126s
im_proposals: 2943/5011 0.126s
im_proposals: 2944/5011 0.126s
im_proposals: 2945/5011 0.126s
im_proposals: 2946/5011 0.126s
im_proposals: 2947/5011 0.126s
im_proposals: 2948/5011 0.126s
im_proposals: 2949/5011 0.126s
im_proposals: 2950/5011 0.126s
im_proposals: 2951/5011 0.126s
im_proposals: 2952/5011 0.126s
im_proposals: 2953/5011 0.126s
im_proposals: 2954/5011 0.126s
im_proposals: 2955/5011 0.126s
im_proposals: 2956/5011 0.126s
im_proposals: 2957/5011 0.126s
im_proposals: 2958/5011 0.126s
im_proposals: 2959/5011 0.126s
im_proposals: 2960/5011 0.126s
im_proposals: 2961/5011 0.126s
im_proposals: 2962/5011 0.126s
im_proposals: 2963/5011 0.126s
im_proposals: 2964/5011 0.126s
im_proposals: 2965/5011 0.126s
im_proposals: 2966/5011 0.126s
im_proposals: 2967/5011 0.126s
im_proposals: 2968/5011 0.126s
im_proposals: 2969/5011 0.126s
im_proposals: 2970/5011 0.126s
im_proposals: 2971/5011 0.126s
im_proposals: 2972/5011 0.126s
im_proposals: 2973/5011 0.126s
im_proposals: 2974/5011 0.126s
im_proposals: 2975/5011 0.126s
im_proposals: 2976/5011 0.126s
im_proposals: 2977/5011 0.126s
im_proposals: 2978/5011 0.126s
im_proposals: 2979/5011 0.126s
im_proposals: 2980/5011 0.126s
im_proposals: 2981/5011 0.126s
im_proposals: 2982/5011 0.126s
im_proposals: 2983/5011 0.126s
im_proposals: 2984/5011 0.126s
im_proposals: 2985/5011 0.126s
im_proposals: 2986/5011 0.126s
im_proposals: 2987/5011 0.126s
im_proposals: 2988/5011 0.126s
im_proposals: 2989/5011 0.126s
im_proposals: 2990/5011 0.126s
im_proposals: 2991/5011 0.126s
im_proposals: 2992/5011 0.126s
im_proposals: 2993/5011 0.126s
im_proposals: 2994/5011 0.126s
im_proposals: 2995/5011 0.126s
im_proposals: 2996/5011 0.126s
im_proposals: 2997/5011 0.126s
im_proposals: 2998/5011 0.126s
im_proposals: 2999/5011 0.126s
im_proposals: 3000/5011 0.126s
im_proposals: 3001/5011 0.126s
im_proposals: 3002/5011 0.126s
im_proposals: 3003/5011 0.126s
im_proposals: 3004/5011 0.126s
im_proposals: 3005/5011 0.126s
im_proposals: 3006/5011 0.126s
im_proposals: 3007/5011 0.126s
im_proposals: 3008/5011 0.126s
im_proposals: 3009/5011 0.126s
im_proposals: 3010/5011 0.126s
im_proposals: 3011/5011 0.126s
im_proposals: 3012/5011 0.126s
im_proposals: 3013/5011 0.126s
im_proposals: 3014/5011 0.126s
im_proposals: 3015/5011 0.126s
im_proposals: 3016/5011 0.126s
im_proposals: 3017/5011 0.126s
im_proposals: 3018/5011 0.126s
im_proposals: 3019/5011 0.126s
im_proposals: 3020/5011 0.126s
im_proposals: 3021/5011 0.126s
im_proposals: 3022/5011 0.126s
im_proposals: 3023/5011 0.126s
im_proposals: 3024/5011 0.126s
im_proposals: 3025/5011 0.126s
im_proposals: 3026/5011 0.126s
im_proposals: 3027/5011 0.126s
im_proposals: 3028/5011 0.126s
im_proposals: 3029/5011 0.126s
im_proposals: 3030/5011 0.126s
im_proposals: 3031/5011 0.126s
im_proposals: 3032/5011 0.126s
im_proposals: 3033/5011 0.126s
im_proposals: 3034/5011 0.126s
im_proposals: 3035/5011 0.126s
im_proposals: 3036/5011 0.126s
im_proposals: 3037/5011 0.126s
im_proposals: 3038/5011 0.126s
im_proposals: 3039/5011 0.126s
im_proposals: 3040/5011 0.126s
im_proposals: 3041/5011 0.126s
im_proposals: 3042/5011 0.126s
im_proposals: 3043/5011 0.126s
im_proposals: 3044/5011 0.126s
im_proposals: 3045/5011 0.126s
im_proposals: 3046/5011 0.126s
im_proposals: 3047/5011 0.126s
im_proposals: 3048/5011 0.126s
im_proposals: 3049/5011 0.126s
im_proposals: 3050/5011 0.126s
im_proposals: 3051/5011 0.126s
im_proposals: 3052/5011 0.126s
im_proposals: 3053/5011 0.126s
im_proposals: 3054/5011 0.126s
im_proposals: 3055/5011 0.126s
im_proposals: 3056/5011 0.126s
im_proposals: 3057/5011 0.126s
im_proposals: 3058/5011 0.126s
im_proposals: 3059/5011 0.126s
im_proposals: 3060/5011 0.126s
im_proposals: 3061/5011 0.126s
im_proposals: 3062/5011 0.126s
im_proposals: 3063/5011 0.126s
im_proposals: 3064/5011 0.126s
im_proposals: 3065/5011 0.126s
im_proposals: 3066/5011 0.126s
im_proposals: 3067/5011 0.126s
im_proposals: 3068/5011 0.126s
im_proposals: 3069/5011 0.126s
im_proposals: 3070/5011 0.126s
im_proposals: 3071/5011 0.126s
im_proposals: 3072/5011 0.126s
im_proposals: 3073/5011 0.126s
im_proposals: 3074/5011 0.126s
im_proposals: 3075/5011 0.126s
im_proposals: 3076/5011 0.126s
im_proposals: 3077/5011 0.126s
im_proposals: 3078/5011 0.126s
im_proposals: 3079/5011 0.126s
im_proposals: 3080/5011 0.126s
im_proposals: 3081/5011 0.126s
im_proposals: 3082/5011 0.126s
im_proposals: 3083/5011 0.126s
im_proposals: 3084/5011 0.126s
im_proposals: 3085/5011 0.126s
im_proposals: 3086/5011 0.126s
im_proposals: 3087/5011 0.126s
im_proposals: 3088/5011 0.126s
im_proposals: 3089/5011 0.126s
im_proposals: 3090/5011 0.126s
im_proposals: 3091/5011 0.126s
im_proposals: 3092/5011 0.126s
im_proposals: 3093/5011 0.126s
im_proposals: 3094/5011 0.126s
im_proposals: 3095/5011 0.126s
im_proposals: 3096/5011 0.126s
im_proposals: 3097/5011 0.126s
im_proposals: 3098/5011 0.126s
im_proposals: 3099/5011 0.126s
im_proposals: 3100/5011 0.126s
im_proposals: 3101/5011 0.126s
im_proposals: 3102/5011 0.126s
im_proposals: 3103/5011 0.126s
im_proposals: 3104/5011 0.126s
im_proposals: 3105/5011 0.126s
im_proposals: 3106/5011 0.126s
im_proposals: 3107/5011 0.126s
im_proposals: 3108/5011 0.126s
im_proposals: 3109/5011 0.126s
im_proposals: 3110/5011 0.126s
im_proposals: 3111/5011 0.126s
im_proposals: 3112/5011 0.126s
im_proposals: 3113/5011 0.126s
im_proposals: 3114/5011 0.126s
im_proposals: 3115/5011 0.126s
im_proposals: 3116/5011 0.126s
im_proposals: 3117/5011 0.126s
im_proposals: 3118/5011 0.126s
im_proposals: 3119/5011 0.126s
im_proposals: 3120/5011 0.126s
im_proposals: 3121/5011 0.126s
im_proposals: 3122/5011 0.126s
im_proposals: 3123/5011 0.126s
im_proposals: 3124/5011 0.126s
im_proposals: 3125/5011 0.126s
im_proposals: 3126/5011 0.126s
im_proposals: 3127/5011 0.126s
im_proposals: 3128/5011 0.126s
im_proposals: 3129/5011 0.126s
im_proposals: 3130/5011 0.126s
im_proposals: 3131/5011 0.126s
im_proposals: 3132/5011 0.126s
im_proposals: 3133/5011 0.126s
im_proposals: 3134/5011 0.126s
im_proposals: 3135/5011 0.126s
im_proposals: 3136/5011 0.126s
im_proposals: 3137/5011 0.126s
im_proposals: 3138/5011 0.126s
im_proposals: 3139/5011 0.126s
im_proposals: 3140/5011 0.126s
im_proposals: 3141/5011 0.126s
im_proposals: 3142/5011 0.126s
im_proposals: 3143/5011 0.126s
im_proposals: 3144/5011 0.126s
im_proposals: 3145/5011 0.126s
im_proposals: 3146/5011 0.126s
im_proposals: 3147/5011 0.126s
im_proposals: 3148/5011 0.126s
im_proposals: 3149/5011 0.126s
im_proposals: 3150/5011 0.126s
im_proposals: 3151/5011 0.126s
im_proposals: 3152/5011 0.126s
im_proposals: 3153/5011 0.126s
im_proposals: 3154/5011 0.126s
im_proposals: 3155/5011 0.126s
im_proposals: 3156/5011 0.126s
im_proposals: 3157/5011 0.126s
im_proposals: 3158/5011 0.126s
im_proposals: 3159/5011 0.126s
im_proposals: 3160/5011 0.126s
im_proposals: 3161/5011 0.126s
im_proposals: 3162/5011 0.126s
im_proposals: 3163/5011 0.126s
im_proposals: 3164/5011 0.126s
im_proposals: 3165/5011 0.126s
im_proposals: 3166/5011 0.126s
im_proposals: 3167/5011 0.126s
im_proposals: 3168/5011 0.126s
im_proposals: 3169/5011 0.126s
im_proposals: 3170/5011 0.126s
im_proposals: 3171/5011 0.126s
im_proposals: 3172/5011 0.126s
im_proposals: 3173/5011 0.126s
im_proposals: 3174/5011 0.126s
im_proposals: 3175/5011 0.126s
im_proposals: 3176/5011 0.126s
im_proposals: 3177/5011 0.126s
im_proposals: 3178/5011 0.126s
im_proposals: 3179/5011 0.126s
im_proposals: 3180/5011 0.126s
im_proposals: 3181/5011 0.126s
im_proposals: 3182/5011 0.126s
im_proposals: 3183/5011 0.126s
im_proposals: 3184/5011 0.126s
im_proposals: 3185/5011 0.126s
im_proposals: 3186/5011 0.126s
im_proposals: 3187/5011 0.126s
im_proposals: 3188/5011 0.126s
im_proposals: 3189/5011 0.126s
im_proposals: 3190/5011 0.126s
im_proposals: 3191/5011 0.126s
im_proposals: 3192/5011 0.126s
im_proposals: 3193/5011 0.126s
im_proposals: 3194/5011 0.126s
im_proposals: 3195/5011 0.126s
im_proposals: 3196/5011 0.126s
im_proposals: 3197/5011 0.126s
im_proposals: 3198/5011 0.126s
im_proposals: 3199/5011 0.126s
im_proposals: 3200/5011 0.126s
im_proposals: 3201/5011 0.126s
im_proposals: 3202/5011 0.126s
im_proposals: 3203/5011 0.126s
im_proposals: 3204/5011 0.126s
im_proposals: 3205/5011 0.126s
im_proposals: 3206/5011 0.126s
im_proposals: 3207/5011 0.126s
im_proposals: 3208/5011 0.126s
im_proposals: 3209/5011 0.126s
im_proposals: 3210/5011 0.126s
im_proposals: 3211/5011 0.126s
im_proposals: 3212/5011 0.126s
im_proposals: 3213/5011 0.126s
im_proposals: 3214/5011 0.126s
im_proposals: 3215/5011 0.126s
im_proposals: 3216/5011 0.126s
im_proposals: 3217/5011 0.126s
im_proposals: 3218/5011 0.126s
im_proposals: 3219/5011 0.126s
im_proposals: 3220/5011 0.126s
im_proposals: 3221/5011 0.126s
im_proposals: 3222/5011 0.126s
im_proposals: 3223/5011 0.126s
im_proposals: 3224/5011 0.126s
im_proposals: 3225/5011 0.126s
im_proposals: 3226/5011 0.126s
im_proposals: 3227/5011 0.126s
im_proposals: 3228/5011 0.126s
im_proposals: 3229/5011 0.126s
im_proposals: 3230/5011 0.126s
im_proposals: 3231/5011 0.126s
im_proposals: 3232/5011 0.126s
im_proposals: 3233/5011 0.126s
im_proposals: 3234/5011 0.126s
im_proposals: 3235/5011 0.126s
im_proposals: 3236/5011 0.126s
im_proposals: 3237/5011 0.126s
im_proposals: 3238/5011 0.126s
im_proposals: 3239/5011 0.126s
im_proposals: 3240/5011 0.126s
im_proposals: 3241/5011 0.126s
im_proposals: 3242/5011 0.126s
im_proposals: 3243/5011 0.126s
im_proposals: 3244/5011 0.126s
im_proposals: 3245/5011 0.126s
im_proposals: 3246/5011 0.126s
im_proposals: 3247/5011 0.126s
im_proposals: 3248/5011 0.126s
im_proposals: 3249/5011 0.126s
im_proposals: 3250/5011 0.126s
im_proposals: 3251/5011 0.126s
im_proposals: 3252/5011 0.126s
im_proposals: 3253/5011 0.126s
im_proposals: 3254/5011 0.126s
im_proposals: 3255/5011 0.126s
im_proposals: 3256/5011 0.126s
im_proposals: 3257/5011 0.126s
im_proposals: 3258/5011 0.126s
im_proposals: 3259/5011 0.126s
im_proposals: 3260/5011 0.126s
im_proposals: 3261/5011 0.126s
im_proposals: 3262/5011 0.126s
im_proposals: 3263/5011 0.126s
im_proposals: 3264/5011 0.126s
im_proposals: 3265/5011 0.126s
im_proposals: 3266/5011 0.126s
im_proposals: 3267/5011 0.126s
im_proposals: 3268/5011 0.126s
im_proposals: 3269/5011 0.126s
im_proposals: 3270/5011 0.126s
im_proposals: 3271/5011 0.126s
im_proposals: 3272/5011 0.126s
im_proposals: 3273/5011 0.126s
im_proposals: 3274/5011 0.126s
im_proposals: 3275/5011 0.126s
im_proposals: 3276/5011 0.126s
im_proposals: 3277/5011 0.126s
im_proposals: 3278/5011 0.126s
im_proposals: 3279/5011 0.126s
im_proposals: 3280/5011 0.126s
im_proposals: 3281/5011 0.126s
im_proposals: 3282/5011 0.126s
im_proposals: 3283/5011 0.126s
im_proposals: 3284/5011 0.126s
im_proposals: 3285/5011 0.126s
im_proposals: 3286/5011 0.126s
im_proposals: 3287/5011 0.126s
im_proposals: 3288/5011 0.126s
im_proposals: 3289/5011 0.126s
im_proposals: 3290/5011 0.126s
im_proposals: 3291/5011 0.126s
im_proposals: 3292/5011 0.126s
im_proposals: 3293/5011 0.126s
im_proposals: 3294/5011 0.126s
im_proposals: 3295/5011 0.126s
im_proposals: 3296/5011 0.126s
im_proposals: 3297/5011 0.126s
im_proposals: 3298/5011 0.126s
im_proposals: 3299/5011 0.126s
im_proposals: 3300/5011 0.126s
im_proposals: 3301/5011 0.126s
im_proposals: 3302/5011 0.126s
im_proposals: 3303/5011 0.126s
im_proposals: 3304/5011 0.126s
im_proposals: 3305/5011 0.126s
im_proposals: 3306/5011 0.126s
im_proposals: 3307/5011 0.126s
im_proposals: 3308/5011 0.126s
im_proposals: 3309/5011 0.126s
im_proposals: 3310/5011 0.126s
im_proposals: 3311/5011 0.126s
im_proposals: 3312/5011 0.126s
im_proposals: 3313/5011 0.126s
im_proposals: 3314/5011 0.126s
im_proposals: 3315/5011 0.126s
im_proposals: 3316/5011 0.126s
im_proposals: 3317/5011 0.126s
im_proposals: 3318/5011 0.126s
im_proposals: 3319/5011 0.126s
im_proposals: 3320/5011 0.126s
im_proposals: 3321/5011 0.126s
im_proposals: 3322/5011 0.126s
im_proposals: 3323/5011 0.126s
im_proposals: 3324/5011 0.126s
im_proposals: 3325/5011 0.126s
im_proposals: 3326/5011 0.126s
im_proposals: 3327/5011 0.126s
im_proposals: 3328/5011 0.126s
im_proposals: 3329/5011 0.126s
im_proposals: 3330/5011 0.126s
im_proposals: 3331/5011 0.126s
im_proposals: 3332/5011 0.126s
im_proposals: 3333/5011 0.126s
im_proposals: 3334/5011 0.126s
im_proposals: 3335/5011 0.126s
im_proposals: 3336/5011 0.126s
im_proposals: 3337/5011 0.126s
im_proposals: 3338/5011 0.126s
im_proposals: 3339/5011 0.126s
im_proposals: 3340/5011 0.126s
im_proposals: 3341/5011 0.126s
im_proposals: 3342/5011 0.126s
im_proposals: 3343/5011 0.126s
im_proposals: 3344/5011 0.126s
im_proposals: 3345/5011 0.126s
im_proposals: 3346/5011 0.126s
im_proposals: 3347/5011 0.126s
im_proposals: 3348/5011 0.126s
im_proposals: 3349/5011 0.126s
im_proposals: 3350/5011 0.126s
im_proposals: 3351/5011 0.126s
im_proposals: 3352/5011 0.126s
im_proposals: 3353/5011 0.126s
im_proposals: 3354/5011 0.126s
im_proposals: 3355/5011 0.126s
im_proposals: 3356/5011 0.126s
im_proposals: 3357/5011 0.126s
im_proposals: 3358/5011 0.126s
im_proposals: 3359/5011 0.126s
im_proposals: 3360/5011 0.126s
im_proposals: 3361/5011 0.126s
im_proposals: 3362/5011 0.126s
im_proposals: 3363/5011 0.126s
im_proposals: 3364/5011 0.126s
im_proposals: 3365/5011 0.126s
im_proposals: 3366/5011 0.126s
im_proposals: 3367/5011 0.126s
im_proposals: 3368/5011 0.126s
im_proposals: 3369/5011 0.126s
im_proposals: 3370/5011 0.126s
im_proposals: 3371/5011 0.126s
im_proposals: 3372/5011 0.126s
im_proposals: 3373/5011 0.126s
im_proposals: 3374/5011 0.126s
im_proposals: 3375/5011 0.126s
im_proposals: 3376/5011 0.126s
im_proposals: 3377/5011 0.126s
im_proposals: 3378/5011 0.126s
im_proposals: 3379/5011 0.126s
im_proposals: 3380/5011 0.126s
im_proposals: 3381/5011 0.126s
im_proposals: 3382/5011 0.126s
im_proposals: 3383/5011 0.126s
im_proposals: 3384/5011 0.126s
im_proposals: 3385/5011 0.126s
im_proposals: 3386/5011 0.126s
im_proposals: 3387/5011 0.126s
im_proposals: 3388/5011 0.126s
im_proposals: 3389/5011 0.126s
im_proposals: 3390/5011 0.126s
im_proposals: 3391/5011 0.126s
im_proposals: 3392/5011 0.126s
im_proposals: 3393/5011 0.126s
im_proposals: 3394/5011 0.126s
im_proposals: 3395/5011 0.126s
im_proposals: 3396/5011 0.126s
im_proposals: 3397/5011 0.126s
im_proposals: 3398/5011 0.126s
im_proposals: 3399/5011 0.126s
im_proposals: 3400/5011 0.126s
im_proposals: 3401/5011 0.126s
im_proposals: 3402/5011 0.126s
im_proposals: 3403/5011 0.126s
im_proposals: 3404/5011 0.126s
im_proposals: 3405/5011 0.126s
im_proposals: 3406/5011 0.126s
im_proposals: 3407/5011 0.126s
im_proposals: 3408/5011 0.126s
im_proposals: 3409/5011 0.126s
im_proposals: 3410/5011 0.126s
im_proposals: 3411/5011 0.126s
im_proposals: 3412/5011 0.126s
im_proposals: 3413/5011 0.126s
im_proposals: 3414/5011 0.126s
im_proposals: 3415/5011 0.126s
im_proposals: 3416/5011 0.126s
im_proposals: 3417/5011 0.126s
im_proposals: 3418/5011 0.126s
im_proposals: 3419/5011 0.126s
im_proposals: 3420/5011 0.126s
im_proposals: 3421/5011 0.126s
im_proposals: 3422/5011 0.126s
im_proposals: 3423/5011 0.126s
im_proposals: 3424/5011 0.126s
im_proposals: 3425/5011 0.126s
im_proposals: 3426/5011 0.126s
im_proposals: 3427/5011 0.126s
im_proposals: 3428/5011 0.126s
im_proposals: 3429/5011 0.126s
im_proposals: 3430/5011 0.126s
im_proposals: 3431/5011 0.126s
im_proposals: 3432/5011 0.126s
im_proposals: 3433/5011 0.126s
im_proposals: 3434/5011 0.126s
im_proposals: 3435/5011 0.126s
im_proposals: 3436/5011 0.126s
im_proposals: 3437/5011 0.126s
im_proposals: 3438/5011 0.126s
im_proposals: 3439/5011 0.126s
im_proposals: 3440/5011 0.126s
im_proposals: 3441/5011 0.126s
im_proposals: 3442/5011 0.126s
im_proposals: 3443/5011 0.126s
im_proposals: 3444/5011 0.126s
im_proposals: 3445/5011 0.126s
im_proposals: 3446/5011 0.126s
im_proposals: 3447/5011 0.126s
im_proposals: 3448/5011 0.126s
im_proposals: 3449/5011 0.126s
im_proposals: 3450/5011 0.126s
im_proposals: 3451/5011 0.126s
im_proposals: 3452/5011 0.126s
im_proposals: 3453/5011 0.126s
im_proposals: 3454/5011 0.126s
im_proposals: 3455/5011 0.126s
im_proposals: 3456/5011 0.126s
im_proposals: 3457/5011 0.126s
im_proposals: 3458/5011 0.126s
im_proposals: 3459/5011 0.126s
im_proposals: 3460/5011 0.126s
im_proposals: 3461/5011 0.126s
im_proposals: 3462/5011 0.126s
im_proposals: 3463/5011 0.126s
im_proposals: 3464/5011 0.126s
im_proposals: 3465/5011 0.126s
im_proposals: 3466/5011 0.126s
im_proposals: 3467/5011 0.126s
im_proposals: 3468/5011 0.126s
im_proposals: 3469/5011 0.126s
im_proposals: 3470/5011 0.126s
im_proposals: 3471/5011 0.126s
im_proposals: 3472/5011 0.126s
im_proposals: 3473/5011 0.126s
im_proposals: 3474/5011 0.126s
im_proposals: 3475/5011 0.126s
im_proposals: 3476/5011 0.126s
im_proposals: 3477/5011 0.126s
im_proposals: 3478/5011 0.126s
im_proposals: 3479/5011 0.126s
im_proposals: 3480/5011 0.126s
im_proposals: 3481/5011 0.126s
im_proposals: 3482/5011 0.126s
im_proposals: 3483/5011 0.126s
im_proposals: 3484/5011 0.126s
im_proposals: 3485/5011 0.126s
im_proposals: 3486/5011 0.126s
im_proposals: 3487/5011 0.126s
im_proposals: 3488/5011 0.126s
im_proposals: 3489/5011 0.126s
im_proposals: 3490/5011 0.126s
im_proposals: 3491/5011 0.126s
im_proposals: 3492/5011 0.126s
im_proposals: 3493/5011 0.126s
im_proposals: 3494/5011 0.126s
im_proposals: 3495/5011 0.126s
im_proposals: 3496/5011 0.126s
im_proposals: 3497/5011 0.126s
im_proposals: 3498/5011 0.126s
im_proposals: 3499/5011 0.126s
im_proposals: 3500/5011 0.126s
im_proposals: 3501/5011 0.126s
im_proposals: 3502/5011 0.126s
im_proposals: 3503/5011 0.126s
im_proposals: 3504/5011 0.126s
im_proposals: 3505/5011 0.126s
im_proposals: 3506/5011 0.126s
im_proposals: 3507/5011 0.126s
im_proposals: 3508/5011 0.126s
im_proposals: 3509/5011 0.126s
im_proposals: 3510/5011 0.126s
im_proposals: 3511/5011 0.126s
im_proposals: 3512/5011 0.126s
im_proposals: 3513/5011 0.126s
im_proposals: 3514/5011 0.126s
im_proposals: 3515/5011 0.126s
im_proposals: 3516/5011 0.126s
im_proposals: 3517/5011 0.126s
im_proposals: 3518/5011 0.126s
im_proposals: 3519/5011 0.126s
im_proposals: 3520/5011 0.126s
im_proposals: 3521/5011 0.126s
im_proposals: 3522/5011 0.126s
im_proposals: 3523/5011 0.126s
im_proposals: 3524/5011 0.126s
im_proposals: 3525/5011 0.126s
im_proposals: 3526/5011 0.126s
im_proposals: 3527/5011 0.126s
im_proposals: 3528/5011 0.126s
im_proposals: 3529/5011 0.126s
im_proposals: 3530/5011 0.126s
im_proposals: 3531/5011 0.126s
im_proposals: 3532/5011 0.126s
im_proposals: 3533/5011 0.126s
im_proposals: 3534/5011 0.126s
im_proposals: 3535/5011 0.126s
im_proposals: 3536/5011 0.126s
im_proposals: 3537/5011 0.126s
im_proposals: 3538/5011 0.126s
im_proposals: 3539/5011 0.126s
im_proposals: 3540/5011 0.126s
im_proposals: 3541/5011 0.126s
im_proposals: 3542/5011 0.126s
im_proposals: 3543/5011 0.126s
im_proposals: 3544/5011 0.126s
im_proposals: 3545/5011 0.126s
im_proposals: 3546/5011 0.126s
im_proposals: 3547/5011 0.126s
im_proposals: 3548/5011 0.126s
im_proposals: 3549/5011 0.126s
im_proposals: 3550/5011 0.126s
im_proposals: 3551/5011 0.126s
im_proposals: 3552/5011 0.126s
im_proposals: 3553/5011 0.126s
im_proposals: 3554/5011 0.126s
im_proposals: 3555/5011 0.126s
im_proposals: 3556/5011 0.126s
im_proposals: 3557/5011 0.126s
im_proposals: 3558/5011 0.126s
im_proposals: 3559/5011 0.126s
im_proposals: 3560/5011 0.126s
im_proposals: 3561/5011 0.126s
im_proposals: 3562/5011 0.126s
im_proposals: 3563/5011 0.126s
im_proposals: 3564/5011 0.126s
im_proposals: 3565/5011 0.126s
im_proposals: 3566/5011 0.126s
im_proposals: 3567/5011 0.126s
im_proposals: 3568/5011 0.126s
im_proposals: 3569/5011 0.126s
im_proposals: 3570/5011 0.126s
im_proposals: 3571/5011 0.126s
im_proposals: 3572/5011 0.126s
im_proposals: 3573/5011 0.126s
im_proposals: 3574/5011 0.126s
im_proposals: 3575/5011 0.126s
im_proposals: 3576/5011 0.126s
im_proposals: 3577/5011 0.126s
im_proposals: 3578/5011 0.126s
im_proposals: 3579/5011 0.126s
im_proposals: 3580/5011 0.126s
im_proposals: 3581/5011 0.126s
im_proposals: 3582/5011 0.126s
im_proposals: 3583/5011 0.126s
im_proposals: 3584/5011 0.126s
im_proposals: 3585/5011 0.126s
im_proposals: 3586/5011 0.126s
im_proposals: 3587/5011 0.126s
im_proposals: 3588/5011 0.126s
im_proposals: 3589/5011 0.126s
im_proposals: 3590/5011 0.126s
im_proposals: 3591/5011 0.126s
im_proposals: 3592/5011 0.126s
im_proposals: 3593/5011 0.126s
im_proposals: 3594/5011 0.126s
im_proposals: 3595/5011 0.126s
im_proposals: 3596/5011 0.126s
im_proposals: 3597/5011 0.126s
im_proposals: 3598/5011 0.126s
im_proposals: 3599/5011 0.126s
im_proposals: 3600/5011 0.126s
im_proposals: 3601/5011 0.126s
im_proposals: 3602/5011 0.126s
im_proposals: 3603/5011 0.126s
im_proposals: 3604/5011 0.126s
im_proposals: 3605/5011 0.126s
im_proposals: 3606/5011 0.126s
im_proposals: 3607/5011 0.126s
im_proposals: 3608/5011 0.126s
im_proposals: 3609/5011 0.126s
im_proposals: 3610/5011 0.126s
im_proposals: 3611/5011 0.126s
im_proposals: 3612/5011 0.126s
im_proposals: 3613/5011 0.126s
im_proposals: 3614/5011 0.126s
im_proposals: 3615/5011 0.126s
im_proposals: 3616/5011 0.126s
im_proposals: 3617/5011 0.126s
im_proposals: 3618/5011 0.126s
im_proposals: 3619/5011 0.126s
im_proposals: 3620/5011 0.126s
im_proposals: 3621/5011 0.126s
im_proposals: 3622/5011 0.126s
im_proposals: 3623/5011 0.126s
im_proposals: 3624/5011 0.126s
im_proposals: 3625/5011 0.126s
im_proposals: 3626/5011 0.126s
im_proposals: 3627/5011 0.126s
im_proposals: 3628/5011 0.126s
im_proposals: 3629/5011 0.126s
im_proposals: 3630/5011 0.126s
im_proposals: 3631/5011 0.126s
im_proposals: 3632/5011 0.126s
im_proposals: 3633/5011 0.126s
im_proposals: 3634/5011 0.126s
im_proposals: 3635/5011 0.126s
im_proposals: 3636/5011 0.126s
im_proposals: 3637/5011 0.126s
im_proposals: 3638/5011 0.126s
im_proposals: 3639/5011 0.126s
im_proposals: 3640/5011 0.126s
im_proposals: 3641/5011 0.126s
im_proposals: 3642/5011 0.126s
im_proposals: 3643/5011 0.126s
im_proposals: 3644/5011 0.126s
im_proposals: 3645/5011 0.126s
im_proposals: 3646/5011 0.126s
im_proposals: 3647/5011 0.126s
im_proposals: 3648/5011 0.126s
im_proposals: 3649/5011 0.126s
im_proposals: 3650/5011 0.126s
im_proposals: 3651/5011 0.126s
im_proposals: 3652/5011 0.126s
im_proposals: 3653/5011 0.126s
im_proposals: 3654/5011 0.126s
im_proposals: 3655/5011 0.126s
im_proposals: 3656/5011 0.126s
im_proposals: 3657/5011 0.126s
im_proposals: 3658/5011 0.126s
im_proposals: 3659/5011 0.126s
im_proposals: 3660/5011 0.126s
im_proposals: 3661/5011 0.126s
im_proposals: 3662/5011 0.126s
im_proposals: 3663/5011 0.126s
im_proposals: 3664/5011 0.126s
im_proposals: 3665/5011 0.126s
im_proposals: 3666/5011 0.126s
im_proposals: 3667/5011 0.126s
im_proposals: 3668/5011 0.126s
im_proposals: 3669/5011 0.126s
im_proposals: 3670/5011 0.126s
im_proposals: 3671/5011 0.126s
im_proposals: 3672/5011 0.126s
im_proposals: 3673/5011 0.126s
im_proposals: 3674/5011 0.126s
im_proposals: 3675/5011 0.126s
im_proposals: 3676/5011 0.126s
im_proposals: 3677/5011 0.126s
im_proposals: 3678/5011 0.126s
im_proposals: 3679/5011 0.126s
im_proposals: 3680/5011 0.126s
im_proposals: 3681/5011 0.126s
im_proposals: 3682/5011 0.126s
im_proposals: 3683/5011 0.126s
im_proposals: 3684/5011 0.126s
im_proposals: 3685/5011 0.126s
im_proposals: 3686/5011 0.126s
im_proposals: 3687/5011 0.126s
im_proposals: 3688/5011 0.126s
im_proposals: 3689/5011 0.126s
im_proposals: 3690/5011 0.126s
im_proposals: 3691/5011 0.126s
im_proposals: 3692/5011 0.126s
im_proposals: 3693/5011 0.126s
im_proposals: 3694/5011 0.126s
im_proposals: 3695/5011 0.126s
im_proposals: 3696/5011 0.126s
im_proposals: 3697/5011 0.126s
im_proposals: 3698/5011 0.126s
im_proposals: 3699/5011 0.126s
im_proposals: 3700/5011 0.126s
im_proposals: 3701/5011 0.126s
im_proposals: 3702/5011 0.126s
im_proposals: 3703/5011 0.126s
im_proposals: 3704/5011 0.126s
im_proposals: 3705/5011 0.126s
im_proposals: 3706/5011 0.126s
im_proposals: 3707/5011 0.126s
im_proposals: 3708/5011 0.126s
im_proposals: 3709/5011 0.126s
im_proposals: 3710/5011 0.126s
im_proposals: 3711/5011 0.126s
im_proposals: 3712/5011 0.126s
im_proposals: 3713/5011 0.126s
im_proposals: 3714/5011 0.126s
im_proposals: 3715/5011 0.126s
im_proposals: 3716/5011 0.126s
im_proposals: 3717/5011 0.126s
im_proposals: 3718/5011 0.126s
im_proposals: 3719/5011 0.126s
im_proposals: 3720/5011 0.126s
im_proposals: 3721/5011 0.126s
im_proposals: 3722/5011 0.126s
im_proposals: 3723/5011 0.126s
im_proposals: 3724/5011 0.126s
im_proposals: 3725/5011 0.126s
im_proposals: 3726/5011 0.126s
im_proposals: 3727/5011 0.126s
im_proposals: 3728/5011 0.126s
im_proposals: 3729/5011 0.126s
im_proposals: 3730/5011 0.126s
im_proposals: 3731/5011 0.126s
im_proposals: 3732/5011 0.126s
im_proposals: 3733/5011 0.126s
im_proposals: 3734/5011 0.126s
im_proposals: 3735/5011 0.126s
im_proposals: 3736/5011 0.126s
im_proposals: 3737/5011 0.126s
im_proposals: 3738/5011 0.126s
im_proposals: 3739/5011 0.126s
im_proposals: 3740/5011 0.126s
im_proposals: 3741/5011 0.126s
im_proposals: 3742/5011 0.126s
im_proposals: 3743/5011 0.126s
im_proposals: 3744/5011 0.126s
im_proposals: 3745/5011 0.126s
im_proposals: 3746/5011 0.126s
im_proposals: 3747/5011 0.126s
im_proposals: 3748/5011 0.126s
im_proposals: 3749/5011 0.126s
im_proposals: 3750/5011 0.126s
im_proposals: 3751/5011 0.126s
im_proposals: 3752/5011 0.126s
im_proposals: 3753/5011 0.126s
im_proposals: 3754/5011 0.126s
im_proposals: 3755/5011 0.126s
im_proposals: 3756/5011 0.126s
im_proposals: 3757/5011 0.126s
im_proposals: 3758/5011 0.126s
im_proposals: 3759/5011 0.126s
im_proposals: 3760/5011 0.126s
im_proposals: 3761/5011 0.126s
im_proposals: 3762/5011 0.126s
im_proposals: 3763/5011 0.126s
im_proposals: 3764/5011 0.126s
im_proposals: 3765/5011 0.126s
im_proposals: 3766/5011 0.126s
im_proposals: 3767/5011 0.126s
im_proposals: 3768/5011 0.126s
im_proposals: 3769/5011 0.126s
im_proposals: 3770/5011 0.126s
im_proposals: 3771/5011 0.126s
im_proposals: 3772/5011 0.126s
im_proposals: 3773/5011 0.126s
im_proposals: 3774/5011 0.126s
im_proposals: 3775/5011 0.126s
im_proposals: 3776/5011 0.126s
im_proposals: 3777/5011 0.126s
im_proposals: 3778/5011 0.126s
im_proposals: 3779/5011 0.126s
im_proposals: 3780/5011 0.126s
im_proposals: 3781/5011 0.126s
im_proposals: 3782/5011 0.126s
im_proposals: 3783/5011 0.126s
im_proposals: 3784/5011 0.126s
im_proposals: 3785/5011 0.126s
im_proposals: 3786/5011 0.126s
im_proposals: 3787/5011 0.126s
im_proposals: 3788/5011 0.126s
im_proposals: 3789/5011 0.126s
im_proposals: 3790/5011 0.126s
im_proposals: 3791/5011 0.126s
im_proposals: 3792/5011 0.126s
im_proposals: 3793/5011 0.126s
im_proposals: 3794/5011 0.126s
im_proposals: 3795/5011 0.126s
im_proposals: 3796/5011 0.126s
im_proposals: 3797/5011 0.126s
im_proposals: 3798/5011 0.126s
im_proposals: 3799/5011 0.126s
im_proposals: 3800/5011 0.126s
im_proposals: 3801/5011 0.126s
im_proposals: 3802/5011 0.126s
im_proposals: 3803/5011 0.126s
im_proposals: 3804/5011 0.126s
im_proposals: 3805/5011 0.126s
im_proposals: 3806/5011 0.126s
im_proposals: 3807/5011 0.126s
im_proposals: 3808/5011 0.126s
im_proposals: 3809/5011 0.126s
im_proposals: 3810/5011 0.126s
im_proposals: 3811/5011 0.126s
im_proposals: 3812/5011 0.126s
im_proposals: 3813/5011 0.126s
im_proposals: 3814/5011 0.126s
im_proposals: 3815/5011 0.126s
im_proposals: 3816/5011 0.126s
im_proposals: 3817/5011 0.126s
im_proposals: 3818/5011 0.126s
im_proposals: 3819/5011 0.126s
im_proposals: 3820/5011 0.126s
im_proposals: 3821/5011 0.126s
im_proposals: 3822/5011 0.126s
im_proposals: 3823/5011 0.126s
im_proposals: 3824/5011 0.126s
im_proposals: 3825/5011 0.126s
im_proposals: 3826/5011 0.126s
im_proposals: 3827/5011 0.126s
im_proposals: 3828/5011 0.126s
im_proposals: 3829/5011 0.126s
im_proposals: 3830/5011 0.126s
im_proposals: 3831/5011 0.126s
im_proposals: 3832/5011 0.126s
im_proposals: 3833/5011 0.126s
im_proposals: 3834/5011 0.126s
im_proposals: 3835/5011 0.126s
im_proposals: 3836/5011 0.126s
im_proposals: 3837/5011 0.126s
im_proposals: 3838/5011 0.126s
im_proposals: 3839/5011 0.126s
im_proposals: 3840/5011 0.126s
im_proposals: 3841/5011 0.126s
im_proposals: 3842/5011 0.126s
im_proposals: 3843/5011 0.126s
im_proposals: 3844/5011 0.126s
im_proposals: 3845/5011 0.126s
im_proposals: 3846/5011 0.126s
im_proposals: 3847/5011 0.126s
im_proposals: 3848/5011 0.126s
im_proposals: 3849/5011 0.126s
im_proposals: 3850/5011 0.126s
im_proposals: 3851/5011 0.126s
im_proposals: 3852/5011 0.126s
im_proposals: 3853/5011 0.126s
im_proposals: 3854/5011 0.126s
im_proposals: 3855/5011 0.126s
im_proposals: 3856/5011 0.126s
im_proposals: 3857/5011 0.126s
im_proposals: 3858/5011 0.126s
im_proposals: 3859/5011 0.126s
im_proposals: 3860/5011 0.126s
im_proposals: 3861/5011 0.126s
im_proposals: 3862/5011 0.126s
im_proposals: 3863/5011 0.126s
im_proposals: 3864/5011 0.126s
im_proposals: 3865/5011 0.126s
im_proposals: 3866/5011 0.126s
im_proposals: 3867/5011 0.126s
im_proposals: 3868/5011 0.126s
im_proposals: 3869/5011 0.126s
im_proposals: 3870/5011 0.126s
im_proposals: 3871/5011 0.126s
im_proposals: 3872/5011 0.126s
im_proposals: 3873/5011 0.126s
im_proposals: 3874/5011 0.126s
im_proposals: 3875/5011 0.126s
im_proposals: 3876/5011 0.126s
im_proposals: 3877/5011 0.126s
im_proposals: 3878/5011 0.126s
im_proposals: 3879/5011 0.126s
im_proposals: 3880/5011 0.126s
im_proposals: 3881/5011 0.126s
im_proposals: 3882/5011 0.126s
im_proposals: 3883/5011 0.126s
im_proposals: 3884/5011 0.126s
im_proposals: 3885/5011 0.126s
im_proposals: 3886/5011 0.126s
im_proposals: 3887/5011 0.126s
im_proposals: 3888/5011 0.126s
im_proposals: 3889/5011 0.126s
im_proposals: 3890/5011 0.126s
im_proposals: 3891/5011 0.126s
im_proposals: 3892/5011 0.126s
im_proposals: 3893/5011 0.126s
im_proposals: 3894/5011 0.126s
im_proposals: 3895/5011 0.126s
im_proposals: 3896/5011 0.126s
im_proposals: 3897/5011 0.126s
im_proposals: 3898/5011 0.126s
im_proposals: 3899/5011 0.126s
im_proposals: 3900/5011 0.126s
im_proposals: 3901/5011 0.126s
im_proposals: 3902/5011 0.126s
im_proposals: 3903/5011 0.126s
im_proposals: 3904/5011 0.126s
im_proposals: 3905/5011 0.126s
im_proposals: 3906/5011 0.126s
im_proposals: 3907/5011 0.126s
im_proposals: 3908/5011 0.126s
im_proposals: 3909/5011 0.126s
im_proposals: 3910/5011 0.126s
im_proposals: 3911/5011 0.126s
im_proposals: 3912/5011 0.126s
im_proposals: 3913/5011 0.126s
im_proposals: 3914/5011 0.126s
im_proposals: 3915/5011 0.126s
im_proposals: 3916/5011 0.126s
im_proposals: 3917/5011 0.126s
im_proposals: 3918/5011 0.126s
im_proposals: 3919/5011 0.126s
im_proposals: 3920/5011 0.126s
im_proposals: 3921/5011 0.126s
im_proposals: 3922/5011 0.126s
im_proposals: 3923/5011 0.126s
im_proposals: 3924/5011 0.126s
im_proposals: 3925/5011 0.126s
im_proposals: 3926/5011 0.126s
im_proposals: 3927/5011 0.126s
im_proposals: 3928/5011 0.126s
im_proposals: 3929/5011 0.126s
im_proposals: 3930/5011 0.126s
im_proposals: 3931/5011 0.126s
im_proposals: 3932/5011 0.126s
im_proposals: 3933/5011 0.126s
im_proposals: 3934/5011 0.126s
im_proposals: 3935/5011 0.126s
im_proposals: 3936/5011 0.126s
im_proposals: 3937/5011 0.126s
im_proposals: 3938/5011 0.126s
im_proposals: 3939/5011 0.126s
im_proposals: 3940/5011 0.126s
im_proposals: 3941/5011 0.126s
im_proposals: 3942/5011 0.126s
im_proposals: 3943/5011 0.126s
im_proposals: 3944/5011 0.126s
im_proposals: 3945/5011 0.126s
im_proposals: 3946/5011 0.126s
im_proposals: 3947/5011 0.126s
im_proposals: 3948/5011 0.126s
im_proposals: 3949/5011 0.126s
im_proposals: 3950/5011 0.126s
im_proposals: 3951/5011 0.126s
im_proposals: 3952/5011 0.126s
im_proposals: 3953/5011 0.126s
im_proposals: 3954/5011 0.126s
im_proposals: 3955/5011 0.126s
im_proposals: 3956/5011 0.126s
im_proposals: 3957/5011 0.126s
im_proposals: 3958/5011 0.126s
im_proposals: 3959/5011 0.126s
im_proposals: 3960/5011 0.126s
im_proposals: 3961/5011 0.126s
im_proposals: 3962/5011 0.126s
im_proposals: 3963/5011 0.126s
im_proposals: 3964/5011 0.126s
im_proposals: 3965/5011 0.126s
im_proposals: 3966/5011 0.126s
im_proposals: 3967/5011 0.126s
im_proposals: 3968/5011 0.126s
im_proposals: 3969/5011 0.126s
im_proposals: 3970/5011 0.126s
im_proposals: 3971/5011 0.126s
im_proposals: 3972/5011 0.126s
im_proposals: 3973/5011 0.126s
im_proposals: 3974/5011 0.126s
im_proposals: 3975/5011 0.126s
im_proposals: 3976/5011 0.126s
im_proposals: 3977/5011 0.126s
im_proposals: 3978/5011 0.126s
im_proposals: 3979/5011 0.126s
im_proposals: 3980/5011 0.126s
im_proposals: 3981/5011 0.126s
im_proposals: 3982/5011 0.126s
im_proposals: 3983/5011 0.126s
im_proposals: 3984/5011 0.126s
im_proposals: 3985/5011 0.126s
im_proposals: 3986/5011 0.126s
im_proposals: 3987/5011 0.126s
im_proposals: 3988/5011 0.126s
im_proposals: 3989/5011 0.126s
im_proposals: 3990/5011 0.126s
im_proposals: 3991/5011 0.126s
im_proposals: 3992/5011 0.126s
im_proposals: 3993/5011 0.126s
im_proposals: 3994/5011 0.126s
im_proposals: 3995/5011 0.126s
im_proposals: 3996/5011 0.126s
im_proposals: 3997/5011 0.126s
im_proposals: 3998/5011 0.126s
im_proposals: 3999/5011 0.126s
im_proposals: 4000/5011 0.126s
im_proposals: 4001/5011 0.126s
im_proposals: 4002/5011 0.126s
im_proposals: 4003/5011 0.126s
im_proposals: 4004/5011 0.126s
im_proposals: 4005/5011 0.126s
im_proposals: 4006/5011 0.126s
im_proposals: 4007/5011 0.126s
im_proposals: 4008/5011 0.126s
im_proposals: 4009/5011 0.126s
im_proposals: 4010/5011 0.126s
im_proposals: 4011/5011 0.126s
im_proposals: 4012/5011 0.126s
im_proposals: 4013/5011 0.126s
im_proposals: 4014/5011 0.126s
im_proposals: 4015/5011 0.126s
im_proposals: 4016/5011 0.126s
im_proposals: 4017/5011 0.126s
im_proposals: 4018/5011 0.126s
im_proposals: 4019/5011 0.126s
im_proposals: 4020/5011 0.126s
im_proposals: 4021/5011 0.126s
im_proposals: 4022/5011 0.126s
im_proposals: 4023/5011 0.126s
im_proposals: 4024/5011 0.126s
im_proposals: 4025/5011 0.126s
im_proposals: 4026/5011 0.126s
im_proposals: 4027/5011 0.126s
im_proposals: 4028/5011 0.126s
im_proposals: 4029/5011 0.126s
im_proposals: 4030/5011 0.126s
im_proposals: 4031/5011 0.126s
im_proposals: 4032/5011 0.126s
im_proposals: 4033/5011 0.126s
im_proposals: 4034/5011 0.126s
im_proposals: 4035/5011 0.126s
im_proposals: 4036/5011 0.126s
im_proposals: 4037/5011 0.126s
im_proposals: 4038/5011 0.126s
im_proposals: 4039/5011 0.126s
im_proposals: 4040/5011 0.126s
im_proposals: 4041/5011 0.126s
im_proposals: 4042/5011 0.126s
im_proposals: 4043/5011 0.126s
im_proposals: 4044/5011 0.126s
im_proposals: 4045/5011 0.126s
im_proposals: 4046/5011 0.126s
im_proposals: 4047/5011 0.126s
im_proposals: 4048/5011 0.126s
im_proposals: 4049/5011 0.126s
im_proposals: 4050/5011 0.126s
im_proposals: 4051/5011 0.126s
im_proposals: 4052/5011 0.126s
im_proposals: 4053/5011 0.126s
im_proposals: 4054/5011 0.126s
im_proposals: 4055/5011 0.126s
im_proposals: 4056/5011 0.126s
im_proposals: 4057/5011 0.126s
im_proposals: 4058/5011 0.126s
im_proposals: 4059/5011 0.126s
im_proposals: 4060/5011 0.126s
im_proposals: 4061/5011 0.126s
im_proposals: 4062/5011 0.126s
im_proposals: 4063/5011 0.126s
im_proposals: 4064/5011 0.126s
im_proposals: 4065/5011 0.126s
im_proposals: 4066/5011 0.126s
im_proposals: 4067/5011 0.126s
im_proposals: 4068/5011 0.126s
im_proposals: 4069/5011 0.126s
im_proposals: 4070/5011 0.126s
im_proposals: 4071/5011 0.126s
im_proposals: 4072/5011 0.126s
im_proposals: 4073/5011 0.126s
im_proposals: 4074/5011 0.126s
im_proposals: 4075/5011 0.126s
im_proposals: 4076/5011 0.126s
im_proposals: 4077/5011 0.126s
im_proposals: 4078/5011 0.126s
im_proposals: 4079/5011 0.126s
im_proposals: 4080/5011 0.126s
im_proposals: 4081/5011 0.126s
im_proposals: 4082/5011 0.126s
im_proposals: 4083/5011 0.126s
im_proposals: 4084/5011 0.126s
im_proposals: 4085/5011 0.126s
im_proposals: 4086/5011 0.126s
im_proposals: 4087/5011 0.126s
im_proposals: 4088/5011 0.126s
im_proposals: 4089/5011 0.126s
im_proposals: 4090/5011 0.126s
im_proposals: 4091/5011 0.126s
im_proposals: 4092/5011 0.126s
im_proposals: 4093/5011 0.126s
im_proposals: 4094/5011 0.126s
im_proposals: 4095/5011 0.126s
im_proposals: 4096/5011 0.126s
im_proposals: 4097/5011 0.126s
im_proposals: 4098/5011 0.126s
im_proposals: 4099/5011 0.126s
im_proposals: 4100/5011 0.126s
im_proposals: 4101/5011 0.126s
im_proposals: 4102/5011 0.126s
im_proposals: 4103/5011 0.126s
im_proposals: 4104/5011 0.126s
im_proposals: 4105/5011 0.126s
im_proposals: 4106/5011 0.126s
im_proposals: 4107/5011 0.126s
im_proposals: 4108/5011 0.126s
im_proposals: 4109/5011 0.126s
im_proposals: 4110/5011 0.126s
im_proposals: 4111/5011 0.126s
im_proposals: 4112/5011 0.126s
im_proposals: 4113/5011 0.126s
im_proposals: 4114/5011 0.126s
im_proposals: 4115/5011 0.126s
im_proposals: 4116/5011 0.126s
im_proposals: 4117/5011 0.126s
im_proposals: 4118/5011 0.126s
im_proposals: 4119/5011 0.126s
im_proposals: 4120/5011 0.126s
im_proposals: 4121/5011 0.126s
im_proposals: 4122/5011 0.126s
im_proposals: 4123/5011 0.126s
im_proposals: 4124/5011 0.126s
im_proposals: 4125/5011 0.126s
im_proposals: 4126/5011 0.126s
im_proposals: 4127/5011 0.126s
im_proposals: 4128/5011 0.126s
im_proposals: 4129/5011 0.126s
im_proposals: 4130/5011 0.126s
im_proposals: 4131/5011 0.126s
im_proposals: 4132/5011 0.126s
im_proposals: 4133/5011 0.126s
im_proposals: 4134/5011 0.126s
im_proposals: 4135/5011 0.126s
im_proposals: 4136/5011 0.126s
im_proposals: 4137/5011 0.126s
im_proposals: 4138/5011 0.126s
im_proposals: 4139/5011 0.126s
im_proposals: 4140/5011 0.126s
im_proposals: 4141/5011 0.126s
im_proposals: 4142/5011 0.126s
im_proposals: 4143/5011 0.126s
im_proposals: 4144/5011 0.126s
im_proposals: 4145/5011 0.126s
im_proposals: 4146/5011 0.126s
im_proposals: 4147/5011 0.126s
im_proposals: 4148/5011 0.126s
im_proposals: 4149/5011 0.126s
im_proposals: 4150/5011 0.126s
im_proposals: 4151/5011 0.126s
im_proposals: 4152/5011 0.126s
im_proposals: 4153/5011 0.126s
im_proposals: 4154/5011 0.126s
im_proposals: 4155/5011 0.126s
im_proposals: 4156/5011 0.126s
im_proposals: 4157/5011 0.126s
im_proposals: 4158/5011 0.126s
im_proposals: 4159/5011 0.126s
im_proposals: 4160/5011 0.126s
im_proposals: 4161/5011 0.126s
im_proposals: 4162/5011 0.126s
im_proposals: 4163/5011 0.126s
im_proposals: 4164/5011 0.126s
im_proposals: 4165/5011 0.126s
im_proposals: 4166/5011 0.126s
im_proposals: 4167/5011 0.126s
im_proposals: 4168/5011 0.126s
im_proposals: 4169/5011 0.126s
im_proposals: 4170/5011 0.126s
im_proposals: 4171/5011 0.126s
im_proposals: 4172/5011 0.126s
im_proposals: 4173/5011 0.126s
im_proposals: 4174/5011 0.126s
im_proposals: 4175/5011 0.126s
im_proposals: 4176/5011 0.126s
im_proposals: 4177/5011 0.126s
im_proposals: 4178/5011 0.126s
im_proposals: 4179/5011 0.126s
im_proposals: 4180/5011 0.126s
im_proposals: 4181/5011 0.126s
im_proposals: 4182/5011 0.126s
im_proposals: 4183/5011 0.126s
im_proposals: 4184/5011 0.126s
im_proposals: 4185/5011 0.126s
im_proposals: 4186/5011 0.126s
im_proposals: 4187/5011 0.126s
im_proposals: 4188/5011 0.126s
im_proposals: 4189/5011 0.126s
im_proposals: 4190/5011 0.126s
im_proposals: 4191/5011 0.126s
im_proposals: 4192/5011 0.126s
im_proposals: 4193/5011 0.126s
im_proposals: 4194/5011 0.126s
im_proposals: 4195/5011 0.126s
im_proposals: 4196/5011 0.126s
im_proposals: 4197/5011 0.126s
im_proposals: 4198/5011 0.126s
im_proposals: 4199/5011 0.126s
im_proposals: 4200/5011 0.126s
im_proposals: 4201/5011 0.126s
im_proposals: 4202/5011 0.126s
im_proposals: 4203/5011 0.126s
im_proposals: 4204/5011 0.126s
im_proposals: 4205/5011 0.126s
im_proposals: 4206/5011 0.126s
im_proposals: 4207/5011 0.126s
im_proposals: 4208/5011 0.126s
im_proposals: 4209/5011 0.126s
im_proposals: 4210/5011 0.126s
im_proposals: 4211/5011 0.126s
im_proposals: 4212/5011 0.126s
im_proposals: 4213/5011 0.126s
im_proposals: 4214/5011 0.126s
im_proposals: 4215/5011 0.126s
im_proposals: 4216/5011 0.126s
im_proposals: 4217/5011 0.126s
im_proposals: 4218/5011 0.126s
im_proposals: 4219/5011 0.126s
im_proposals: 4220/5011 0.126s
im_proposals: 4221/5011 0.126s
im_proposals: 4222/5011 0.126s
im_proposals: 4223/5011 0.126s
im_proposals: 4224/5011 0.126s
im_proposals: 4225/5011 0.126s
im_proposals: 4226/5011 0.126s
im_proposals: 4227/5011 0.126s
im_proposals: 4228/5011 0.126s
im_proposals: 4229/5011 0.126s
im_proposals: 4230/5011 0.126s
im_proposals: 4231/5011 0.126s
im_proposals: 4232/5011 0.126s
im_proposals: 4233/5011 0.126s
im_proposals: 4234/5011 0.126s
im_proposals: 4235/5011 0.126s
im_proposals: 4236/5011 0.126s
im_proposals: 4237/5011 0.126s
im_proposals: 4238/5011 0.126s
im_proposals: 4239/5011 0.126s
im_proposals: 4240/5011 0.126s
im_proposals: 4241/5011 0.126s
im_proposals: 4242/5011 0.126s
im_proposals: 4243/5011 0.126s
im_proposals: 4244/5011 0.126s
im_proposals: 4245/5011 0.126s
im_proposals: 4246/5011 0.126s
im_proposals: 4247/5011 0.126s
im_proposals: 4248/5011 0.126s
im_proposals: 4249/5011 0.126s
im_proposals: 4250/5011 0.126s
im_proposals: 4251/5011 0.126s
im_proposals: 4252/5011 0.126s
im_proposals: 4253/5011 0.126s
im_proposals: 4254/5011 0.126s
im_proposals: 4255/5011 0.126s
im_proposals: 4256/5011 0.126s
im_proposals: 4257/5011 0.126s
im_proposals: 4258/5011 0.126s
im_proposals: 4259/5011 0.126s
im_proposals: 4260/5011 0.126s
im_proposals: 4261/5011 0.126s
im_proposals: 4262/5011 0.126s
im_proposals: 4263/5011 0.126s
im_proposals: 4264/5011 0.126s
im_proposals: 4265/5011 0.126s
im_proposals: 4266/5011 0.126s
im_proposals: 4267/5011 0.126s
im_proposals: 4268/5011 0.126s
im_proposals: 4269/5011 0.126s
im_proposals: 4270/5011 0.126s
im_proposals: 4271/5011 0.126s
im_proposals: 4272/5011 0.126s
im_proposals: 4273/5011 0.126s
im_proposals: 4274/5011 0.126s
im_proposals: 4275/5011 0.126s
im_proposals: 4276/5011 0.126s
im_proposals: 4277/5011 0.126s
im_proposals: 4278/5011 0.126s
im_proposals: 4279/5011 0.126s
im_proposals: 4280/5011 0.126s
im_proposals: 4281/5011 0.126s
im_proposals: 4282/5011 0.126s
im_proposals: 4283/5011 0.126s
im_proposals: 4284/5011 0.126s
im_proposals: 4285/5011 0.126s
im_proposals: 4286/5011 0.126s
im_proposals: 4287/5011 0.126s
im_proposals: 4288/5011 0.126s
im_proposals: 4289/5011 0.126s
im_proposals: 4290/5011 0.126s
im_proposals: 4291/5011 0.126s
im_proposals: 4292/5011 0.126s
im_proposals: 4293/5011 0.126s
im_proposals: 4294/5011 0.126s
im_proposals: 4295/5011 0.126s
im_proposals: 4296/5011 0.126s
im_proposals: 4297/5011 0.126s
im_proposals: 4298/5011 0.126s
im_proposals: 4299/5011 0.126s
im_proposals: 4300/5011 0.126s
im_proposals: 4301/5011 0.126s
im_proposals: 4302/5011 0.126s
im_proposals: 4303/5011 0.126s
im_proposals: 4304/5011 0.126s
im_proposals: 4305/5011 0.126s
im_proposals: 4306/5011 0.126s
im_proposals: 4307/5011 0.126s
im_proposals: 4308/5011 0.126s
im_proposals: 4309/5011 0.126s
im_proposals: 4310/5011 0.126s
im_proposals: 4311/5011 0.126s
im_proposals: 4312/5011 0.126s
im_proposals: 4313/5011 0.126s
im_proposals: 4314/5011 0.126s
im_proposals: 4315/5011 0.126s
im_proposals: 4316/5011 0.126s
im_proposals: 4317/5011 0.126s
im_proposals: 4318/5011 0.126s
im_proposals: 4319/5011 0.126s
im_proposals: 4320/5011 0.126s
im_proposals: 4321/5011 0.126s
im_proposals: 4322/5011 0.126s
im_proposals: 4323/5011 0.126s
im_proposals: 4324/5011 0.126s
im_proposals: 4325/5011 0.126s
im_proposals: 4326/5011 0.126s
im_proposals: 4327/5011 0.126s
im_proposals: 4328/5011 0.126s
im_proposals: 4329/5011 0.126s
im_proposals: 4330/5011 0.126s
im_proposals: 4331/5011 0.126s
im_proposals: 4332/5011 0.126s
im_proposals: 4333/5011 0.126s
im_proposals: 4334/5011 0.126s
im_proposals: 4335/5011 0.126s
im_proposals: 4336/5011 0.126s
im_proposals: 4337/5011 0.126s
im_proposals: 4338/5011 0.126s
im_proposals: 4339/5011 0.126s
im_proposals: 4340/5011 0.126s
im_proposals: 4341/5011 0.126s
im_proposals: 4342/5011 0.126s
im_proposals: 4343/5011 0.126s
im_proposals: 4344/5011 0.126s
im_proposals: 4345/5011 0.126s
im_proposals: 4346/5011 0.126s
im_proposals: 4347/5011 0.126s
im_proposals: 4348/5011 0.126s
im_proposals: 4349/5011 0.126s
im_proposals: 4350/5011 0.126s
im_proposals: 4351/5011 0.126s
im_proposals: 4352/5011 0.126s
im_proposals: 4353/5011 0.126s
im_proposals: 4354/5011 0.126s
im_proposals: 4355/5011 0.126s
im_proposals: 4356/5011 0.126s
im_proposals: 4357/5011 0.126s
im_proposals: 4358/5011 0.126s
im_proposals: 4359/5011 0.126s
im_proposals: 4360/5011 0.126s
im_proposals: 4361/5011 0.126s
im_proposals: 4362/5011 0.126s
im_proposals: 4363/5011 0.126s
im_proposals: 4364/5011 0.126s
im_proposals: 4365/5011 0.126s
im_proposals: 4366/5011 0.126s
im_proposals: 4367/5011 0.126s
im_proposals: 4368/5011 0.126s
im_proposals: 4369/5011 0.126s
im_proposals: 4370/5011 0.126s
im_proposals: 4371/5011 0.126s
im_proposals: 4372/5011 0.126s
im_proposals: 4373/5011 0.126s
im_proposals: 4374/5011 0.126s
im_proposals: 4375/5011 0.126s
im_proposals: 4376/5011 0.126s
im_proposals: 4377/5011 0.126s
im_proposals: 4378/5011 0.126s
im_proposals: 4379/5011 0.126s
im_proposals: 4380/5011 0.126s
im_proposals: 4381/5011 0.126s
im_proposals: 4382/5011 0.126s
im_proposals: 4383/5011 0.126s
im_proposals: 4384/5011 0.126s
im_proposals: 4385/5011 0.126s
im_proposals: 4386/5011 0.126s
im_proposals: 4387/5011 0.126s
im_proposals: 4388/5011 0.126s
im_proposals: 4389/5011 0.126s
im_proposals: 4390/5011 0.126s
im_proposals: 4391/5011 0.126s
im_proposals: 4392/5011 0.126s
im_proposals: 4393/5011 0.126s
im_proposals: 4394/5011 0.126s
im_proposals: 4395/5011 0.126s
im_proposals: 4396/5011 0.126s
im_proposals: 4397/5011 0.126s
im_proposals: 4398/5011 0.126s
im_proposals: 4399/5011 0.126s
im_proposals: 4400/5011 0.126s
im_proposals: 4401/5011 0.126s
im_proposals: 4402/5011 0.126s
im_proposals: 4403/5011 0.126s
im_proposals: 4404/5011 0.126s
im_proposals: 4405/5011 0.126s
im_proposals: 4406/5011 0.126s
im_proposals: 4407/5011 0.126s
im_proposals: 4408/5011 0.126s
im_proposals: 4409/5011 0.126s
im_proposals: 4410/5011 0.126s
im_proposals: 4411/5011 0.126s
im_proposals: 4412/5011 0.126s
im_proposals: 4413/5011 0.126s
im_proposals: 4414/5011 0.126s
im_proposals: 4415/5011 0.126s
im_proposals: 4416/5011 0.126s
im_proposals: 4417/5011 0.126s
im_proposals: 4418/5011 0.126s
im_proposals: 4419/5011 0.126s
im_proposals: 4420/5011 0.126s
im_proposals: 4421/5011 0.126s
im_proposals: 4422/5011 0.126s
im_proposals: 4423/5011 0.126s
im_proposals: 4424/5011 0.126s
im_proposals: 4425/5011 0.126s
im_proposals: 4426/5011 0.126s
im_proposals: 4427/5011 0.126s
im_proposals: 4428/5011 0.126s
im_proposals: 4429/5011 0.126s
im_proposals: 4430/5011 0.126s
im_proposals: 4431/5011 0.126s
im_proposals: 4432/5011 0.126s
im_proposals: 4433/5011 0.126s
im_proposals: 4434/5011 0.126s
im_proposals: 4435/5011 0.126s
im_proposals: 4436/5011 0.126s
im_proposals: 4437/5011 0.126s
im_proposals: 4438/5011 0.126s
im_proposals: 4439/5011 0.126s
im_proposals: 4440/5011 0.126s
im_proposals: 4441/5011 0.126s
im_proposals: 4442/5011 0.126s
im_proposals: 4443/5011 0.126s
im_proposals: 4444/5011 0.126s
im_proposals: 4445/5011 0.126s
im_proposals: 4446/5011 0.126s
im_proposals: 4447/5011 0.126s
im_proposals: 4448/5011 0.126s
im_proposals: 4449/5011 0.126s
im_proposals: 4450/5011 0.126s
im_proposals: 4451/5011 0.126s
im_proposals: 4452/5011 0.126s
im_proposals: 4453/5011 0.126s
im_proposals: 4454/5011 0.126s
im_proposals: 4455/5011 0.126s
im_proposals: 4456/5011 0.126s
im_proposals: 4457/5011 0.126s
im_proposals: 4458/5011 0.126s
im_proposals: 4459/5011 0.126s
im_proposals: 4460/5011 0.126s
im_proposals: 4461/5011 0.126s
im_proposals: 4462/5011 0.126s
im_proposals: 4463/5011 0.126s
im_proposals: 4464/5011 0.126s
im_proposals: 4465/5011 0.126s
im_proposals: 4466/5011 0.126s
im_proposals: 4467/5011 0.126s
im_proposals: 4468/5011 0.126s
im_proposals: 4469/5011 0.126s
im_proposals: 4470/5011 0.126s
im_proposals: 4471/5011 0.126s
im_proposals: 4472/5011 0.126s
im_proposals: 4473/5011 0.126s
im_proposals: 4474/5011 0.126s
im_proposals: 4475/5011 0.126s
im_proposals: 4476/5011 0.126s
im_proposals: 4477/5011 0.126s
im_proposals: 4478/5011 0.126s
im_proposals: 4479/5011 0.126s
im_proposals: 4480/5011 0.126s
im_proposals: 4481/5011 0.126s
im_proposals: 4482/5011 0.126s
im_proposals: 4483/5011 0.126s
im_proposals: 4484/5011 0.126s
im_proposals: 4485/5011 0.126s
im_proposals: 4486/5011 0.126s
im_proposals: 4487/5011 0.126s
im_proposals: 4488/5011 0.126s
im_proposals: 4489/5011 0.126s
im_proposals: 4490/5011 0.126s
im_proposals: 4491/5011 0.126s
im_proposals: 4492/5011 0.126s
im_proposals: 4493/5011 0.126s
im_proposals: 4494/5011 0.126s
im_proposals: 4495/5011 0.126s
im_proposals: 4496/5011 0.126s
im_proposals: 4497/5011 0.126s
im_proposals: 4498/5011 0.126s
im_proposals: 4499/5011 0.126s
im_proposals: 4500/5011 0.126s
im_proposals: 4501/5011 0.126s
im_proposals: 4502/5011 0.126s
im_proposals: 4503/5011 0.126s
im_proposals: 4504/5011 0.126s
im_proposals: 4505/5011 0.126s
im_proposals: 4506/5011 0.126s
im_proposals: 4507/5011 0.126s
im_proposals: 4508/5011 0.126s
im_proposals: 4509/5011 0.126s
im_proposals: 4510/5011 0.126s
im_proposals: 4511/5011 0.126s
im_proposals: 4512/5011 0.126s
im_proposals: 4513/5011 0.126s
im_proposals: 4514/5011 0.126s
im_proposals: 4515/5011 0.126s
im_proposals: 4516/5011 0.126s
im_proposals: 4517/5011 0.126s
im_proposals: 4518/5011 0.126s
im_proposals: 4519/5011 0.126s
im_proposals: 4520/5011 0.126s
im_proposals: 4521/5011 0.126s
im_proposals: 4522/5011 0.126s
im_proposals: 4523/5011 0.126s
im_proposals: 4524/5011 0.126s
im_proposals: 4525/5011 0.126s
im_proposals: 4526/5011 0.126s
im_proposals: 4527/5011 0.126s
im_proposals: 4528/5011 0.126s
im_proposals: 4529/5011 0.126s
im_proposals: 4530/5011 0.126s
im_proposals: 4531/5011 0.126s
im_proposals: 4532/5011 0.126s
im_proposals: 4533/5011 0.126s
im_proposals: 4534/5011 0.126s
im_proposals: 4535/5011 0.126s
im_proposals: 4536/5011 0.126s
im_proposals: 4537/5011 0.126s
im_proposals: 4538/5011 0.126s
im_proposals: 4539/5011 0.126s
im_proposals: 4540/5011 0.126s
im_proposals: 4541/5011 0.126s
im_proposals: 4542/5011 0.126s
im_proposals: 4543/5011 0.126s
im_proposals: 4544/5011 0.126s
im_proposals: 4545/5011 0.126s
im_proposals: 4546/5011 0.126s
im_proposals: 4547/5011 0.126s
im_proposals: 4548/5011 0.126s
im_proposals: 4549/5011 0.126s
im_proposals: 4550/5011 0.126s
im_proposals: 4551/5011 0.126s
im_proposals: 4552/5011 0.126s
im_proposals: 4553/5011 0.126s
im_proposals: 4554/5011 0.126s
im_proposals: 4555/5011 0.126s
im_proposals: 4556/5011 0.126s
im_proposals: 4557/5011 0.126s
im_proposals: 4558/5011 0.126s
im_proposals: 4559/5011 0.126s
im_proposals: 4560/5011 0.126s
im_proposals: 4561/5011 0.126s
im_proposals: 4562/5011 0.126s
im_proposals: 4563/5011 0.126s
im_proposals: 4564/5011 0.126s
im_proposals: 4565/5011 0.126s
im_proposals: 4566/5011 0.126s
im_proposals: 4567/5011 0.126s
im_proposals: 4568/5011 0.126s
im_proposals: 4569/5011 0.126s
im_proposals: 4570/5011 0.126s
im_proposals: 4571/5011 0.126s
im_proposals: 4572/5011 0.126s
im_proposals: 4573/5011 0.126s
im_proposals: 4574/5011 0.126s
im_proposals: 4575/5011 0.126s
im_proposals: 4576/5011 0.126s
im_proposals: 4577/5011 0.126s
im_proposals: 4578/5011 0.126s
im_proposals: 4579/5011 0.126s
im_proposals: 4580/5011 0.126s
im_proposals: 4581/5011 0.126s
im_proposals: 4582/5011 0.126s
im_proposals: 4583/5011 0.126s
im_proposals: 4584/5011 0.126s
im_proposals: 4585/5011 0.126s
im_proposals: 4586/5011 0.126s
im_proposals: 4587/5011 0.126s
im_proposals: 4588/5011 0.126s
im_proposals: 4589/5011 0.126s
im_proposals: 4590/5011 0.126s
im_proposals: 4591/5011 0.126s
im_proposals: 4592/5011 0.126s
im_proposals: 4593/5011 0.126s
im_proposals: 4594/5011 0.126s
im_proposals: 4595/5011 0.126s
im_proposals: 4596/5011 0.126s
im_proposals: 4597/5011 0.126s
im_proposals: 4598/5011 0.126s
im_proposals: 4599/5011 0.126s
im_proposals: 4600/5011 0.126s
im_proposals: 4601/5011 0.126s
im_proposals: 4602/5011 0.126s
im_proposals: 4603/5011 0.126s
im_proposals: 4604/5011 0.126s
im_proposals: 4605/5011 0.126s
im_proposals: 4606/5011 0.126s
im_proposals: 4607/5011 0.126s
im_proposals: 4608/5011 0.126s
im_proposals: 4609/5011 0.126s
im_proposals: 4610/5011 0.126s
im_proposals: 4611/5011 0.126s
im_proposals: 4612/5011 0.126s
im_proposals: 4613/5011 0.126s
im_proposals: 4614/5011 0.126s
im_proposals: 4615/5011 0.126s
im_proposals: 4616/5011 0.126s
im_proposals: 4617/5011 0.126s
im_proposals: 4618/5011 0.126s
im_proposals: 4619/5011 0.126s
im_proposals: 4620/5011 0.126s
im_proposals: 4621/5011 0.126s
im_proposals: 4622/5011 0.126s
im_proposals: 4623/5011 0.126s
im_proposals: 4624/5011 0.126s
im_proposals: 4625/5011 0.126s
im_proposals: 4626/5011 0.126s
im_proposals: 4627/5011 0.126s
im_proposals: 4628/5011 0.126s
im_proposals: 4629/5011 0.126s
im_proposals: 4630/5011 0.126s
im_proposals: 4631/5011 0.126s
im_proposals: 4632/5011 0.126s
im_proposals: 4633/5011 0.126s
im_proposals: 4634/5011 0.126s
im_proposals: 4635/5011 0.126s
im_proposals: 4636/5011 0.126s
im_proposals: 4637/5011 0.126s
im_proposals: 4638/5011 0.126s
im_proposals: 4639/5011 0.126s
im_proposals: 4640/5011 0.126s
im_proposals: 4641/5011 0.126s
im_proposals: 4642/5011 0.126s
im_proposals: 4643/5011 0.126s
im_proposals: 4644/5011 0.126s
im_proposals: 4645/5011 0.126s
im_proposals: 4646/5011 0.126s
im_proposals: 4647/5011 0.126s
im_proposals: 4648/5011 0.126s
im_proposals: 4649/5011 0.126s
im_proposals: 4650/5011 0.126s
im_proposals: 4651/5011 0.126s
im_proposals: 4652/5011 0.126s
im_proposals: 4653/5011 0.126s
im_proposals: 4654/5011 0.126s
im_proposals: 4655/5011 0.126s
im_proposals: 4656/5011 0.126s
im_proposals: 4657/5011 0.126s
im_proposals: 4658/5011 0.126s
im_proposals: 4659/5011 0.126s
im_proposals: 4660/5011 0.126s
im_proposals: 4661/5011 0.126s
im_proposals: 4662/5011 0.126s
im_proposals: 4663/5011 0.126s
im_proposals: 4664/5011 0.126s
im_proposals: 4665/5011 0.126s
im_proposals: 4666/5011 0.126s
im_proposals: 4667/5011 0.126s
im_proposals: 4668/5011 0.126s
im_proposals: 4669/5011 0.126s
im_proposals: 4670/5011 0.126s
im_proposals: 4671/5011 0.126s
im_proposals: 4672/5011 0.126s
im_proposals: 4673/5011 0.126s
im_proposals: 4674/5011 0.126s
im_proposals: 4675/5011 0.126s
im_proposals: 4676/5011 0.126s
im_proposals: 4677/5011 0.126s
im_proposals: 4678/5011 0.126s
im_proposals: 4679/5011 0.126s
im_proposals: 4680/5011 0.126s
im_proposals: 4681/5011 0.126s
im_proposals: 4682/5011 0.126s
im_proposals: 4683/5011 0.126s
im_proposals: 4684/5011 0.126s
im_proposals: 4685/5011 0.126s
im_proposals: 4686/5011 0.126s
im_proposals: 4687/5011 0.126s
im_proposals: 4688/5011 0.126s
im_proposals: 4689/5011 0.126s
im_proposals: 4690/5011 0.126s
im_proposals: 4691/5011 0.126s
im_proposals: 4692/5011 0.126s
im_proposals: 4693/5011 0.126s
im_proposals: 4694/5011 0.126s
im_proposals: 4695/5011 0.126s
im_proposals: 4696/5011 0.126s
im_proposals: 4697/5011 0.126s
im_proposals: 4698/5011 0.126s
im_proposals: 4699/5011 0.126s
im_proposals: 4700/5011 0.126s
im_proposals: 4701/5011 0.126s
im_proposals: 4702/5011 0.126s
im_proposals: 4703/5011 0.126s
im_proposals: 4704/5011 0.126s
im_proposals: 4705/5011 0.126s
im_proposals: 4706/5011 0.126s
im_proposals: 4707/5011 0.126s
im_proposals: 4708/5011 0.126s
im_proposals: 4709/5011 0.126s
im_proposals: 4710/5011 0.126s
im_proposals: 4711/5011 0.126s
im_proposals: 4712/5011 0.126s
im_proposals: 4713/5011 0.126s
im_proposals: 4714/5011 0.126s
im_proposals: 4715/5011 0.126s
im_proposals: 4716/5011 0.126s
im_proposals: 4717/5011 0.126s
im_proposals: 4718/5011 0.126s
im_proposals: 4719/5011 0.126s
im_proposals: 4720/5011 0.126s
im_proposals: 4721/5011 0.126s
im_proposals: 4722/5011 0.126s
im_proposals: 4723/5011 0.126s
im_proposals: 4724/5011 0.126s
im_proposals: 4725/5011 0.126s
im_proposals: 4726/5011 0.126s
im_proposals: 4727/5011 0.126s
im_proposals: 4728/5011 0.126s
im_proposals: 4729/5011 0.126s
im_proposals: 4730/5011 0.126s
im_proposals: 4731/5011 0.126s
im_proposals: 4732/5011 0.126s
im_proposals: 4733/5011 0.126s
im_proposals: 4734/5011 0.126s
im_proposals: 4735/5011 0.126s
im_proposals: 4736/5011 0.126s
im_proposals: 4737/5011 0.126s
im_proposals: 4738/5011 0.126s
im_proposals: 4739/5011 0.126s
im_proposals: 4740/5011 0.126s
im_proposals: 4741/5011 0.126s
im_proposals: 4742/5011 0.126s
im_proposals: 4743/5011 0.126s
im_proposals: 4744/5011 0.126s
im_proposals: 4745/5011 0.126s
im_proposals: 4746/5011 0.126s
im_proposals: 4747/5011 0.126s
im_proposals: 4748/5011 0.126s
im_proposals: 4749/5011 0.126s
im_proposals: 4750/5011 0.126s
im_proposals: 4751/5011 0.126s
im_proposals: 4752/5011 0.126s
im_proposals: 4753/5011 0.126s
im_proposals: 4754/5011 0.126s
im_proposals: 4755/5011 0.126s
im_proposals: 4756/5011 0.126s
im_proposals: 4757/5011 0.126s
im_proposals: 4758/5011 0.126s
im_proposals: 4759/5011 0.126s
im_proposals: 4760/5011 0.126s
im_proposals: 4761/5011 0.126s
im_proposals: 4762/5011 0.126s
im_proposals: 4763/5011 0.126s
im_proposals: 4764/5011 0.126s
im_proposals: 4765/5011 0.126s
im_proposals: 4766/5011 0.126s
im_proposals: 4767/5011 0.126s
im_proposals: 4768/5011 0.126s
im_proposals: 4769/5011 0.126s
im_proposals: 4770/5011 0.126s
im_proposals: 4771/5011 0.126s
im_proposals: 4772/5011 0.126s
im_proposals: 4773/5011 0.126s
im_proposals: 4774/5011 0.126s
im_proposals: 4775/5011 0.126s
im_proposals: 4776/5011 0.126s
im_proposals: 4777/5011 0.126s
im_proposals: 4778/5011 0.126s
im_proposals: 4779/5011 0.126s
im_proposals: 4780/5011 0.126s
im_proposals: 4781/5011 0.126s
im_proposals: 4782/5011 0.126s
im_proposals: 4783/5011 0.126s
im_proposals: 4784/5011 0.126s
im_proposals: 4785/5011 0.126s
im_proposals: 4786/5011 0.126s
im_proposals: 4787/5011 0.126s
im_proposals: 4788/5011 0.126s
im_proposals: 4789/5011 0.126s
im_proposals: 4790/5011 0.126s
im_proposals: 4791/5011 0.126s
im_proposals: 4792/5011 0.126s
im_proposals: 4793/5011 0.126s
im_proposals: 4794/5011 0.126s
im_proposals: 4795/5011 0.126s
im_proposals: 4796/5011 0.126s
im_proposals: 4797/5011 0.126s
im_proposals: 4798/5011 0.126s
im_proposals: 4799/5011 0.126s
im_proposals: 4800/5011 0.126s
im_proposals: 4801/5011 0.126s
im_proposals: 4802/5011 0.126s
im_proposals: 4803/5011 0.126s
im_proposals: 4804/5011 0.126s
im_proposals: 4805/5011 0.126s
im_proposals: 4806/5011 0.126s
im_proposals: 4807/5011 0.126s
im_proposals: 4808/5011 0.126s
im_proposals: 4809/5011 0.126s
im_proposals: 4810/5011 0.126s
im_proposals: 4811/5011 0.126s
im_proposals: 4812/5011 0.126s
im_proposals: 4813/5011 0.126s
im_proposals: 4814/5011 0.126s
im_proposals: 4815/5011 0.126s
im_proposals: 4816/5011 0.126s
im_proposals: 4817/5011 0.126s
im_proposals: 4818/5011 0.126s
im_proposals: 4819/5011 0.126s
im_proposals: 4820/5011 0.126s
im_proposals: 4821/5011 0.126s
im_proposals: 4822/5011 0.126s
im_proposals: 4823/5011 0.126s
im_proposals: 4824/5011 0.126s
im_proposals: 4825/5011 0.126s
im_proposals: 4826/5011 0.126s
im_proposals: 4827/5011 0.126s
im_proposals: 4828/5011 0.126s
im_proposals: 4829/5011 0.126s
im_proposals: 4830/5011 0.126s
im_proposals: 4831/5011 0.126s
im_proposals: 4832/5011 0.126s
im_proposals: 4833/5011 0.126s
im_proposals: 4834/5011 0.126s
im_proposals: 4835/5011 0.126s
im_proposals: 4836/5011 0.126s
im_proposals: 4837/5011 0.126s
im_proposals: 4838/5011 0.126s
im_proposals: 4839/5011 0.126s
im_proposals: 4840/5011 0.126s
im_proposals: 4841/5011 0.126s
im_proposals: 4842/5011 0.126s
im_proposals: 4843/5011 0.126s
im_proposals: 4844/5011 0.126s
im_proposals: 4845/5011 0.126s
im_proposals: 4846/5011 0.126s
im_proposals: 4847/5011 0.126s
im_proposals: 4848/5011 0.126s
im_proposals: 4849/5011 0.126s
im_proposals: 4850/5011 0.126s
im_proposals: 4851/5011 0.126s
im_proposals: 4852/5011 0.126s
im_proposals: 4853/5011 0.126s
im_proposals: 4854/5011 0.126s
im_proposals: 4855/5011 0.126s
im_proposals: 4856/5011 0.126s
im_proposals: 4857/5011 0.126s
im_proposals: 4858/5011 0.126s
im_proposals: 4859/5011 0.126s
im_proposals: 4860/5011 0.126s
im_proposals: 4861/5011 0.126s
im_proposals: 4862/5011 0.126s
im_proposals: 4863/5011 0.126s
im_proposals: 4864/5011 0.126s
im_proposals: 4865/5011 0.126s
im_proposals: 4866/5011 0.126s
im_proposals: 4867/5011 0.126s
im_proposals: 4868/5011 0.126s
im_proposals: 4869/5011 0.126s
im_proposals: 4870/5011 0.126s
im_proposals: 4871/5011 0.126s
im_proposals: 4872/5011 0.126s
im_proposals: 4873/5011 0.126s
im_proposals: 4874/5011 0.126s
im_proposals: 4875/5011 0.126s
im_proposals: 4876/5011 0.126s
im_proposals: 4877/5011 0.126s
im_proposals: 4878/5011 0.126s
im_proposals: 4879/5011 0.126s
im_proposals: 4880/5011 0.126s
im_proposals: 4881/5011 0.126s
im_proposals: 4882/5011 0.126s
im_proposals: 4883/5011 0.126s
im_proposals: 4884/5011 0.126s
im_proposals: 4885/5011 0.126s
im_proposals: 4886/5011 0.126s
im_proposals: 4887/5011 0.126s
im_proposals: 4888/5011 0.126s
im_proposals: 4889/5011 0.126s
im_proposals: 4890/5011 0.126s
im_proposals: 4891/5011 0.126s
im_proposals: 4892/5011 0.126s
im_proposals: 4893/5011 0.126s
im_proposals: 4894/5011 0.126s
im_proposals: 4895/5011 0.126s
im_proposals: 4896/5011 0.126s
im_proposals: 4897/5011 0.126s
im_proposals: 4898/5011 0.126s
im_proposals: 4899/5011 0.126s
im_proposals: 4900/5011 0.126s
im_proposals: 4901/5011 0.126s
im_proposals: 4902/5011 0.126s
im_proposals: 4903/5011 0.126s
im_proposals: 4904/5011 0.126s
im_proposals: 4905/5011 0.126s
im_proposals: 4906/5011 0.126s
im_proposals: 4907/5011 0.126s
im_proposals: 4908/5011 0.126s
im_proposals: 4909/5011 0.126s
im_proposals: 4910/5011 0.126s
im_proposals: 4911/5011 0.126s
im_proposals: 4912/5011 0.126s
im_proposals: 4913/5011 0.126s
im_proposals: 4914/5011 0.126s
im_proposals: 4915/5011 0.126s
im_proposals: 4916/5011 0.126s
im_proposals: 4917/5011 0.126s
im_proposals: 4918/5011 0.126s
im_proposals: 4919/5011 0.126s
im_proposals: 4920/5011 0.126s
im_proposals: 4921/5011 0.126s
im_proposals: 4922/5011 0.126s
im_proposals: 4923/5011 0.126s
im_proposals: 4924/5011 0.126s
im_proposals: 4925/5011 0.126s
im_proposals: 4926/5011 0.126s
im_proposals: 4927/5011 0.126s
im_proposals: 4928/5011 0.126s
im_proposals: 4929/5011 0.126s
im_proposals: 4930/5011 0.126s
im_proposals: 4931/5011 0.126s
im_proposals: 4932/5011 0.126s
im_proposals: 4933/5011 0.126s
im_proposals: 4934/5011 0.126s
im_proposals: 4935/5011 0.126s
im_proposals: 4936/5011 0.126s
im_proposals: 4937/5011 0.126s
im_proposals: 4938/5011 0.126s
im_proposals: 4939/5011 0.126s
im_proposals: 4940/5011 0.126s
im_proposals: 4941/5011 0.126s
im_proposals: 4942/5011 0.126s
im_proposals: 4943/5011 0.126s
im_proposals: 4944/5011 0.126s
im_proposals: 4945/5011 0.126s
im_proposals: 4946/5011 0.126s
im_proposals: 4947/5011 0.126s
im_proposals: 4948/5011 0.126s
im_proposals: 4949/5011 0.126s
im_proposals: 4950/5011 0.126s
im_proposals: 4951/5011 0.126s
im_proposals: 4952/5011 0.126s
im_proposals: 4953/5011 0.126s
im_proposals: 4954/5011 0.126s
im_proposals: 4955/5011 0.126s
im_proposals: 4956/5011 0.126s
im_proposals: 4957/5011 0.126s
im_proposals: 4958/5011 0.126s
im_proposals: 4959/5011 0.126s
im_proposals: 4960/5011 0.126s
im_proposals: 4961/5011 0.126s
im_proposals: 4962/5011 0.126s
im_proposals: 4963/5011 0.126s
im_proposals: 4964/5011 0.126s
im_proposals: 4965/5011 0.126s
im_proposals: 4966/5011 0.126s
im_proposals: 4967/5011 0.126s
im_proposals: 4968/5011 0.126s
im_proposals: 4969/5011 0.126s
im_proposals: 4970/5011 0.126s
im_proposals: 4971/5011 0.126s
im_proposals: 4972/5011 0.126s
im_proposals: 4973/5011 0.126s
im_proposals: 4974/5011 0.126s
im_proposals: 4975/5011 0.126s
im_proposals: 4976/5011 0.126s
im_proposals: 4977/5011 0.126s
im_proposals: 4978/5011 0.126s
im_proposals: 4979/5011 0.126s
im_proposals: 4980/5011 0.126s
im_proposals: 4981/5011 0.126s
im_proposals: 4982/5011 0.126s
im_proposals: 4983/5011 0.126s
im_proposals: 4984/5011 0.126s
im_proposals: 4985/5011 0.126s
im_proposals: 4986/5011 0.126s
im_proposals: 4987/5011 0.126s
im_proposals: 4988/5011 0.126s
im_proposals: 4989/5011 0.126s
im_proposals: 4990/5011 0.126s
im_proposals: 4991/5011 0.126s
im_proposals: 4992/5011 0.126s
im_proposals: 4993/5011 0.126s
im_proposals: 4994/5011 0.126s
im_proposals: 4995/5011 0.126s
im_proposals: 4996/5011 0.126s
im_proposals: 4997/5011 0.126s
im_proposals: 4998/5011 0.126s
im_proposals: 4999/5011 0.126s
im_proposals: 5000/5011 0.126s
im_proposals: 5001/5011 0.126s
im_proposals: 5002/5011 0.126s
im_proposals: 5003/5011 0.126s
im_proposals: 5004/5011 0.126s
im_proposals: 5005/5011 0.126s
im_proposals: 5006/5011 0.126s
im_proposals: 5007/5011 0.126s
im_proposals: 5008/5011 0.126s
im_proposals: 5009/5011 0.126s
im_proposals: 5010/5011 0.126s
im_proposals: 5011/5011 0.126s
Wrote RPN proposals to /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000_proposals.pkl
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Stage 2 Fast R-CNN, init from stage 2 RPN R-CNN model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Init model: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000.caffemodel
RPN proposals: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000_proposals.pkl
Using config:
{'ASPECT_GROUPING': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_alt_opt',
 'GPU_ID': 0,
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/bsl/py-faster-rcnn-master',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'OHEM_USE_NMS': False,
           'PROPOSAL_METHOD': 'rpn',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': 'stage2',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_OHEM': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for training
Set proposal method: rpn
Appending horizontally-flipped training examples...
voc_2007_trainval gt roidb loaded from /home/bsl/py-faster-rcnn-master/data/cache/voc_2007_trainval_gt_roidb.pkl
loading /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000_proposals.pkl
/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2652: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.
  VisibleDeprecationWarning)
done
Preparing training data...
done
Output will be saved to `/home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval`
Computing bounding-box regression targets...
bbox target means:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.04301734e-10  -1.01170573e-02   1.05572098e-01   1.12375988e-02]
 [  2.75126804e-11   3.71873413e-03   4.28099609e-02   3.71795747e-02]
 [ -1.51206263e-11   4.69467197e-03   2.88197336e-02   4.06375143e-02]
 [ -5.56149555e-10  -3.73757000e-03   3.93615809e-02   3.13585247e-02]
 [  8.41410154e-11   5.03750694e-03  -5.16336782e-02   1.03352019e-01]
 [  6.18739690e-10  -1.83123482e-03   7.39311617e-02   2.92993999e-02]
 [  4.16170716e-10   3.10482934e-03   8.02323271e-02   1.02311927e-02]
 [ -4.63033402e-10   3.15539499e-03   8.84051848e-02   5.20383113e-02]
 [ -3.16881540e-10   1.02479482e-02   1.57362300e-03   6.22700786e-02]
 [  1.74920385e-09   1.03482571e-02   4.66115188e-02   3.91731857e-02]
 [  6.52451973e-10   2.17609806e-02   1.28229587e-01   3.39981339e-03]
 [  2.58447037e-10   5.94609847e-03   6.05152378e-02   5.49155444e-02]
 [ -2.75018193e-10   8.06129929e-03   4.37346969e-02   5.35584866e-02]
 [  1.13970987e-09  -1.55826218e-03   6.19447139e-02   4.58844969e-02]
 [  2.01381198e-10   9.47955905e-03  -9.21167308e-03   9.68009691e-02]
 [ -9.09530038e-10  -3.12460037e-03  -2.53877179e-03   6.11544355e-02]
 [ -2.15293339e-09   3.44576464e-03   2.75427554e-02   4.13185694e-02]
 [  5.69489657e-10   8.61362395e-03   1.22686972e-01   2.02690011e-03]
 [  1.04875482e-10   3.77317462e-03   9.27878406e-02   3.37224186e-02]
 [  2.52607602e-10  -7.56318939e-04   3.52246920e-02   2.42056754e-02]]
[  7.45182881e-11   4.01313999e-03   5.08299780e-02   4.16882355e-02]
bbox target stdevs:
[[ 0.          0.          0.          0.        ]
 [ 0.13603283  0.12742713  0.23606271  0.24221837]
 [ 0.13803506  0.12201865  0.25639261  0.22917247]
 [ 0.13375756  0.12955549  0.25095971  0.2273589 ]
 [ 0.13296504  0.12686332  0.25157261  0.24185473]
 [ 0.11776106  0.13126023  0.23078715  0.21010511]
 [ 0.13934414  0.13199008  0.24735939  0.24066783]
 [ 0.13685872  0.1253404   0.24042398  0.23698134]
 [ 0.14111742  0.13363676  0.24991302  0.23363701]
 [ 0.13227873  0.13014021  0.2510658   0.23468638]
 [ 0.13754511  0.1273864   0.25203124  0.23339028]
 [ 0.14900433  0.12884164  0.24270073  0.23538878]
 [ 0.13980231  0.13091284  0.25343721  0.23154737]
 [ 0.13557464  0.12906479  0.25576215  0.23553958]
 [ 0.13944286  0.12884857  0.25132064  0.23091269]
 [ 0.1312996   0.13416735  0.25297012  0.22306004]
 [ 0.1276171   0.13207538  0.24601766  0.23166465]
 [ 0.13370616  0.12814191  0.24816379  0.23129106]
 [ 0.14521389  0.13071909  0.24159665  0.23457843]
 [ 0.13685698  0.13378698  0.23632809  0.24764457]
 [ 0.13658778  0.12568443  0.24689235  0.23277361]]
[ 0.13604007  0.12939308  0.24708788  0.23322366]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1018 08:51:41.628595 11069 solver.cpp:54] Initializing solver from parameters: 
train_net: "/home/bsl/py-faster-rcnn-master/models/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_ohem_train.pt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 0
snapshot_prefix: "vgg16_fast_rcnn"
average_loss: 100
I1018 08:51:41.628619 11069 solver.cpp:86] Creating training net from train_net file: /home/bsl/py-faster-rcnn-master/models/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_ohem_train.pt
I1018 08:51:41.629429 11069 net.cpp:50] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "roi_pool5_readonly"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5_readonly"
  propagate_down: false
  propagate_down: false
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6_readonly"
  type: "InnerProduct"
  bottom: "pool5_readonly"
  top: "fc6_readonly"
  param {
    name: "fc6_w"
  }
  param {
    name: "fc6_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6_readonly"
  type: "ReLU"
  bottom: "fc6_readonly"
  top: "fc6_readonly"
  propagate_down: false
}
layer {
  name: "drop6_readonly"
  type: "Dropout"
  bottom: "fc6_readonly"
  top: "fc6_readonly"
  propagate_down: false
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_readonly"
  type: "InnerProduct"
  bottom: "fc6_readonly"
  top: "fc7_readonly"
  param {
    name: "fc7_w"
  }
  param {
    name: "fc7_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7_readonly"
  type: "ReLU"
  bottom: "fc7_readonly"
  top: "fc7_readonly"
  propagate_down: false
}
layer {
  name: "drop7_readonly"
  type: "Dropout"
  bottom: "fc7_readonly"
  top: "fc7_readonly"
  propagate_down: false
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score_readonly"
  type: "InnerProduct"
  bottom: "fc7_readonly"
  top: "cls_score_readonly"
  param {
    name: "cls_score_w"
  }
  param {
    name: "cls_score_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred_readonly"
  type: "InnerProduct"
  bottom: "fc7_readonly"
  top: "bbox_pred_readonly"
  param {
    name: "bbox_pred_w"
  }
  param {
    name: "bbox_pred_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_prob_readonly"
  type: "Softmax"
  bottom: "cls_score_readonly"
  top: "cls_prob_readonly"
  propagate_down: false
}
layer {
  name: "hard_roi_mining"
  type: "Python"
  bottom: "cls_prob_readonly"
  bottom: "bbox_pred_readonly"
  bottom: "rois"
  bottom: "labels"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "rois_hard"
  top: "labels_hard"
  top: "bbox_targets_hard"
  top: "bbox_inside_weights_hard"
  top: "bbox_outside_weights_hard"
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  python_param {
    module: "roi_data_layer.layer"
    layer: "OHEMDataLayer"
    param_str: "\'num_classes\': 21"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois_hard"
  top: "pool5"
  propagate_down: true
  propagate_down: false
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    name: "cls_score_w"
    lr_mult: 1
  }
  param {
    name: "cls_score_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    name: "bbox_pred_w"
    lr_mult: 1
  }
  param {
    name: "bbox_pred_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels_hard"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets_hard"
  bottom: "bbox_inside_weights_hard"
  bottom: "bbox_outside_weights_hard"
  top: "loss_bbox"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  propagate_down: false
  propagate_down: false
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "silence_rpn_cls_score"
  type: "Silence"
  bottom: "rpn_cls_score"
}
layer {
  name: "silence_rpn_bbox_pred"
  type: "Silence"
  bottom: "rpn_bbox_pred"
}
I1018 08:51:41.629582 11069 layer_factory.hpp:76] Creating layer data
I1018 08:51:41.629981 11069 net.cpp:110] Creating Layer data
I1018 08:51:41.629987 11069 net.cpp:433] data -> data
I1018 08:51:41.629995 11069 net.cpp:433] data -> rois
I1018 08:51:41.629999 11069 net.cpp:433] data -> labels
I1018 08:51:41.630003 11069 net.cpp:433] data -> bbox_targets
I1018 08:51:41.630007 11069 net.cpp:433] data -> bbox_inside_weights
I1018 08:51:41.630010 11069 net.cpp:433] data -> bbox_outside_weights
I1018 08:51:41.630394 11069 net.cpp:155] Setting up data
I1018 08:51:41.630401 11069 net.cpp:163] Top shape: 1 3 600 1000 (1800000)
I1018 08:51:41.630404 11069 net.cpp:163] Top shape: 1 5 (5)
I1018 08:51:41.630406 11069 net.cpp:163] Top shape: 1 (1)
I1018 08:51:41.630409 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.630411 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.630414 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.630415 11069 layer_factory.hpp:76] Creating layer rois_data_1_split
I1018 08:51:41.630422 11069 net.cpp:110] Creating Layer rois_data_1_split
I1018 08:51:41.630425 11069 net.cpp:477] rois_data_1_split <- rois
I1018 08:51:41.630429 11069 net.cpp:433] rois_data_1_split -> rois_data_1_split_0
I1018 08:51:41.630432 11069 net.cpp:433] rois_data_1_split -> rois_data_1_split_1
I1018 08:51:41.630439 11069 net.cpp:155] Setting up rois_data_1_split
I1018 08:51:41.630440 11069 net.cpp:163] Top shape: 1 5 (5)
I1018 08:51:41.630442 11069 net.cpp:163] Top shape: 1 5 (5)
I1018 08:51:41.630445 11069 layer_factory.hpp:76] Creating layer conv1_1
I1018 08:51:41.630450 11069 net.cpp:110] Creating Layer conv1_1
I1018 08:51:41.630451 11069 net.cpp:477] conv1_1 <- data
I1018 08:51:41.630455 11069 net.cpp:433] conv1_1 -> conv1_1
RoiDataLayer: name_to_top: {'bbox_inside_weights': 4, 'labels': 2, 'rois': 1, 'bbox_targets': 3, 'bbox_outside_weights': 5, 'data': 0}
I1018 08:51:41.635145 11069 net.cpp:155] Setting up conv1_1
I1018 08:51:41.635161 11069 net.cpp:163] Top shape: 1 64 600 1000 (38400000)
I1018 08:51:41.635170 11069 layer_factory.hpp:76] Creating layer relu1_1
I1018 08:51:41.635177 11069 net.cpp:110] Creating Layer relu1_1
I1018 08:51:41.635180 11069 net.cpp:477] relu1_1 <- conv1_1
I1018 08:51:41.635185 11069 net.cpp:419] relu1_1 -> conv1_1 (in-place)
I1018 08:51:41.635191 11069 net.cpp:155] Setting up relu1_1
I1018 08:51:41.635195 11069 net.cpp:163] Top shape: 1 64 600 1000 (38400000)
I1018 08:51:41.635196 11069 layer_factory.hpp:76] Creating layer conv1_2
I1018 08:51:41.635201 11069 net.cpp:110] Creating Layer conv1_2
I1018 08:51:41.635203 11069 net.cpp:477] conv1_2 <- conv1_1
I1018 08:51:41.635207 11069 net.cpp:433] conv1_2 -> conv1_2
I1018 08:51:41.636155 11069 net.cpp:155] Setting up conv1_2
I1018 08:51:41.636163 11069 net.cpp:163] Top shape: 1 64 600 1000 (38400000)
I1018 08:51:41.636168 11069 layer_factory.hpp:76] Creating layer relu1_2
I1018 08:51:41.636174 11069 net.cpp:110] Creating Layer relu1_2
I1018 08:51:41.636176 11069 net.cpp:477] relu1_2 <- conv1_2
I1018 08:51:41.636179 11069 net.cpp:419] relu1_2 -> conv1_2 (in-place)
I1018 08:51:41.636183 11069 net.cpp:155] Setting up relu1_2
I1018 08:51:41.636186 11069 net.cpp:163] Top shape: 1 64 600 1000 (38400000)
I1018 08:51:41.636188 11069 layer_factory.hpp:76] Creating layer pool1
I1018 08:51:41.636193 11069 net.cpp:110] Creating Layer pool1
I1018 08:51:41.636194 11069 net.cpp:477] pool1 <- conv1_2
I1018 08:51:41.636198 11069 net.cpp:433] pool1 -> pool1
I1018 08:51:41.636203 11069 net.cpp:155] Setting up pool1
I1018 08:51:41.636205 11069 net.cpp:163] Top shape: 1 64 300 500 (9600000)
I1018 08:51:41.636207 11069 layer_factory.hpp:76] Creating layer conv2_1
I1018 08:51:41.636211 11069 net.cpp:110] Creating Layer conv2_1
I1018 08:51:41.636214 11069 net.cpp:477] conv2_1 <- pool1
I1018 08:51:41.636216 11069 net.cpp:433] conv2_1 -> conv2_1
I1018 08:51:41.636554 11069 net.cpp:155] Setting up conv2_1
I1018 08:51:41.636561 11069 net.cpp:163] Top shape: 1 128 300 500 (19200000)
I1018 08:51:41.636566 11069 layer_factory.hpp:76] Creating layer relu2_1
I1018 08:51:41.636572 11069 net.cpp:110] Creating Layer relu2_1
I1018 08:51:41.636574 11069 net.cpp:477] relu2_1 <- conv2_1
I1018 08:51:41.636577 11069 net.cpp:419] relu2_1 -> conv2_1 (in-place)
I1018 08:51:41.636581 11069 net.cpp:155] Setting up relu2_1
I1018 08:51:41.636584 11069 net.cpp:163] Top shape: 1 128 300 500 (19200000)
I1018 08:51:41.636585 11069 layer_factory.hpp:76] Creating layer conv2_2
I1018 08:51:41.636590 11069 net.cpp:110] Creating Layer conv2_2
I1018 08:51:41.636591 11069 net.cpp:477] conv2_2 <- conv2_1
I1018 08:51:41.636595 11069 net.cpp:433] conv2_2 -> conv2_2
I1018 08:51:41.637188 11069 net.cpp:155] Setting up conv2_2
I1018 08:51:41.637195 11069 net.cpp:163] Top shape: 1 128 300 500 (19200000)
I1018 08:51:41.637199 11069 layer_factory.hpp:76] Creating layer relu2_2
I1018 08:51:41.637204 11069 net.cpp:110] Creating Layer relu2_2
I1018 08:51:41.637207 11069 net.cpp:477] relu2_2 <- conv2_2
I1018 08:51:41.637209 11069 net.cpp:419] relu2_2 -> conv2_2 (in-place)
I1018 08:51:41.637213 11069 net.cpp:155] Setting up relu2_2
I1018 08:51:41.637215 11069 net.cpp:163] Top shape: 1 128 300 500 (19200000)
I1018 08:51:41.637217 11069 layer_factory.hpp:76] Creating layer pool2
I1018 08:51:41.637222 11069 net.cpp:110] Creating Layer pool2
I1018 08:51:41.637223 11069 net.cpp:477] pool2 <- conv2_2
I1018 08:51:41.637226 11069 net.cpp:433] pool2 -> pool2
I1018 08:51:41.637231 11069 net.cpp:155] Setting up pool2
I1018 08:51:41.637234 11069 net.cpp:163] Top shape: 1 128 150 250 (4800000)
I1018 08:51:41.637236 11069 layer_factory.hpp:76] Creating layer conv3_1
I1018 08:51:41.637240 11069 net.cpp:110] Creating Layer conv3_1
I1018 08:51:41.637243 11069 net.cpp:477] conv3_1 <- pool2
I1018 08:51:41.637246 11069 net.cpp:433] conv3_1 -> conv3_1
I1018 08:51:41.637645 11069 net.cpp:155] Setting up conv3_1
I1018 08:51:41.637652 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.637658 11069 layer_factory.hpp:76] Creating layer relu3_1
I1018 08:51:41.637662 11069 net.cpp:110] Creating Layer relu3_1
I1018 08:51:41.637665 11069 net.cpp:477] relu3_1 <- conv3_1
I1018 08:51:41.637668 11069 net.cpp:419] relu3_1 -> conv3_1 (in-place)
I1018 08:51:41.637672 11069 net.cpp:155] Setting up relu3_1
I1018 08:51:41.637675 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.637676 11069 layer_factory.hpp:76] Creating layer conv3_2
I1018 08:51:41.637681 11069 net.cpp:110] Creating Layer conv3_2
I1018 08:51:41.637682 11069 net.cpp:477] conv3_2 <- conv3_1
I1018 08:51:41.637686 11069 net.cpp:433] conv3_2 -> conv3_2
I1018 08:51:41.638368 11069 net.cpp:155] Setting up conv3_2
I1018 08:51:41.638375 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.638380 11069 layer_factory.hpp:76] Creating layer relu3_2
I1018 08:51:41.638383 11069 net.cpp:110] Creating Layer relu3_2
I1018 08:51:41.638386 11069 net.cpp:477] relu3_2 <- conv3_2
I1018 08:51:41.638388 11069 net.cpp:419] relu3_2 -> conv3_2 (in-place)
I1018 08:51:41.638392 11069 net.cpp:155] Setting up relu3_2
I1018 08:51:41.638394 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.638396 11069 layer_factory.hpp:76] Creating layer conv3_3
I1018 08:51:41.638402 11069 net.cpp:110] Creating Layer conv3_3
I1018 08:51:41.638406 11069 net.cpp:477] conv3_3 <- conv3_2
I1018 08:51:41.638409 11069 net.cpp:433] conv3_3 -> conv3_3
I1018 08:51:41.639119 11069 net.cpp:155] Setting up conv3_3
I1018 08:51:41.639128 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.639133 11069 layer_factory.hpp:76] Creating layer relu3_3
I1018 08:51:41.639137 11069 net.cpp:110] Creating Layer relu3_3
I1018 08:51:41.639140 11069 net.cpp:477] relu3_3 <- conv3_3
I1018 08:51:41.639143 11069 net.cpp:419] relu3_3 -> conv3_3 (in-place)
I1018 08:51:41.639147 11069 net.cpp:155] Setting up relu3_3
I1018 08:51:41.639149 11069 net.cpp:163] Top shape: 1 256 150 250 (9600000)
I1018 08:51:41.639152 11069 layer_factory.hpp:76] Creating layer pool3
I1018 08:51:41.639155 11069 net.cpp:110] Creating Layer pool3
I1018 08:51:41.639158 11069 net.cpp:477] pool3 <- conv3_3
I1018 08:51:41.639160 11069 net.cpp:433] pool3 -> pool3
I1018 08:51:41.639165 11069 net.cpp:155] Setting up pool3
I1018 08:51:41.639168 11069 net.cpp:163] Top shape: 1 256 75 125 (2400000)
I1018 08:51:41.639169 11069 layer_factory.hpp:76] Creating layer conv4_1
I1018 08:51:41.639174 11069 net.cpp:110] Creating Layer conv4_1
I1018 08:51:41.639176 11069 net.cpp:477] conv4_1 <- pool3
I1018 08:51:41.639179 11069 net.cpp:433] conv4_1 -> conv4_1
I1018 08:51:41.640955 11069 net.cpp:155] Setting up conv4_1
I1018 08:51:41.640974 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.640981 11069 layer_factory.hpp:76] Creating layer relu4_1
I1018 08:51:41.640988 11069 net.cpp:110] Creating Layer relu4_1
I1018 08:51:41.640991 11069 net.cpp:477] relu4_1 <- conv4_1
I1018 08:51:41.640995 11069 net.cpp:419] relu4_1 -> conv4_1 (in-place)
I1018 08:51:41.641001 11069 net.cpp:155] Setting up relu4_1
I1018 08:51:41.641003 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.641005 11069 layer_factory.hpp:76] Creating layer conv4_2
I1018 08:51:41.641010 11069 net.cpp:110] Creating Layer conv4_2
I1018 08:51:41.641012 11069 net.cpp:477] conv4_2 <- conv4_1
I1018 08:51:41.641016 11069 net.cpp:433] conv4_2 -> conv4_2
I1018 08:51:41.644023 11069 net.cpp:155] Setting up conv4_2
I1018 08:51:41.644047 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.644058 11069 layer_factory.hpp:76] Creating layer relu4_2
I1018 08:51:41.644067 11069 net.cpp:110] Creating Layer relu4_2
I1018 08:51:41.644069 11069 net.cpp:477] relu4_2 <- conv4_2
I1018 08:51:41.644074 11069 net.cpp:419] relu4_2 -> conv4_2 (in-place)
I1018 08:51:41.644083 11069 net.cpp:155] Setting up relu4_2
I1018 08:51:41.644084 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.644086 11069 layer_factory.hpp:76] Creating layer conv4_3
I1018 08:51:41.644093 11069 net.cpp:110] Creating Layer conv4_3
I1018 08:51:41.644094 11069 net.cpp:477] conv4_3 <- conv4_2
I1018 08:51:41.644098 11069 net.cpp:433] conv4_3 -> conv4_3
I1018 08:51:41.647253 11069 net.cpp:155] Setting up conv4_3
I1018 08:51:41.647279 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.647286 11069 layer_factory.hpp:76] Creating layer relu4_3
I1018 08:51:41.647294 11069 net.cpp:110] Creating Layer relu4_3
I1018 08:51:41.647297 11069 net.cpp:477] relu4_3 <- conv4_3
I1018 08:51:41.647301 11069 net.cpp:419] relu4_3 -> conv4_3 (in-place)
I1018 08:51:41.647307 11069 net.cpp:155] Setting up relu4_3
I1018 08:51:41.647310 11069 net.cpp:163] Top shape: 1 512 75 125 (4800000)
I1018 08:51:41.647311 11069 layer_factory.hpp:76] Creating layer pool4
I1018 08:51:41.647323 11069 net.cpp:110] Creating Layer pool4
I1018 08:51:41.647325 11069 net.cpp:477] pool4 <- conv4_3
I1018 08:51:41.647328 11069 net.cpp:433] pool4 -> pool4
I1018 08:51:41.647334 11069 net.cpp:155] Setting up pool4
I1018 08:51:41.647337 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.647339 11069 layer_factory.hpp:76] Creating layer conv5_1
I1018 08:51:41.647344 11069 net.cpp:110] Creating Layer conv5_1
I1018 08:51:41.647346 11069 net.cpp:477] conv5_1 <- pool4
I1018 08:51:41.647349 11069 net.cpp:433] conv5_1 -> conv5_1
I1018 08:51:41.650318 11069 net.cpp:155] Setting up conv5_1
I1018 08:51:41.650349 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.650357 11069 layer_factory.hpp:76] Creating layer relu5_1
I1018 08:51:41.650364 11069 net.cpp:110] Creating Layer relu5_1
I1018 08:51:41.650368 11069 net.cpp:477] relu5_1 <- conv5_1
I1018 08:51:41.650372 11069 net.cpp:419] relu5_1 -> conv5_1 (in-place)
I1018 08:51:41.650377 11069 net.cpp:155] Setting up relu5_1
I1018 08:51:41.650380 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.650382 11069 layer_factory.hpp:76] Creating layer conv5_2
I1018 08:51:41.650388 11069 net.cpp:110] Creating Layer conv5_2
I1018 08:51:41.650389 11069 net.cpp:477] conv5_2 <- conv5_1
I1018 08:51:41.650393 11069 net.cpp:433] conv5_2 -> conv5_2
I1018 08:51:41.653427 11069 net.cpp:155] Setting up conv5_2
I1018 08:51:41.653451 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.653458 11069 layer_factory.hpp:76] Creating layer relu5_2
I1018 08:51:41.653465 11069 net.cpp:110] Creating Layer relu5_2
I1018 08:51:41.653470 11069 net.cpp:477] relu5_2 <- conv5_2
I1018 08:51:41.653473 11069 net.cpp:419] relu5_2 -> conv5_2 (in-place)
I1018 08:51:41.653479 11069 net.cpp:155] Setting up relu5_2
I1018 08:51:41.653482 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.653484 11069 layer_factory.hpp:76] Creating layer conv5_3
I1018 08:51:41.653489 11069 net.cpp:110] Creating Layer conv5_3
I1018 08:51:41.653494 11069 net.cpp:477] conv5_3 <- conv5_2
I1018 08:51:41.653497 11069 net.cpp:433] conv5_3 -> conv5_3
I1018 08:51:41.656579 11069 net.cpp:155] Setting up conv5_3
I1018 08:51:41.656605 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.656611 11069 layer_factory.hpp:76] Creating layer relu5_3
I1018 08:51:41.656620 11069 net.cpp:110] Creating Layer relu5_3
I1018 08:51:41.656626 11069 net.cpp:477] relu5_3 <- conv5_3
I1018 08:51:41.656630 11069 net.cpp:419] relu5_3 -> conv5_3 (in-place)
I1018 08:51:41.656636 11069 net.cpp:155] Setting up relu5_3
I1018 08:51:41.656639 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.656641 11069 layer_factory.hpp:76] Creating layer conv5_3_relu5_3_0_split
I1018 08:51:41.656648 11069 net.cpp:110] Creating Layer conv5_3_relu5_3_0_split
I1018 08:51:41.656651 11069 net.cpp:477] conv5_3_relu5_3_0_split <- conv5_3
I1018 08:51:41.656653 11069 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I1018 08:51:41.656657 11069 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I1018 08:51:41.656661 11069 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I1018 08:51:41.656666 11069 net.cpp:155] Setting up conv5_3_relu5_3_0_split
I1018 08:51:41.656667 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.656669 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.656672 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:41.656674 11069 layer_factory.hpp:76] Creating layer roi_pool5_readonly
I1018 08:51:41.656687 11069 net.cpp:110] Creating Layer roi_pool5_readonly
I1018 08:51:41.656688 11069 net.cpp:477] roi_pool5_readonly <- conv5_3_relu5_3_0_split_0
I1018 08:51:41.656692 11069 net.cpp:477] roi_pool5_readonly <- rois_data_1_split_0
I1018 08:51:41.656694 11069 net.cpp:433] roi_pool5_readonly -> pool5_readonly
I1018 08:51:41.656698 11069 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1018 08:51:41.656708 11069 net.cpp:155] Setting up roi_pool5_readonly
I1018 08:51:41.656710 11069 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1018 08:51:41.656713 11069 layer_factory.hpp:76] Creating layer fc6_readonly
I1018 08:51:41.656718 11069 net.cpp:110] Creating Layer fc6_readonly
I1018 08:51:41.656720 11069 net.cpp:477] fc6_readonly <- pool5_readonly
I1018 08:51:41.656723 11069 net.cpp:433] fc6_readonly -> fc6_readonly
I1018 08:51:41.791693 11069 net.cpp:155] Setting up fc6_readonly
I1018 08:51:41.791718 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.791726 11069 layer_factory.hpp:76] Creating layer relu6_readonly
I1018 08:51:41.791734 11069 net.cpp:110] Creating Layer relu6_readonly
I1018 08:51:41.791738 11069 net.cpp:477] relu6_readonly <- fc6_readonly
I1018 08:51:41.791743 11069 net.cpp:419] relu6_readonly -> fc6_readonly (in-place)
I1018 08:51:41.791751 11069 net.cpp:155] Setting up relu6_readonly
I1018 08:51:41.791754 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.791756 11069 layer_factory.hpp:76] Creating layer drop6_readonly
I1018 08:51:41.791761 11069 net.cpp:110] Creating Layer drop6_readonly
I1018 08:51:41.791764 11069 net.cpp:477] drop6_readonly <- fc6_readonly
I1018 08:51:41.791766 11069 net.cpp:419] drop6_readonly -> fc6_readonly (in-place)
I1018 08:51:41.791770 11069 net.cpp:155] Setting up drop6_readonly
I1018 08:51:41.791774 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.791775 11069 layer_factory.hpp:76] Creating layer fc7_readonly
I1018 08:51:41.791780 11069 net.cpp:110] Creating Layer fc7_readonly
I1018 08:51:41.791782 11069 net.cpp:477] fc7_readonly <- fc6_readonly
I1018 08:51:41.791785 11069 net.cpp:433] fc7_readonly -> fc7_readonly
I1018 08:51:41.813987 11069 net.cpp:155] Setting up fc7_readonly
I1018 08:51:41.814008 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.814016 11069 layer_factory.hpp:76] Creating layer relu7_readonly
I1018 08:51:41.814023 11069 net.cpp:110] Creating Layer relu7_readonly
I1018 08:51:41.814028 11069 net.cpp:477] relu7_readonly <- fc7_readonly
I1018 08:51:41.814031 11069 net.cpp:419] relu7_readonly -> fc7_readonly (in-place)
I1018 08:51:41.814038 11069 net.cpp:155] Setting up relu7_readonly
I1018 08:51:41.814039 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.814041 11069 layer_factory.hpp:76] Creating layer drop7_readonly
I1018 08:51:41.814046 11069 net.cpp:110] Creating Layer drop7_readonly
I1018 08:51:41.814049 11069 net.cpp:477] drop7_readonly <- fc7_readonly
I1018 08:51:41.814051 11069 net.cpp:419] drop7_readonly -> fc7_readonly (in-place)
I1018 08:51:41.814055 11069 net.cpp:155] Setting up drop7_readonly
I1018 08:51:41.814059 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.814059 11069 layer_factory.hpp:76] Creating layer fc7_readonly_drop7_readonly_0_split
I1018 08:51:41.814064 11069 net.cpp:110] Creating Layer fc7_readonly_drop7_readonly_0_split
I1018 08:51:41.814065 11069 net.cpp:477] fc7_readonly_drop7_readonly_0_split <- fc7_readonly
I1018 08:51:41.814069 11069 net.cpp:433] fc7_readonly_drop7_readonly_0_split -> fc7_readonly_drop7_readonly_0_split_0
I1018 08:51:41.814072 11069 net.cpp:433] fc7_readonly_drop7_readonly_0_split -> fc7_readonly_drop7_readonly_0_split_1
I1018 08:51:41.814079 11069 net.cpp:155] Setting up fc7_readonly_drop7_readonly_0_split
I1018 08:51:41.814081 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.814085 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.814086 11069 layer_factory.hpp:76] Creating layer cls_score_readonly
I1018 08:51:41.814092 11069 net.cpp:110] Creating Layer cls_score_readonly
I1018 08:51:41.814095 11069 net.cpp:477] cls_score_readonly <- fc7_readonly_drop7_readonly_0_split_0
I1018 08:51:41.814097 11069 net.cpp:433] cls_score_readonly -> cls_score_readonly
I1018 08:51:41.815820 11069 net.cpp:155] Setting up cls_score_readonly
I1018 08:51:41.815825 11069 net.cpp:163] Top shape: 1 21 (21)
I1018 08:51:41.815829 11069 layer_factory.hpp:76] Creating layer bbox_pred_readonly
I1018 08:51:41.815834 11069 net.cpp:110] Creating Layer bbox_pred_readonly
I1018 08:51:41.815836 11069 net.cpp:477] bbox_pred_readonly <- fc7_readonly_drop7_readonly_0_split_1
I1018 08:51:41.815840 11069 net.cpp:433] bbox_pred_readonly -> bbox_pred_readonly
OHEMDataLayer: name_to_top: {'bbox_outside_weights_hard': 4, 'bbox_inside_weights_hard': 3, 'labels_hard': 1, 'rois_hard': 0, 'bbox_targets_hard': 2}
I1018 08:51:41.822891 11069 net.cpp:155] Setting up bbox_pred_readonly
I1018 08:51:41.822898 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.822906 11069 layer_factory.hpp:76] Creating layer cls_prob_readonly
I1018 08:51:41.822911 11069 net.cpp:110] Creating Layer cls_prob_readonly
I1018 08:51:41.822916 11069 net.cpp:477] cls_prob_readonly <- cls_score_readonly
I1018 08:51:41.822921 11069 net.cpp:433] cls_prob_readonly -> cls_prob_readonly
I1018 08:51:41.822934 11069 net.cpp:155] Setting up cls_prob_readonly
I1018 08:51:41.822937 11069 net.cpp:163] Top shape: 1 21 (21)
I1018 08:51:41.822939 11069 layer_factory.hpp:76] Creating layer hard_roi_mining
I1018 08:51:41.822979 11069 net.cpp:110] Creating Layer hard_roi_mining
I1018 08:51:41.822983 11069 net.cpp:477] hard_roi_mining <- cls_prob_readonly
I1018 08:51:41.822985 11069 net.cpp:477] hard_roi_mining <- bbox_pred_readonly
I1018 08:51:41.822988 11069 net.cpp:477] hard_roi_mining <- rois_data_1_split_1
I1018 08:51:41.822990 11069 net.cpp:477] hard_roi_mining <- labels
I1018 08:51:41.822993 11069 net.cpp:477] hard_roi_mining <- bbox_targets
I1018 08:51:41.822995 11069 net.cpp:477] hard_roi_mining <- bbox_inside_weights
I1018 08:51:41.822998 11069 net.cpp:477] hard_roi_mining <- bbox_outside_weights
I1018 08:51:41.823000 11069 net.cpp:433] hard_roi_mining -> rois_hard
I1018 08:51:41.823005 11069 net.cpp:433] hard_roi_mining -> labels_hard
I1018 08:51:41.823009 11069 net.cpp:433] hard_roi_mining -> bbox_targets_hard
I1018 08:51:41.823014 11069 net.cpp:433] hard_roi_mining -> bbox_inside_weights_hard
I1018 08:51:41.823016 11069 net.cpp:433] hard_roi_mining -> bbox_outside_weights_hard
I1018 08:51:41.823336 11069 net.cpp:155] Setting up hard_roi_mining
I1018 08:51:41.823343 11069 net.cpp:163] Top shape: 1 5 (5)
I1018 08:51:41.823345 11069 net.cpp:163] Top shape: 1 (1)
I1018 08:51:41.823348 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.823349 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.823351 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:41.823354 11069 layer_factory.hpp:76] Creating layer roi_pool5
I1018 08:51:41.823359 11069 net.cpp:110] Creating Layer roi_pool5
I1018 08:51:41.823361 11069 net.cpp:477] roi_pool5 <- conv5_3_relu5_3_0_split_1
I1018 08:51:41.823364 11069 net.cpp:477] roi_pool5 <- rois_hard
I1018 08:51:41.823367 11069 net.cpp:433] roi_pool5 -> pool5
I1018 08:51:41.823372 11069 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1018 08:51:41.823379 11069 net.cpp:155] Setting up roi_pool5
I1018 08:51:41.823382 11069 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1018 08:51:41.823385 11069 layer_factory.hpp:76] Creating layer fc6
I1018 08:51:41.823388 11069 net.cpp:110] Creating Layer fc6
I1018 08:51:41.823390 11069 net.cpp:477] fc6 <- pool5
I1018 08:51:41.823393 11069 net.cpp:433] fc6 -> fc6
I1018 08:51:41.970379 11069 net.cpp:155] Setting up fc6
I1018 08:51:41.970404 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.970410 11069 net.cpp:537] Sharing parameters 'fc6_w' owned by layer 'fc6_readonly', param index 0
I1018 08:51:41.970415 11069 net.cpp:537] Sharing parameters 'fc6_b' owned by layer 'fc6_readonly', param index 1
I1018 08:51:41.970418 11069 layer_factory.hpp:76] Creating layer relu6
I1018 08:51:41.970427 11069 net.cpp:110] Creating Layer relu6
I1018 08:51:41.970430 11069 net.cpp:477] relu6 <- fc6
I1018 08:51:41.970435 11069 net.cpp:419] relu6 -> fc6 (in-place)
I1018 08:51:41.970441 11069 net.cpp:155] Setting up relu6
I1018 08:51:41.970445 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.970448 11069 layer_factory.hpp:76] Creating layer drop6
I1018 08:51:41.970453 11069 net.cpp:110] Creating Layer drop6
I1018 08:51:41.970454 11069 net.cpp:477] drop6 <- fc6
I1018 08:51:41.970458 11069 net.cpp:419] drop6 -> fc6 (in-place)
I1018 08:51:41.970463 11069 net.cpp:155] Setting up drop6
I1018 08:51:41.970464 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.970466 11069 layer_factory.hpp:76] Creating layer fc7
I1018 08:51:41.970471 11069 net.cpp:110] Creating Layer fc7
I1018 08:51:41.970474 11069 net.cpp:477] fc7 <- fc6
I1018 08:51:41.970476 11069 net.cpp:433] fc7 -> fc7
I1018 08:51:41.993355 11069 net.cpp:155] Setting up fc7
I1018 08:51:41.993378 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.993384 11069 net.cpp:537] Sharing parameters 'fc7_w' owned by layer 'fc7_readonly', param index 0
I1018 08:51:41.993389 11069 net.cpp:537] Sharing parameters 'fc7_b' owned by layer 'fc7_readonly', param index 1
I1018 08:51:41.993392 11069 layer_factory.hpp:76] Creating layer relu7
I1018 08:51:41.993401 11069 net.cpp:110] Creating Layer relu7
I1018 08:51:41.993404 11069 net.cpp:477] relu7 <- fc7
I1018 08:51:41.993409 11069 net.cpp:419] relu7 -> fc7 (in-place)
I1018 08:51:41.993417 11069 net.cpp:155] Setting up relu7
I1018 08:51:41.993419 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.993422 11069 layer_factory.hpp:76] Creating layer drop7
I1018 08:51:41.993427 11069 net.cpp:110] Creating Layer drop7
I1018 08:51:41.993428 11069 net.cpp:477] drop7 <- fc7
I1018 08:51:41.993432 11069 net.cpp:419] drop7 -> fc7 (in-place)
I1018 08:51:41.993435 11069 net.cpp:155] Setting up drop7
I1018 08:51:41.993438 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.993440 11069 layer_factory.hpp:76] Creating layer fc7_drop7_0_split
I1018 08:51:41.993444 11069 net.cpp:110] Creating Layer fc7_drop7_0_split
I1018 08:51:41.993446 11069 net.cpp:477] fc7_drop7_0_split <- fc7
I1018 08:51:41.993449 11069 net.cpp:433] fc7_drop7_0_split -> fc7_drop7_0_split_0
I1018 08:51:41.993453 11069 net.cpp:433] fc7_drop7_0_split -> fc7_drop7_0_split_1
I1018 08:51:41.993458 11069 net.cpp:155] Setting up fc7_drop7_0_split
I1018 08:51:41.993459 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.993463 11069 net.cpp:163] Top shape: 1 4096 (4096)
I1018 08:51:41.993464 11069 layer_factory.hpp:76] Creating layer cls_score
I1018 08:51:41.993469 11069 net.cpp:110] Creating Layer cls_score
I1018 08:51:41.993471 11069 net.cpp:477] cls_score <- fc7_drop7_0_split_0
I1018 08:51:41.993476 11069 net.cpp:433] cls_score -> cls_score
I1018 08:51:41.995210 11069 net.cpp:155] Setting up cls_score
I1018 08:51:41.995215 11069 net.cpp:163] Top shape: 1 21 (21)
I1018 08:51:41.995219 11069 net.cpp:537] Sharing parameters 'cls_score_w' owned by layer 'cls_score_readonly', param index 0
I1018 08:51:41.995223 11069 net.cpp:537] Sharing parameters 'cls_score_b' owned by layer 'cls_score_readonly', param index 1
I1018 08:51:41.995224 11069 layer_factory.hpp:76] Creating layer bbox_pred
I1018 08:51:41.995229 11069 net.cpp:110] Creating Layer bbox_pred
I1018 08:51:41.995231 11069 net.cpp:477] bbox_pred <- fc7_drop7_0_split_1
I1018 08:51:41.995235 11069 net.cpp:433] bbox_pred -> bbox_pred
I1018 08:51:42.002377 11069 net.cpp:155] Setting up bbox_pred
I1018 08:51:42.002385 11069 net.cpp:163] Top shape: 1 84 (84)
I1018 08:51:42.002389 11069 net.cpp:537] Sharing parameters 'bbox_pred_w' owned by layer 'bbox_pred_readonly', param index 0
I1018 08:51:42.002393 11069 net.cpp:537] Sharing parameters 'bbox_pred_b' owned by layer 'bbox_pred_readonly', param index 1
I1018 08:51:42.002394 11069 layer_factory.hpp:76] Creating layer loss_cls
I1018 08:51:42.002399 11069 net.cpp:110] Creating Layer loss_cls
I1018 08:51:42.002403 11069 net.cpp:477] loss_cls <- cls_score
I1018 08:51:42.002406 11069 net.cpp:477] loss_cls <- labels_hard
I1018 08:51:42.002410 11069 net.cpp:433] loss_cls -> loss_cls
I1018 08:51:42.002418 11069 layer_factory.hpp:76] Creating layer loss_cls
I1018 08:51:42.002456 11069 net.cpp:155] Setting up loss_cls
I1018 08:51:42.002460 11069 net.cpp:163] Top shape: (1)
I1018 08:51:42.002462 11069 net.cpp:168]     with loss weight 1
I1018 08:51:42.002470 11069 layer_factory.hpp:76] Creating layer loss_bbox
I1018 08:51:42.002477 11069 net.cpp:110] Creating Layer loss_bbox
I1018 08:51:42.002480 11069 net.cpp:477] loss_bbox <- bbox_pred
I1018 08:51:42.002483 11069 net.cpp:477] loss_bbox <- bbox_targets_hard
I1018 08:51:42.002486 11069 net.cpp:477] loss_bbox <- bbox_inside_weights_hard
I1018 08:51:42.002490 11069 net.cpp:477] loss_bbox <- bbox_outside_weights_hard
I1018 08:51:42.002492 11069 net.cpp:433] loss_bbox -> loss_bbox
I1018 08:51:42.002516 11069 net.cpp:155] Setting up loss_bbox
I1018 08:51:42.002519 11069 net.cpp:163] Top shape: (1)
I1018 08:51:42.002521 11069 net.cpp:168]     with loss weight 1
I1018 08:51:42.002524 11069 layer_factory.hpp:76] Creating layer rpn_conv/3x3
I1018 08:51:42.002529 11069 net.cpp:110] Creating Layer rpn_conv/3x3
I1018 08:51:42.002532 11069 net.cpp:477] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_2
I1018 08:51:42.002535 11069 net.cpp:433] rpn_conv/3x3 -> rpn/output
I1018 08:51:42.050302 11069 net.cpp:155] Setting up rpn_conv/3x3
I1018 08:51:42.050323 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:42.050330 11069 layer_factory.hpp:76] Creating layer rpn_relu/3x3
I1018 08:51:42.050338 11069 net.cpp:110] Creating Layer rpn_relu/3x3
I1018 08:51:42.050343 11069 net.cpp:477] rpn_relu/3x3 <- rpn/output
I1018 08:51:42.050348 11069 net.cpp:419] rpn_relu/3x3 -> rpn/output (in-place)
I1018 08:51:42.050354 11069 net.cpp:155] Setting up rpn_relu/3x3
I1018 08:51:42.050356 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:42.050359 11069 layer_factory.hpp:76] Creating layer rpn/output_rpn_relu/3x3_0_split
I1018 08:51:42.050362 11069 net.cpp:110] Creating Layer rpn/output_rpn_relu/3x3_0_split
I1018 08:51:42.050364 11069 net.cpp:477] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I1018 08:51:42.050369 11069 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I1018 08:51:42.050372 11069 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I1018 08:51:42.050376 11069 net.cpp:155] Setting up rpn/output_rpn_relu/3x3_0_split
I1018 08:51:42.050379 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:42.050382 11069 net.cpp:163] Top shape: 1 512 38 63 (1225728)
I1018 08:51:42.050384 11069 layer_factory.hpp:76] Creating layer rpn_cls_score
I1018 08:51:42.050390 11069 net.cpp:110] Creating Layer rpn_cls_score
I1018 08:51:42.050391 11069 net.cpp:477] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I1018 08:51:42.050395 11069 net.cpp:433] rpn_cls_score -> rpn_cls_score
I1018 08:51:42.050633 11069 net.cpp:155] Setting up rpn_cls_score
I1018 08:51:42.050638 11069 net.cpp:163] Top shape: 1 18 38 63 (43092)
I1018 08:51:42.050642 11069 layer_factory.hpp:76] Creating layer rpn_bbox_pred
I1018 08:51:42.050647 11069 net.cpp:110] Creating Layer rpn_bbox_pred
I1018 08:51:42.050648 11069 net.cpp:477] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I1018 08:51:42.050652 11069 net.cpp:433] rpn_bbox_pred -> rpn_bbox_pred
I1018 08:51:42.051055 11069 net.cpp:155] Setting up rpn_bbox_pred
I1018 08:51:42.051059 11069 net.cpp:163] Top shape: 1 36 38 63 (86184)
I1018 08:51:42.051064 11069 layer_factory.hpp:76] Creating layer silence_rpn_cls_score
I1018 08:51:42.051066 11069 net.cpp:110] Creating Layer silence_rpn_cls_score
I1018 08:51:42.051069 11069 net.cpp:477] silence_rpn_cls_score <- rpn_cls_score
I1018 08:51:42.051072 11069 net.cpp:155] Setting up silence_rpn_cls_score
I1018 08:51:42.051074 11069 layer_factory.hpp:76] Creating layer silence_rpn_bbox_pred
I1018 08:51:42.051076 11069 net.cpp:110] Creating Layer silence_rpn_bbox_pred
I1018 08:51:42.051079 11069 net.cpp:477] silence_rpn_bbox_pred <- rpn_bbox_pred
I1018 08:51:42.051081 11069 net.cpp:155] Setting up silence_rpn_bbox_pred
I1018 08:51:42.051084 11069 net.cpp:240] silence_rpn_bbox_pred does not need backward computation.
I1018 08:51:42.051085 11069 net.cpp:240] silence_rpn_cls_score does not need backward computation.
I1018 08:51:42.051087 11069 net.cpp:240] rpn_bbox_pred does not need backward computation.
I1018 08:51:42.051090 11069 net.cpp:240] rpn_cls_score does not need backward computation.
I1018 08:51:42.051091 11069 net.cpp:240] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I1018 08:51:42.051095 11069 net.cpp:240] rpn_relu/3x3 does not need backward computation.
I1018 08:51:42.051096 11069 net.cpp:240] rpn_conv/3x3 does not need backward computation.
I1018 08:51:42.051100 11069 net.cpp:236] loss_bbox needs backward computation.
I1018 08:51:42.051102 11069 net.cpp:236] loss_cls needs backward computation.
I1018 08:51:42.051105 11069 net.cpp:236] bbox_pred needs backward computation.
I1018 08:51:42.051108 11069 net.cpp:236] cls_score needs backward computation.
I1018 08:51:42.051110 11069 net.cpp:236] fc7_drop7_0_split needs backward computation.
I1018 08:51:42.051113 11069 net.cpp:236] drop7 needs backward computation.
I1018 08:51:42.051115 11069 net.cpp:236] relu7 needs backward computation.
I1018 08:51:42.051117 11069 net.cpp:236] fc7 needs backward computation.
I1018 08:51:42.051120 11069 net.cpp:236] drop6 needs backward computation.
I1018 08:51:42.051121 11069 net.cpp:236] relu6 needs backward computation.
I1018 08:51:42.051125 11069 net.cpp:236] fc6 needs backward computation.
I1018 08:51:42.051126 11069 net.cpp:236] roi_pool5 needs backward computation.
I1018 08:51:42.051131 11069 net.cpp:240] hard_roi_mining does not need backward computation.
I1018 08:51:42.051136 11069 net.cpp:240] cls_prob_readonly does not need backward computation.
I1018 08:51:42.051138 11069 net.cpp:240] bbox_pred_readonly does not need backward computation.
I1018 08:51:42.051141 11069 net.cpp:240] cls_score_readonly does not need backward computation.
I1018 08:51:42.051144 11069 net.cpp:240] fc7_readonly_drop7_readonly_0_split does not need backward computation.
I1018 08:51:42.051146 11069 net.cpp:240] drop7_readonly does not need backward computation.
I1018 08:51:42.051149 11069 net.cpp:240] relu7_readonly does not need backward computation.
I1018 08:51:42.051151 11069 net.cpp:240] fc7_readonly does not need backward computation.
I1018 08:51:42.051154 11069 net.cpp:240] drop6_readonly does not need backward computation.
I1018 08:51:42.051156 11069 net.cpp:240] relu6_readonly does not need backward computation.
I1018 08:51:42.051158 11069 net.cpp:240] fc6_readonly does not need backward computation.
I1018 08:51:42.051162 11069 net.cpp:240] roi_pool5_readonly does not need backward computation.
I1018 08:51:42.051164 11069 net.cpp:240] conv5_3_relu5_3_0_split does not need backward computation.
I1018 08:51:42.051167 11069 net.cpp:240] relu5_3 does not need backward computation.
I1018 08:51:42.051169 11069 net.cpp:240] conv5_3 does not need backward computation.
I1018 08:51:42.051172 11069 net.cpp:240] relu5_2 does not need backward computation.
I1018 08:51:42.051174 11069 net.cpp:240] conv5_2 does not need backward computation.
I1018 08:51:42.051177 11069 net.cpp:240] relu5_1 does not need backward computation.
I1018 08:51:42.051179 11069 net.cpp:240] conv5_1 does not need backward computation.
I1018 08:51:42.051182 11069 net.cpp:240] pool4 does not need backward computation.
I1018 08:51:42.051184 11069 net.cpp:240] relu4_3 does not need backward computation.
I1018 08:51:42.051187 11069 net.cpp:240] conv4_3 does not need backward computation.
I1018 08:51:42.051189 11069 net.cpp:240] relu4_2 does not need backward computation.
I1018 08:51:42.051192 11069 net.cpp:240] conv4_2 does not need backward computation.
I1018 08:51:42.051194 11069 net.cpp:240] relu4_1 does not need backward computation.
I1018 08:51:42.051197 11069 net.cpp:240] conv4_1 does not need backward computation.
I1018 08:51:42.051199 11069 net.cpp:240] pool3 does not need backward computation.
I1018 08:51:42.051201 11069 net.cpp:240] relu3_3 does not need backward computation.
I1018 08:51:42.051204 11069 net.cpp:240] conv3_3 does not need backward computation.
I1018 08:51:42.051206 11069 net.cpp:240] relu3_2 does not need backward computation.
I1018 08:51:42.051208 11069 net.cpp:240] conv3_2 does not need backward computation.
I1018 08:51:42.051211 11069 net.cpp:240] relu3_1 does not need backward computation.
I1018 08:51:42.051213 11069 net.cpp:240] conv3_1 does not need backward computation.
I1018 08:51:42.051215 11069 net.cpp:240] pool2 does not need backward computation.
I1018 08:51:42.051218 11069 net.cpp:240] relu2_2 does not need backward computation.
I1018 08:51:42.051220 11069 net.cpp:240] conv2_2 does not need backward computation.
I1018 08:51:42.051223 11069 net.cpp:240] relu2_1 does not need backward computation.
I1018 08:51:42.051226 11069 net.cpp:240] conv2_1 does not need backward computation.
I1018 08:51:42.051229 11069 net.cpp:240] pool1 does not need backward computation.
I1018 08:51:42.051231 11069 net.cpp:240] relu1_2 does not need backward computation.
I1018 08:51:42.051234 11069 net.cpp:240] conv1_2 does not need backward computation.
I1018 08:51:42.051236 11069 net.cpp:240] relu1_1 does not need backward computation.
I1018 08:51:42.051239 11069 net.cpp:240] conv1_1 does not need backward computation.
I1018 08:51:42.051242 11069 net.cpp:240] rois_data_1_split does not need backward computation.
I1018 08:51:42.051246 11069 net.cpp:240] data does not need backward computation.
I1018 08:51:42.051249 11069 net.cpp:283] This network produces output loss_bbox
I1018 08:51:42.051250 11069 net.cpp:283] This network produces output loss_cls
I1018 08:51:42.089143 11069 net.cpp:297] Network initialization done.
I1018 08:51:42.089159 11069 net.cpp:298] Memory required for data: 1411223756
I1018 08:51:42.089488 11069 solver.cpp:65] Solver scaffolding done.
Loading pretrained model weights from /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_rpn_stage2_iter_80000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 546596435
Solving...
/home/bsl/py-faster-rcnn-master/tools/../lib/roi_data_layer/minibatch.py:315: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
/home/bsl/py-faster-rcnn-master/tools/../lib/roi_data_layer/minibatch.py:316: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS
/home/bsl/py-faster-rcnn-master/tools/../lib/roi_data_layer/layer.py:282: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  for x in [cls_prob[i,label] for i, label in enumerate(labels)]]
I1018 08:51:43.049850 11069 solver.cpp:242] Iteration 0, loss = 2.68576
I1018 08:51:43.049875 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.325441 (* 1 = 0.325441 loss)
I1018 08:51:43.049880 11069 solver.cpp:258]     Train net output #1: loss_cls = 2.36032 (* 1 = 2.36032 loss)
I1018 08:51:43.049888 11069 solver.cpp:571] Iteration 0, lr = 0.001
I1018 08:51:50.148334 11069 solver.cpp:242] Iteration 20, loss = 1.5728
I1018 08:51:50.148357 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.563237 (* 1 = 0.563237 loss)
I1018 08:51:50.148361 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.00956 (* 1 = 1.00956 loss)
I1018 08:51:50.148366 11069 solver.cpp:571] Iteration 20, lr = 0.001
I1018 08:51:57.254355 11069 solver.cpp:242] Iteration 40, loss = 1.47545
I1018 08:51:57.254379 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.652562 (* 1 = 0.652562 loss)
I1018 08:51:57.254384 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.822889 (* 1 = 0.822889 loss)
I1018 08:51:57.254389 11069 solver.cpp:571] Iteration 40, lr = 0.001
I1018 08:52:04.411073 11069 solver.cpp:242] Iteration 60, loss = 0.429471
I1018 08:52:04.411098 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153569 (* 1 = 0.153569 loss)
I1018 08:52:04.411103 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.275902 (* 1 = 0.275902 loss)
I1018 08:52:04.411108 11069 solver.cpp:571] Iteration 60, lr = 0.001
I1018 08:52:11.668761 11069 solver.cpp:242] Iteration 80, loss = 1.27973
I1018 08:52:11.668787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.504576 (* 1 = 0.504576 loss)
I1018 08:52:11.668792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.775155 (* 1 = 0.775155 loss)
I1018 08:52:11.668795 11069 solver.cpp:571] Iteration 80, lr = 0.001
I1018 08:52:19.324755 11069 solver.cpp:242] Iteration 100, loss = 0.861088
I1018 08:52:19.324780 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.283469 (* 1 = 0.283469 loss)
I1018 08:52:19.324785 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.577618 (* 1 = 0.577618 loss)
I1018 08:52:19.324790 11069 solver.cpp:571] Iteration 100, lr = 0.001
I1018 08:52:26.996130 11069 solver.cpp:242] Iteration 120, loss = 0.897059
I1018 08:52:26.996155 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.287359 (* 1 = 0.287359 loss)
I1018 08:52:26.996160 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.6097 (* 1 = 0.6097 loss)
I1018 08:52:26.996163 11069 solver.cpp:571] Iteration 120, lr = 0.001
I1018 08:52:34.577982 11069 solver.cpp:242] Iteration 140, loss = 1.71731
I1018 08:52:34.578006 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.889778 (* 1 = 0.889778 loss)
I1018 08:52:34.578011 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.827527 (* 1 = 0.827527 loss)
I1018 08:52:34.578016 11069 solver.cpp:571] Iteration 140, lr = 0.001
I1018 08:52:42.211906 11069 solver.cpp:242] Iteration 160, loss = 0.498739
I1018 08:52:42.211931 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.226163 (* 1 = 0.226163 loss)
I1018 08:52:42.211935 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.272576 (* 1 = 0.272576 loss)
I1018 08:52:42.211940 11069 solver.cpp:571] Iteration 160, lr = 0.001
I1018 08:52:49.762632 11069 solver.cpp:242] Iteration 180, loss = 1.97035
I1018 08:52:49.762658 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.684909 (* 1 = 0.684909 loss)
I1018 08:52:49.762662 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.28544 (* 1 = 1.28544 loss)
I1018 08:52:49.762667 11069 solver.cpp:571] Iteration 180, lr = 0.001
speed: 0.371s / iter
I1018 08:52:57.236018 11069 solver.cpp:242] Iteration 200, loss = 0.772612
I1018 08:52:57.236044 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150184 (* 1 = 0.150184 loss)
I1018 08:52:57.236048 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.622428 (* 1 = 0.622428 loss)
I1018 08:52:57.236052 11069 solver.cpp:571] Iteration 200, lr = 0.001
I1018 08:53:04.786650 11069 solver.cpp:242] Iteration 220, loss = 1.52088
I1018 08:53:04.786672 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.531181 (* 1 = 0.531181 loss)
I1018 08:53:04.786677 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.989701 (* 1 = 0.989701 loss)
I1018 08:53:04.786681 11069 solver.cpp:571] Iteration 220, lr = 0.001
I1018 08:53:12.352803 11069 solver.cpp:242] Iteration 240, loss = 0.486443
I1018 08:53:12.352828 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.141122 (* 1 = 0.141122 loss)
I1018 08:53:12.352833 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.345321 (* 1 = 0.345321 loss)
I1018 08:53:12.352838 11069 solver.cpp:571] Iteration 240, lr = 0.001
I1018 08:53:19.953914 11069 solver.cpp:242] Iteration 260, loss = 1.00334
I1018 08:53:19.953939 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.357021 (* 1 = 0.357021 loss)
I1018 08:53:19.953944 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.646315 (* 1 = 0.646315 loss)
I1018 08:53:19.953948 11069 solver.cpp:571] Iteration 260, lr = 0.001
I1018 08:53:27.516160 11069 solver.cpp:242] Iteration 280, loss = 0.680926
I1018 08:53:27.516185 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.22488 (* 1 = 0.22488 loss)
I1018 08:53:27.516190 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.456046 (* 1 = 0.456046 loss)
I1018 08:53:27.516193 11069 solver.cpp:571] Iteration 280, lr = 0.001
I1018 08:53:35.097530 11069 solver.cpp:242] Iteration 300, loss = 0.494134
I1018 08:53:35.097555 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.195808 (* 1 = 0.195808 loss)
I1018 08:53:35.097559 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.298326 (* 1 = 0.298326 loss)
I1018 08:53:35.097563 11069 solver.cpp:571] Iteration 300, lr = 0.001
I1018 08:53:42.591840 11069 solver.cpp:242] Iteration 320, loss = 1.09294
I1018 08:53:42.591866 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.359333 (* 1 = 0.359333 loss)
I1018 08:53:42.591871 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.733606 (* 1 = 0.733606 loss)
I1018 08:53:42.591874 11069 solver.cpp:571] Iteration 320, lr = 0.001
I1018 08:53:50.169574 11069 solver.cpp:242] Iteration 340, loss = 0.660065
I1018 08:53:50.169595 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171447 (* 1 = 0.171447 loss)
I1018 08:53:50.169600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.488618 (* 1 = 0.488618 loss)
I1018 08:53:50.169605 11069 solver.cpp:571] Iteration 340, lr = 0.001
I1018 08:53:57.663218 11069 solver.cpp:242] Iteration 360, loss = 1.57187
I1018 08:53:57.663242 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.510182 (* 1 = 0.510182 loss)
I1018 08:53:57.663246 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.06169 (* 1 = 1.06169 loss)
I1018 08:53:57.663251 11069 solver.cpp:571] Iteration 360, lr = 0.001
I1018 08:54:05.200729 11069 solver.cpp:242] Iteration 380, loss = 2.05394
I1018 08:54:05.200753 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.832712 (* 1 = 0.832712 loss)
I1018 08:54:05.200758 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.22123 (* 1 = 1.22123 loss)
I1018 08:54:05.200762 11069 solver.cpp:571] Iteration 380, lr = 0.001
speed: 0.374s / iter
I1018 08:54:12.701110 11069 solver.cpp:242] Iteration 400, loss = 1.21847
I1018 08:54:12.701135 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.430784 (* 1 = 0.430784 loss)
I1018 08:54:12.701140 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.787686 (* 1 = 0.787686 loss)
I1018 08:54:12.701144 11069 solver.cpp:571] Iteration 400, lr = 0.001
I1018 08:54:20.124635 11069 solver.cpp:242] Iteration 420, loss = 1.34771
I1018 08:54:20.124658 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.507755 (* 1 = 0.507755 loss)
I1018 08:54:20.124663 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.83995 (* 1 = 0.83995 loss)
I1018 08:54:20.124667 11069 solver.cpp:571] Iteration 420, lr = 0.001
I1018 08:54:27.669128 11069 solver.cpp:242] Iteration 440, loss = 2.83713
I1018 08:54:27.669152 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.32396 (* 1 = 1.32396 loss)
I1018 08:54:27.669157 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.51318 (* 1 = 1.51318 loss)
I1018 08:54:27.669162 11069 solver.cpp:571] Iteration 440, lr = 0.001
I1018 08:54:35.148730 11069 solver.cpp:242] Iteration 460, loss = 1.46466
I1018 08:54:35.148754 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.575058 (* 1 = 0.575058 loss)
I1018 08:54:35.148759 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.889598 (* 1 = 0.889598 loss)
I1018 08:54:35.148763 11069 solver.cpp:571] Iteration 460, lr = 0.001
I1018 08:54:42.642920 11069 solver.cpp:242] Iteration 480, loss = 0.444882
I1018 08:54:42.642946 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147184 (* 1 = 0.147184 loss)
I1018 08:54:42.642951 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.297697 (* 1 = 0.297697 loss)
I1018 08:54:42.642954 11069 solver.cpp:571] Iteration 480, lr = 0.001
I1018 08:54:50.175240 11069 solver.cpp:242] Iteration 500, loss = 0.522966
I1018 08:54:50.175264 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.154304 (* 1 = 0.154304 loss)
I1018 08:54:50.175269 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.368662 (* 1 = 0.368662 loss)
I1018 08:54:50.175273 11069 solver.cpp:571] Iteration 500, lr = 0.001
I1018 08:54:57.741983 11069 solver.cpp:242] Iteration 520, loss = 0.385967
I1018 08:54:57.742008 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0889931 (* 1 = 0.0889931 loss)
I1018 08:54:57.742013 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296974 (* 1 = 0.296974 loss)
I1018 08:54:57.742017 11069 solver.cpp:571] Iteration 520, lr = 0.001
I1018 08:55:05.271898 11069 solver.cpp:242] Iteration 540, loss = 1.33025
I1018 08:55:05.271921 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.451509 (* 1 = 0.451509 loss)
I1018 08:55:05.271926 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.878738 (* 1 = 0.878738 loss)
I1018 08:55:05.271930 11069 solver.cpp:571] Iteration 540, lr = 0.001
I1018 08:55:12.724138 11069 solver.cpp:242] Iteration 560, loss = 0.217771
I1018 08:55:12.724162 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0631187 (* 1 = 0.0631187 loss)
I1018 08:55:12.724167 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.154652 (* 1 = 0.154652 loss)
I1018 08:55:12.724171 11069 solver.cpp:571] Iteration 560, lr = 0.001
I1018 08:55:20.242274 11069 solver.cpp:242] Iteration 580, loss = 0.322786
I1018 08:55:20.242297 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1181 (* 1 = 0.1181 loss)
I1018 08:55:20.242301 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204686 (* 1 = 0.204686 loss)
I1018 08:55:20.242306 11069 solver.cpp:571] Iteration 580, lr = 0.001
speed: 0.375s / iter
I1018 08:55:27.808429 11069 solver.cpp:242] Iteration 600, loss = 0.760908
I1018 08:55:27.808454 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.111829 (* 1 = 0.111829 loss)
I1018 08:55:27.808459 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.64908 (* 1 = 0.64908 loss)
I1018 08:55:27.808462 11069 solver.cpp:571] Iteration 600, lr = 0.001
I1018 08:55:35.318547 11069 solver.cpp:242] Iteration 620, loss = 0.359727
I1018 08:55:35.318572 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0537699 (* 1 = 0.0537699 loss)
I1018 08:55:35.318578 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.305957 (* 1 = 0.305957 loss)
I1018 08:55:35.318581 11069 solver.cpp:571] Iteration 620, lr = 0.001
I1018 08:55:42.824550 11069 solver.cpp:242] Iteration 640, loss = 0.265518
I1018 08:55:42.824575 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0936556 (* 1 = 0.0936556 loss)
I1018 08:55:42.824580 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.171862 (* 1 = 0.171862 loss)
I1018 08:55:42.824584 11069 solver.cpp:571] Iteration 640, lr = 0.001
I1018 08:55:50.366871 11069 solver.cpp:242] Iteration 660, loss = 0.997034
I1018 08:55:50.366894 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244334 (* 1 = 0.244334 loss)
I1018 08:55:50.366899 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.752701 (* 1 = 0.752701 loss)
I1018 08:55:50.366904 11069 solver.cpp:571] Iteration 660, lr = 0.001
I1018 08:55:57.913568 11069 solver.cpp:242] Iteration 680, loss = 0.95781
I1018 08:55:57.913594 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.383261 (* 1 = 0.383261 loss)
I1018 08:55:57.913597 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.57455 (* 1 = 0.57455 loss)
I1018 08:55:57.913601 11069 solver.cpp:571] Iteration 680, lr = 0.001
I1018 08:56:05.483201 11069 solver.cpp:242] Iteration 700, loss = 0.403569
I1018 08:56:05.483225 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.102785 (* 1 = 0.102785 loss)
I1018 08:56:05.483230 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.300784 (* 1 = 0.300784 loss)
I1018 08:56:05.483234 11069 solver.cpp:571] Iteration 700, lr = 0.001
I1018 08:56:13.018085 11069 solver.cpp:242] Iteration 720, loss = 0.714853
I1018 08:56:13.018110 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.305557 (* 1 = 0.305557 loss)
I1018 08:56:13.018115 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.409296 (* 1 = 0.409296 loss)
I1018 08:56:13.018120 11069 solver.cpp:571] Iteration 720, lr = 0.001
I1018 08:56:20.502127 11069 solver.cpp:242] Iteration 740, loss = 1.09086
I1018 08:56:20.502152 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.343467 (* 1 = 0.343467 loss)
I1018 08:56:20.502156 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.747393 (* 1 = 0.747393 loss)
I1018 08:56:20.502161 11069 solver.cpp:571] Iteration 740, lr = 0.001
I1018 08:56:28.034082 11069 solver.cpp:242] Iteration 760, loss = 0.725247
I1018 08:56:28.034107 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.258266 (* 1 = 0.258266 loss)
I1018 08:56:28.034111 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.46698 (* 1 = 0.46698 loss)
I1018 08:56:28.034116 11069 solver.cpp:571] Iteration 760, lr = 0.001
I1018 08:56:35.617188 11069 solver.cpp:242] Iteration 780, loss = 0.650038
I1018 08:56:35.617213 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.262663 (* 1 = 0.262663 loss)
I1018 08:56:35.617218 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.387375 (* 1 = 0.387375 loss)
I1018 08:56:35.617221 11069 solver.cpp:571] Iteration 780, lr = 0.001
speed: 0.375s / iter
I1018 08:56:42.960554 11069 solver.cpp:242] Iteration 800, loss = 0.298826
I1018 08:56:42.960579 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100677 (* 1 = 0.100677 loss)
I1018 08:56:42.960584 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.198149 (* 1 = 0.198149 loss)
I1018 08:56:42.960588 11069 solver.cpp:571] Iteration 800, lr = 0.001
I1018 08:56:50.379523 11069 solver.cpp:242] Iteration 820, loss = 1.32128
I1018 08:56:50.379549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.564253 (* 1 = 0.564253 loss)
I1018 08:56:50.379552 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.757026 (* 1 = 0.757026 loss)
I1018 08:56:50.379557 11069 solver.cpp:571] Iteration 820, lr = 0.001
I1018 08:56:57.954497 11069 solver.cpp:242] Iteration 840, loss = 0.404757
I1018 08:56:57.954521 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105082 (* 1 = 0.105082 loss)
I1018 08:56:57.954526 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.299675 (* 1 = 0.299675 loss)
I1018 08:56:57.954530 11069 solver.cpp:571] Iteration 840, lr = 0.001
I1018 08:57:05.488945 11069 solver.cpp:242] Iteration 860, loss = 0.24989
I1018 08:57:05.488970 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0640911 (* 1 = 0.0640911 loss)
I1018 08:57:05.488975 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.185799 (* 1 = 0.185799 loss)
I1018 08:57:05.488978 11069 solver.cpp:571] Iteration 860, lr = 0.001
I1018 08:57:13.015930 11069 solver.cpp:242] Iteration 880, loss = 0.903138
I1018 08:57:13.015955 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.338173 (* 1 = 0.338173 loss)
I1018 08:57:13.015959 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.564965 (* 1 = 0.564965 loss)
I1018 08:57:13.015964 11069 solver.cpp:571] Iteration 880, lr = 0.001
I1018 08:57:20.458621 11069 solver.cpp:242] Iteration 900, loss = 0.753551
I1018 08:57:20.458645 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.263461 (* 1 = 0.263461 loss)
I1018 08:57:20.458650 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.49009 (* 1 = 0.49009 loss)
I1018 08:57:20.458654 11069 solver.cpp:571] Iteration 900, lr = 0.001
I1018 08:57:28.017741 11069 solver.cpp:242] Iteration 920, loss = 1.07445
I1018 08:57:28.017765 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.375379 (* 1 = 0.375379 loss)
I1018 08:57:28.017771 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.699075 (* 1 = 0.699075 loss)
I1018 08:57:28.017774 11069 solver.cpp:571] Iteration 920, lr = 0.001
I1018 08:57:35.514019 11069 solver.cpp:242] Iteration 940, loss = 0.37301
I1018 08:57:35.514044 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0926171 (* 1 = 0.0926171 loss)
I1018 08:57:35.514047 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280393 (* 1 = 0.280393 loss)
I1018 08:57:35.514052 11069 solver.cpp:571] Iteration 940, lr = 0.001
I1018 08:57:42.943617 11069 solver.cpp:242] Iteration 960, loss = 0.413814
I1018 08:57:42.943641 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.134272 (* 1 = 0.134272 loss)
I1018 08:57:42.943646 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.279542 (* 1 = 0.279542 loss)
I1018 08:57:42.943650 11069 solver.cpp:571] Iteration 960, lr = 0.001
I1018 08:57:50.402884 11069 solver.cpp:242] Iteration 980, loss = 1.27301
I1018 08:57:50.402909 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.345936 (* 1 = 0.345936 loss)
I1018 08:57:50.402914 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.927079 (* 1 = 0.927079 loss)
I1018 08:57:50.402917 11069 solver.cpp:571] Iteration 980, lr = 0.001
speed: 0.375s / iter
I1018 08:57:57.889436 11069 solver.cpp:242] Iteration 1000, loss = 1.96322
I1018 08:57:57.889462 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.92934 (* 1 = 0.92934 loss)
I1018 08:57:57.889467 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.03388 (* 1 = 1.03388 loss)
I1018 08:57:57.889470 11069 solver.cpp:571] Iteration 1000, lr = 0.001
I1018 08:58:05.452584 11069 solver.cpp:242] Iteration 1020, loss = 0.808153
I1018 08:58:05.452608 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.221303 (* 1 = 0.221303 loss)
I1018 08:58:05.452613 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.58685 (* 1 = 0.58685 loss)
I1018 08:58:05.452617 11069 solver.cpp:571] Iteration 1020, lr = 0.001
I1018 08:58:12.950428 11069 solver.cpp:242] Iteration 1040, loss = 0.323636
I1018 08:58:12.950453 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0998889 (* 1 = 0.0998889 loss)
I1018 08:58:12.950459 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.223747 (* 1 = 0.223747 loss)
I1018 08:58:12.950462 11069 solver.cpp:571] Iteration 1040, lr = 0.001
I1018 08:58:20.474627 11069 solver.cpp:242] Iteration 1060, loss = 0.347154
I1018 08:58:20.474653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0700225 (* 1 = 0.0700225 loss)
I1018 08:58:20.474658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.277131 (* 1 = 0.277131 loss)
I1018 08:58:20.474661 11069 solver.cpp:571] Iteration 1060, lr = 0.001
I1018 08:58:27.902963 11069 solver.cpp:242] Iteration 1080, loss = 1.67919
I1018 08:58:27.902988 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.546507 (* 1 = 0.546507 loss)
I1018 08:58:27.902993 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.13269 (* 1 = 1.13269 loss)
I1018 08:58:27.902997 11069 solver.cpp:571] Iteration 1080, lr = 0.001
I1018 08:58:35.344568 11069 solver.cpp:242] Iteration 1100, loss = 0.773776
I1018 08:58:35.344593 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212428 (* 1 = 0.212428 loss)
I1018 08:58:35.344597 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.561348 (* 1 = 0.561348 loss)
I1018 08:58:35.344601 11069 solver.cpp:571] Iteration 1100, lr = 0.001
I1018 08:58:42.845607 11069 solver.cpp:242] Iteration 1120, loss = 0.990995
I1018 08:58:42.845631 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.2201 (* 1 = 0.2201 loss)
I1018 08:58:42.845636 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.770895 (* 1 = 0.770895 loss)
I1018 08:58:42.845640 11069 solver.cpp:571] Iteration 1120, lr = 0.001
I1018 08:58:50.353325 11069 solver.cpp:242] Iteration 1140, loss = 0.383375
I1018 08:58:50.353349 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.136209 (* 1 = 0.136209 loss)
I1018 08:58:50.353353 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.247166 (* 1 = 0.247166 loss)
I1018 08:58:50.353358 11069 solver.cpp:571] Iteration 1140, lr = 0.001
I1018 08:58:57.970206 11069 solver.cpp:242] Iteration 1160, loss = 1.20616
I1018 08:58:57.970230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.388099 (* 1 = 0.388099 loss)
I1018 08:58:57.970234 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.818065 (* 1 = 0.818065 loss)
I1018 08:58:57.970238 11069 solver.cpp:571] Iteration 1160, lr = 0.001
I1018 08:59:05.471725 11069 solver.cpp:242] Iteration 1180, loss = 0.733237
I1018 08:59:05.471750 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.21606 (* 1 = 0.21606 loss)
I1018 08:59:05.471755 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.517177 (* 1 = 0.517177 loss)
I1018 08:59:05.471758 11069 solver.cpp:571] Iteration 1180, lr = 0.001
speed: 0.375s / iter
I1018 08:59:12.941841 11069 solver.cpp:242] Iteration 1200, loss = 0.443961
I1018 08:59:12.941876 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.107464 (* 1 = 0.107464 loss)
I1018 08:59:12.941881 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.336497 (* 1 = 0.336497 loss)
I1018 08:59:12.941895 11069 solver.cpp:571] Iteration 1200, lr = 0.001
I1018 08:59:20.489899 11069 solver.cpp:242] Iteration 1220, loss = 0.500035
I1018 08:59:20.489924 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.183635 (* 1 = 0.183635 loss)
I1018 08:59:20.489929 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3164 (* 1 = 0.3164 loss)
I1018 08:59:20.489933 11069 solver.cpp:571] Iteration 1220, lr = 0.001
I1018 08:59:28.078277 11069 solver.cpp:242] Iteration 1240, loss = 1.2788
I1018 08:59:28.078302 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.419748 (* 1 = 0.419748 loss)
I1018 08:59:28.078307 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.859052 (* 1 = 0.859052 loss)
I1018 08:59:28.078311 11069 solver.cpp:571] Iteration 1240, lr = 0.001
I1018 08:59:35.571166 11069 solver.cpp:242] Iteration 1260, loss = 0.675971
I1018 08:59:35.571189 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159739 (* 1 = 0.159739 loss)
I1018 08:59:35.571194 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.516232 (* 1 = 0.516232 loss)
I1018 08:59:35.571198 11069 solver.cpp:571] Iteration 1260, lr = 0.001
I1018 08:59:43.064046 11069 solver.cpp:242] Iteration 1280, loss = 0.144909
I1018 08:59:43.064071 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0352795 (* 1 = 0.0352795 loss)
I1018 08:59:43.064076 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.109629 (* 1 = 0.109629 loss)
I1018 08:59:43.064080 11069 solver.cpp:571] Iteration 1280, lr = 0.001
I1018 08:59:50.569430 11069 solver.cpp:242] Iteration 1300, loss = 0.661886
I1018 08:59:50.569454 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108729 (* 1 = 0.108729 loss)
I1018 08:59:50.569459 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.553157 (* 1 = 0.553157 loss)
I1018 08:59:50.569464 11069 solver.cpp:571] Iteration 1300, lr = 0.001
I1018 08:59:58.190563 11069 solver.cpp:242] Iteration 1320, loss = 0.26848
I1018 08:59:58.190588 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108087 (* 1 = 0.108087 loss)
I1018 08:59:58.190593 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.160393 (* 1 = 0.160393 loss)
I1018 08:59:58.190598 11069 solver.cpp:571] Iteration 1320, lr = 0.001
I1018 09:00:05.465626 11069 solver.cpp:242] Iteration 1340, loss = 1.71519
I1018 09:00:05.465651 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.632684 (* 1 = 0.632684 loss)
I1018 09:00:05.465656 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.0825 (* 1 = 1.0825 loss)
I1018 09:00:05.465661 11069 solver.cpp:571] Iteration 1340, lr = 0.001
I1018 09:00:13.012470 11069 solver.cpp:242] Iteration 1360, loss = 0.56261
I1018 09:00:13.012495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.138743 (* 1 = 0.138743 loss)
I1018 09:00:13.012500 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.423867 (* 1 = 0.423867 loss)
I1018 09:00:13.012504 11069 solver.cpp:571] Iteration 1360, lr = 0.001
I1018 09:00:20.554965 11069 solver.cpp:242] Iteration 1380, loss = 0.748295
I1018 09:00:20.554989 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.269437 (* 1 = 0.269437 loss)
I1018 09:00:20.554994 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.478859 (* 1 = 0.478859 loss)
I1018 09:00:20.554998 11069 solver.cpp:571] Iteration 1380, lr = 0.001
speed: 0.375s / iter
I1018 09:00:28.023279 11069 solver.cpp:242] Iteration 1400, loss = 0.713865
I1018 09:00:28.023304 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143859 (* 1 = 0.143859 loss)
I1018 09:00:28.023309 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.570006 (* 1 = 0.570006 loss)
I1018 09:00:28.023316 11069 solver.cpp:571] Iteration 1400, lr = 0.001
I1018 09:00:35.586191 11069 solver.cpp:242] Iteration 1420, loss = 0.44821
I1018 09:00:35.586215 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153365 (* 1 = 0.153365 loss)
I1018 09:00:35.586220 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.294845 (* 1 = 0.294845 loss)
I1018 09:00:35.586225 11069 solver.cpp:571] Iteration 1420, lr = 0.001
I1018 09:00:43.163028 11069 solver.cpp:242] Iteration 1440, loss = 0.935229
I1018 09:00:43.163053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.258367 (* 1 = 0.258367 loss)
I1018 09:00:43.163058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.676862 (* 1 = 0.676862 loss)
I1018 09:00:43.163061 11069 solver.cpp:571] Iteration 1440, lr = 0.001
I1018 09:00:50.697082 11069 solver.cpp:242] Iteration 1460, loss = 1.08977
I1018 09:00:50.697105 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.435563 (* 1 = 0.435563 loss)
I1018 09:00:50.697109 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.654205 (* 1 = 0.654205 loss)
I1018 09:00:50.697113 11069 solver.cpp:571] Iteration 1460, lr = 0.001
I1018 09:00:58.213590 11069 solver.cpp:242] Iteration 1480, loss = 0.884168
I1018 09:00:58.213616 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.220578 (* 1 = 0.220578 loss)
I1018 09:00:58.213620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.66359 (* 1 = 0.66359 loss)
I1018 09:00:58.213624 11069 solver.cpp:571] Iteration 1480, lr = 0.001
I1018 09:01:05.679801 11069 solver.cpp:242] Iteration 1500, loss = 0.504846
I1018 09:01:05.679826 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116525 (* 1 = 0.116525 loss)
I1018 09:01:05.679831 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.388321 (* 1 = 0.388321 loss)
I1018 09:01:05.679836 11069 solver.cpp:571] Iteration 1500, lr = 0.001
I1018 09:01:13.238174 11069 solver.cpp:242] Iteration 1520, loss = 1.25495
I1018 09:01:13.238198 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.230427 (* 1 = 0.230427 loss)
I1018 09:01:13.238203 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.02453 (* 1 = 1.02453 loss)
I1018 09:01:13.238206 11069 solver.cpp:571] Iteration 1520, lr = 0.001
I1018 09:01:20.842025 11069 solver.cpp:242] Iteration 1540, loss = 0.276399
I1018 09:01:20.842051 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0576705 (* 1 = 0.0576705 loss)
I1018 09:01:20.842054 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218729 (* 1 = 0.218729 loss)
I1018 09:01:20.842058 11069 solver.cpp:571] Iteration 1540, lr = 0.001
I1018 09:01:28.316920 11069 solver.cpp:242] Iteration 1560, loss = 0.433089
I1018 09:01:28.316946 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142951 (* 1 = 0.142951 loss)
I1018 09:01:28.316951 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.290138 (* 1 = 0.290138 loss)
I1018 09:01:28.316954 11069 solver.cpp:571] Iteration 1560, lr = 0.001
I1018 09:01:35.892916 11069 solver.cpp:242] Iteration 1580, loss = 0.739456
I1018 09:01:35.892941 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.224606 (* 1 = 0.224606 loss)
I1018 09:01:35.892946 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.51485 (* 1 = 0.51485 loss)
I1018 09:01:35.892951 11069 solver.cpp:571] Iteration 1580, lr = 0.001
speed: 0.375s / iter
I1018 09:01:43.301252 11069 solver.cpp:242] Iteration 1600, loss = 0.727551
I1018 09:01:43.301277 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.18371 (* 1 = 0.18371 loss)
I1018 09:01:43.301281 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.543842 (* 1 = 0.543842 loss)
I1018 09:01:43.301285 11069 solver.cpp:571] Iteration 1600, lr = 0.001
I1018 09:01:50.761193 11069 solver.cpp:242] Iteration 1620, loss = 1.08408
I1018 09:01:50.761217 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.396866 (* 1 = 0.396866 loss)
I1018 09:01:50.761221 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.687214 (* 1 = 0.687214 loss)
I1018 09:01:50.761225 11069 solver.cpp:571] Iteration 1620, lr = 0.001
I1018 09:01:58.263854 11069 solver.cpp:242] Iteration 1640, loss = 0.497526
I1018 09:01:58.263878 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.148861 (* 1 = 0.148861 loss)
I1018 09:01:58.263882 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.348666 (* 1 = 0.348666 loss)
I1018 09:01:58.263887 11069 solver.cpp:571] Iteration 1640, lr = 0.001
I1018 09:02:05.714318 11069 solver.cpp:242] Iteration 1660, loss = 0.801786
I1018 09:02:05.714342 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206504 (* 1 = 0.206504 loss)
I1018 09:02:05.714346 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.595282 (* 1 = 0.595282 loss)
I1018 09:02:05.714350 11069 solver.cpp:571] Iteration 1660, lr = 0.001
I1018 09:02:13.340138 11069 solver.cpp:242] Iteration 1680, loss = 1.35428
I1018 09:02:13.340163 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.599702 (* 1 = 0.599702 loss)
I1018 09:02:13.340168 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.754583 (* 1 = 0.754583 loss)
I1018 09:02:13.340173 11069 solver.cpp:571] Iteration 1680, lr = 0.001
I1018 09:02:20.834859 11069 solver.cpp:242] Iteration 1700, loss = 1.7643
I1018 09:02:20.834884 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.66035 (* 1 = 0.66035 loss)
I1018 09:02:20.834889 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.10395 (* 1 = 1.10395 loss)
I1018 09:02:20.834893 11069 solver.cpp:571] Iteration 1700, lr = 0.001
I1018 09:02:28.445106 11069 solver.cpp:242] Iteration 1720, loss = 0.493426
I1018 09:02:28.445130 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205915 (* 1 = 0.205915 loss)
I1018 09:02:28.445134 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.287511 (* 1 = 0.287511 loss)
I1018 09:02:28.445138 11069 solver.cpp:571] Iteration 1720, lr = 0.001
I1018 09:02:35.952102 11069 solver.cpp:242] Iteration 1740, loss = 0.450005
I1018 09:02:35.952126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0993737 (* 1 = 0.0993737 loss)
I1018 09:02:35.952131 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.350632 (* 1 = 0.350632 loss)
I1018 09:02:35.952134 11069 solver.cpp:571] Iteration 1740, lr = 0.001
I1018 09:02:43.578410 11069 solver.cpp:242] Iteration 1760, loss = 0.61839
I1018 09:02:43.578435 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.133211 (* 1 = 0.133211 loss)
I1018 09:02:43.578440 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.485179 (* 1 = 0.485179 loss)
I1018 09:02:43.578444 11069 solver.cpp:571] Iteration 1760, lr = 0.001
I1018 09:02:51.179533 11069 solver.cpp:242] Iteration 1780, loss = 1.87886
I1018 09:02:51.179558 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.769579 (* 1 = 0.769579 loss)
I1018 09:02:51.179561 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.10928 (* 1 = 1.10928 loss)
I1018 09:02:51.179565 11069 solver.cpp:571] Iteration 1780, lr = 0.001
speed: 0.375s / iter
I1018 09:02:58.710203 11069 solver.cpp:242] Iteration 1800, loss = 0.319628
I1018 09:02:58.710229 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0761786 (* 1 = 0.0761786 loss)
I1018 09:02:58.710233 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.243449 (* 1 = 0.243449 loss)
I1018 09:02:58.710238 11069 solver.cpp:571] Iteration 1800, lr = 0.001
I1018 09:03:06.252224 11069 solver.cpp:242] Iteration 1820, loss = 0.927309
I1018 09:03:06.252249 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.204304 (* 1 = 0.204304 loss)
I1018 09:03:06.252254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.723005 (* 1 = 0.723005 loss)
I1018 09:03:06.252257 11069 solver.cpp:571] Iteration 1820, lr = 0.001
I1018 09:03:13.790006 11069 solver.cpp:242] Iteration 1840, loss = 1.45799
I1018 09:03:13.790031 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.588553 (* 1 = 0.588553 loss)
I1018 09:03:13.790036 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.86944 (* 1 = 0.86944 loss)
I1018 09:03:13.790040 11069 solver.cpp:571] Iteration 1840, lr = 0.001
I1018 09:03:21.364071 11069 solver.cpp:242] Iteration 1860, loss = 0.293454
I1018 09:03:21.364096 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0804944 (* 1 = 0.0804944 loss)
I1018 09:03:21.364101 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21296 (* 1 = 0.21296 loss)
I1018 09:03:21.364105 11069 solver.cpp:571] Iteration 1860, lr = 0.001
I1018 09:03:28.920920 11069 solver.cpp:242] Iteration 1880, loss = 0.196957
I1018 09:03:28.920945 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0375208 (* 1 = 0.0375208 loss)
I1018 09:03:28.920949 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159436 (* 1 = 0.159436 loss)
I1018 09:03:28.920954 11069 solver.cpp:571] Iteration 1880, lr = 0.001
I1018 09:03:36.416998 11069 solver.cpp:242] Iteration 1900, loss = 0.230387
I1018 09:03:36.417023 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.048693 (* 1 = 0.048693 loss)
I1018 09:03:36.417028 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.181694 (* 1 = 0.181694 loss)
I1018 09:03:36.417033 11069 solver.cpp:571] Iteration 1900, lr = 0.001
I1018 09:03:43.892773 11069 solver.cpp:242] Iteration 1920, loss = 0.426051
I1018 09:03:43.892798 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142727 (* 1 = 0.142727 loss)
I1018 09:03:43.892802 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.283324 (* 1 = 0.283324 loss)
I1018 09:03:43.892807 11069 solver.cpp:571] Iteration 1920, lr = 0.001
I1018 09:03:51.455590 11069 solver.cpp:242] Iteration 1940, loss = 0.330258
I1018 09:03:51.455615 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0667055 (* 1 = 0.0667055 loss)
I1018 09:03:51.455620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.263552 (* 1 = 0.263552 loss)
I1018 09:03:51.455623 11069 solver.cpp:571] Iteration 1940, lr = 0.001
I1018 09:03:58.972301 11069 solver.cpp:242] Iteration 1960, loss = 0.319672
I1018 09:03:58.972324 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0581708 (* 1 = 0.0581708 loss)
I1018 09:03:58.972328 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.261501 (* 1 = 0.261501 loss)
I1018 09:03:58.972333 11069 solver.cpp:571] Iteration 1960, lr = 0.001
I1018 09:04:06.483407 11069 solver.cpp:242] Iteration 1980, loss = 0.375246
I1018 09:04:06.483431 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.136929 (* 1 = 0.136929 loss)
I1018 09:04:06.483436 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.238317 (* 1 = 0.238317 loss)
I1018 09:04:06.483440 11069 solver.cpp:571] Iteration 1980, lr = 0.001
speed: 0.376s / iter
I1018 09:04:14.106304 11069 solver.cpp:242] Iteration 2000, loss = 0.401436
I1018 09:04:14.106329 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120587 (* 1 = 0.120587 loss)
I1018 09:04:14.106334 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280849 (* 1 = 0.280849 loss)
I1018 09:04:14.106338 11069 solver.cpp:571] Iteration 2000, lr = 0.001
I1018 09:04:21.665628 11069 solver.cpp:242] Iteration 2020, loss = 0.910666
I1018 09:04:21.665653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.249665 (* 1 = 0.249665 loss)
I1018 09:04:21.665657 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.661001 (* 1 = 0.661001 loss)
I1018 09:04:21.665662 11069 solver.cpp:571] Iteration 2020, lr = 0.001
I1018 09:04:29.224078 11069 solver.cpp:242] Iteration 2040, loss = 0.918075
I1018 09:04:29.224103 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.343897 (* 1 = 0.343897 loss)
I1018 09:04:29.224107 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.574178 (* 1 = 0.574178 loss)
I1018 09:04:29.224112 11069 solver.cpp:571] Iteration 2040, lr = 0.001
I1018 09:04:36.690403 11069 solver.cpp:242] Iteration 2060, loss = 1.24258
I1018 09:04:36.690428 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.494278 (* 1 = 0.494278 loss)
I1018 09:04:36.690433 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.748304 (* 1 = 0.748304 loss)
I1018 09:04:36.690438 11069 solver.cpp:571] Iteration 2060, lr = 0.001
I1018 09:04:44.135295 11069 solver.cpp:242] Iteration 2080, loss = 0.348931
I1018 09:04:44.135324 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153837 (* 1 = 0.153837 loss)
I1018 09:04:44.135329 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195094 (* 1 = 0.195094 loss)
I1018 09:04:44.135332 11069 solver.cpp:571] Iteration 2080, lr = 0.001
I1018 09:04:51.620195 11069 solver.cpp:242] Iteration 2100, loss = 0.416591
I1018 09:04:51.620219 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103948 (* 1 = 0.103948 loss)
I1018 09:04:51.620224 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.312643 (* 1 = 0.312643 loss)
I1018 09:04:51.620229 11069 solver.cpp:571] Iteration 2100, lr = 0.001
I1018 09:04:59.267391 11069 solver.cpp:242] Iteration 2120, loss = 0.47268
I1018 09:04:59.267416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.078616 (* 1 = 0.078616 loss)
I1018 09:04:59.267421 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.394064 (* 1 = 0.394064 loss)
I1018 09:04:59.267426 11069 solver.cpp:571] Iteration 2120, lr = 0.001
I1018 09:05:06.738879 11069 solver.cpp:242] Iteration 2140, loss = 0.42915
I1018 09:05:06.738904 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0684362 (* 1 = 0.0684362 loss)
I1018 09:05:06.738909 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.360714 (* 1 = 0.360714 loss)
I1018 09:05:06.738914 11069 solver.cpp:571] Iteration 2140, lr = 0.001
I1018 09:05:14.302116 11069 solver.cpp:242] Iteration 2160, loss = 0.648834
I1018 09:05:14.302141 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.162369 (* 1 = 0.162369 loss)
I1018 09:05:14.302146 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.486465 (* 1 = 0.486465 loss)
I1018 09:05:14.302150 11069 solver.cpp:571] Iteration 2160, lr = 0.001
I1018 09:05:21.858180 11069 solver.cpp:242] Iteration 2180, loss = 0.501612
I1018 09:05:21.858203 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0806669 (* 1 = 0.0806669 loss)
I1018 09:05:21.858208 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.420945 (* 1 = 0.420945 loss)
I1018 09:05:21.858212 11069 solver.cpp:571] Iteration 2180, lr = 0.001
speed: 0.376s / iter
I1018 09:05:29.270761 11069 solver.cpp:242] Iteration 2200, loss = 0.409847
I1018 09:05:29.270786 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0760763 (* 1 = 0.0760763 loss)
I1018 09:05:29.270789 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.333771 (* 1 = 0.333771 loss)
I1018 09:05:29.270794 11069 solver.cpp:571] Iteration 2200, lr = 0.001
I1018 09:05:36.808913 11069 solver.cpp:242] Iteration 2220, loss = 0.750813
I1018 09:05:36.808938 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.311621 (* 1 = 0.311621 loss)
I1018 09:05:36.808943 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.439192 (* 1 = 0.439192 loss)
I1018 09:05:36.808948 11069 solver.cpp:571] Iteration 2220, lr = 0.001
I1018 09:05:44.199602 11069 solver.cpp:242] Iteration 2240, loss = 0.305071
I1018 09:05:44.199626 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0471734 (* 1 = 0.0471734 loss)
I1018 09:05:44.199631 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.257898 (* 1 = 0.257898 loss)
I1018 09:05:44.199635 11069 solver.cpp:571] Iteration 2240, lr = 0.001
I1018 09:05:51.734509 11069 solver.cpp:242] Iteration 2260, loss = 0.187489
I1018 09:05:51.734534 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0378548 (* 1 = 0.0378548 loss)
I1018 09:05:51.734539 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149634 (* 1 = 0.149634 loss)
I1018 09:05:51.734544 11069 solver.cpp:571] Iteration 2260, lr = 0.001
I1018 09:05:59.172447 11069 solver.cpp:242] Iteration 2280, loss = 1.00095
I1018 09:05:59.172472 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.332157 (* 1 = 0.332157 loss)
I1018 09:05:59.172477 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.668797 (* 1 = 0.668797 loss)
I1018 09:05:59.172480 11069 solver.cpp:571] Iteration 2280, lr = 0.001
I1018 09:06:06.771740 11069 solver.cpp:242] Iteration 2300, loss = 0.432912
I1018 09:06:06.771765 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0869689 (* 1 = 0.0869689 loss)
I1018 09:06:06.771770 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.345943 (* 1 = 0.345943 loss)
I1018 09:06:06.771775 11069 solver.cpp:571] Iteration 2300, lr = 0.001
I1018 09:06:14.302309 11069 solver.cpp:242] Iteration 2320, loss = 0.915873
I1018 09:06:14.302333 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.332927 (* 1 = 0.332927 loss)
I1018 09:06:14.302337 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.582946 (* 1 = 0.582946 loss)
I1018 09:06:14.302342 11069 solver.cpp:571] Iteration 2320, lr = 0.001
I1018 09:06:21.818929 11069 solver.cpp:242] Iteration 2340, loss = 0.299578
I1018 09:06:21.818954 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0464533 (* 1 = 0.0464533 loss)
I1018 09:06:21.818959 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.253125 (* 1 = 0.253125 loss)
I1018 09:06:21.818964 11069 solver.cpp:571] Iteration 2340, lr = 0.001
I1018 09:06:29.350633 11069 solver.cpp:242] Iteration 2360, loss = 0.188808
I1018 09:06:29.350657 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0475482 (* 1 = 0.0475482 loss)
I1018 09:06:29.350662 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141259 (* 1 = 0.141259 loss)
I1018 09:06:29.350666 11069 solver.cpp:571] Iteration 2360, lr = 0.001
I1018 09:06:36.898103 11069 solver.cpp:242] Iteration 2380, loss = 1.2938
I1018 09:06:36.898128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.555088 (* 1 = 0.555088 loss)
I1018 09:06:36.898133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.738717 (* 1 = 0.738717 loss)
I1018 09:06:36.898138 11069 solver.cpp:571] Iteration 2380, lr = 0.001
speed: 0.376s / iter
I1018 09:06:44.496511 11069 solver.cpp:242] Iteration 2400, loss = 0.439385
I1018 09:06:44.496536 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0965175 (* 1 = 0.0965175 loss)
I1018 09:06:44.496541 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342867 (* 1 = 0.342867 loss)
I1018 09:06:44.496546 11069 solver.cpp:571] Iteration 2400, lr = 0.001
I1018 09:06:52.012106 11069 solver.cpp:242] Iteration 2420, loss = 0.911705
I1018 09:06:52.012131 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.214871 (* 1 = 0.214871 loss)
I1018 09:06:52.012135 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.696834 (* 1 = 0.696834 loss)
I1018 09:06:52.012140 11069 solver.cpp:571] Iteration 2420, lr = 0.001
I1018 09:06:59.403067 11069 solver.cpp:242] Iteration 2440, loss = 1.12272
I1018 09:06:59.403092 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.397859 (* 1 = 0.397859 loss)
I1018 09:06:59.403097 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.724858 (* 1 = 0.724858 loss)
I1018 09:06:59.403102 11069 solver.cpp:571] Iteration 2440, lr = 0.001
I1018 09:07:06.879966 11069 solver.cpp:242] Iteration 2460, loss = 0.673797
I1018 09:07:06.879990 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.196661 (* 1 = 0.196661 loss)
I1018 09:07:06.879995 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.477137 (* 1 = 0.477137 loss)
I1018 09:07:06.880000 11069 solver.cpp:571] Iteration 2460, lr = 0.001
I1018 09:07:14.448472 11069 solver.cpp:242] Iteration 2480, loss = 0.96397
I1018 09:07:14.448496 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241813 (* 1 = 0.241813 loss)
I1018 09:07:14.448501 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.722157 (* 1 = 0.722157 loss)
I1018 09:07:14.448505 11069 solver.cpp:571] Iteration 2480, lr = 0.001
I1018 09:07:22.026104 11069 solver.cpp:242] Iteration 2500, loss = 0.817559
I1018 09:07:22.026129 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.25139 (* 1 = 0.25139 loss)
I1018 09:07:22.026134 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.56617 (* 1 = 0.56617 loss)
I1018 09:07:22.026137 11069 solver.cpp:571] Iteration 2500, lr = 0.001
I1018 09:07:29.591809 11069 solver.cpp:242] Iteration 2520, loss = 0.381374
I1018 09:07:29.591835 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105583 (* 1 = 0.105583 loss)
I1018 09:07:29.591840 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.275791 (* 1 = 0.275791 loss)
I1018 09:07:29.591843 11069 solver.cpp:571] Iteration 2520, lr = 0.001
I1018 09:07:37.119242 11069 solver.cpp:242] Iteration 2540, loss = 0.336446
I1018 09:07:37.119267 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142997 (* 1 = 0.142997 loss)
I1018 09:07:37.119271 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.19345 (* 1 = 0.19345 loss)
I1018 09:07:37.119277 11069 solver.cpp:571] Iteration 2540, lr = 0.001
I1018 09:07:44.635196 11069 solver.cpp:242] Iteration 2560, loss = 0.604948
I1018 09:07:44.635221 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13839 (* 1 = 0.13839 loss)
I1018 09:07:44.635226 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.466558 (* 1 = 0.466558 loss)
I1018 09:07:44.635229 11069 solver.cpp:571] Iteration 2560, lr = 0.001
I1018 09:07:52.258671 11069 solver.cpp:242] Iteration 2580, loss = 0.662217
I1018 09:07:52.258697 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240495 (* 1 = 0.240495 loss)
I1018 09:07:52.258702 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.421722 (* 1 = 0.421722 loss)
I1018 09:07:52.258705 11069 solver.cpp:571] Iteration 2580, lr = 0.001
speed: 0.376s / iter
I1018 09:07:59.745173 11069 solver.cpp:242] Iteration 2600, loss = 1.46992
I1018 09:07:59.745198 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.54967 (* 1 = 0.54967 loss)
I1018 09:07:59.745203 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.920252 (* 1 = 0.920252 loss)
I1018 09:07:59.745208 11069 solver.cpp:571] Iteration 2600, lr = 0.001
I1018 09:08:07.337462 11069 solver.cpp:242] Iteration 2620, loss = 0.254384
I1018 09:08:07.337486 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0336168 (* 1 = 0.0336168 loss)
I1018 09:08:07.337491 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.220768 (* 1 = 0.220768 loss)
I1018 09:08:07.337496 11069 solver.cpp:571] Iteration 2620, lr = 0.001
I1018 09:08:14.868724 11069 solver.cpp:242] Iteration 2640, loss = 0.403764
I1018 09:08:14.868749 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.089817 (* 1 = 0.089817 loss)
I1018 09:08:14.868754 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.313947 (* 1 = 0.313947 loss)
I1018 09:08:14.868758 11069 solver.cpp:571] Iteration 2640, lr = 0.001
I1018 09:08:22.345568 11069 solver.cpp:242] Iteration 2660, loss = 1.86284
I1018 09:08:22.345593 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.550279 (* 1 = 0.550279 loss)
I1018 09:08:22.345597 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.31256 (* 1 = 1.31256 loss)
I1018 09:08:22.345602 11069 solver.cpp:571] Iteration 2660, lr = 0.001
I1018 09:08:29.913645 11069 solver.cpp:242] Iteration 2680, loss = 0.522631
I1018 09:08:29.913669 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128149 (* 1 = 0.128149 loss)
I1018 09:08:29.913673 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.394482 (* 1 = 0.394482 loss)
I1018 09:08:29.913678 11069 solver.cpp:571] Iteration 2680, lr = 0.001
I1018 09:08:37.404713 11069 solver.cpp:242] Iteration 2700, loss = 0.455929
I1018 09:08:37.404738 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11944 (* 1 = 0.11944 loss)
I1018 09:08:37.404743 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.336489 (* 1 = 0.336489 loss)
I1018 09:08:37.404747 11069 solver.cpp:571] Iteration 2700, lr = 0.001
I1018 09:08:44.887464 11069 solver.cpp:242] Iteration 2720, loss = 1.41438
I1018 09:08:44.887488 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.577303 (* 1 = 0.577303 loss)
I1018 09:08:44.887493 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.837079 (* 1 = 0.837079 loss)
I1018 09:08:44.887497 11069 solver.cpp:571] Iteration 2720, lr = 0.001
I1018 09:08:52.406431 11069 solver.cpp:242] Iteration 2740, loss = 0.349702
I1018 09:08:52.406457 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0728125 (* 1 = 0.0728125 loss)
I1018 09:08:52.406461 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27689 (* 1 = 0.27689 loss)
I1018 09:08:52.406466 11069 solver.cpp:571] Iteration 2740, lr = 0.001
I1018 09:08:59.885701 11069 solver.cpp:242] Iteration 2760, loss = 0.48443
I1018 09:08:59.885726 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0712699 (* 1 = 0.0712699 loss)
I1018 09:08:59.885730 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.41316 (* 1 = 0.41316 loss)
I1018 09:08:59.885735 11069 solver.cpp:571] Iteration 2760, lr = 0.001
I1018 09:09:07.491822 11069 solver.cpp:242] Iteration 2780, loss = 0.333856
I1018 09:09:07.491847 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0650965 (* 1 = 0.0650965 loss)
I1018 09:09:07.491852 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.26876 (* 1 = 0.26876 loss)
I1018 09:09:07.491855 11069 solver.cpp:571] Iteration 2780, lr = 0.001
speed: 0.376s / iter
I1018 09:09:15.002938 11069 solver.cpp:242] Iteration 2800, loss = 0.421542
I1018 09:09:15.002964 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0795195 (* 1 = 0.0795195 loss)
I1018 09:09:15.002969 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342022 (* 1 = 0.342022 loss)
I1018 09:09:15.002972 11069 solver.cpp:571] Iteration 2800, lr = 0.001
I1018 09:09:22.557644 11069 solver.cpp:242] Iteration 2820, loss = 0.741152
I1018 09:09:22.557669 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244656 (* 1 = 0.244656 loss)
I1018 09:09:22.557673 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.496496 (* 1 = 0.496496 loss)
I1018 09:09:22.557677 11069 solver.cpp:571] Iteration 2820, lr = 0.001
I1018 09:09:30.057418 11069 solver.cpp:242] Iteration 2840, loss = 0.193521
I1018 09:09:30.057441 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0280663 (* 1 = 0.0280663 loss)
I1018 09:09:30.057446 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165455 (* 1 = 0.165455 loss)
I1018 09:09:30.057451 11069 solver.cpp:571] Iteration 2840, lr = 0.001
I1018 09:09:37.631145 11069 solver.cpp:242] Iteration 2860, loss = 0.395719
I1018 09:09:37.631168 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143973 (* 1 = 0.143973 loss)
I1018 09:09:37.631173 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.251747 (* 1 = 0.251747 loss)
I1018 09:09:37.631177 11069 solver.cpp:571] Iteration 2860, lr = 0.001
I1018 09:09:45.150414 11069 solver.cpp:242] Iteration 2880, loss = 0.619392
I1018 09:09:45.150439 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120693 (* 1 = 0.120693 loss)
I1018 09:09:45.150444 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.498699 (* 1 = 0.498699 loss)
I1018 09:09:45.150449 11069 solver.cpp:571] Iteration 2880, lr = 0.001
I1018 09:09:52.677531 11069 solver.cpp:242] Iteration 2900, loss = 0.346954
I1018 09:09:52.677556 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0666871 (* 1 = 0.0666871 loss)
I1018 09:09:52.677561 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280267 (* 1 = 0.280267 loss)
I1018 09:09:52.677564 11069 solver.cpp:571] Iteration 2900, lr = 0.001
I1018 09:10:00.300542 11069 solver.cpp:242] Iteration 2920, loss = 0.495832
I1018 09:10:00.300567 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.154568 (* 1 = 0.154568 loss)
I1018 09:10:00.300572 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.341264 (* 1 = 0.341264 loss)
I1018 09:10:00.300576 11069 solver.cpp:571] Iteration 2920, lr = 0.001
I1018 09:10:07.804256 11069 solver.cpp:242] Iteration 2940, loss = 0.586379
I1018 09:10:07.804281 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100017 (* 1 = 0.100017 loss)
I1018 09:10:07.804286 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.486362 (* 1 = 0.486362 loss)
I1018 09:10:07.804291 11069 solver.cpp:571] Iteration 2940, lr = 0.001
I1018 09:10:15.294821 11069 solver.cpp:242] Iteration 2960, loss = 0.549809
I1018 09:10:15.294845 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.131535 (* 1 = 0.131535 loss)
I1018 09:10:15.294849 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.418275 (* 1 = 0.418275 loss)
I1018 09:10:15.294854 11069 solver.cpp:571] Iteration 2960, lr = 0.001
I1018 09:10:22.702734 11069 solver.cpp:242] Iteration 2980, loss = 0.629854
I1018 09:10:22.702759 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170011 (* 1 = 0.170011 loss)
I1018 09:10:22.702764 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.459843 (* 1 = 0.459843 loss)
I1018 09:10:22.702767 11069 solver.cpp:571] Iteration 2980, lr = 0.001
speed: 0.376s / iter
I1018 09:10:30.274072 11069 solver.cpp:242] Iteration 3000, loss = 1.61849
I1018 09:10:30.274096 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.588198 (* 1 = 0.588198 loss)
I1018 09:10:30.274101 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.03029 (* 1 = 1.03029 loss)
I1018 09:10:30.274106 11069 solver.cpp:571] Iteration 3000, lr = 0.001
I1018 09:10:37.730751 11069 solver.cpp:242] Iteration 3020, loss = 1.26393
I1018 09:10:37.730774 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.433908 (* 1 = 0.433908 loss)
I1018 09:10:37.730779 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.830025 (* 1 = 0.830025 loss)
I1018 09:10:37.730783 11069 solver.cpp:571] Iteration 3020, lr = 0.001
I1018 09:10:45.295411 11069 solver.cpp:242] Iteration 3040, loss = 1.68695
I1018 09:10:45.295435 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.830945 (* 1 = 0.830945 loss)
I1018 09:10:45.295440 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.856001 (* 1 = 0.856001 loss)
I1018 09:10:45.295444 11069 solver.cpp:571] Iteration 3040, lr = 0.001
I1018 09:10:52.872064 11069 solver.cpp:242] Iteration 3060, loss = 0.316038
I1018 09:10:52.872088 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0801985 (* 1 = 0.0801985 loss)
I1018 09:10:52.872093 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.235839 (* 1 = 0.235839 loss)
I1018 09:10:52.872098 11069 solver.cpp:571] Iteration 3060, lr = 0.001
I1018 09:11:00.317067 11069 solver.cpp:242] Iteration 3080, loss = 0.802819
I1018 09:11:00.317092 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.273647 (* 1 = 0.273647 loss)
I1018 09:11:00.317096 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.529172 (* 1 = 0.529172 loss)
I1018 09:11:00.317101 11069 solver.cpp:571] Iteration 3080, lr = 0.001
I1018 09:11:07.788022 11069 solver.cpp:242] Iteration 3100, loss = 0.389856
I1018 09:11:07.788045 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.111601 (* 1 = 0.111601 loss)
I1018 09:11:07.788050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.278255 (* 1 = 0.278255 loss)
I1018 09:11:07.788054 11069 solver.cpp:571] Iteration 3100, lr = 0.001
I1018 09:11:15.281659 11069 solver.cpp:242] Iteration 3120, loss = 0.573077
I1018 09:11:15.281684 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.160388 (* 1 = 0.160388 loss)
I1018 09:11:15.281688 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.412689 (* 1 = 0.412689 loss)
I1018 09:11:15.281692 11069 solver.cpp:571] Iteration 3120, lr = 0.001
I1018 09:11:22.812078 11069 solver.cpp:242] Iteration 3140, loss = 0.321462
I1018 09:11:22.812103 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0847607 (* 1 = 0.0847607 loss)
I1018 09:11:22.812108 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.236701 (* 1 = 0.236701 loss)
I1018 09:11:22.812113 11069 solver.cpp:571] Iteration 3140, lr = 0.001
I1018 09:11:30.339406 11069 solver.cpp:242] Iteration 3160, loss = 2.54307
I1018 09:11:30.339431 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.898356 (* 1 = 0.898356 loss)
I1018 09:11:30.339434 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.64471 (* 1 = 1.64471 loss)
I1018 09:11:30.339438 11069 solver.cpp:571] Iteration 3160, lr = 0.001
I1018 09:11:37.825578 11069 solver.cpp:242] Iteration 3180, loss = 0.28927
I1018 09:11:37.825603 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0750061 (* 1 = 0.0750061 loss)
I1018 09:11:37.825608 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.214264 (* 1 = 0.214264 loss)
I1018 09:11:37.825611 11069 solver.cpp:571] Iteration 3180, lr = 0.001
speed: 0.376s / iter
I1018 09:11:45.337929 11069 solver.cpp:242] Iteration 3200, loss = 0.774275
I1018 09:11:45.337954 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.138823 (* 1 = 0.138823 loss)
I1018 09:11:45.337959 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.635452 (* 1 = 0.635452 loss)
I1018 09:11:45.337963 11069 solver.cpp:571] Iteration 3200, lr = 0.001
I1018 09:11:52.816512 11069 solver.cpp:242] Iteration 3220, loss = 0.866821
I1018 09:11:52.816537 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.196701 (* 1 = 0.196701 loss)
I1018 09:11:52.816541 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.670121 (* 1 = 0.670121 loss)
I1018 09:11:52.816545 11069 solver.cpp:571] Iteration 3220, lr = 0.001
I1018 09:12:00.288332 11069 solver.cpp:242] Iteration 3240, loss = 0.220348
I1018 09:12:00.288357 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0568888 (* 1 = 0.0568888 loss)
I1018 09:12:00.288362 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.163459 (* 1 = 0.163459 loss)
I1018 09:12:00.288365 11069 solver.cpp:571] Iteration 3240, lr = 0.001
I1018 09:12:07.855450 11069 solver.cpp:242] Iteration 3260, loss = 0.428545
I1018 09:12:07.855474 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.102348 (* 1 = 0.102348 loss)
I1018 09:12:07.855479 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.326197 (* 1 = 0.326197 loss)
I1018 09:12:07.855484 11069 solver.cpp:571] Iteration 3260, lr = 0.001
I1018 09:12:15.463729 11069 solver.cpp:242] Iteration 3280, loss = 0.31705
I1018 09:12:15.463755 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0883598 (* 1 = 0.0883598 loss)
I1018 09:12:15.463760 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.228691 (* 1 = 0.228691 loss)
I1018 09:12:15.463764 11069 solver.cpp:571] Iteration 3280, lr = 0.001
I1018 09:12:22.927894 11069 solver.cpp:242] Iteration 3300, loss = 0.360626
I1018 09:12:22.927920 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0453167 (* 1 = 0.0453167 loss)
I1018 09:12:22.927925 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.315309 (* 1 = 0.315309 loss)
I1018 09:12:22.927929 11069 solver.cpp:571] Iteration 3300, lr = 0.001
I1018 09:12:30.455940 11069 solver.cpp:242] Iteration 3320, loss = 0.156302
I1018 09:12:30.455965 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0439454 (* 1 = 0.0439454 loss)
I1018 09:12:30.455970 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.112356 (* 1 = 0.112356 loss)
I1018 09:12:30.455974 11069 solver.cpp:571] Iteration 3320, lr = 0.001
I1018 09:12:37.876302 11069 solver.cpp:242] Iteration 3340, loss = 0.227683
I1018 09:12:37.876325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0569253 (* 1 = 0.0569253 loss)
I1018 09:12:37.876330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.170758 (* 1 = 0.170758 loss)
I1018 09:12:37.876334 11069 solver.cpp:571] Iteration 3340, lr = 0.001
I1018 09:12:45.428788 11069 solver.cpp:242] Iteration 3360, loss = 1.3614
I1018 09:12:45.428813 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.615079 (* 1 = 0.615079 loss)
I1018 09:12:45.428817 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.746318 (* 1 = 0.746318 loss)
I1018 09:12:45.428822 11069 solver.cpp:571] Iteration 3360, lr = 0.001
I1018 09:12:52.991539 11069 solver.cpp:242] Iteration 3380, loss = 0.928622
I1018 09:12:52.991562 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.295629 (* 1 = 0.295629 loss)
I1018 09:12:52.991567 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.632993 (* 1 = 0.632993 loss)
I1018 09:12:52.991571 11069 solver.cpp:571] Iteration 3380, lr = 0.001
speed: 0.376s / iter
I1018 09:13:00.488299 11069 solver.cpp:242] Iteration 3400, loss = 0.240067
I1018 09:13:00.488324 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.044923 (* 1 = 0.044923 loss)
I1018 09:13:00.488328 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195144 (* 1 = 0.195144 loss)
I1018 09:13:00.488332 11069 solver.cpp:571] Iteration 3400, lr = 0.001
I1018 09:13:08.030838 11069 solver.cpp:242] Iteration 3420, loss = 0.362389
I1018 09:13:08.030863 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0689125 (* 1 = 0.0689125 loss)
I1018 09:13:08.030867 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.293476 (* 1 = 0.293476 loss)
I1018 09:13:08.030871 11069 solver.cpp:571] Iteration 3420, lr = 0.001
I1018 09:13:15.566200 11069 solver.cpp:242] Iteration 3440, loss = 0.824642
I1018 09:13:15.566226 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.326418 (* 1 = 0.326418 loss)
I1018 09:13:15.566231 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.498224 (* 1 = 0.498224 loss)
I1018 09:13:15.566236 11069 solver.cpp:571] Iteration 3440, lr = 0.001
I1018 09:13:23.046057 11069 solver.cpp:242] Iteration 3460, loss = 0.586747
I1018 09:13:23.046082 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.233936 (* 1 = 0.233936 loss)
I1018 09:13:23.046087 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.352811 (* 1 = 0.352811 loss)
I1018 09:13:23.046090 11069 solver.cpp:571] Iteration 3460, lr = 0.001
I1018 09:13:30.572451 11069 solver.cpp:242] Iteration 3480, loss = 1.25399
I1018 09:13:30.572475 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.433861 (* 1 = 0.433861 loss)
I1018 09:13:30.572480 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.820128 (* 1 = 0.820128 loss)
I1018 09:13:30.572484 11069 solver.cpp:571] Iteration 3480, lr = 0.001
I1018 09:13:38.143390 11069 solver.cpp:242] Iteration 3500, loss = 0.575267
I1018 09:13:38.143414 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0884613 (* 1 = 0.0884613 loss)
I1018 09:13:38.143419 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.486805 (* 1 = 0.486805 loss)
I1018 09:13:38.143424 11069 solver.cpp:571] Iteration 3500, lr = 0.001
I1018 09:13:45.676151 11069 solver.cpp:242] Iteration 3520, loss = 0.415168
I1018 09:13:45.676175 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0743064 (* 1 = 0.0743064 loss)
I1018 09:13:45.676180 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.340862 (* 1 = 0.340862 loss)
I1018 09:13:45.676184 11069 solver.cpp:571] Iteration 3520, lr = 0.001
I1018 09:13:53.169759 11069 solver.cpp:242] Iteration 3540, loss = 1.03334
I1018 09:13:53.169782 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.359974 (* 1 = 0.359974 loss)
I1018 09:13:53.169787 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.673363 (* 1 = 0.673363 loss)
I1018 09:13:53.169791 11069 solver.cpp:571] Iteration 3540, lr = 0.001
I1018 09:14:00.699545 11069 solver.cpp:242] Iteration 3560, loss = 0.897447
I1018 09:14:00.699569 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.336063 (* 1 = 0.336063 loss)
I1018 09:14:00.699574 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.561384 (* 1 = 0.561384 loss)
I1018 09:14:00.699579 11069 solver.cpp:571] Iteration 3560, lr = 0.001
I1018 09:14:08.402518 11069 solver.cpp:242] Iteration 3580, loss = 0.546709
I1018 09:14:08.402542 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104199 (* 1 = 0.104199 loss)
I1018 09:14:08.402546 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.44251 (* 1 = 0.44251 loss)
I1018 09:14:08.402551 11069 solver.cpp:571] Iteration 3580, lr = 0.001
speed: 0.376s / iter
I1018 09:14:15.857635 11069 solver.cpp:242] Iteration 3600, loss = 0.834916
I1018 09:14:15.857661 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.232767 (* 1 = 0.232767 loss)
I1018 09:14:15.857666 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.602149 (* 1 = 0.602149 loss)
I1018 09:14:15.857669 11069 solver.cpp:571] Iteration 3600, lr = 0.001
I1018 09:14:23.410434 11069 solver.cpp:242] Iteration 3620, loss = 0.65714
I1018 09:14:23.410457 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137325 (* 1 = 0.137325 loss)
I1018 09:14:23.410461 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.519815 (* 1 = 0.519815 loss)
I1018 09:14:23.410465 11069 solver.cpp:571] Iteration 3620, lr = 0.001
I1018 09:14:30.867959 11069 solver.cpp:242] Iteration 3640, loss = 2.03081
I1018 09:14:30.867982 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.508391 (* 1 = 0.508391 loss)
I1018 09:14:30.867987 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.52242 (* 1 = 1.52242 loss)
I1018 09:14:30.867991 11069 solver.cpp:571] Iteration 3640, lr = 0.001
I1018 09:14:38.379904 11069 solver.cpp:242] Iteration 3660, loss = 0.64101
I1018 09:14:38.379927 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.20433 (* 1 = 0.20433 loss)
I1018 09:14:38.379932 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.43668 (* 1 = 0.43668 loss)
I1018 09:14:38.379936 11069 solver.cpp:571] Iteration 3660, lr = 0.001
I1018 09:14:45.864668 11069 solver.cpp:242] Iteration 3680, loss = 0.396881
I1018 09:14:45.864693 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108391 (* 1 = 0.108391 loss)
I1018 09:14:45.864697 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.28849 (* 1 = 0.28849 loss)
I1018 09:14:45.864701 11069 solver.cpp:571] Iteration 3680, lr = 0.001
I1018 09:14:53.390262 11069 solver.cpp:242] Iteration 3700, loss = 0.791332
I1018 09:14:53.390286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.213092 (* 1 = 0.213092 loss)
I1018 09:14:53.390291 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.57824 (* 1 = 0.57824 loss)
I1018 09:14:53.390295 11069 solver.cpp:571] Iteration 3700, lr = 0.001
I1018 09:15:00.967489 11069 solver.cpp:242] Iteration 3720, loss = 0.429822
I1018 09:15:00.967514 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.145003 (* 1 = 0.145003 loss)
I1018 09:15:00.967517 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.28482 (* 1 = 0.28482 loss)
I1018 09:15:00.967521 11069 solver.cpp:571] Iteration 3720, lr = 0.001
I1018 09:15:08.448240 11069 solver.cpp:242] Iteration 3740, loss = 0.359297
I1018 09:15:08.448263 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.121306 (* 1 = 0.121306 loss)
I1018 09:15:08.448268 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.237991 (* 1 = 0.237991 loss)
I1018 09:15:08.448272 11069 solver.cpp:571] Iteration 3740, lr = 0.001
I1018 09:15:15.962100 11069 solver.cpp:242] Iteration 3760, loss = 0.485841
I1018 09:15:15.962123 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.169215 (* 1 = 0.169215 loss)
I1018 09:15:15.962128 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.316625 (* 1 = 0.316625 loss)
I1018 09:15:15.962132 11069 solver.cpp:571] Iteration 3760, lr = 0.001
I1018 09:15:23.481256 11069 solver.cpp:242] Iteration 3780, loss = 0.921619
I1018 09:15:23.481279 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.273578 (* 1 = 0.273578 loss)
I1018 09:15:23.481284 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.64804 (* 1 = 0.64804 loss)
I1018 09:15:23.481288 11069 solver.cpp:571] Iteration 3780, lr = 0.001
speed: 0.376s / iter
I1018 09:15:30.939718 11069 solver.cpp:242] Iteration 3800, loss = 0.183906
I1018 09:15:30.939743 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0460826 (* 1 = 0.0460826 loss)
I1018 09:15:30.939749 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137823 (* 1 = 0.137823 loss)
I1018 09:15:30.939752 11069 solver.cpp:571] Iteration 3800, lr = 0.001
I1018 09:15:38.452122 11069 solver.cpp:242] Iteration 3820, loss = 0.595865
I1018 09:15:38.452147 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142197 (* 1 = 0.142197 loss)
I1018 09:15:38.452152 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.453668 (* 1 = 0.453668 loss)
I1018 09:15:38.452157 11069 solver.cpp:571] Iteration 3820, lr = 0.001
I1018 09:15:45.971027 11069 solver.cpp:242] Iteration 3840, loss = 0.570499
I1018 09:15:45.971052 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.15296 (* 1 = 0.15296 loss)
I1018 09:15:45.971057 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.417539 (* 1 = 0.417539 loss)
I1018 09:15:45.971061 11069 solver.cpp:571] Iteration 3840, lr = 0.001
I1018 09:15:53.466552 11069 solver.cpp:242] Iteration 3860, loss = 0.532559
I1018 09:15:53.466575 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200091 (* 1 = 0.200091 loss)
I1018 09:15:53.466580 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.332468 (* 1 = 0.332468 loss)
I1018 09:15:53.466584 11069 solver.cpp:571] Iteration 3860, lr = 0.001
I1018 09:16:01.038708 11069 solver.cpp:242] Iteration 3880, loss = 1.50125
I1018 09:16:01.038733 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.533771 (* 1 = 0.533771 loss)
I1018 09:16:01.038738 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.967475 (* 1 = 0.967475 loss)
I1018 09:16:01.038743 11069 solver.cpp:571] Iteration 3880, lr = 0.001
I1018 09:16:08.530776 11069 solver.cpp:242] Iteration 3900, loss = 1.37634
I1018 09:16:08.530802 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.410217 (* 1 = 0.410217 loss)
I1018 09:16:08.530805 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.966127 (* 1 = 0.966127 loss)
I1018 09:16:08.530809 11069 solver.cpp:571] Iteration 3900, lr = 0.001
I1018 09:16:16.045735 11069 solver.cpp:242] Iteration 3920, loss = 0.269182
I1018 09:16:16.045760 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0407724 (* 1 = 0.0407724 loss)
I1018 09:16:16.045764 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22841 (* 1 = 0.22841 loss)
I1018 09:16:16.045769 11069 solver.cpp:571] Iteration 3920, lr = 0.001
I1018 09:16:23.565059 11069 solver.cpp:242] Iteration 3940, loss = 0.553473
I1018 09:16:23.565085 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.189719 (* 1 = 0.189719 loss)
I1018 09:16:23.565089 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.363753 (* 1 = 0.363753 loss)
I1018 09:16:23.565093 11069 solver.cpp:571] Iteration 3940, lr = 0.001
I1018 09:16:31.170008 11069 solver.cpp:242] Iteration 3960, loss = 0.396676
I1018 09:16:31.170033 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11072 (* 1 = 0.11072 loss)
I1018 09:16:31.170038 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.285955 (* 1 = 0.285955 loss)
I1018 09:16:31.170042 11069 solver.cpp:571] Iteration 3960, lr = 0.001
I1018 09:16:38.743249 11069 solver.cpp:242] Iteration 3980, loss = 1.02133
I1018 09:16:38.743273 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.391274 (* 1 = 0.391274 loss)
I1018 09:16:38.743278 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.630059 (* 1 = 0.630059 loss)
I1018 09:16:38.743283 11069 solver.cpp:571] Iteration 3980, lr = 0.001
speed: 0.376s / iter
I1018 09:16:46.304349 11069 solver.cpp:242] Iteration 4000, loss = 0.271229
I1018 09:16:46.304375 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0759714 (* 1 = 0.0759714 loss)
I1018 09:16:46.304380 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195258 (* 1 = 0.195258 loss)
I1018 09:16:46.304384 11069 solver.cpp:571] Iteration 4000, lr = 0.001
I1018 09:16:53.867740 11069 solver.cpp:242] Iteration 4020, loss = 0.709748
I1018 09:16:53.867764 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153287 (* 1 = 0.153287 loss)
I1018 09:16:53.867769 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.556461 (* 1 = 0.556461 loss)
I1018 09:16:53.867774 11069 solver.cpp:571] Iteration 4020, lr = 0.001
I1018 09:17:01.379851 11069 solver.cpp:242] Iteration 4040, loss = 0.712261
I1018 09:17:01.379874 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205897 (* 1 = 0.205897 loss)
I1018 09:17:01.379879 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.506364 (* 1 = 0.506364 loss)
I1018 09:17:01.379884 11069 solver.cpp:571] Iteration 4040, lr = 0.001
I1018 09:17:08.863032 11069 solver.cpp:242] Iteration 4060, loss = 0.682915
I1018 09:17:08.863056 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128191 (* 1 = 0.128191 loss)
I1018 09:17:08.863061 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.554724 (* 1 = 0.554724 loss)
I1018 09:17:08.863065 11069 solver.cpp:571] Iteration 4060, lr = 0.001
I1018 09:17:16.303627 11069 solver.cpp:242] Iteration 4080, loss = 0.55256
I1018 09:17:16.303653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200949 (* 1 = 0.200949 loss)
I1018 09:17:16.303658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35161 (* 1 = 0.35161 loss)
I1018 09:17:16.303661 11069 solver.cpp:571] Iteration 4080, lr = 0.001
I1018 09:17:23.836388 11069 solver.cpp:242] Iteration 4100, loss = 0.321284
I1018 09:17:23.836413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0519411 (* 1 = 0.0519411 loss)
I1018 09:17:23.836417 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269343 (* 1 = 0.269343 loss)
I1018 09:17:23.836421 11069 solver.cpp:571] Iteration 4100, lr = 0.001
I1018 09:17:31.374358 11069 solver.cpp:242] Iteration 4120, loss = 0.634723
I1018 09:17:31.374383 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158818 (* 1 = 0.158818 loss)
I1018 09:17:31.374387 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.475905 (* 1 = 0.475905 loss)
I1018 09:17:31.374392 11069 solver.cpp:571] Iteration 4120, lr = 0.001
I1018 09:17:38.867390 11069 solver.cpp:242] Iteration 4140, loss = 0.474594
I1018 09:17:38.867415 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.12095 (* 1 = 0.12095 loss)
I1018 09:17:38.867420 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.353644 (* 1 = 0.353644 loss)
I1018 09:17:38.867424 11069 solver.cpp:571] Iteration 4140, lr = 0.001
I1018 09:17:46.465948 11069 solver.cpp:242] Iteration 4160, loss = 0.373468
I1018 09:17:46.465973 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0673216 (* 1 = 0.0673216 loss)
I1018 09:17:46.465977 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.306146 (* 1 = 0.306146 loss)
I1018 09:17:46.465981 11069 solver.cpp:571] Iteration 4160, lr = 0.001
I1018 09:17:54.058104 11069 solver.cpp:242] Iteration 4180, loss = 1.00153
I1018 09:17:54.058128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.349699 (* 1 = 0.349699 loss)
I1018 09:17:54.058133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.651834 (* 1 = 0.651834 loss)
I1018 09:17:54.058137 11069 solver.cpp:571] Iteration 4180, lr = 0.001
speed: 0.376s / iter
I1018 09:18:01.584851 11069 solver.cpp:242] Iteration 4200, loss = 0.662731
I1018 09:18:01.584872 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206428 (* 1 = 0.206428 loss)
I1018 09:18:01.584877 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.456303 (* 1 = 0.456303 loss)
I1018 09:18:01.584882 11069 solver.cpp:571] Iteration 4200, lr = 0.001
I1018 09:18:09.065049 11069 solver.cpp:242] Iteration 4220, loss = 0.758508
I1018 09:18:09.065075 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.242483 (* 1 = 0.242483 loss)
I1018 09:18:09.065080 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.516024 (* 1 = 0.516024 loss)
I1018 09:18:09.065084 11069 solver.cpp:571] Iteration 4220, lr = 0.001
I1018 09:18:16.556448 11069 solver.cpp:242] Iteration 4240, loss = 1.09971
I1018 09:18:16.556473 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.448501 (* 1 = 0.448501 loss)
I1018 09:18:16.556478 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.651208 (* 1 = 0.651208 loss)
I1018 09:18:16.556481 11069 solver.cpp:571] Iteration 4240, lr = 0.001
I1018 09:18:24.051689 11069 solver.cpp:242] Iteration 4260, loss = 1.13484
I1018 09:18:24.051713 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.311335 (* 1 = 0.311335 loss)
I1018 09:18:24.051718 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.823504 (* 1 = 0.823504 loss)
I1018 09:18:24.051723 11069 solver.cpp:571] Iteration 4260, lr = 0.001
I1018 09:18:31.609089 11069 solver.cpp:242] Iteration 4280, loss = 0.741898
I1018 09:18:31.609113 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.234284 (* 1 = 0.234284 loss)
I1018 09:18:31.609118 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.507614 (* 1 = 0.507614 loss)
I1018 09:18:31.609122 11069 solver.cpp:571] Iteration 4280, lr = 0.001
I1018 09:18:39.015163 11069 solver.cpp:242] Iteration 4300, loss = 0.652512
I1018 09:18:39.015188 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200904 (* 1 = 0.200904 loss)
I1018 09:18:39.015192 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.451608 (* 1 = 0.451608 loss)
I1018 09:18:39.015197 11069 solver.cpp:571] Iteration 4300, lr = 0.001
I1018 09:18:46.460723 11069 solver.cpp:242] Iteration 4320, loss = 0.363877
I1018 09:18:46.460748 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0869471 (* 1 = 0.0869471 loss)
I1018 09:18:46.460753 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27693 (* 1 = 0.27693 loss)
I1018 09:18:46.460757 11069 solver.cpp:571] Iteration 4320, lr = 0.001
I1018 09:18:54.069057 11069 solver.cpp:242] Iteration 4340, loss = 0.316821
I1018 09:18:54.069082 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108552 (* 1 = 0.108552 loss)
I1018 09:18:54.069087 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208269 (* 1 = 0.208269 loss)
I1018 09:18:54.069092 11069 solver.cpp:571] Iteration 4340, lr = 0.001
I1018 09:19:01.602658 11069 solver.cpp:242] Iteration 4360, loss = 0.315588
I1018 09:19:01.602681 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0662291 (* 1 = 0.0662291 loss)
I1018 09:19:01.602686 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249359 (* 1 = 0.249359 loss)
I1018 09:19:01.602691 11069 solver.cpp:571] Iteration 4360, lr = 0.001
I1018 09:19:09.124294 11069 solver.cpp:242] Iteration 4380, loss = 0.261748
I1018 09:19:09.124318 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557905 (* 1 = 0.0557905 loss)
I1018 09:19:09.124323 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205958 (* 1 = 0.205958 loss)
I1018 09:19:09.124328 11069 solver.cpp:571] Iteration 4380, lr = 0.001
speed: 0.376s / iter
I1018 09:19:16.598028 11069 solver.cpp:242] Iteration 4400, loss = 0.338761
I1018 09:19:16.598053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0866235 (* 1 = 0.0866235 loss)
I1018 09:19:16.598058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.252137 (* 1 = 0.252137 loss)
I1018 09:19:16.598063 11069 solver.cpp:571] Iteration 4400, lr = 0.001
I1018 09:19:24.052666 11069 solver.cpp:242] Iteration 4420, loss = 0.800396
I1018 09:19:24.052692 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.234698 (* 1 = 0.234698 loss)
I1018 09:19:24.052696 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.565699 (* 1 = 0.565699 loss)
I1018 09:19:24.052701 11069 solver.cpp:571] Iteration 4420, lr = 0.001
I1018 09:19:31.616698 11069 solver.cpp:242] Iteration 4440, loss = 0.848406
I1018 09:19:31.616724 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.229763 (* 1 = 0.229763 loss)
I1018 09:19:31.616727 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.618643 (* 1 = 0.618643 loss)
I1018 09:19:31.616732 11069 solver.cpp:571] Iteration 4440, lr = 0.001
I1018 09:19:39.164716 11069 solver.cpp:242] Iteration 4460, loss = 1.23475
I1018 09:19:39.164741 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.483473 (* 1 = 0.483473 loss)
I1018 09:19:39.164746 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.751278 (* 1 = 0.751278 loss)
I1018 09:19:39.164749 11069 solver.cpp:571] Iteration 4460, lr = 0.001
I1018 09:19:46.678777 11069 solver.cpp:242] Iteration 4480, loss = 0.344716
I1018 09:19:46.678802 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0803192 (* 1 = 0.0803192 loss)
I1018 09:19:46.678807 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264397 (* 1 = 0.264397 loss)
I1018 09:19:46.678810 11069 solver.cpp:571] Iteration 4480, lr = 0.001
I1018 09:19:54.148690 11069 solver.cpp:242] Iteration 4500, loss = 1.82
I1018 09:19:54.148715 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.961103 (* 1 = 0.961103 loss)
I1018 09:19:54.148720 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.858895 (* 1 = 0.858895 loss)
I1018 09:19:54.148723 11069 solver.cpp:571] Iteration 4500, lr = 0.001
I1018 09:20:01.632593 11069 solver.cpp:242] Iteration 4520, loss = 0.712098
I1018 09:20:01.632614 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.256059 (* 1 = 0.256059 loss)
I1018 09:20:01.632619 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.456039 (* 1 = 0.456039 loss)
I1018 09:20:01.632623 11069 solver.cpp:571] Iteration 4520, lr = 0.001
I1018 09:20:09.209323 11069 solver.cpp:242] Iteration 4540, loss = 0.515096
I1018 09:20:09.209347 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123865 (* 1 = 0.123865 loss)
I1018 09:20:09.209352 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.391231 (* 1 = 0.391231 loss)
I1018 09:20:09.209357 11069 solver.cpp:571] Iteration 4540, lr = 0.001
I1018 09:20:16.730708 11069 solver.cpp:242] Iteration 4560, loss = 0.758772
I1018 09:20:16.730732 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.178516 (* 1 = 0.178516 loss)
I1018 09:20:16.730736 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.580256 (* 1 = 0.580256 loss)
I1018 09:20:16.730741 11069 solver.cpp:571] Iteration 4560, lr = 0.001
I1018 09:20:24.282840 11069 solver.cpp:242] Iteration 4580, loss = 0.2601
I1018 09:20:24.282866 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.063879 (* 1 = 0.063879 loss)
I1018 09:20:24.282869 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.196221 (* 1 = 0.196221 loss)
I1018 09:20:24.282873 11069 solver.cpp:571] Iteration 4580, lr = 0.001
speed: 0.376s / iter
I1018 09:20:31.730829 11069 solver.cpp:242] Iteration 4600, loss = 0.271597
I1018 09:20:31.730854 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0877647 (* 1 = 0.0877647 loss)
I1018 09:20:31.730859 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.183832 (* 1 = 0.183832 loss)
I1018 09:20:31.730862 11069 solver.cpp:571] Iteration 4600, lr = 0.001
I1018 09:20:39.249464 11069 solver.cpp:242] Iteration 4620, loss = 0.606441
I1018 09:20:39.249487 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161903 (* 1 = 0.161903 loss)
I1018 09:20:39.249492 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.444537 (* 1 = 0.444537 loss)
I1018 09:20:39.249496 11069 solver.cpp:571] Iteration 4620, lr = 0.001
I1018 09:20:46.718487 11069 solver.cpp:242] Iteration 4640, loss = 0.821626
I1018 09:20:46.718511 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.287955 (* 1 = 0.287955 loss)
I1018 09:20:46.718516 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.533671 (* 1 = 0.533671 loss)
I1018 09:20:46.718520 11069 solver.cpp:571] Iteration 4640, lr = 0.001
I1018 09:20:54.365690 11069 solver.cpp:242] Iteration 4660, loss = 1.00522
I1018 09:20:54.365725 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.345138 (* 1 = 0.345138 loss)
I1018 09:20:54.365739 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.660087 (* 1 = 0.660087 loss)
I1018 09:20:54.365743 11069 solver.cpp:571] Iteration 4660, lr = 0.001
I1018 09:21:01.889789 11069 solver.cpp:242] Iteration 4680, loss = 0.245592
I1018 09:21:01.889812 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0667892 (* 1 = 0.0667892 loss)
I1018 09:21:01.889816 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178803 (* 1 = 0.178803 loss)
I1018 09:21:01.889820 11069 solver.cpp:571] Iteration 4680, lr = 0.001
I1018 09:21:09.389364 11069 solver.cpp:242] Iteration 4700, loss = 2.10194
I1018 09:21:09.389387 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.09439 (* 1 = 1.09439 loss)
I1018 09:21:09.389392 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.00755 (* 1 = 1.00755 loss)
I1018 09:21:09.389396 11069 solver.cpp:571] Iteration 4700, lr = 0.001
I1018 09:21:16.980665 11069 solver.cpp:242] Iteration 4720, loss = 0.226938
I1018 09:21:16.980690 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0612997 (* 1 = 0.0612997 loss)
I1018 09:21:16.980693 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165638 (* 1 = 0.165638 loss)
I1018 09:21:16.980697 11069 solver.cpp:571] Iteration 4720, lr = 0.001
I1018 09:21:24.527415 11069 solver.cpp:242] Iteration 4740, loss = 0.380674
I1018 09:21:24.527439 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0756041 (* 1 = 0.0756041 loss)
I1018 09:21:24.527443 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.30507 (* 1 = 0.30507 loss)
I1018 09:21:24.527448 11069 solver.cpp:571] Iteration 4740, lr = 0.001
I1018 09:21:32.034379 11069 solver.cpp:242] Iteration 4760, loss = 0.304589
I1018 09:21:32.034404 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0720989 (* 1 = 0.0720989 loss)
I1018 09:21:32.034409 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.23249 (* 1 = 0.23249 loss)
I1018 09:21:32.034413 11069 solver.cpp:571] Iteration 4760, lr = 0.001
I1018 09:21:39.602921 11069 solver.cpp:242] Iteration 4780, loss = 0.478355
I1018 09:21:39.602947 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0907497 (* 1 = 0.0907497 loss)
I1018 09:21:39.602952 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.387605 (* 1 = 0.387605 loss)
I1018 09:21:39.602955 11069 solver.cpp:571] Iteration 4780, lr = 0.001
speed: 0.376s / iter
I1018 09:21:47.079452 11069 solver.cpp:242] Iteration 4800, loss = 0.600482
I1018 09:21:47.079476 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.175414 (* 1 = 0.175414 loss)
I1018 09:21:47.079480 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.425068 (* 1 = 0.425068 loss)
I1018 09:21:47.079484 11069 solver.cpp:571] Iteration 4800, lr = 0.001
I1018 09:21:54.634829 11069 solver.cpp:242] Iteration 4820, loss = 0.42531
I1018 09:21:54.634852 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.109345 (* 1 = 0.109345 loss)
I1018 09:21:54.634857 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.315965 (* 1 = 0.315965 loss)
I1018 09:21:54.634861 11069 solver.cpp:571] Iteration 4820, lr = 0.001
I1018 09:22:02.212025 11069 solver.cpp:242] Iteration 4840, loss = 0.232468
I1018 09:22:02.212049 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0314178 (* 1 = 0.0314178 loss)
I1018 09:22:02.212054 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.20105 (* 1 = 0.20105 loss)
I1018 09:22:02.212059 11069 solver.cpp:571] Iteration 4840, lr = 0.001
I1018 09:22:09.745224 11069 solver.cpp:242] Iteration 4860, loss = 0.703012
I1018 09:22:09.745249 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.209028 (* 1 = 0.209028 loss)
I1018 09:22:09.745254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.493985 (* 1 = 0.493985 loss)
I1018 09:22:09.745257 11069 solver.cpp:571] Iteration 4860, lr = 0.001
I1018 09:22:17.257704 11069 solver.cpp:242] Iteration 4880, loss = 1.14568
I1018 09:22:17.257727 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.353609 (* 1 = 0.353609 loss)
I1018 09:22:17.257732 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.792071 (* 1 = 0.792071 loss)
I1018 09:22:17.257736 11069 solver.cpp:571] Iteration 4880, lr = 0.001
I1018 09:22:24.720494 11069 solver.cpp:242] Iteration 4900, loss = 0.979236
I1018 09:22:24.720518 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.224182 (* 1 = 0.224182 loss)
I1018 09:22:24.720522 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.755054 (* 1 = 0.755054 loss)
I1018 09:22:24.720526 11069 solver.cpp:571] Iteration 4900, lr = 0.001
I1018 09:22:32.365527 11069 solver.cpp:242] Iteration 4920, loss = 0.7833
I1018 09:22:32.365551 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.247955 (* 1 = 0.247955 loss)
I1018 09:22:32.365556 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.535345 (* 1 = 0.535345 loss)
I1018 09:22:32.365561 11069 solver.cpp:571] Iteration 4920, lr = 0.001
I1018 09:22:39.822782 11069 solver.cpp:242] Iteration 4940, loss = 0.237926
I1018 09:22:39.822806 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0499581 (* 1 = 0.0499581 loss)
I1018 09:22:39.822811 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.187968 (* 1 = 0.187968 loss)
I1018 09:22:39.822815 11069 solver.cpp:571] Iteration 4940, lr = 0.001
I1018 09:22:47.362433 11069 solver.cpp:242] Iteration 4960, loss = 0.279652
I1018 09:22:47.362457 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0693583 (* 1 = 0.0693583 loss)
I1018 09:22:47.362462 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.210293 (* 1 = 0.210293 loss)
I1018 09:22:47.362467 11069 solver.cpp:571] Iteration 4960, lr = 0.001
I1018 09:22:54.882361 11069 solver.cpp:242] Iteration 4980, loss = 1.74739
I1018 09:22:54.882385 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.744082 (* 1 = 0.744082 loss)
I1018 09:22:54.882390 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.00331 (* 1 = 1.00331 loss)
I1018 09:22:54.882395 11069 solver.cpp:571] Iteration 4980, lr = 0.001
speed: 0.376s / iter
I1018 09:23:02.415582 11069 solver.cpp:242] Iteration 5000, loss = 0.524434
I1018 09:23:02.415607 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.101639 (* 1 = 0.101639 loss)
I1018 09:23:02.415612 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.422795 (* 1 = 0.422795 loss)
I1018 09:23:02.415616 11069 solver.cpp:571] Iteration 5000, lr = 0.001
I1018 09:23:09.946755 11069 solver.cpp:242] Iteration 5020, loss = 1.45783
I1018 09:23:09.946779 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.54776 (* 1 = 0.54776 loss)
I1018 09:23:09.946784 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.910066 (* 1 = 0.910066 loss)
I1018 09:23:09.946789 11069 solver.cpp:571] Iteration 5020, lr = 0.001
I1018 09:23:17.404695 11069 solver.cpp:242] Iteration 5040, loss = 0.634433
I1018 09:23:17.404721 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.221105 (* 1 = 0.221105 loss)
I1018 09:23:17.404726 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.413328 (* 1 = 0.413328 loss)
I1018 09:23:17.404729 11069 solver.cpp:571] Iteration 5040, lr = 0.001
I1018 09:23:24.946280 11069 solver.cpp:242] Iteration 5060, loss = 1.07443
I1018 09:23:24.946303 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.335095 (* 1 = 0.335095 loss)
I1018 09:23:24.946308 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.739338 (* 1 = 0.739338 loss)
I1018 09:23:24.946312 11069 solver.cpp:571] Iteration 5060, lr = 0.001
I1018 09:23:32.472494 11069 solver.cpp:242] Iteration 5080, loss = 0.412539
I1018 09:23:32.472518 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122939 (* 1 = 0.122939 loss)
I1018 09:23:32.472523 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.2896 (* 1 = 0.2896 loss)
I1018 09:23:32.472527 11069 solver.cpp:571] Iteration 5080, lr = 0.001
I1018 09:23:39.962455 11069 solver.cpp:242] Iteration 5100, loss = 0.923345
I1018 09:23:39.962479 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240357 (* 1 = 0.240357 loss)
I1018 09:23:39.962483 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.682988 (* 1 = 0.682988 loss)
I1018 09:23:39.962488 11069 solver.cpp:571] Iteration 5100, lr = 0.001
I1018 09:23:47.369935 11069 solver.cpp:242] Iteration 5120, loss = 0.746731
I1018 09:23:47.369958 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.211727 (* 1 = 0.211727 loss)
I1018 09:23:47.369963 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.535005 (* 1 = 0.535005 loss)
I1018 09:23:47.369967 11069 solver.cpp:571] Iteration 5120, lr = 0.001
I1018 09:23:54.851902 11069 solver.cpp:242] Iteration 5140, loss = 1.08578
I1018 09:23:54.851927 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.295742 (* 1 = 0.295742 loss)
I1018 09:23:54.851930 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.790039 (* 1 = 0.790039 loss)
I1018 09:23:54.851934 11069 solver.cpp:571] Iteration 5140, lr = 0.001
I1018 09:24:02.349578 11069 solver.cpp:242] Iteration 5160, loss = 0.502376
I1018 09:24:02.349603 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0805936 (* 1 = 0.0805936 loss)
I1018 09:24:02.349608 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.421782 (* 1 = 0.421782 loss)
I1018 09:24:02.349612 11069 solver.cpp:571] Iteration 5160, lr = 0.001
I1018 09:24:09.967849 11069 solver.cpp:242] Iteration 5180, loss = 0.466639
I1018 09:24:09.967874 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113195 (* 1 = 0.113195 loss)
I1018 09:24:09.967878 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.353444 (* 1 = 0.353444 loss)
I1018 09:24:09.967882 11069 solver.cpp:571] Iteration 5180, lr = 0.001
speed: 0.376s / iter
I1018 09:24:17.407274 11069 solver.cpp:242] Iteration 5200, loss = 0.659227
I1018 09:24:17.407300 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1454 (* 1 = 0.1454 loss)
I1018 09:24:17.407305 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.513827 (* 1 = 0.513827 loss)
I1018 09:24:17.407310 11069 solver.cpp:571] Iteration 5200, lr = 0.001
I1018 09:24:24.968466 11069 solver.cpp:242] Iteration 5220, loss = 0.811638
I1018 09:24:24.968490 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.394022 (* 1 = 0.394022 loss)
I1018 09:24:24.968495 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.417616 (* 1 = 0.417616 loss)
I1018 09:24:24.968499 11069 solver.cpp:571] Iteration 5220, lr = 0.001
I1018 09:24:32.474655 11069 solver.cpp:242] Iteration 5240, loss = 1.42674
I1018 09:24:32.474679 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.441187 (* 1 = 0.441187 loss)
I1018 09:24:32.474684 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.985554 (* 1 = 0.985554 loss)
I1018 09:24:32.474689 11069 solver.cpp:571] Iteration 5240, lr = 0.001
I1018 09:24:39.892324 11069 solver.cpp:242] Iteration 5260, loss = 0.662019
I1018 09:24:39.892349 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.247708 (* 1 = 0.247708 loss)
I1018 09:24:39.892354 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.414311 (* 1 = 0.414311 loss)
I1018 09:24:39.892359 11069 solver.cpp:571] Iteration 5260, lr = 0.001
I1018 09:24:47.367733 11069 solver.cpp:242] Iteration 5280, loss = 1.6453
I1018 09:24:47.367755 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.805595 (* 1 = 0.805595 loss)
I1018 09:24:47.367760 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.83971 (* 1 = 0.83971 loss)
I1018 09:24:47.367764 11069 solver.cpp:571] Iteration 5280, lr = 0.001
I1018 09:24:54.973418 11069 solver.cpp:242] Iteration 5300, loss = 0.428887
I1018 09:24:54.973443 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.118656 (* 1 = 0.118656 loss)
I1018 09:24:54.973448 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.310231 (* 1 = 0.310231 loss)
I1018 09:24:54.973451 11069 solver.cpp:571] Iteration 5300, lr = 0.001
I1018 09:25:02.378800 11069 solver.cpp:242] Iteration 5320, loss = 0.942945
I1018 09:25:02.378825 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.447088 (* 1 = 0.447088 loss)
I1018 09:25:02.378829 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495857 (* 1 = 0.495857 loss)
I1018 09:25:02.378834 11069 solver.cpp:571] Iteration 5320, lr = 0.001
I1018 09:25:09.813148 11069 solver.cpp:242] Iteration 5340, loss = 0.688808
I1018 09:25:09.813172 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.280966 (* 1 = 0.280966 loss)
I1018 09:25:09.813177 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.407842 (* 1 = 0.407842 loss)
I1018 09:25:09.813181 11069 solver.cpp:571] Iteration 5340, lr = 0.001
I1018 09:25:17.410225 11069 solver.cpp:242] Iteration 5360, loss = 0.586772
I1018 09:25:17.410249 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.157229 (* 1 = 0.157229 loss)
I1018 09:25:17.410254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.429543 (* 1 = 0.429543 loss)
I1018 09:25:17.410259 11069 solver.cpp:571] Iteration 5360, lr = 0.001
I1018 09:25:24.873169 11069 solver.cpp:242] Iteration 5380, loss = 1.25261
I1018 09:25:24.873193 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.381381 (* 1 = 0.381381 loss)
I1018 09:25:24.873198 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.871225 (* 1 = 0.871225 loss)
I1018 09:25:24.873203 11069 solver.cpp:571] Iteration 5380, lr = 0.001
speed: 0.376s / iter
I1018 09:25:32.351546 11069 solver.cpp:242] Iteration 5400, loss = 0.200682
I1018 09:25:32.351569 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0412857 (* 1 = 0.0412857 loss)
I1018 09:25:32.351574 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159396 (* 1 = 0.159396 loss)
I1018 09:25:32.351578 11069 solver.cpp:571] Iteration 5400, lr = 0.001
I1018 09:25:39.992651 11069 solver.cpp:242] Iteration 5420, loss = 0.143246
I1018 09:25:39.992676 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0386817 (* 1 = 0.0386817 loss)
I1018 09:25:39.992681 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.104564 (* 1 = 0.104564 loss)
I1018 09:25:39.992684 11069 solver.cpp:571] Iteration 5420, lr = 0.001
I1018 09:25:47.530102 11069 solver.cpp:242] Iteration 5440, loss = 0.451241
I1018 09:25:47.530127 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0566163 (* 1 = 0.0566163 loss)
I1018 09:25:47.530130 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.394624 (* 1 = 0.394624 loss)
I1018 09:25:47.530134 11069 solver.cpp:571] Iteration 5440, lr = 0.001
I1018 09:25:55.020829 11069 solver.cpp:242] Iteration 5460, loss = 0.432885
I1018 09:25:55.020853 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0940539 (* 1 = 0.0940539 loss)
I1018 09:25:55.020859 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.338832 (* 1 = 0.338832 loss)
I1018 09:25:55.020862 11069 solver.cpp:571] Iteration 5460, lr = 0.001
I1018 09:26:02.589387 11069 solver.cpp:242] Iteration 5480, loss = 1.09474
I1018 09:26:02.589413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.36092 (* 1 = 0.36092 loss)
I1018 09:26:02.589417 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.73382 (* 1 = 0.73382 loss)
I1018 09:26:02.589422 11069 solver.cpp:571] Iteration 5480, lr = 0.001
I1018 09:26:10.103574 11069 solver.cpp:242] Iteration 5500, loss = 0.462022
I1018 09:26:10.103596 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0819791 (* 1 = 0.0819791 loss)
I1018 09:26:10.103600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.380043 (* 1 = 0.380043 loss)
I1018 09:26:10.103605 11069 solver.cpp:571] Iteration 5500, lr = 0.001
I1018 09:26:17.639807 11069 solver.cpp:242] Iteration 5520, loss = 0.731137
I1018 09:26:17.639832 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177438 (* 1 = 0.177438 loss)
I1018 09:26:17.639837 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.553698 (* 1 = 0.553698 loss)
I1018 09:26:17.639840 11069 solver.cpp:571] Iteration 5520, lr = 0.001
I1018 09:26:25.125962 11069 solver.cpp:242] Iteration 5540, loss = 1.55265
I1018 09:26:25.125986 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.601762 (* 1 = 0.601762 loss)
I1018 09:26:25.125990 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.950885 (* 1 = 0.950885 loss)
I1018 09:26:25.125995 11069 solver.cpp:571] Iteration 5540, lr = 0.001
I1018 09:26:32.734151 11069 solver.cpp:242] Iteration 5560, loss = 0.238686
I1018 09:26:32.734175 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0614543 (* 1 = 0.0614543 loss)
I1018 09:26:32.734180 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177231 (* 1 = 0.177231 loss)
I1018 09:26:32.734184 11069 solver.cpp:571] Iteration 5560, lr = 0.001
I1018 09:26:40.211285 11069 solver.cpp:242] Iteration 5580, loss = 0.775779
I1018 09:26:40.211308 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.2348 (* 1 = 0.2348 loss)
I1018 09:26:40.211316 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.540979 (* 1 = 0.540979 loss)
I1018 09:26:40.211320 11069 solver.cpp:571] Iteration 5580, lr = 0.001
speed: 0.376s / iter
I1018 09:26:47.695267 11069 solver.cpp:242] Iteration 5600, loss = 0.998837
I1018 09:26:47.695292 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.381359 (* 1 = 0.381359 loss)
I1018 09:26:47.695297 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.617478 (* 1 = 0.617478 loss)
I1018 09:26:47.695302 11069 solver.cpp:571] Iteration 5600, lr = 0.001
I1018 09:26:55.214395 11069 solver.cpp:242] Iteration 5620, loss = 0.371507
I1018 09:26:55.214419 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147144 (* 1 = 0.147144 loss)
I1018 09:26:55.214423 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224363 (* 1 = 0.224363 loss)
I1018 09:26:55.214427 11069 solver.cpp:571] Iteration 5620, lr = 0.001
I1018 09:27:02.688860 11069 solver.cpp:242] Iteration 5640, loss = 0.305673
I1018 09:27:02.688886 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0665871 (* 1 = 0.0665871 loss)
I1018 09:27:02.688890 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.239086 (* 1 = 0.239086 loss)
I1018 09:27:02.688894 11069 solver.cpp:571] Iteration 5640, lr = 0.001
I1018 09:27:10.258821 11069 solver.cpp:242] Iteration 5660, loss = 0.810206
I1018 09:27:10.258844 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.225281 (* 1 = 0.225281 loss)
I1018 09:27:10.258848 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.584924 (* 1 = 0.584924 loss)
I1018 09:27:10.258852 11069 solver.cpp:571] Iteration 5660, lr = 0.001
I1018 09:27:17.764099 11069 solver.cpp:242] Iteration 5680, loss = 0.355628
I1018 09:27:17.764124 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0901867 (* 1 = 0.0901867 loss)
I1018 09:27:17.764128 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265441 (* 1 = 0.265441 loss)
I1018 09:27:17.764133 11069 solver.cpp:571] Iteration 5680, lr = 0.001
I1018 09:27:25.229979 11069 solver.cpp:242] Iteration 5700, loss = 1.49245
I1018 09:27:25.230002 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.509693 (* 1 = 0.509693 loss)
I1018 09:27:25.230007 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.982753 (* 1 = 0.982753 loss)
I1018 09:27:25.230011 11069 solver.cpp:571] Iteration 5700, lr = 0.001
I1018 09:27:32.756023 11069 solver.cpp:242] Iteration 5720, loss = 0.301666
I1018 09:27:32.756047 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0459065 (* 1 = 0.0459065 loss)
I1018 09:27:32.756052 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.255759 (* 1 = 0.255759 loss)
I1018 09:27:32.756055 11069 solver.cpp:571] Iteration 5720, lr = 0.001
I1018 09:27:40.261106 11069 solver.cpp:242] Iteration 5740, loss = 0.43545
I1018 09:27:40.261128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0948405 (* 1 = 0.0948405 loss)
I1018 09:27:40.261133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.34061 (* 1 = 0.34061 loss)
I1018 09:27:40.261137 11069 solver.cpp:571] Iteration 5740, lr = 0.001
I1018 09:27:47.748963 11069 solver.cpp:242] Iteration 5760, loss = 0.213272
I1018 09:27:47.748987 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0607521 (* 1 = 0.0607521 loss)
I1018 09:27:47.748992 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.15252 (* 1 = 0.15252 loss)
I1018 09:27:47.748996 11069 solver.cpp:571] Iteration 5760, lr = 0.001
I1018 09:27:55.139447 11069 solver.cpp:242] Iteration 5780, loss = 0.236983
I1018 09:27:55.139472 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.056593 (* 1 = 0.056593 loss)
I1018 09:27:55.139477 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18039 (* 1 = 0.18039 loss)
I1018 09:27:55.139480 11069 solver.cpp:571] Iteration 5780, lr = 0.001
speed: 0.376s / iter
I1018 09:28:02.578222 11069 solver.cpp:242] Iteration 5800, loss = 0.278707
I1018 09:28:02.578246 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0321257 (* 1 = 0.0321257 loss)
I1018 09:28:02.578250 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.246582 (* 1 = 0.246582 loss)
I1018 09:28:02.578254 11069 solver.cpp:571] Iteration 5800, lr = 0.001
I1018 09:28:10.102129 11069 solver.cpp:242] Iteration 5820, loss = 0.964786
I1018 09:28:10.102152 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.215754 (* 1 = 0.215754 loss)
I1018 09:28:10.102157 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.749032 (* 1 = 0.749032 loss)
I1018 09:28:10.102161 11069 solver.cpp:571] Iteration 5820, lr = 0.001
I1018 09:28:17.627761 11069 solver.cpp:242] Iteration 5840, loss = 0.275456
I1018 09:28:17.627787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0764403 (* 1 = 0.0764403 loss)
I1018 09:28:17.627791 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.199015 (* 1 = 0.199015 loss)
I1018 09:28:17.627795 11069 solver.cpp:571] Iteration 5840, lr = 0.001
I1018 09:28:25.095289 11069 solver.cpp:242] Iteration 5860, loss = 0.310094
I1018 09:28:25.095317 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0739508 (* 1 = 0.0739508 loss)
I1018 09:28:25.095322 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.236143 (* 1 = 0.236143 loss)
I1018 09:28:25.095326 11069 solver.cpp:571] Iteration 5860, lr = 0.001
I1018 09:28:32.626418 11069 solver.cpp:242] Iteration 5880, loss = 0.820449
I1018 09:28:32.626443 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158971 (* 1 = 0.158971 loss)
I1018 09:28:32.626447 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.661478 (* 1 = 0.661478 loss)
I1018 09:28:32.626451 11069 solver.cpp:571] Iteration 5880, lr = 0.001
I1018 09:28:40.124028 11069 solver.cpp:242] Iteration 5900, loss = 0.371125
I1018 09:28:40.124052 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1052 (* 1 = 0.1052 loss)
I1018 09:28:40.124056 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265925 (* 1 = 0.265925 loss)
I1018 09:28:40.124060 11069 solver.cpp:571] Iteration 5900, lr = 0.001
I1018 09:28:47.740603 11069 solver.cpp:242] Iteration 5920, loss = 1.54299
I1018 09:28:47.740628 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.721596 (* 1 = 0.721596 loss)
I1018 09:28:47.740633 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.821392 (* 1 = 0.821392 loss)
I1018 09:28:47.740638 11069 solver.cpp:571] Iteration 5920, lr = 0.001
I1018 09:28:55.241220 11069 solver.cpp:242] Iteration 5940, loss = 2.09456
I1018 09:28:55.241245 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.08351 (* 1 = 1.08351 loss)
I1018 09:28:55.241250 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.01105 (* 1 = 1.01105 loss)
I1018 09:28:55.241252 11069 solver.cpp:571] Iteration 5940, lr = 0.001
I1018 09:29:02.775818 11069 solver.cpp:242] Iteration 5960, loss = 0.478509
I1018 09:29:02.775842 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135576 (* 1 = 0.135576 loss)
I1018 09:29:02.775846 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342933 (* 1 = 0.342933 loss)
I1018 09:29:02.775851 11069 solver.cpp:571] Iteration 5960, lr = 0.001
I1018 09:29:10.334749 11069 solver.cpp:242] Iteration 5980, loss = 0.199216
I1018 09:29:10.334772 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0381156 (* 1 = 0.0381156 loss)
I1018 09:29:10.334777 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.1611 (* 1 = 0.1611 loss)
I1018 09:29:10.334781 11069 solver.cpp:571] Iteration 5980, lr = 0.001
speed: 0.376s / iter
I1018 09:29:17.875741 11069 solver.cpp:242] Iteration 6000, loss = 0.47298
I1018 09:29:17.875766 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.145451 (* 1 = 0.145451 loss)
I1018 09:29:17.875771 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.32753 (* 1 = 0.32753 loss)
I1018 09:29:17.875774 11069 solver.cpp:571] Iteration 6000, lr = 0.001
I1018 09:29:25.434432 11069 solver.cpp:242] Iteration 6020, loss = 1.87928
I1018 09:29:25.434455 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.711223 (* 1 = 0.711223 loss)
I1018 09:29:25.434459 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.16805 (* 1 = 1.16805 loss)
I1018 09:29:25.434463 11069 solver.cpp:571] Iteration 6020, lr = 0.001
I1018 09:29:32.979285 11069 solver.cpp:242] Iteration 6040, loss = 0.244414
I1018 09:29:32.979310 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.106786 (* 1 = 0.106786 loss)
I1018 09:29:32.979317 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137629 (* 1 = 0.137629 loss)
I1018 09:29:32.979321 11069 solver.cpp:571] Iteration 6040, lr = 0.001
I1018 09:29:40.455845 11069 solver.cpp:242] Iteration 6060, loss = 0.390018
I1018 09:29:40.455871 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.110408 (* 1 = 0.110408 loss)
I1018 09:29:40.455875 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27961 (* 1 = 0.27961 loss)
I1018 09:29:40.455879 11069 solver.cpp:571] Iteration 6060, lr = 0.001
I1018 09:29:47.927741 11069 solver.cpp:242] Iteration 6080, loss = 1.00034
I1018 09:29:47.927765 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.234937 (* 1 = 0.234937 loss)
I1018 09:29:47.927770 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.765406 (* 1 = 0.765406 loss)
I1018 09:29:47.927774 11069 solver.cpp:571] Iteration 6080, lr = 0.001
I1018 09:29:55.482965 11069 solver.cpp:242] Iteration 6100, loss = 0.558959
I1018 09:29:55.482990 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.198939 (* 1 = 0.198939 loss)
I1018 09:29:55.482995 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.36002 (* 1 = 0.36002 loss)
I1018 09:29:55.483001 11069 solver.cpp:571] Iteration 6100, lr = 0.001
I1018 09:30:02.890681 11069 solver.cpp:242] Iteration 6120, loss = 1.72242
I1018 09:30:02.890704 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.619913 (* 1 = 0.619913 loss)
I1018 09:30:02.890709 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.1025 (* 1 = 1.1025 loss)
I1018 09:30:02.890713 11069 solver.cpp:571] Iteration 6120, lr = 0.001
I1018 09:30:10.308049 11069 solver.cpp:242] Iteration 6140, loss = 0.325716
I1018 09:30:10.308073 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0600763 (* 1 = 0.0600763 loss)
I1018 09:30:10.308078 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.26564 (* 1 = 0.26564 loss)
I1018 09:30:10.308081 11069 solver.cpp:571] Iteration 6140, lr = 0.001
I1018 09:30:17.817261 11069 solver.cpp:242] Iteration 6160, loss = 1.08091
I1018 09:30:17.817286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.174749 (* 1 = 0.174749 loss)
I1018 09:30:17.817289 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.906157 (* 1 = 0.906157 loss)
I1018 09:30:17.817293 11069 solver.cpp:571] Iteration 6160, lr = 0.001
I1018 09:30:25.310750 11069 solver.cpp:242] Iteration 6180, loss = 0.313183
I1018 09:30:25.310775 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0613746 (* 1 = 0.0613746 loss)
I1018 09:30:25.310780 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.251809 (* 1 = 0.251809 loss)
I1018 09:30:25.310783 11069 solver.cpp:571] Iteration 6180, lr = 0.001
speed: 0.376s / iter
I1018 09:30:32.781661 11069 solver.cpp:242] Iteration 6200, loss = 0.445581
I1018 09:30:32.781687 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.111611 (* 1 = 0.111611 loss)
I1018 09:30:32.781692 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.333969 (* 1 = 0.333969 loss)
I1018 09:30:32.781695 11069 solver.cpp:571] Iteration 6200, lr = 0.001
I1018 09:30:40.246081 11069 solver.cpp:242] Iteration 6220, loss = 1.07764
I1018 09:30:40.246105 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.37638 (* 1 = 0.37638 loss)
I1018 09:30:40.246109 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.701256 (* 1 = 0.701256 loss)
I1018 09:30:40.246114 11069 solver.cpp:571] Iteration 6220, lr = 0.001
I1018 09:30:47.780803 11069 solver.cpp:242] Iteration 6240, loss = 0.645975
I1018 09:30:47.780827 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.183245 (* 1 = 0.183245 loss)
I1018 09:30:47.780833 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.46273 (* 1 = 0.46273 loss)
I1018 09:30:47.780836 11069 solver.cpp:571] Iteration 6240, lr = 0.001
I1018 09:30:55.233211 11069 solver.cpp:242] Iteration 6260, loss = 0.56639
I1018 09:30:55.233234 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168505 (* 1 = 0.168505 loss)
I1018 09:30:55.233238 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.397885 (* 1 = 0.397885 loss)
I1018 09:30:55.233242 11069 solver.cpp:571] Iteration 6260, lr = 0.001
I1018 09:31:02.800742 11069 solver.cpp:242] Iteration 6280, loss = 0.233064
I1018 09:31:02.800767 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0501448 (* 1 = 0.0501448 loss)
I1018 09:31:02.800772 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182919 (* 1 = 0.182919 loss)
I1018 09:31:02.800776 11069 solver.cpp:571] Iteration 6280, lr = 0.001
I1018 09:31:10.298296 11069 solver.cpp:242] Iteration 6300, loss = 0.349734
I1018 09:31:10.298319 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103813 (* 1 = 0.103813 loss)
I1018 09:31:10.298324 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.245921 (* 1 = 0.245921 loss)
I1018 09:31:10.298328 11069 solver.cpp:571] Iteration 6300, lr = 0.001
I1018 09:31:17.779780 11069 solver.cpp:242] Iteration 6320, loss = 0.986296
I1018 09:31:17.779805 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.278696 (* 1 = 0.278696 loss)
I1018 09:31:17.779810 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.7076 (* 1 = 0.7076 loss)
I1018 09:31:17.779814 11069 solver.cpp:571] Iteration 6320, lr = 0.001
I1018 09:31:25.365474 11069 solver.cpp:242] Iteration 6340, loss = 1.17667
I1018 09:31:25.365499 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.342562 (* 1 = 0.342562 loss)
I1018 09:31:25.365504 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.834103 (* 1 = 0.834103 loss)
I1018 09:31:25.365507 11069 solver.cpp:571] Iteration 6340, lr = 0.001
I1018 09:31:32.884861 11069 solver.cpp:242] Iteration 6360, loss = 0.928717
I1018 09:31:32.884886 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.31403 (* 1 = 0.31403 loss)
I1018 09:31:32.884889 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.614687 (* 1 = 0.614687 loss)
I1018 09:31:32.884893 11069 solver.cpp:571] Iteration 6360, lr = 0.001
I1018 09:31:40.351228 11069 solver.cpp:242] Iteration 6380, loss = 0.435541
I1018 09:31:40.351253 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105516 (* 1 = 0.105516 loss)
I1018 09:31:40.351258 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.330025 (* 1 = 0.330025 loss)
I1018 09:31:40.351261 11069 solver.cpp:571] Iteration 6380, lr = 0.001
speed: 0.376s / iter
I1018 09:31:47.830981 11069 solver.cpp:242] Iteration 6400, loss = 0.354242
I1018 09:31:47.831007 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0950949 (* 1 = 0.0950949 loss)
I1018 09:31:47.831012 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259147 (* 1 = 0.259147 loss)
I1018 09:31:47.831015 11069 solver.cpp:571] Iteration 6400, lr = 0.001
I1018 09:31:55.306877 11069 solver.cpp:242] Iteration 6420, loss = 0.183396
I1018 09:31:55.306901 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0443907 (* 1 = 0.0443907 loss)
I1018 09:31:55.306906 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.139005 (* 1 = 0.139005 loss)
I1018 09:31:55.306910 11069 solver.cpp:571] Iteration 6420, lr = 0.001
I1018 09:32:02.897714 11069 solver.cpp:242] Iteration 6440, loss = 0.158419
I1018 09:32:02.897738 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0391469 (* 1 = 0.0391469 loss)
I1018 09:32:02.897743 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.119272 (* 1 = 0.119272 loss)
I1018 09:32:02.897747 11069 solver.cpp:571] Iteration 6440, lr = 0.001
I1018 09:32:10.412109 11069 solver.cpp:242] Iteration 6460, loss = 0.286949
I1018 09:32:10.412134 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0521185 (* 1 = 0.0521185 loss)
I1018 09:32:10.412138 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.234831 (* 1 = 0.234831 loss)
I1018 09:32:10.412142 11069 solver.cpp:571] Iteration 6460, lr = 0.001
I1018 09:32:18.059787 11069 solver.cpp:242] Iteration 6480, loss = 0.356845
I1018 09:32:18.059811 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0953842 (* 1 = 0.0953842 loss)
I1018 09:32:18.059816 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.261461 (* 1 = 0.261461 loss)
I1018 09:32:18.059820 11069 solver.cpp:571] Iteration 6480, lr = 0.001
I1018 09:32:25.517985 11069 solver.cpp:242] Iteration 6500, loss = 0.38396
I1018 09:32:25.518009 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.109931 (* 1 = 0.109931 loss)
I1018 09:32:25.518013 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.274028 (* 1 = 0.274028 loss)
I1018 09:32:25.518018 11069 solver.cpp:571] Iteration 6500, lr = 0.001
I1018 09:32:33.093648 11069 solver.cpp:242] Iteration 6520, loss = 0.590536
I1018 09:32:33.093672 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164983 (* 1 = 0.164983 loss)
I1018 09:32:33.093677 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.425552 (* 1 = 0.425552 loss)
I1018 09:32:33.093680 11069 solver.cpp:571] Iteration 6520, lr = 0.001
I1018 09:32:40.639595 11069 solver.cpp:242] Iteration 6540, loss = 0.495447
I1018 09:32:40.639619 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.17769 (* 1 = 0.17769 loss)
I1018 09:32:40.639624 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.317757 (* 1 = 0.317757 loss)
I1018 09:32:40.639628 11069 solver.cpp:571] Iteration 6540, lr = 0.001
I1018 09:32:48.260782 11069 solver.cpp:242] Iteration 6560, loss = 0.26439
I1018 09:32:48.260807 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0688051 (* 1 = 0.0688051 loss)
I1018 09:32:48.260812 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195585 (* 1 = 0.195585 loss)
I1018 09:32:48.260817 11069 solver.cpp:571] Iteration 6560, lr = 0.001
I1018 09:32:55.870532 11069 solver.cpp:242] Iteration 6580, loss = 0.804418
I1018 09:32:55.870558 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.262779 (* 1 = 0.262779 loss)
I1018 09:32:55.870561 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.541638 (* 1 = 0.541638 loss)
I1018 09:32:55.870565 11069 solver.cpp:571] Iteration 6580, lr = 0.001
speed: 0.376s / iter
I1018 09:33:03.290712 11069 solver.cpp:242] Iteration 6600, loss = 0.98608
I1018 09:33:03.290737 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.316601 (* 1 = 0.316601 loss)
I1018 09:33:03.290741 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.669479 (* 1 = 0.669479 loss)
I1018 09:33:03.290745 11069 solver.cpp:571] Iteration 6600, lr = 0.001
I1018 09:33:10.812762 11069 solver.cpp:242] Iteration 6620, loss = 0.95259
I1018 09:33:10.812786 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.276486 (* 1 = 0.276486 loss)
I1018 09:33:10.812790 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.676104 (* 1 = 0.676104 loss)
I1018 09:33:10.812795 11069 solver.cpp:571] Iteration 6620, lr = 0.001
I1018 09:33:18.268721 11069 solver.cpp:242] Iteration 6640, loss = 1.10589
I1018 09:33:18.268746 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.356568 (* 1 = 0.356568 loss)
I1018 09:33:18.268750 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.749319 (* 1 = 0.749319 loss)
I1018 09:33:18.268754 11069 solver.cpp:571] Iteration 6640, lr = 0.001
I1018 09:33:25.760360 11069 solver.cpp:242] Iteration 6660, loss = 0.753706
I1018 09:33:25.760385 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143689 (* 1 = 0.143689 loss)
I1018 09:33:25.760388 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.610017 (* 1 = 0.610017 loss)
I1018 09:33:25.760392 11069 solver.cpp:571] Iteration 6660, lr = 0.001
I1018 09:33:33.218679 11069 solver.cpp:242] Iteration 6680, loss = 0.817856
I1018 09:33:33.218704 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.208367 (* 1 = 0.208367 loss)
I1018 09:33:33.218708 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.609489 (* 1 = 0.609489 loss)
I1018 09:33:33.218713 11069 solver.cpp:571] Iteration 6680, lr = 0.001
I1018 09:33:40.756510 11069 solver.cpp:242] Iteration 6700, loss = 0.18896
I1018 09:33:40.756536 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0376012 (* 1 = 0.0376012 loss)
I1018 09:33:40.756539 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.151359 (* 1 = 0.151359 loss)
I1018 09:33:40.756543 11069 solver.cpp:571] Iteration 6700, lr = 0.001
I1018 09:33:48.225620 11069 solver.cpp:242] Iteration 6720, loss = 0.296462
I1018 09:33:48.225643 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0839517 (* 1 = 0.0839517 loss)
I1018 09:33:48.225648 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21251 (* 1 = 0.21251 loss)
I1018 09:33:48.225652 11069 solver.cpp:571] Iteration 6720, lr = 0.001
I1018 09:33:55.796043 11069 solver.cpp:242] Iteration 6740, loss = 0.260818
I1018 09:33:55.796068 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0716511 (* 1 = 0.0716511 loss)
I1018 09:33:55.796072 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189166 (* 1 = 0.189166 loss)
I1018 09:33:55.796077 11069 solver.cpp:571] Iteration 6740, lr = 0.001
I1018 09:34:03.344851 11069 solver.cpp:242] Iteration 6760, loss = 1.13784
I1018 09:34:03.344876 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.426264 (* 1 = 0.426264 loss)
I1018 09:34:03.344879 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.711578 (* 1 = 0.711578 loss)
I1018 09:34:03.344884 11069 solver.cpp:571] Iteration 6760, lr = 0.001
I1018 09:34:10.809252 11069 solver.cpp:242] Iteration 6780, loss = 0.301626
I1018 09:34:10.809278 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0677194 (* 1 = 0.0677194 loss)
I1018 09:34:10.809281 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.233907 (* 1 = 0.233907 loss)
I1018 09:34:10.809285 11069 solver.cpp:571] Iteration 6780, lr = 0.001
speed: 0.376s / iter
I1018 09:34:18.284090 11069 solver.cpp:242] Iteration 6800, loss = 0.252146
I1018 09:34:18.284116 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0357424 (* 1 = 0.0357424 loss)
I1018 09:34:18.284121 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216404 (* 1 = 0.216404 loss)
I1018 09:34:18.284126 11069 solver.cpp:571] Iteration 6800, lr = 0.001
I1018 09:34:25.798022 11069 solver.cpp:242] Iteration 6820, loss = 0.191195
I1018 09:34:25.798046 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0628406 (* 1 = 0.0628406 loss)
I1018 09:34:25.798051 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.128354 (* 1 = 0.128354 loss)
I1018 09:34:25.798055 11069 solver.cpp:571] Iteration 6820, lr = 0.001
I1018 09:34:33.336973 11069 solver.cpp:242] Iteration 6840, loss = 1.23466
I1018 09:34:33.336998 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.541797 (* 1 = 0.541797 loss)
I1018 09:34:33.337002 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.692862 (* 1 = 0.692862 loss)
I1018 09:34:33.337007 11069 solver.cpp:571] Iteration 6840, lr = 0.001
I1018 09:34:40.838307 11069 solver.cpp:242] Iteration 6860, loss = 0.227414
I1018 09:34:40.838331 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0553917 (* 1 = 0.0553917 loss)
I1018 09:34:40.838336 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.172022 (* 1 = 0.172022 loss)
I1018 09:34:40.838340 11069 solver.cpp:571] Iteration 6860, lr = 0.001
I1018 09:34:48.396890 11069 solver.cpp:242] Iteration 6880, loss = 0.518448
I1018 09:34:48.396914 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.131179 (* 1 = 0.131179 loss)
I1018 09:34:48.396919 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.38727 (* 1 = 0.38727 loss)
I1018 09:34:48.396924 11069 solver.cpp:571] Iteration 6880, lr = 0.001
I1018 09:34:55.813699 11069 solver.cpp:242] Iteration 6900, loss = 0.632648
I1018 09:34:55.813724 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159549 (* 1 = 0.159549 loss)
I1018 09:34:55.813729 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473099 (* 1 = 0.473099 loss)
I1018 09:34:55.813732 11069 solver.cpp:571] Iteration 6900, lr = 0.001
I1018 09:35:03.351342 11069 solver.cpp:242] Iteration 6920, loss = 0.810111
I1018 09:35:03.351366 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.284507 (* 1 = 0.284507 loss)
I1018 09:35:03.351372 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.525604 (* 1 = 0.525604 loss)
I1018 09:35:03.351375 11069 solver.cpp:571] Iteration 6920, lr = 0.001
I1018 09:35:10.868566 11069 solver.cpp:242] Iteration 6940, loss = 0.19289
I1018 09:35:10.868590 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0768263 (* 1 = 0.0768263 loss)
I1018 09:35:10.868594 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116063 (* 1 = 0.116063 loss)
I1018 09:35:10.868599 11069 solver.cpp:571] Iteration 6940, lr = 0.001
I1018 09:35:18.336921 11069 solver.cpp:242] Iteration 6960, loss = 0.744835
I1018 09:35:18.336947 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.236198 (* 1 = 0.236198 loss)
I1018 09:35:18.336952 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.508636 (* 1 = 0.508636 loss)
I1018 09:35:18.336956 11069 solver.cpp:571] Iteration 6960, lr = 0.001
I1018 09:35:25.807271 11069 solver.cpp:242] Iteration 6980, loss = 0.850999
I1018 09:35:25.807294 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.26715 (* 1 = 0.26715 loss)
I1018 09:35:25.807299 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.583849 (* 1 = 0.583849 loss)
I1018 09:35:25.807303 11069 solver.cpp:571] Iteration 6980, lr = 0.001
speed: 0.376s / iter
I1018 09:35:33.211218 11069 solver.cpp:242] Iteration 7000, loss = 0.538013
I1018 09:35:33.211243 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122238 (* 1 = 0.122238 loss)
I1018 09:35:33.211248 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.415775 (* 1 = 0.415775 loss)
I1018 09:35:33.211252 11069 solver.cpp:571] Iteration 7000, lr = 0.001
I1018 09:35:40.714114 11069 solver.cpp:242] Iteration 7020, loss = 1.62049
I1018 09:35:40.714140 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.629472 (* 1 = 0.629472 loss)
I1018 09:35:40.714145 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.991022 (* 1 = 0.991022 loss)
I1018 09:35:40.714149 11069 solver.cpp:571] Iteration 7020, lr = 0.001
I1018 09:35:48.216475 11069 solver.cpp:242] Iteration 7040, loss = 0.644545
I1018 09:35:48.216500 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.183075 (* 1 = 0.183075 loss)
I1018 09:35:48.216505 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.461471 (* 1 = 0.461471 loss)
I1018 09:35:48.216509 11069 solver.cpp:571] Iteration 7040, lr = 0.001
I1018 09:35:55.757995 11069 solver.cpp:242] Iteration 7060, loss = 0.274178
I1018 09:35:55.758019 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0717021 (* 1 = 0.0717021 loss)
I1018 09:35:55.758024 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.202476 (* 1 = 0.202476 loss)
I1018 09:35:55.758028 11069 solver.cpp:571] Iteration 7060, lr = 0.001
I1018 09:36:03.277447 11069 solver.cpp:242] Iteration 7080, loss = 0.430548
I1018 09:36:03.277472 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.117785 (* 1 = 0.117785 loss)
I1018 09:36:03.277477 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.312762 (* 1 = 0.312762 loss)
I1018 09:36:03.277482 11069 solver.cpp:571] Iteration 7080, lr = 0.001
I1018 09:36:10.748525 11069 solver.cpp:242] Iteration 7100, loss = 2.20542
I1018 09:36:10.748549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.957983 (* 1 = 0.957983 loss)
I1018 09:36:10.748554 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.24743 (* 1 = 1.24743 loss)
I1018 09:36:10.748558 11069 solver.cpp:571] Iteration 7100, lr = 0.001
I1018 09:36:18.257143 11069 solver.cpp:242] Iteration 7120, loss = 0.308464
I1018 09:36:18.257167 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0422267 (* 1 = 0.0422267 loss)
I1018 09:36:18.257172 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.266237 (* 1 = 0.266237 loss)
I1018 09:36:18.257176 11069 solver.cpp:571] Iteration 7120, lr = 0.001
I1018 09:36:25.774056 11069 solver.cpp:242] Iteration 7140, loss = 0.768694
I1018 09:36:25.774081 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.264661 (* 1 = 0.264661 loss)
I1018 09:36:25.774086 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.504033 (* 1 = 0.504033 loss)
I1018 09:36:25.774091 11069 solver.cpp:571] Iteration 7140, lr = 0.001
I1018 09:36:33.312813 11069 solver.cpp:242] Iteration 7160, loss = 0.951075
I1018 09:36:33.312837 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244849 (* 1 = 0.244849 loss)
I1018 09:36:33.312842 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.706226 (* 1 = 0.706226 loss)
I1018 09:36:33.312846 11069 solver.cpp:571] Iteration 7160, lr = 0.001
I1018 09:36:40.882910 11069 solver.cpp:242] Iteration 7180, loss = 0.291389
I1018 09:36:40.882933 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.086286 (* 1 = 0.086286 loss)
I1018 09:36:40.882938 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205103 (* 1 = 0.205103 loss)
I1018 09:36:40.882942 11069 solver.cpp:571] Iteration 7180, lr = 0.001
speed: 0.376s / iter
I1018 09:36:48.412041 11069 solver.cpp:242] Iteration 7200, loss = 0.260723
I1018 09:36:48.412065 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.094528 (* 1 = 0.094528 loss)
I1018 09:36:48.412070 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166195 (* 1 = 0.166195 loss)
I1018 09:36:48.412075 11069 solver.cpp:571] Iteration 7200, lr = 0.001
I1018 09:36:55.944636 11069 solver.cpp:242] Iteration 7220, loss = 0.630501
I1018 09:36:55.944660 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.156796 (* 1 = 0.156796 loss)
I1018 09:36:55.944665 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473705 (* 1 = 0.473705 loss)
I1018 09:36:55.944669 11069 solver.cpp:571] Iteration 7220, lr = 0.001
I1018 09:37:03.500854 11069 solver.cpp:242] Iteration 7240, loss = 0.419689
I1018 09:37:03.500877 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115286 (* 1 = 0.115286 loss)
I1018 09:37:03.500882 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.304403 (* 1 = 0.304403 loss)
I1018 09:37:03.500886 11069 solver.cpp:571] Iteration 7240, lr = 0.001
I1018 09:37:10.999974 11069 solver.cpp:242] Iteration 7260, loss = 0.309279
I1018 09:37:11.000000 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0664661 (* 1 = 0.0664661 loss)
I1018 09:37:11.000005 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242813 (* 1 = 0.242813 loss)
I1018 09:37:11.000008 11069 solver.cpp:571] Iteration 7260, lr = 0.001
I1018 09:37:18.586370 11069 solver.cpp:242] Iteration 7280, loss = 0.588485
I1018 09:37:18.586395 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.156339 (* 1 = 0.156339 loss)
I1018 09:37:18.586398 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.432146 (* 1 = 0.432146 loss)
I1018 09:37:18.586402 11069 solver.cpp:571] Iteration 7280, lr = 0.001
I1018 09:37:26.100916 11069 solver.cpp:242] Iteration 7300, loss = 0.17422
I1018 09:37:26.100941 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0282421 (* 1 = 0.0282421 loss)
I1018 09:37:26.100945 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.145978 (* 1 = 0.145978 loss)
I1018 09:37:26.100950 11069 solver.cpp:571] Iteration 7300, lr = 0.001
I1018 09:37:33.598315 11069 solver.cpp:242] Iteration 7320, loss = 0.202442
I1018 09:37:33.598340 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0454209 (* 1 = 0.0454209 loss)
I1018 09:37:33.598345 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.157021 (* 1 = 0.157021 loss)
I1018 09:37:33.598348 11069 solver.cpp:571] Iteration 7320, lr = 0.001
I1018 09:37:40.974287 11069 solver.cpp:242] Iteration 7340, loss = 0.239074
I1018 09:37:40.974310 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0774416 (* 1 = 0.0774416 loss)
I1018 09:37:40.974315 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.161632 (* 1 = 0.161632 loss)
I1018 09:37:40.974319 11069 solver.cpp:571] Iteration 7340, lr = 0.001
I1018 09:37:48.555768 11069 solver.cpp:242] Iteration 7360, loss = 0.152835
I1018 09:37:48.555793 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0402598 (* 1 = 0.0402598 loss)
I1018 09:37:48.555796 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.112575 (* 1 = 0.112575 loss)
I1018 09:37:48.555800 11069 solver.cpp:571] Iteration 7360, lr = 0.001
I1018 09:37:56.091933 11069 solver.cpp:242] Iteration 7380, loss = 0.293971
I1018 09:37:56.091958 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.013869 (* 1 = 0.013869 loss)
I1018 09:37:56.091962 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280102 (* 1 = 0.280102 loss)
I1018 09:37:56.091966 11069 solver.cpp:571] Iteration 7380, lr = 0.001
speed: 0.376s / iter
I1018 09:38:03.606515 11069 solver.cpp:242] Iteration 7400, loss = 0.625826
I1018 09:38:03.606540 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152302 (* 1 = 0.152302 loss)
I1018 09:38:03.606544 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473524 (* 1 = 0.473524 loss)
I1018 09:38:03.606549 11069 solver.cpp:571] Iteration 7400, lr = 0.001
I1018 09:38:11.206967 11069 solver.cpp:242] Iteration 7420, loss = 0.578428
I1018 09:38:11.206991 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.101949 (* 1 = 0.101949 loss)
I1018 09:38:11.206996 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.476478 (* 1 = 0.476478 loss)
I1018 09:38:11.207000 11069 solver.cpp:571] Iteration 7420, lr = 0.001
I1018 09:38:18.682474 11069 solver.cpp:242] Iteration 7440, loss = 0.372648
I1018 09:38:18.682499 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0861629 (* 1 = 0.0861629 loss)
I1018 09:38:18.682504 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.286485 (* 1 = 0.286485 loss)
I1018 09:38:18.682508 11069 solver.cpp:571] Iteration 7440, lr = 0.001
I1018 09:38:26.239469 11069 solver.cpp:242] Iteration 7460, loss = 0.307975
I1018 09:38:26.239493 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0659626 (* 1 = 0.0659626 loss)
I1018 09:38:26.239498 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242012 (* 1 = 0.242012 loss)
I1018 09:38:26.239502 11069 solver.cpp:571] Iteration 7460, lr = 0.001
I1018 09:38:33.676854 11069 solver.cpp:242] Iteration 7480, loss = 0.625984
I1018 09:38:33.676878 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139376 (* 1 = 0.139376 loss)
I1018 09:38:33.676883 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.486608 (* 1 = 0.486608 loss)
I1018 09:38:33.676887 11069 solver.cpp:571] Iteration 7480, lr = 0.001
I1018 09:38:41.199587 11069 solver.cpp:242] Iteration 7500, loss = 0.706097
I1018 09:38:41.199611 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210618 (* 1 = 0.210618 loss)
I1018 09:38:41.199615 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495479 (* 1 = 0.495479 loss)
I1018 09:38:41.199620 11069 solver.cpp:571] Iteration 7500, lr = 0.001
I1018 09:38:48.658876 11069 solver.cpp:242] Iteration 7520, loss = 1.46089
I1018 09:38:48.658900 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.578118 (* 1 = 0.578118 loss)
I1018 09:38:48.658905 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.882769 (* 1 = 0.882769 loss)
I1018 09:38:48.658908 11069 solver.cpp:571] Iteration 7520, lr = 0.001
I1018 09:38:56.161025 11069 solver.cpp:242] Iteration 7540, loss = 0.534236
I1018 09:38:56.161048 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115125 (* 1 = 0.115125 loss)
I1018 09:38:56.161053 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.419111 (* 1 = 0.419111 loss)
I1018 09:38:56.161057 11069 solver.cpp:571] Iteration 7540, lr = 0.001
I1018 09:39:03.682277 11069 solver.cpp:242] Iteration 7560, loss = 1.11257
I1018 09:39:03.682302 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.407264 (* 1 = 0.407264 loss)
I1018 09:39:03.682307 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.70531 (* 1 = 0.70531 loss)
I1018 09:39:03.682312 11069 solver.cpp:571] Iteration 7560, lr = 0.001
I1018 09:39:11.207132 11069 solver.cpp:242] Iteration 7580, loss = 0.172042
I1018 09:39:11.207157 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0304045 (* 1 = 0.0304045 loss)
I1018 09:39:11.207161 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141637 (* 1 = 0.141637 loss)
I1018 09:39:11.207165 11069 solver.cpp:571] Iteration 7580, lr = 0.001
speed: 0.376s / iter
I1018 09:39:18.715075 11069 solver.cpp:242] Iteration 7600, loss = 0.257451
I1018 09:39:18.715100 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.074138 (* 1 = 0.074138 loss)
I1018 09:39:18.715104 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.183313 (* 1 = 0.183313 loss)
I1018 09:39:18.715107 11069 solver.cpp:571] Iteration 7600, lr = 0.001
I1018 09:39:26.193348 11069 solver.cpp:242] Iteration 7620, loss = 0.19032
I1018 09:39:26.193374 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0457032 (* 1 = 0.0457032 loss)
I1018 09:39:26.193378 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144617 (* 1 = 0.144617 loss)
I1018 09:39:26.193382 11069 solver.cpp:571] Iteration 7620, lr = 0.001
I1018 09:39:33.652166 11069 solver.cpp:242] Iteration 7640, loss = 1.6868
I1018 09:39:33.652190 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.661183 (* 1 = 0.661183 loss)
I1018 09:39:33.652195 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.02562 (* 1 = 1.02562 loss)
I1018 09:39:33.652199 11069 solver.cpp:571] Iteration 7640, lr = 0.001
I1018 09:39:41.253623 11069 solver.cpp:242] Iteration 7660, loss = 1.18843
I1018 09:39:41.253648 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.379906 (* 1 = 0.379906 loss)
I1018 09:39:41.253653 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.80852 (* 1 = 0.80852 loss)
I1018 09:39:41.253657 11069 solver.cpp:571] Iteration 7660, lr = 0.001
I1018 09:39:48.736029 11069 solver.cpp:242] Iteration 7680, loss = 0.833519
I1018 09:39:48.736054 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.251142 (* 1 = 0.251142 loss)
I1018 09:39:48.736058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.582377 (* 1 = 0.582377 loss)
I1018 09:39:48.736063 11069 solver.cpp:571] Iteration 7680, lr = 0.001
I1018 09:39:56.251958 11069 solver.cpp:242] Iteration 7700, loss = 0.475767
I1018 09:39:56.251982 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152853 (* 1 = 0.152853 loss)
I1018 09:39:56.251986 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.322914 (* 1 = 0.322914 loss)
I1018 09:39:56.251991 11069 solver.cpp:571] Iteration 7700, lr = 0.001
I1018 09:40:03.790827 11069 solver.cpp:242] Iteration 7720, loss = 0.620656
I1018 09:40:03.790853 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.194349 (* 1 = 0.194349 loss)
I1018 09:40:03.790856 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.426307 (* 1 = 0.426307 loss)
I1018 09:40:03.790861 11069 solver.cpp:571] Iteration 7720, lr = 0.001
I1018 09:40:11.350473 11069 solver.cpp:242] Iteration 7740, loss = 0.284614
I1018 09:40:11.350498 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0518962 (* 1 = 0.0518962 loss)
I1018 09:40:11.350502 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232718 (* 1 = 0.232718 loss)
I1018 09:40:11.350507 11069 solver.cpp:571] Iteration 7740, lr = 0.001
I1018 09:40:18.979900 11069 solver.cpp:242] Iteration 7760, loss = 0.612138
I1018 09:40:18.979924 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.189139 (* 1 = 0.189139 loss)
I1018 09:40:18.979928 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.423 (* 1 = 0.423 loss)
I1018 09:40:18.979933 11069 solver.cpp:571] Iteration 7760, lr = 0.001
I1018 09:40:26.557632 11069 solver.cpp:242] Iteration 7780, loss = 0.491182
I1018 09:40:26.557657 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.132206 (* 1 = 0.132206 loss)
I1018 09:40:26.557662 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.358977 (* 1 = 0.358977 loss)
I1018 09:40:26.557665 11069 solver.cpp:571] Iteration 7780, lr = 0.001
speed: 0.376s / iter
I1018 09:40:34.083585 11069 solver.cpp:242] Iteration 7800, loss = 1.09198
I1018 09:40:34.083611 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.275747 (* 1 = 0.275747 loss)
I1018 09:40:34.083616 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.816229 (* 1 = 0.816229 loss)
I1018 09:40:34.083619 11069 solver.cpp:571] Iteration 7800, lr = 0.001
I1018 09:40:41.583910 11069 solver.cpp:242] Iteration 7820, loss = 0.409706
I1018 09:40:41.583935 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.125796 (* 1 = 0.125796 loss)
I1018 09:40:41.583938 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.28391 (* 1 = 0.28391 loss)
I1018 09:40:41.583942 11069 solver.cpp:571] Iteration 7820, lr = 0.001
I1018 09:40:49.141788 11069 solver.cpp:242] Iteration 7840, loss = 1.43807
I1018 09:40:49.141813 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.622976 (* 1 = 0.622976 loss)
I1018 09:40:49.141816 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.815093 (* 1 = 0.815093 loss)
I1018 09:40:49.141820 11069 solver.cpp:571] Iteration 7840, lr = 0.001
I1018 09:40:56.720679 11069 solver.cpp:242] Iteration 7860, loss = 0.193731
I1018 09:40:56.720705 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.044295 (* 1 = 0.044295 loss)
I1018 09:40:56.720710 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149436 (* 1 = 0.149436 loss)
I1018 09:40:56.720713 11069 solver.cpp:571] Iteration 7860, lr = 0.001
I1018 09:41:04.310398 11069 solver.cpp:242] Iteration 7880, loss = 0.651885
I1018 09:41:04.310423 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137891 (* 1 = 0.137891 loss)
I1018 09:41:04.310428 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.513994 (* 1 = 0.513994 loss)
I1018 09:41:04.310432 11069 solver.cpp:571] Iteration 7880, lr = 0.001
I1018 09:41:11.913694 11069 solver.cpp:242] Iteration 7900, loss = 1.09009
I1018 09:41:11.913719 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.308383 (* 1 = 0.308383 loss)
I1018 09:41:11.913723 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.781706 (* 1 = 0.781706 loss)
I1018 09:41:11.913727 11069 solver.cpp:571] Iteration 7900, lr = 0.001
I1018 09:41:19.479763 11069 solver.cpp:242] Iteration 7920, loss = 0.994538
I1018 09:41:19.479789 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.38345 (* 1 = 0.38345 loss)
I1018 09:41:19.479792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.611088 (* 1 = 0.611088 loss)
I1018 09:41:19.479796 11069 solver.cpp:571] Iteration 7920, lr = 0.001
I1018 09:41:27.033182 11069 solver.cpp:242] Iteration 7940, loss = 0.911952
I1018 09:41:27.033206 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.247355 (* 1 = 0.247355 loss)
I1018 09:41:27.033211 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664596 (* 1 = 0.664596 loss)
I1018 09:41:27.033215 11069 solver.cpp:571] Iteration 7940, lr = 0.001
I1018 09:41:34.590821 11069 solver.cpp:242] Iteration 7960, loss = 0.237149
I1018 09:41:34.590845 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0535882 (* 1 = 0.0535882 loss)
I1018 09:41:34.590849 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.183561 (* 1 = 0.183561 loss)
I1018 09:41:34.590853 11069 solver.cpp:571] Iteration 7960, lr = 0.001
I1018 09:41:42.192061 11069 solver.cpp:242] Iteration 7980, loss = 0.241865
I1018 09:41:42.192086 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0480685 (* 1 = 0.0480685 loss)
I1018 09:41:42.192090 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.193797 (* 1 = 0.193797 loss)
I1018 09:41:42.192095 11069 solver.cpp:571] Iteration 7980, lr = 0.001
speed: 0.376s / iter
I1018 09:41:49.601318 11069 solver.cpp:242] Iteration 8000, loss = 0.75135
I1018 09:41:49.601342 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.286586 (* 1 = 0.286586 loss)
I1018 09:41:49.601347 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.464764 (* 1 = 0.464764 loss)
I1018 09:41:49.601351 11069 solver.cpp:571] Iteration 8000, lr = 0.001
I1018 09:41:57.135994 11069 solver.cpp:242] Iteration 8020, loss = 0.319686
I1018 09:41:57.136019 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0342652 (* 1 = 0.0342652 loss)
I1018 09:41:57.136024 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.285421 (* 1 = 0.285421 loss)
I1018 09:41:57.136029 11069 solver.cpp:571] Iteration 8020, lr = 0.001
I1018 09:42:04.666120 11069 solver.cpp:242] Iteration 8040, loss = 1.54873
I1018 09:42:04.666144 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.780784 (* 1 = 0.780784 loss)
I1018 09:42:04.666148 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.767951 (* 1 = 0.767951 loss)
I1018 09:42:04.666152 11069 solver.cpp:571] Iteration 8040, lr = 0.001
I1018 09:42:12.191349 11069 solver.cpp:242] Iteration 8060, loss = 1.14635
I1018 09:42:12.191372 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.404773 (* 1 = 0.404773 loss)
I1018 09:42:12.191377 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.741581 (* 1 = 0.741581 loss)
I1018 09:42:12.191381 11069 solver.cpp:571] Iteration 8060, lr = 0.001
I1018 09:42:19.723525 11069 solver.cpp:242] Iteration 8080, loss = 0.66201
I1018 09:42:19.723549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206832 (* 1 = 0.206832 loss)
I1018 09:42:19.723553 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.455177 (* 1 = 0.455177 loss)
I1018 09:42:19.723558 11069 solver.cpp:571] Iteration 8080, lr = 0.001
I1018 09:42:27.236688 11069 solver.cpp:242] Iteration 8100, loss = 0.553761
I1018 09:42:27.236713 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203739 (* 1 = 0.203739 loss)
I1018 09:42:27.236717 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.350022 (* 1 = 0.350022 loss)
I1018 09:42:27.236721 11069 solver.cpp:571] Iteration 8100, lr = 0.001
I1018 09:42:34.850420 11069 solver.cpp:242] Iteration 8120, loss = 0.363991
I1018 09:42:34.850445 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0954492 (* 1 = 0.0954492 loss)
I1018 09:42:34.850450 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.268541 (* 1 = 0.268541 loss)
I1018 09:42:34.850455 11069 solver.cpp:571] Iteration 8120, lr = 0.001
I1018 09:42:42.348868 11069 solver.cpp:242] Iteration 8140, loss = 0.281161
I1018 09:42:42.348892 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0322468 (* 1 = 0.0322468 loss)
I1018 09:42:42.348897 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.248914 (* 1 = 0.248914 loss)
I1018 09:42:42.348901 11069 solver.cpp:571] Iteration 8140, lr = 0.001
I1018 09:42:49.861110 11069 solver.cpp:242] Iteration 8160, loss = 0.815144
I1018 09:42:49.861135 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.315002 (* 1 = 0.315002 loss)
I1018 09:42:49.861138 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.500141 (* 1 = 0.500141 loss)
I1018 09:42:49.861142 11069 solver.cpp:571] Iteration 8160, lr = 0.001
I1018 09:42:57.430418 11069 solver.cpp:242] Iteration 8180, loss = 0.204272
I1018 09:42:57.430443 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0594402 (* 1 = 0.0594402 loss)
I1018 09:42:57.430446 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144832 (* 1 = 0.144832 loss)
I1018 09:42:57.430450 11069 solver.cpp:571] Iteration 8180, lr = 0.001
speed: 0.376s / iter
I1018 09:43:04.770365 11069 solver.cpp:242] Iteration 8200, loss = 0.535615
I1018 09:43:04.770392 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.106601 (* 1 = 0.106601 loss)
I1018 09:43:04.770397 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.429013 (* 1 = 0.429013 loss)
I1018 09:43:04.770401 11069 solver.cpp:571] Iteration 8200, lr = 0.001
I1018 09:43:12.292204 11069 solver.cpp:242] Iteration 8220, loss = 1.72179
I1018 09:43:12.292229 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.77817 (* 1 = 0.77817 loss)
I1018 09:43:12.292233 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.943624 (* 1 = 0.943624 loss)
I1018 09:43:12.292237 11069 solver.cpp:571] Iteration 8220, lr = 0.001
I1018 09:43:19.767398 11069 solver.cpp:242] Iteration 8240, loss = 0.651406
I1018 09:43:19.767423 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.201412 (* 1 = 0.201412 loss)
I1018 09:43:19.767428 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.449994 (* 1 = 0.449994 loss)
I1018 09:43:19.767432 11069 solver.cpp:571] Iteration 8240, lr = 0.001
I1018 09:43:27.264442 11069 solver.cpp:242] Iteration 8260, loss = 1.52539
I1018 09:43:27.264467 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.63527 (* 1 = 0.63527 loss)
I1018 09:43:27.264472 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.890117 (* 1 = 0.890117 loss)
I1018 09:43:27.264477 11069 solver.cpp:571] Iteration 8260, lr = 0.001
I1018 09:43:34.731019 11069 solver.cpp:242] Iteration 8280, loss = 1.40587
I1018 09:43:34.731043 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.497988 (* 1 = 0.497988 loss)
I1018 09:43:34.731048 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.907886 (* 1 = 0.907886 loss)
I1018 09:43:34.731052 11069 solver.cpp:571] Iteration 8280, lr = 0.001
I1018 09:43:42.299892 11069 solver.cpp:242] Iteration 8300, loss = 0.358802
I1018 09:43:42.299918 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.119386 (* 1 = 0.119386 loss)
I1018 09:43:42.299922 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.239417 (* 1 = 0.239417 loss)
I1018 09:43:42.299926 11069 solver.cpp:571] Iteration 8300, lr = 0.001
I1018 09:43:49.857162 11069 solver.cpp:242] Iteration 8320, loss = 0.844212
I1018 09:43:49.857187 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.271516 (* 1 = 0.271516 loss)
I1018 09:43:49.857192 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.572696 (* 1 = 0.572696 loss)
I1018 09:43:49.857195 11069 solver.cpp:571] Iteration 8320, lr = 0.001
I1018 09:43:57.399835 11069 solver.cpp:242] Iteration 8340, loss = 1.55021
I1018 09:43:57.399859 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.703288 (* 1 = 0.703288 loss)
I1018 09:43:57.399863 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.846921 (* 1 = 0.846921 loss)
I1018 09:43:57.399868 11069 solver.cpp:571] Iteration 8340, lr = 0.001
I1018 09:44:04.807610 11069 solver.cpp:242] Iteration 8360, loss = 1.19697
I1018 09:44:04.807634 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.368025 (* 1 = 0.368025 loss)
I1018 09:44:04.807639 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.828949 (* 1 = 0.828949 loss)
I1018 09:44:04.807643 11069 solver.cpp:571] Iteration 8360, lr = 0.001
I1018 09:44:12.309851 11069 solver.cpp:242] Iteration 8380, loss = 0.34653
I1018 09:44:12.309885 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0775774 (* 1 = 0.0775774 loss)
I1018 09:44:12.309890 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.268952 (* 1 = 0.268952 loss)
I1018 09:44:12.309895 11069 solver.cpp:571] Iteration 8380, lr = 0.001
speed: 0.376s / iter
I1018 09:44:19.759290 11069 solver.cpp:242] Iteration 8400, loss = 1.15853
I1018 09:44:19.759318 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.346261 (* 1 = 0.346261 loss)
I1018 09:44:19.759323 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.81227 (* 1 = 0.81227 loss)
I1018 09:44:19.759327 11069 solver.cpp:571] Iteration 8400, lr = 0.001
I1018 09:44:27.181304 11069 solver.cpp:242] Iteration 8420, loss = 0.89666
I1018 09:44:27.181327 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.287543 (* 1 = 0.287543 loss)
I1018 09:44:27.181332 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.609117 (* 1 = 0.609117 loss)
I1018 09:44:27.181336 11069 solver.cpp:571] Iteration 8420, lr = 0.001
I1018 09:44:34.635021 11069 solver.cpp:242] Iteration 8440, loss = 1.35652
I1018 09:44:34.635046 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.356822 (* 1 = 0.356822 loss)
I1018 09:44:34.635051 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.999699 (* 1 = 0.999699 loss)
I1018 09:44:34.635054 11069 solver.cpp:571] Iteration 8440, lr = 0.001
I1018 09:44:42.161506 11069 solver.cpp:242] Iteration 8460, loss = 0.230093
I1018 09:44:42.161530 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0586226 (* 1 = 0.0586226 loss)
I1018 09:44:42.161535 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.171471 (* 1 = 0.171471 loss)
I1018 09:44:42.161540 11069 solver.cpp:571] Iteration 8460, lr = 0.001
I1018 09:44:49.612267 11069 solver.cpp:242] Iteration 8480, loss = 0.861906
I1018 09:44:49.612293 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.211356 (* 1 = 0.211356 loss)
I1018 09:44:49.612298 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.65055 (* 1 = 0.65055 loss)
I1018 09:44:49.612301 11069 solver.cpp:571] Iteration 8480, lr = 0.001
I1018 09:44:57.083168 11069 solver.cpp:242] Iteration 8500, loss = 0.531814
I1018 09:44:57.083192 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834624 (* 1 = 0.0834624 loss)
I1018 09:44:57.083197 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.448352 (* 1 = 0.448352 loss)
I1018 09:44:57.083201 11069 solver.cpp:571] Iteration 8500, lr = 0.001
I1018 09:45:04.543994 11069 solver.cpp:242] Iteration 8520, loss = 0.491573
I1018 09:45:04.544019 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0857509 (* 1 = 0.0857509 loss)
I1018 09:45:04.544023 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.405822 (* 1 = 0.405822 loss)
I1018 09:45:04.544028 11069 solver.cpp:571] Iteration 8520, lr = 0.001
I1018 09:45:12.129824 11069 solver.cpp:242] Iteration 8540, loss = 0.28672
I1018 09:45:12.129849 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0552756 (* 1 = 0.0552756 loss)
I1018 09:45:12.129853 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231444 (* 1 = 0.231444 loss)
I1018 09:45:12.129858 11069 solver.cpp:571] Iteration 8540, lr = 0.001
I1018 09:45:19.667826 11069 solver.cpp:242] Iteration 8560, loss = 0.564825
I1018 09:45:19.667851 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.145637 (* 1 = 0.145637 loss)
I1018 09:45:19.667855 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.419188 (* 1 = 0.419188 loss)
I1018 09:45:19.667860 11069 solver.cpp:571] Iteration 8560, lr = 0.001
I1018 09:45:27.169425 11069 solver.cpp:242] Iteration 8580, loss = 0.672011
I1018 09:45:27.169450 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177887 (* 1 = 0.177887 loss)
I1018 09:45:27.169453 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.494123 (* 1 = 0.494123 loss)
I1018 09:45:27.169457 11069 solver.cpp:571] Iteration 8580, lr = 0.001
speed: 0.376s / iter
I1018 09:45:34.692924 11069 solver.cpp:242] Iteration 8600, loss = 0.367258
I1018 09:45:34.692948 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0976982 (* 1 = 0.0976982 loss)
I1018 09:45:34.692953 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.26956 (* 1 = 0.26956 loss)
I1018 09:45:34.692957 11069 solver.cpp:571] Iteration 8600, lr = 0.001
I1018 09:45:42.192344 11069 solver.cpp:242] Iteration 8620, loss = 1.78745
I1018 09:45:42.192368 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.736167 (* 1 = 0.736167 loss)
I1018 09:45:42.192373 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.05129 (* 1 = 1.05129 loss)
I1018 09:45:42.192376 11069 solver.cpp:571] Iteration 8620, lr = 0.001
I1018 09:45:49.723798 11069 solver.cpp:242] Iteration 8640, loss = 1.66994
I1018 09:45:49.723822 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.808361 (* 1 = 0.808361 loss)
I1018 09:45:49.723827 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.861576 (* 1 = 0.861576 loss)
I1018 09:45:49.723831 11069 solver.cpp:571] Iteration 8640, lr = 0.001
I1018 09:45:57.264529 11069 solver.cpp:242] Iteration 8660, loss = 0.432879
I1018 09:45:57.264554 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151437 (* 1 = 0.151437 loss)
I1018 09:45:57.264559 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.281442 (* 1 = 0.281442 loss)
I1018 09:45:57.264564 11069 solver.cpp:571] Iteration 8660, lr = 0.001
I1018 09:46:04.765405 11069 solver.cpp:242] Iteration 8680, loss = 0.156603
I1018 09:46:04.765431 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0367459 (* 1 = 0.0367459 loss)
I1018 09:46:04.765436 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.119857 (* 1 = 0.119857 loss)
I1018 09:46:04.765440 11069 solver.cpp:571] Iteration 8680, lr = 0.001
I1018 09:46:12.258627 11069 solver.cpp:242] Iteration 8700, loss = 0.677481
I1018 09:46:12.258652 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.211248 (* 1 = 0.211248 loss)
I1018 09:46:12.258656 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.466233 (* 1 = 0.466233 loss)
I1018 09:46:12.258661 11069 solver.cpp:571] Iteration 8700, lr = 0.001
I1018 09:46:19.743811 11069 solver.cpp:242] Iteration 8720, loss = 0.190842
I1018 09:46:19.743836 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0310284 (* 1 = 0.0310284 loss)
I1018 09:46:19.743841 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159814 (* 1 = 0.159814 loss)
I1018 09:46:19.743845 11069 solver.cpp:571] Iteration 8720, lr = 0.001
I1018 09:46:27.267011 11069 solver.cpp:242] Iteration 8740, loss = 0.305119
I1018 09:46:27.267035 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0740576 (* 1 = 0.0740576 loss)
I1018 09:46:27.267040 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231062 (* 1 = 0.231062 loss)
I1018 09:46:27.267045 11069 solver.cpp:571] Iteration 8740, lr = 0.001
I1018 09:46:34.876068 11069 solver.cpp:242] Iteration 8760, loss = 0.580296
I1018 09:46:34.876092 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0592505 (* 1 = 0.0592505 loss)
I1018 09:46:34.876097 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.521046 (* 1 = 0.521046 loss)
I1018 09:46:34.876101 11069 solver.cpp:571] Iteration 8760, lr = 0.001
I1018 09:46:42.420649 11069 solver.cpp:242] Iteration 8780, loss = 1.69514
I1018 09:46:42.420672 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.714862 (* 1 = 0.714862 loss)
I1018 09:46:42.420677 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.980279 (* 1 = 0.980279 loss)
I1018 09:46:42.420681 11069 solver.cpp:571] Iteration 8780, lr = 0.001
speed: 0.376s / iter
I1018 09:46:49.874778 11069 solver.cpp:242] Iteration 8800, loss = 1.70096
I1018 09:46:49.874802 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.940107 (* 1 = 0.940107 loss)
I1018 09:46:49.874807 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.760854 (* 1 = 0.760854 loss)
I1018 09:46:49.874811 11069 solver.cpp:571] Iteration 8800, lr = 0.001
I1018 09:46:57.381104 11069 solver.cpp:242] Iteration 8820, loss = 0.362375
I1018 09:46:57.381129 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0929377 (* 1 = 0.0929377 loss)
I1018 09:46:57.381134 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269437 (* 1 = 0.269437 loss)
I1018 09:46:57.381137 11069 solver.cpp:571] Iteration 8820, lr = 0.001
I1018 09:47:04.856972 11069 solver.cpp:242] Iteration 8840, loss = 0.666749
I1018 09:47:04.856997 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.130099 (* 1 = 0.130099 loss)
I1018 09:47:04.857002 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.536649 (* 1 = 0.536649 loss)
I1018 09:47:04.857007 11069 solver.cpp:571] Iteration 8840, lr = 0.001
I1018 09:47:12.344506 11069 solver.cpp:242] Iteration 8860, loss = 0.427687
I1018 09:47:12.344532 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.092306 (* 1 = 0.092306 loss)
I1018 09:47:12.344537 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.335381 (* 1 = 0.335381 loss)
I1018 09:47:12.344542 11069 solver.cpp:571] Iteration 8860, lr = 0.001
I1018 09:47:19.904398 11069 solver.cpp:242] Iteration 8880, loss = 0.287796
I1018 09:47:19.904423 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0631418 (* 1 = 0.0631418 loss)
I1018 09:47:19.904428 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224654 (* 1 = 0.224654 loss)
I1018 09:47:19.904431 11069 solver.cpp:571] Iteration 8880, lr = 0.001
I1018 09:47:27.355494 11069 solver.cpp:242] Iteration 8900, loss = 0.75804
I1018 09:47:27.355518 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.238126 (* 1 = 0.238126 loss)
I1018 09:47:27.355522 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.519914 (* 1 = 0.519914 loss)
I1018 09:47:27.355527 11069 solver.cpp:571] Iteration 8900, lr = 0.001
I1018 09:47:34.943400 11069 solver.cpp:242] Iteration 8920, loss = 0.319048
I1018 09:47:34.943424 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116688 (* 1 = 0.116688 loss)
I1018 09:47:34.943429 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.202359 (* 1 = 0.202359 loss)
I1018 09:47:34.943434 11069 solver.cpp:571] Iteration 8920, lr = 0.001
I1018 09:47:42.530853 11069 solver.cpp:242] Iteration 8940, loss = 1.2956
I1018 09:47:42.530877 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.513919 (* 1 = 0.513919 loss)
I1018 09:47:42.530881 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.781684 (* 1 = 0.781684 loss)
I1018 09:47:42.530885 11069 solver.cpp:571] Iteration 8940, lr = 0.001
I1018 09:47:50.051082 11069 solver.cpp:242] Iteration 8960, loss = 0.96113
I1018 09:47:50.051106 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.280581 (* 1 = 0.280581 loss)
I1018 09:47:50.051110 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.680549 (* 1 = 0.680549 loss)
I1018 09:47:50.051115 11069 solver.cpp:571] Iteration 8960, lr = 0.001
I1018 09:47:57.651618 11069 solver.cpp:242] Iteration 8980, loss = 0.428948
I1018 09:47:57.651643 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.110619 (* 1 = 0.110619 loss)
I1018 09:47:57.651648 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.318329 (* 1 = 0.318329 loss)
I1018 09:47:57.651651 11069 solver.cpp:571] Iteration 8980, lr = 0.001
speed: 0.376s / iter
I1018 09:48:05.169778 11069 solver.cpp:242] Iteration 9000, loss = 0.809841
I1018 09:48:05.169803 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.178616 (* 1 = 0.178616 loss)
I1018 09:48:05.169808 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.631225 (* 1 = 0.631225 loss)
I1018 09:48:05.169812 11069 solver.cpp:571] Iteration 9000, lr = 0.001
I1018 09:48:12.661670 11069 solver.cpp:242] Iteration 9020, loss = 0.63654
I1018 09:48:12.661695 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.167604 (* 1 = 0.167604 loss)
I1018 09:48:12.661700 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.468936 (* 1 = 0.468936 loss)
I1018 09:48:12.661703 11069 solver.cpp:571] Iteration 9020, lr = 0.001
I1018 09:48:20.295339 11069 solver.cpp:242] Iteration 9040, loss = 0.360645
I1018 09:48:20.295363 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151531 (* 1 = 0.151531 loss)
I1018 09:48:20.295368 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.209114 (* 1 = 0.209114 loss)
I1018 09:48:20.295372 11069 solver.cpp:571] Iteration 9040, lr = 0.001
I1018 09:48:27.764730 11069 solver.cpp:242] Iteration 9060, loss = 0.400878
I1018 09:48:27.764755 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.174643 (* 1 = 0.174643 loss)
I1018 09:48:27.764760 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.226235 (* 1 = 0.226235 loss)
I1018 09:48:27.764763 11069 solver.cpp:571] Iteration 9060, lr = 0.001
I1018 09:48:35.352435 11069 solver.cpp:242] Iteration 9080, loss = 1.10773
I1018 09:48:35.352460 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.43307 (* 1 = 0.43307 loss)
I1018 09:48:35.352465 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.674655 (* 1 = 0.674655 loss)
I1018 09:48:35.352469 11069 solver.cpp:571] Iteration 9080, lr = 0.001
I1018 09:48:42.831650 11069 solver.cpp:242] Iteration 9100, loss = 0.658808
I1018 09:48:42.831674 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.149323 (* 1 = 0.149323 loss)
I1018 09:48:42.831678 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.509486 (* 1 = 0.509486 loss)
I1018 09:48:42.831682 11069 solver.cpp:571] Iteration 9100, lr = 0.001
I1018 09:48:50.379258 11069 solver.cpp:242] Iteration 9120, loss = 1.18888
I1018 09:48:50.379282 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.357733 (* 1 = 0.357733 loss)
I1018 09:48:50.379287 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.831143 (* 1 = 0.831143 loss)
I1018 09:48:50.379292 11069 solver.cpp:571] Iteration 9120, lr = 0.001
I1018 09:48:57.811663 11069 solver.cpp:242] Iteration 9140, loss = 0.709756
I1018 09:48:57.811688 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.239567 (* 1 = 0.239567 loss)
I1018 09:48:57.811693 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.470189 (* 1 = 0.470189 loss)
I1018 09:48:57.811697 11069 solver.cpp:571] Iteration 9140, lr = 0.001
I1018 09:49:05.425473 11069 solver.cpp:242] Iteration 9160, loss = 0.582783
I1018 09:49:05.425498 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.157333 (* 1 = 0.157333 loss)
I1018 09:49:05.425503 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.425449 (* 1 = 0.425449 loss)
I1018 09:49:05.425508 11069 solver.cpp:571] Iteration 9160, lr = 0.001
I1018 09:49:12.995192 11069 solver.cpp:242] Iteration 9180, loss = 0.172164
I1018 09:49:12.995216 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0406301 (* 1 = 0.0406301 loss)
I1018 09:49:12.995221 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131534 (* 1 = 0.131534 loss)
I1018 09:49:12.995225 11069 solver.cpp:571] Iteration 9180, lr = 0.001
speed: 0.376s / iter
I1018 09:49:20.580194 11069 solver.cpp:242] Iteration 9200, loss = 0.835243
I1018 09:49:20.580220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.192179 (* 1 = 0.192179 loss)
I1018 09:49:20.580224 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.643064 (* 1 = 0.643064 loss)
I1018 09:49:20.580229 11069 solver.cpp:571] Iteration 9200, lr = 0.001
I1018 09:49:28.059219 11069 solver.cpp:242] Iteration 9220, loss = 0.272473
I1018 09:49:28.059243 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0664247 (* 1 = 0.0664247 loss)
I1018 09:49:28.059248 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.206048 (* 1 = 0.206048 loss)
I1018 09:49:28.059253 11069 solver.cpp:571] Iteration 9220, lr = 0.001
I1018 09:49:35.562486 11069 solver.cpp:242] Iteration 9240, loss = 1.61131
I1018 09:49:35.562512 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.799429 (* 1 = 0.799429 loss)
I1018 09:49:35.562516 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.811885 (* 1 = 0.811885 loss)
I1018 09:49:35.562520 11069 solver.cpp:571] Iteration 9240, lr = 0.001
I1018 09:49:43.076952 11069 solver.cpp:242] Iteration 9260, loss = 0.928534
I1018 09:49:43.076977 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.35348 (* 1 = 0.35348 loss)
I1018 09:49:43.076982 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.575054 (* 1 = 0.575054 loss)
I1018 09:49:43.076985 11069 solver.cpp:571] Iteration 9260, lr = 0.001
I1018 09:49:50.701763 11069 solver.cpp:242] Iteration 9280, loss = 1.00379
I1018 09:49:50.701788 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.260478 (* 1 = 0.260478 loss)
I1018 09:49:50.701793 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.743315 (* 1 = 0.743315 loss)
I1018 09:49:50.701797 11069 solver.cpp:571] Iteration 9280, lr = 0.001
I1018 09:49:58.291972 11069 solver.cpp:242] Iteration 9300, loss = 0.792273
I1018 09:49:58.291997 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.309863 (* 1 = 0.309863 loss)
I1018 09:49:58.292001 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.48241 (* 1 = 0.48241 loss)
I1018 09:49:58.292006 11069 solver.cpp:571] Iteration 9300, lr = 0.001
I1018 09:50:05.903326 11069 solver.cpp:242] Iteration 9320, loss = 0.839687
I1018 09:50:05.903350 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.252846 (* 1 = 0.252846 loss)
I1018 09:50:05.903355 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.586841 (* 1 = 0.586841 loss)
I1018 09:50:05.903359 11069 solver.cpp:571] Iteration 9320, lr = 0.001
I1018 09:50:13.416333 11069 solver.cpp:242] Iteration 9340, loss = 0.155195
I1018 09:50:13.416358 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0447417 (* 1 = 0.0447417 loss)
I1018 09:50:13.416363 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.110453 (* 1 = 0.110453 loss)
I1018 09:50:13.416368 11069 solver.cpp:571] Iteration 9340, lr = 0.001
I1018 09:50:20.952692 11069 solver.cpp:242] Iteration 9360, loss = 0.292729
I1018 09:50:20.952716 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0507058 (* 1 = 0.0507058 loss)
I1018 09:50:20.952721 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242023 (* 1 = 0.242023 loss)
I1018 09:50:20.952725 11069 solver.cpp:571] Iteration 9360, lr = 0.001
I1018 09:50:28.490612 11069 solver.cpp:242] Iteration 9380, loss = 0.618917
I1018 09:50:28.490638 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.14852 (* 1 = 0.14852 loss)
I1018 09:50:28.490641 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.470396 (* 1 = 0.470396 loss)
I1018 09:50:28.490646 11069 solver.cpp:571] Iteration 9380, lr = 0.001
speed: 0.376s / iter
I1018 09:50:36.065152 11069 solver.cpp:242] Iteration 9400, loss = 0.841139
I1018 09:50:36.065177 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.256389 (* 1 = 0.256389 loss)
I1018 09:50:36.065181 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.58475 (* 1 = 0.58475 loss)
I1018 09:50:36.065186 11069 solver.cpp:571] Iteration 9400, lr = 0.001
I1018 09:50:43.541426 11069 solver.cpp:242] Iteration 9420, loss = 0.320166
I1018 09:50:43.541451 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0710741 (* 1 = 0.0710741 loss)
I1018 09:50:43.541455 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249092 (* 1 = 0.249092 loss)
I1018 09:50:43.541460 11069 solver.cpp:571] Iteration 9420, lr = 0.001
I1018 09:50:51.035862 11069 solver.cpp:242] Iteration 9440, loss = 0.401254
I1018 09:50:51.035887 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0894498 (* 1 = 0.0894498 loss)
I1018 09:50:51.035892 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.311804 (* 1 = 0.311804 loss)
I1018 09:50:51.035897 11069 solver.cpp:571] Iteration 9440, lr = 0.001
I1018 09:50:58.580376 11069 solver.cpp:242] Iteration 9460, loss = 0.728979
I1018 09:50:58.580401 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.209445 (* 1 = 0.209445 loss)
I1018 09:50:58.580405 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.519535 (* 1 = 0.519535 loss)
I1018 09:50:58.580410 11069 solver.cpp:571] Iteration 9460, lr = 0.001
I1018 09:51:06.006223 11069 solver.cpp:242] Iteration 9480, loss = 0.571976
I1018 09:51:06.006248 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122004 (* 1 = 0.122004 loss)
I1018 09:51:06.006253 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.449972 (* 1 = 0.449972 loss)
I1018 09:51:06.006258 11069 solver.cpp:571] Iteration 9480, lr = 0.001
I1018 09:51:13.624112 11069 solver.cpp:242] Iteration 9500, loss = 1.5241
I1018 09:51:13.624136 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.509732 (* 1 = 0.509732 loss)
I1018 09:51:13.624141 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.01437 (* 1 = 1.01437 loss)
I1018 09:51:13.624145 11069 solver.cpp:571] Iteration 9500, lr = 0.001
I1018 09:51:21.235962 11069 solver.cpp:242] Iteration 9520, loss = 0.989608
I1018 09:51:21.235987 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.381563 (* 1 = 0.381563 loss)
I1018 09:51:21.235991 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.608046 (* 1 = 0.608046 loss)
I1018 09:51:21.235996 11069 solver.cpp:571] Iteration 9520, lr = 0.001
I1018 09:51:28.777413 11069 solver.cpp:242] Iteration 9540, loss = 0.266713
I1018 09:51:28.777438 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0843213 (* 1 = 0.0843213 loss)
I1018 09:51:28.777443 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182391 (* 1 = 0.182391 loss)
I1018 09:51:28.777447 11069 solver.cpp:571] Iteration 9540, lr = 0.001
I1018 09:51:36.297466 11069 solver.cpp:242] Iteration 9560, loss = 1.06115
I1018 09:51:36.297490 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.375644 (* 1 = 0.375644 loss)
I1018 09:51:36.297495 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.685502 (* 1 = 0.685502 loss)
I1018 09:51:36.297499 11069 solver.cpp:571] Iteration 9560, lr = 0.001
I1018 09:51:43.898689 11069 solver.cpp:242] Iteration 9580, loss = 1.0275
I1018 09:51:43.898715 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.367637 (* 1 = 0.367637 loss)
I1018 09:51:43.898720 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.659859 (* 1 = 0.659859 loss)
I1018 09:51:43.898723 11069 solver.cpp:571] Iteration 9580, lr = 0.001
speed: 0.376s / iter
I1018 09:51:51.437377 11069 solver.cpp:242] Iteration 9600, loss = 1.28448
I1018 09:51:51.437403 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.516924 (* 1 = 0.516924 loss)
I1018 09:51:51.437410 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.767554 (* 1 = 0.767554 loss)
I1018 09:51:51.437417 11069 solver.cpp:571] Iteration 9600, lr = 0.001
I1018 09:51:58.958325 11069 solver.cpp:242] Iteration 9620, loss = 0.583972
I1018 09:51:58.958349 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.149272 (* 1 = 0.149272 loss)
I1018 09:51:58.958353 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.4347 (* 1 = 0.4347 loss)
I1018 09:51:58.958358 11069 solver.cpp:571] Iteration 9620, lr = 0.001
I1018 09:52:06.302683 11069 solver.cpp:242] Iteration 9640, loss = 0.830369
I1018 09:52:06.302708 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.280556 (* 1 = 0.280556 loss)
I1018 09:52:06.302712 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.549813 (* 1 = 0.549813 loss)
I1018 09:52:06.302717 11069 solver.cpp:571] Iteration 9640, lr = 0.001
I1018 09:52:13.811975 11069 solver.cpp:242] Iteration 9660, loss = 1.96511
I1018 09:52:13.812000 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.0432 (* 1 = 1.0432 loss)
I1018 09:52:13.812005 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.921916 (* 1 = 0.921916 loss)
I1018 09:52:13.812008 11069 solver.cpp:571] Iteration 9660, lr = 0.001
I1018 09:52:21.322198 11069 solver.cpp:242] Iteration 9680, loss = 0.278016
I1018 09:52:21.322223 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529015 (* 1 = 0.0529015 loss)
I1018 09:52:21.322228 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.225114 (* 1 = 0.225114 loss)
I1018 09:52:21.322232 11069 solver.cpp:571] Iteration 9680, lr = 0.001
I1018 09:52:28.868943 11069 solver.cpp:242] Iteration 9700, loss = 1.75626
I1018 09:52:28.868968 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.819777 (* 1 = 0.819777 loss)
I1018 09:52:28.868973 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.936486 (* 1 = 0.936486 loss)
I1018 09:52:28.868978 11069 solver.cpp:571] Iteration 9700, lr = 0.001
I1018 09:52:36.392705 11069 solver.cpp:242] Iteration 9720, loss = 0.739694
I1018 09:52:36.392731 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.221456 (* 1 = 0.221456 loss)
I1018 09:52:36.392735 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.518237 (* 1 = 0.518237 loss)
I1018 09:52:36.392740 11069 solver.cpp:571] Iteration 9720, lr = 0.001
I1018 09:52:43.906224 11069 solver.cpp:242] Iteration 9740, loss = 0.295879
I1018 09:52:43.906250 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0895326 (* 1 = 0.0895326 loss)
I1018 09:52:43.906255 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.206346 (* 1 = 0.206346 loss)
I1018 09:52:43.906260 11069 solver.cpp:571] Iteration 9740, lr = 0.001
I1018 09:52:51.480123 11069 solver.cpp:242] Iteration 9760, loss = 0.617059
I1018 09:52:51.480146 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.255407 (* 1 = 0.255407 loss)
I1018 09:52:51.480151 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.361652 (* 1 = 0.361652 loss)
I1018 09:52:51.480155 11069 solver.cpp:571] Iteration 9760, lr = 0.001
I1018 09:52:59.007721 11069 solver.cpp:242] Iteration 9780, loss = 0.795784
I1018 09:52:59.007746 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.193627 (* 1 = 0.193627 loss)
I1018 09:52:59.007751 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.602157 (* 1 = 0.602157 loss)
I1018 09:52:59.007755 11069 solver.cpp:571] Iteration 9780, lr = 0.001
speed: 0.376s / iter
I1018 09:53:06.603958 11069 solver.cpp:242] Iteration 9800, loss = 0.474326
I1018 09:53:06.603983 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.129442 (* 1 = 0.129442 loss)
I1018 09:53:06.603987 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.344884 (* 1 = 0.344884 loss)
I1018 09:53:06.603991 11069 solver.cpp:571] Iteration 9800, lr = 0.001
I1018 09:53:14.164851 11069 solver.cpp:242] Iteration 9820, loss = 0.976092
I1018 09:53:14.164876 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.271034 (* 1 = 0.271034 loss)
I1018 09:53:14.164880 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.705058 (* 1 = 0.705058 loss)
I1018 09:53:14.164885 11069 solver.cpp:571] Iteration 9820, lr = 0.001
I1018 09:53:21.547160 11069 solver.cpp:242] Iteration 9840, loss = 0.953882
I1018 09:53:21.547185 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.315633 (* 1 = 0.315633 loss)
I1018 09:53:21.547189 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.638249 (* 1 = 0.638249 loss)
I1018 09:53:21.547194 11069 solver.cpp:571] Iteration 9840, lr = 0.001
I1018 09:53:29.069746 11069 solver.cpp:242] Iteration 9860, loss = 0.377805
I1018 09:53:29.069771 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122673 (* 1 = 0.122673 loss)
I1018 09:53:29.069775 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.255132 (* 1 = 0.255132 loss)
I1018 09:53:29.069779 11069 solver.cpp:571] Iteration 9860, lr = 0.001
I1018 09:53:36.590591 11069 solver.cpp:242] Iteration 9880, loss = 0.321507
I1018 09:53:36.590615 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0904258 (* 1 = 0.0904258 loss)
I1018 09:53:36.590620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231081 (* 1 = 0.231081 loss)
I1018 09:53:36.590625 11069 solver.cpp:571] Iteration 9880, lr = 0.001
I1018 09:53:44.172605 11069 solver.cpp:242] Iteration 9900, loss = 0.258831
I1018 09:53:44.172626 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0745805 (* 1 = 0.0745805 loss)
I1018 09:53:44.172631 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.184251 (* 1 = 0.184251 loss)
I1018 09:53:44.172634 11069 solver.cpp:571] Iteration 9900, lr = 0.001
I1018 09:53:51.640689 11069 solver.cpp:242] Iteration 9920, loss = 0.947595
I1018 09:53:51.640713 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.216682 (* 1 = 0.216682 loss)
I1018 09:53:51.640717 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.730912 (* 1 = 0.730912 loss)
I1018 09:53:51.640722 11069 solver.cpp:571] Iteration 9920, lr = 0.001
I1018 09:53:59.204377 11069 solver.cpp:242] Iteration 9940, loss = 0.354605
I1018 09:53:59.204401 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0785909 (* 1 = 0.0785909 loss)
I1018 09:53:59.204406 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.276014 (* 1 = 0.276014 loss)
I1018 09:53:59.204411 11069 solver.cpp:571] Iteration 9940, lr = 0.001
I1018 09:54:06.643905 11069 solver.cpp:242] Iteration 9960, loss = 0.156872
I1018 09:54:06.643930 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0387126 (* 1 = 0.0387126 loss)
I1018 09:54:06.643935 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.11816 (* 1 = 0.11816 loss)
I1018 09:54:06.643939 11069 solver.cpp:571] Iteration 9960, lr = 0.001
I1018 09:54:14.168962 11069 solver.cpp:242] Iteration 9980, loss = 0.517515
I1018 09:54:14.168985 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206272 (* 1 = 0.206272 loss)
I1018 09:54:14.168990 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.311243 (* 1 = 0.311243 loss)
I1018 09:54:14.168994 11069 solver.cpp:571] Iteration 9980, lr = 0.001
speed: 0.376s / iter
Wrote snapshot to: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_fast_rcnn_stage2_iter_10000.caffemodel
I1018 09:54:22.941195 11069 solver.cpp:242] Iteration 10000, loss = 0.705973
I1018 09:54:22.941220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.295742 (* 1 = 0.295742 loss)
I1018 09:54:22.941226 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.410231 (* 1 = 0.410231 loss)
I1018 09:54:22.941229 11069 solver.cpp:571] Iteration 10000, lr = 0.001
I1018 09:54:30.183629 11069 solver.cpp:242] Iteration 10020, loss = 0.487684
I1018 09:54:30.183652 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.124249 (* 1 = 0.124249 loss)
I1018 09:54:30.183656 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.363435 (* 1 = 0.363435 loss)
I1018 09:54:30.183660 11069 solver.cpp:571] Iteration 10020, lr = 0.001
I1018 09:54:37.611827 11069 solver.cpp:242] Iteration 10040, loss = 1.51475
I1018 09:54:37.611852 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.522308 (* 1 = 0.522308 loss)
I1018 09:54:37.611856 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.992438 (* 1 = 0.992438 loss)
I1018 09:54:37.611860 11069 solver.cpp:571] Iteration 10040, lr = 0.001
I1018 09:54:45.064399 11069 solver.cpp:242] Iteration 10060, loss = 1.05387
I1018 09:54:45.064424 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.220463 (* 1 = 0.220463 loss)
I1018 09:54:45.064429 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.833406 (* 1 = 0.833406 loss)
I1018 09:54:45.064432 11069 solver.cpp:571] Iteration 10060, lr = 0.001
I1018 09:54:52.538085 11069 solver.cpp:242] Iteration 10080, loss = 0.17483
I1018 09:54:52.538110 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0534159 (* 1 = 0.0534159 loss)
I1018 09:54:52.538115 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.121414 (* 1 = 0.121414 loss)
I1018 09:54:52.538120 11069 solver.cpp:571] Iteration 10080, lr = 0.001
I1018 09:55:00.090962 11069 solver.cpp:242] Iteration 10100, loss = 0.76191
I1018 09:55:00.090986 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.230084 (* 1 = 0.230084 loss)
I1018 09:55:00.090991 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.531826 (* 1 = 0.531826 loss)
I1018 09:55:00.090996 11069 solver.cpp:571] Iteration 10100, lr = 0.001
I1018 09:55:07.560600 11069 solver.cpp:242] Iteration 10120, loss = 0.446642
I1018 09:55:07.560624 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.133742 (* 1 = 0.133742 loss)
I1018 09:55:07.560629 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3129 (* 1 = 0.3129 loss)
I1018 09:55:07.560633 11069 solver.cpp:571] Iteration 10120, lr = 0.001
I1018 09:55:15.045740 11069 solver.cpp:242] Iteration 10140, loss = 0.30593
I1018 09:55:15.045766 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0637727 (* 1 = 0.0637727 loss)
I1018 09:55:15.045771 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242157 (* 1 = 0.242157 loss)
I1018 09:55:15.045775 11069 solver.cpp:571] Iteration 10140, lr = 0.001
I1018 09:55:22.638111 11069 solver.cpp:242] Iteration 10160, loss = 1.02767
I1018 09:55:22.638136 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.363403 (* 1 = 0.363403 loss)
I1018 09:55:22.638141 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664269 (* 1 = 0.664269 loss)
I1018 09:55:22.638145 11069 solver.cpp:571] Iteration 10160, lr = 0.001
I1018 09:55:30.164186 11069 solver.cpp:242] Iteration 10180, loss = 0.247517
I1018 09:55:30.164211 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0609758 (* 1 = 0.0609758 loss)
I1018 09:55:30.164214 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.186541 (* 1 = 0.186541 loss)
I1018 09:55:30.164219 11069 solver.cpp:571] Iteration 10180, lr = 0.001
speed: 0.376s / iter
I1018 09:55:37.661847 11069 solver.cpp:242] Iteration 10200, loss = 1.21454
I1018 09:55:37.661871 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.370805 (* 1 = 0.370805 loss)
I1018 09:55:37.661876 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.843739 (* 1 = 0.843739 loss)
I1018 09:55:37.661880 11069 solver.cpp:571] Iteration 10200, lr = 0.001
I1018 09:55:45.162421 11069 solver.cpp:242] Iteration 10220, loss = 1.16676
I1018 09:55:45.162446 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.389669 (* 1 = 0.389669 loss)
I1018 09:55:45.162451 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.777091 (* 1 = 0.777091 loss)
I1018 09:55:45.162454 11069 solver.cpp:571] Iteration 10220, lr = 0.001
I1018 09:55:52.763016 11069 solver.cpp:242] Iteration 10240, loss = 0.466567
I1018 09:55:52.763041 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0967954 (* 1 = 0.0967954 loss)
I1018 09:55:52.763046 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.369771 (* 1 = 0.369771 loss)
I1018 09:55:52.763051 11069 solver.cpp:571] Iteration 10240, lr = 0.001
I1018 09:56:00.276391 11069 solver.cpp:242] Iteration 10260, loss = 0.647922
I1018 09:56:00.276414 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.20869 (* 1 = 0.20869 loss)
I1018 09:56:00.276419 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.439232 (* 1 = 0.439232 loss)
I1018 09:56:00.276423 11069 solver.cpp:571] Iteration 10260, lr = 0.001
I1018 09:56:07.859994 11069 solver.cpp:242] Iteration 10280, loss = 0.317412
I1018 09:56:07.860019 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0682891 (* 1 = 0.0682891 loss)
I1018 09:56:07.860023 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249123 (* 1 = 0.249123 loss)
I1018 09:56:07.860028 11069 solver.cpp:571] Iteration 10280, lr = 0.001
I1018 09:56:15.260494 11069 solver.cpp:242] Iteration 10300, loss = 0.947989
I1018 09:56:15.260519 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.319698 (* 1 = 0.319698 loss)
I1018 09:56:15.260524 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.628291 (* 1 = 0.628291 loss)
I1018 09:56:15.260527 11069 solver.cpp:571] Iteration 10300, lr = 0.001
I1018 09:56:22.849195 11069 solver.cpp:242] Iteration 10320, loss = 1.592
I1018 09:56:22.849218 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.525368 (* 1 = 0.525368 loss)
I1018 09:56:22.849222 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.06663 (* 1 = 1.06663 loss)
I1018 09:56:22.849227 11069 solver.cpp:571] Iteration 10320, lr = 0.001
I1018 09:56:30.374459 11069 solver.cpp:242] Iteration 10340, loss = 1.53446
I1018 09:56:30.374485 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.724552 (* 1 = 0.724552 loss)
I1018 09:56:30.374488 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.809912 (* 1 = 0.809912 loss)
I1018 09:56:30.374493 11069 solver.cpp:571] Iteration 10340, lr = 0.001
I1018 09:56:37.911428 11069 solver.cpp:242] Iteration 10360, loss = 1.18347
I1018 09:56:37.911453 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.40424 (* 1 = 0.40424 loss)
I1018 09:56:37.911458 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.779226 (* 1 = 0.779226 loss)
I1018 09:56:37.911461 11069 solver.cpp:571] Iteration 10360, lr = 0.001
I1018 09:56:45.485100 11069 solver.cpp:242] Iteration 10380, loss = 0.428452
I1018 09:56:45.485126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.15192 (* 1 = 0.15192 loss)
I1018 09:56:45.485129 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.276532 (* 1 = 0.276532 loss)
I1018 09:56:45.485133 11069 solver.cpp:571] Iteration 10380, lr = 0.001
speed: 0.376s / iter
I1018 09:56:52.918462 11069 solver.cpp:242] Iteration 10400, loss = 0.407044
I1018 09:56:52.918488 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0796113 (* 1 = 0.0796113 loss)
I1018 09:56:52.918491 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.327432 (* 1 = 0.327432 loss)
I1018 09:56:52.918495 11069 solver.cpp:571] Iteration 10400, lr = 0.001
I1018 09:57:00.465239 11069 solver.cpp:242] Iteration 10420, loss = 0.375811
I1018 09:57:00.465263 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0817999 (* 1 = 0.0817999 loss)
I1018 09:57:00.465268 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.294011 (* 1 = 0.294011 loss)
I1018 09:57:00.465272 11069 solver.cpp:571] Iteration 10420, lr = 0.001
I1018 09:57:08.085481 11069 solver.cpp:242] Iteration 10440, loss = 0.391852
I1018 09:57:08.085507 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0957667 (* 1 = 0.0957667 loss)
I1018 09:57:08.085512 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296085 (* 1 = 0.296085 loss)
I1018 09:57:08.085516 11069 solver.cpp:571] Iteration 10440, lr = 0.001
I1018 09:57:15.554239 11069 solver.cpp:242] Iteration 10460, loss = 0.401279
I1018 09:57:15.554265 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108866 (* 1 = 0.108866 loss)
I1018 09:57:15.554270 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.292413 (* 1 = 0.292413 loss)
I1018 09:57:15.554273 11069 solver.cpp:571] Iteration 10460, lr = 0.001
I1018 09:57:23.061823 11069 solver.cpp:242] Iteration 10480, loss = 0.779588
I1018 09:57:23.061848 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137228 (* 1 = 0.137228 loss)
I1018 09:57:23.061852 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.642361 (* 1 = 0.642361 loss)
I1018 09:57:23.061856 11069 solver.cpp:571] Iteration 10480, lr = 0.001
I1018 09:57:30.568619 11069 solver.cpp:242] Iteration 10500, loss = 0.181757
I1018 09:57:30.568644 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0551176 (* 1 = 0.0551176 loss)
I1018 09:57:30.568648 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126639 (* 1 = 0.126639 loss)
I1018 09:57:30.568651 11069 solver.cpp:571] Iteration 10500, lr = 0.001
I1018 09:57:38.025657 11069 solver.cpp:242] Iteration 10520, loss = 1.19102
I1018 09:57:38.025682 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.460375 (* 1 = 0.460375 loss)
I1018 09:57:38.025686 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.730646 (* 1 = 0.730646 loss)
I1018 09:57:38.025691 11069 solver.cpp:571] Iteration 10520, lr = 0.001
I1018 09:57:45.545202 11069 solver.cpp:242] Iteration 10540, loss = 0.683944
I1018 09:57:45.545227 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.219973 (* 1 = 0.219973 loss)
I1018 09:57:45.545230 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.463971 (* 1 = 0.463971 loss)
I1018 09:57:45.545234 11069 solver.cpp:571] Iteration 10540, lr = 0.001
I1018 09:57:53.081796 11069 solver.cpp:242] Iteration 10560, loss = 0.309346
I1018 09:57:53.081821 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0772107 (* 1 = 0.0772107 loss)
I1018 09:57:53.081826 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232135 (* 1 = 0.232135 loss)
I1018 09:57:53.081830 11069 solver.cpp:571] Iteration 10560, lr = 0.001
I1018 09:58:00.601806 11069 solver.cpp:242] Iteration 10580, loss = 1.19409
I1018 09:58:00.601827 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.471467 (* 1 = 0.471467 loss)
I1018 09:58:00.601832 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.722627 (* 1 = 0.722627 loss)
I1018 09:58:00.601836 11069 solver.cpp:571] Iteration 10580, lr = 0.001
speed: 0.376s / iter
I1018 09:58:08.239994 11069 solver.cpp:242] Iteration 10600, loss = 0.186967
I1018 09:58:08.240020 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0386684 (* 1 = 0.0386684 loss)
I1018 09:58:08.240025 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148299 (* 1 = 0.148299 loss)
I1018 09:58:08.240028 11069 solver.cpp:571] Iteration 10600, lr = 0.001
I1018 09:58:15.574637 11069 solver.cpp:242] Iteration 10620, loss = 0.47526
I1018 09:58:15.574662 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.131463 (* 1 = 0.131463 loss)
I1018 09:58:15.574666 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.343798 (* 1 = 0.343798 loss)
I1018 09:58:15.574671 11069 solver.cpp:571] Iteration 10620, lr = 0.001
I1018 09:58:23.033843 11069 solver.cpp:242] Iteration 10640, loss = 0.540653
I1018 09:58:23.033866 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104216 (* 1 = 0.104216 loss)
I1018 09:58:23.033871 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.436437 (* 1 = 0.436437 loss)
I1018 09:58:23.033875 11069 solver.cpp:571] Iteration 10640, lr = 0.001
I1018 09:58:30.612251 11069 solver.cpp:242] Iteration 10660, loss = 0.514108
I1018 09:58:30.612275 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.172919 (* 1 = 0.172919 loss)
I1018 09:58:30.612280 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.341189 (* 1 = 0.341189 loss)
I1018 09:58:30.612284 11069 solver.cpp:571] Iteration 10660, lr = 0.001
I1018 09:58:38.134209 11069 solver.cpp:242] Iteration 10680, loss = 0.361917
I1018 09:58:38.134234 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0663217 (* 1 = 0.0663217 loss)
I1018 09:58:38.134239 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.295596 (* 1 = 0.295596 loss)
I1018 09:58:38.134243 11069 solver.cpp:571] Iteration 10680, lr = 0.001
I1018 09:58:45.573860 11069 solver.cpp:242] Iteration 10700, loss = 0.595124
I1018 09:58:45.573885 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200998 (* 1 = 0.200998 loss)
I1018 09:58:45.573890 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.394126 (* 1 = 0.394126 loss)
I1018 09:58:45.573894 11069 solver.cpp:571] Iteration 10700, lr = 0.001
I1018 09:58:53.128793 11069 solver.cpp:242] Iteration 10720, loss = 0.620867
I1018 09:58:53.128818 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.202894 (* 1 = 0.202894 loss)
I1018 09:58:53.128821 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.417973 (* 1 = 0.417973 loss)
I1018 09:58:53.128825 11069 solver.cpp:571] Iteration 10720, lr = 0.001
I1018 09:59:00.634172 11069 solver.cpp:242] Iteration 10740, loss = 0.368605
I1018 09:59:00.634197 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123335 (* 1 = 0.123335 loss)
I1018 09:59:00.634202 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.24527 (* 1 = 0.24527 loss)
I1018 09:59:00.634207 11069 solver.cpp:571] Iteration 10740, lr = 0.001
I1018 09:59:08.161144 11069 solver.cpp:242] Iteration 10760, loss = 1.12048
I1018 09:59:08.161169 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.368745 (* 1 = 0.368745 loss)
I1018 09:59:08.161173 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.751733 (* 1 = 0.751733 loss)
I1018 09:59:08.161177 11069 solver.cpp:571] Iteration 10760, lr = 0.001
I1018 09:59:15.663544 11069 solver.cpp:242] Iteration 10780, loss = 0.163471
I1018 09:59:15.663569 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0276055 (* 1 = 0.0276055 loss)
I1018 09:59:15.663573 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.135866 (* 1 = 0.135866 loss)
I1018 09:59:15.663578 11069 solver.cpp:571] Iteration 10780, lr = 0.001
speed: 0.376s / iter
I1018 09:59:23.223881 11069 solver.cpp:242] Iteration 10800, loss = 0.337651
I1018 09:59:23.223906 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0692014 (* 1 = 0.0692014 loss)
I1018 09:59:23.223911 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.26845 (* 1 = 0.26845 loss)
I1018 09:59:23.223914 11069 solver.cpp:571] Iteration 10800, lr = 0.001
I1018 09:59:30.678298 11069 solver.cpp:242] Iteration 10820, loss = 0.168168
I1018 09:59:30.678323 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0349998 (* 1 = 0.0349998 loss)
I1018 09:59:30.678328 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133168 (* 1 = 0.133168 loss)
I1018 09:59:30.678331 11069 solver.cpp:571] Iteration 10820, lr = 0.001
I1018 09:59:38.264191 11069 solver.cpp:242] Iteration 10840, loss = 0.522814
I1018 09:59:38.264215 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159746 (* 1 = 0.159746 loss)
I1018 09:59:38.264219 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.363069 (* 1 = 0.363069 loss)
I1018 09:59:38.264225 11069 solver.cpp:571] Iteration 10840, lr = 0.001
I1018 09:59:45.719214 11069 solver.cpp:242] Iteration 10860, loss = 0.36346
I1018 09:59:45.719239 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0782623 (* 1 = 0.0782623 loss)
I1018 09:59:45.719244 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.285198 (* 1 = 0.285198 loss)
I1018 09:59:45.719247 11069 solver.cpp:571] Iteration 10860, lr = 0.001
I1018 09:59:53.272467 11069 solver.cpp:242] Iteration 10880, loss = 1.78418
I1018 09:59:53.272492 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.739945 (* 1 = 0.739945 loss)
I1018 09:59:53.272497 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.04424 (* 1 = 1.04424 loss)
I1018 09:59:53.272501 11069 solver.cpp:571] Iteration 10880, lr = 0.001
I1018 10:00:00.656499 11069 solver.cpp:242] Iteration 10900, loss = 0.654583
I1018 10:00:00.656523 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.189158 (* 1 = 0.189158 loss)
I1018 10:00:00.656528 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.465426 (* 1 = 0.465426 loss)
I1018 10:00:00.656533 11069 solver.cpp:571] Iteration 10900, lr = 0.001
I1018 10:00:08.146884 11069 solver.cpp:242] Iteration 10920, loss = 0.278236
I1018 10:00:08.146910 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0620672 (* 1 = 0.0620672 loss)
I1018 10:00:08.146915 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216169 (* 1 = 0.216169 loss)
I1018 10:00:08.146919 11069 solver.cpp:571] Iteration 10920, lr = 0.001
I1018 10:00:15.653645 11069 solver.cpp:242] Iteration 10940, loss = 0.486693
I1018 10:00:15.653669 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.146076 (* 1 = 0.146076 loss)
I1018 10:00:15.653674 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.340617 (* 1 = 0.340617 loss)
I1018 10:00:15.653678 11069 solver.cpp:571] Iteration 10940, lr = 0.001
I1018 10:00:23.094542 11069 solver.cpp:242] Iteration 10960, loss = 0.654224
I1018 10:00:23.094566 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164816 (* 1 = 0.164816 loss)
I1018 10:00:23.094571 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.489408 (* 1 = 0.489408 loss)
I1018 10:00:23.094575 11069 solver.cpp:571] Iteration 10960, lr = 0.001
I1018 10:00:30.622711 11069 solver.cpp:242] Iteration 10980, loss = 0.522746
I1018 10:00:30.622736 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142615 (* 1 = 0.142615 loss)
I1018 10:00:30.622741 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.380131 (* 1 = 0.380131 loss)
I1018 10:00:30.622745 11069 solver.cpp:571] Iteration 10980, lr = 0.001
speed: 0.376s / iter
I1018 10:00:38.150281 11069 solver.cpp:242] Iteration 11000, loss = 0.563139
I1018 10:00:38.150306 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13415 (* 1 = 0.13415 loss)
I1018 10:00:38.150311 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.42899 (* 1 = 0.42899 loss)
I1018 10:00:38.150315 11069 solver.cpp:571] Iteration 11000, lr = 0.001
I1018 10:00:45.597659 11069 solver.cpp:242] Iteration 11020, loss = 1.05833
I1018 10:00:45.597683 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.45625 (* 1 = 0.45625 loss)
I1018 10:00:45.597688 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.602084 (* 1 = 0.602084 loss)
I1018 10:00:45.597692 11069 solver.cpp:571] Iteration 11020, lr = 0.001
I1018 10:00:53.124582 11069 solver.cpp:242] Iteration 11040, loss = 0.849217
I1018 10:00:53.124606 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.343574 (* 1 = 0.343574 loss)
I1018 10:00:53.124611 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.505644 (* 1 = 0.505644 loss)
I1018 10:00:53.124615 11069 solver.cpp:571] Iteration 11040, lr = 0.001
I1018 10:01:00.648326 11069 solver.cpp:242] Iteration 11060, loss = 0.655842
I1018 10:01:00.648351 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.182274 (* 1 = 0.182274 loss)
I1018 10:01:00.648355 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473568 (* 1 = 0.473568 loss)
I1018 10:01:00.648360 11069 solver.cpp:571] Iteration 11060, lr = 0.001
I1018 10:01:08.170024 11069 solver.cpp:242] Iteration 11080, loss = 0.275204
I1018 10:01:08.170049 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0745447 (* 1 = 0.0745447 loss)
I1018 10:01:08.170054 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.200659 (* 1 = 0.200659 loss)
I1018 10:01:08.170058 11069 solver.cpp:571] Iteration 11080, lr = 0.001
I1018 10:01:15.649338 11069 solver.cpp:242] Iteration 11100, loss = 1.30286
I1018 10:01:15.649363 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.568229 (* 1 = 0.568229 loss)
I1018 10:01:15.649369 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.734626 (* 1 = 0.734626 loss)
I1018 10:01:15.649372 11069 solver.cpp:571] Iteration 11100, lr = 0.001
I1018 10:01:23.168134 11069 solver.cpp:242] Iteration 11120, loss = 0.628868
I1018 10:01:23.168160 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.232043 (* 1 = 0.232043 loss)
I1018 10:01:23.168164 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.396825 (* 1 = 0.396825 loss)
I1018 10:01:23.168169 11069 solver.cpp:571] Iteration 11120, lr = 0.001
I1018 10:01:30.744674 11069 solver.cpp:242] Iteration 11140, loss = 0.228105
I1018 10:01:30.744699 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.043572 (* 1 = 0.043572 loss)
I1018 10:01:30.744704 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.184533 (* 1 = 0.184533 loss)
I1018 10:01:30.744707 11069 solver.cpp:571] Iteration 11140, lr = 0.001
I1018 10:01:38.305049 11069 solver.cpp:242] Iteration 11160, loss = 0.319353
I1018 10:01:38.305074 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0663923 (* 1 = 0.0663923 loss)
I1018 10:01:38.305078 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.25296 (* 1 = 0.25296 loss)
I1018 10:01:38.305083 11069 solver.cpp:571] Iteration 11160, lr = 0.001
I1018 10:01:45.894521 11069 solver.cpp:242] Iteration 11180, loss = 0.413191
I1018 10:01:45.894546 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.111484 (* 1 = 0.111484 loss)
I1018 10:01:45.894551 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.301707 (* 1 = 0.301707 loss)
I1018 10:01:45.894554 11069 solver.cpp:571] Iteration 11180, lr = 0.001
speed: 0.376s / iter
I1018 10:01:53.418673 11069 solver.cpp:242] Iteration 11200, loss = 0.923701
I1018 10:01:53.418697 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.321963 (* 1 = 0.321963 loss)
I1018 10:01:53.418702 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.601738 (* 1 = 0.601738 loss)
I1018 10:01:53.418706 11069 solver.cpp:571] Iteration 11200, lr = 0.001
I1018 10:02:00.956773 11069 solver.cpp:242] Iteration 11220, loss = 0.220868
I1018 10:02:00.956800 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0508076 (* 1 = 0.0508076 loss)
I1018 10:02:00.956805 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.17006 (* 1 = 0.17006 loss)
I1018 10:02:00.956809 11069 solver.cpp:571] Iteration 11220, lr = 0.001
I1018 10:02:08.474963 11069 solver.cpp:242] Iteration 11240, loss = 1.76053
I1018 10:02:08.474988 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.710508 (* 1 = 0.710508 loss)
I1018 10:02:08.474992 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.05002 (* 1 = 1.05002 loss)
I1018 10:02:08.474997 11069 solver.cpp:571] Iteration 11240, lr = 0.001
I1018 10:02:15.976267 11069 solver.cpp:242] Iteration 11260, loss = 1.95813
I1018 10:02:15.976292 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.862082 (* 1 = 0.862082 loss)
I1018 10:02:15.976297 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.09605 (* 1 = 1.09605 loss)
I1018 10:02:15.976301 11069 solver.cpp:571] Iteration 11260, lr = 0.001
I1018 10:02:23.510994 11069 solver.cpp:242] Iteration 11280, loss = 0.713801
I1018 10:02:23.511020 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.270527 (* 1 = 0.270527 loss)
I1018 10:02:23.511024 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.443274 (* 1 = 0.443274 loss)
I1018 10:02:23.511029 11069 solver.cpp:571] Iteration 11280, lr = 0.001
I1018 10:02:31.004279 11069 solver.cpp:242] Iteration 11300, loss = 0.513151
I1018 10:02:31.004304 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113146 (* 1 = 0.113146 loss)
I1018 10:02:31.004308 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.400005 (* 1 = 0.400005 loss)
I1018 10:02:31.004312 11069 solver.cpp:571] Iteration 11300, lr = 0.001
I1018 10:02:38.537540 11069 solver.cpp:242] Iteration 11320, loss = 1.17456
I1018 10:02:38.537565 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.432135 (* 1 = 0.432135 loss)
I1018 10:02:38.537570 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.742427 (* 1 = 0.742427 loss)
I1018 10:02:38.537575 11069 solver.cpp:571] Iteration 11320, lr = 0.001
I1018 10:02:46.071259 11069 solver.cpp:242] Iteration 11340, loss = 0.919785
I1018 10:02:46.071285 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206017 (* 1 = 0.206017 loss)
I1018 10:02:46.071288 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.713769 (* 1 = 0.713769 loss)
I1018 10:02:46.071293 11069 solver.cpp:571] Iteration 11340, lr = 0.001
I1018 10:02:53.558229 11069 solver.cpp:242] Iteration 11360, loss = 0.865856
I1018 10:02:53.558255 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.26244 (* 1 = 0.26244 loss)
I1018 10:02:53.558259 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.603416 (* 1 = 0.603416 loss)
I1018 10:02:53.558264 11069 solver.cpp:571] Iteration 11360, lr = 0.001
I1018 10:03:01.066984 11069 solver.cpp:242] Iteration 11380, loss = 0.336509
I1018 10:03:01.067008 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0436056 (* 1 = 0.0436056 loss)
I1018 10:03:01.067013 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.292903 (* 1 = 0.292903 loss)
I1018 10:03:01.067018 11069 solver.cpp:571] Iteration 11380, lr = 0.001
speed: 0.376s / iter
I1018 10:03:08.466853 11069 solver.cpp:242] Iteration 11400, loss = 0.436992
I1018 10:03:08.466878 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.141901 (* 1 = 0.141901 loss)
I1018 10:03:08.466883 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.29509 (* 1 = 0.29509 loss)
I1018 10:03:08.466887 11069 solver.cpp:571] Iteration 11400, lr = 0.001
I1018 10:03:16.096365 11069 solver.cpp:242] Iteration 11420, loss = 1.1662
I1018 10:03:16.096390 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.271626 (* 1 = 0.271626 loss)
I1018 10:03:16.096395 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.894573 (* 1 = 0.894573 loss)
I1018 10:03:16.096398 11069 solver.cpp:571] Iteration 11420, lr = 0.001
I1018 10:03:23.702520 11069 solver.cpp:242] Iteration 11440, loss = 0.285619
I1018 10:03:23.702546 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0716325 (* 1 = 0.0716325 loss)
I1018 10:03:23.702550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.213987 (* 1 = 0.213987 loss)
I1018 10:03:23.702554 11069 solver.cpp:571] Iteration 11440, lr = 0.001
I1018 10:03:31.210002 11069 solver.cpp:242] Iteration 11460, loss = 0.822249
I1018 10:03:31.210026 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.253422 (* 1 = 0.253422 loss)
I1018 10:03:31.210031 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.568827 (* 1 = 0.568827 loss)
I1018 10:03:31.210034 11069 solver.cpp:571] Iteration 11460, lr = 0.001
I1018 10:03:38.622917 11069 solver.cpp:242] Iteration 11480, loss = 1.05384
I1018 10:03:38.622942 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.309972 (* 1 = 0.309972 loss)
I1018 10:03:38.622946 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.743868 (* 1 = 0.743868 loss)
I1018 10:03:38.622951 11069 solver.cpp:571] Iteration 11480, lr = 0.001
I1018 10:03:46.102066 11069 solver.cpp:242] Iteration 11500, loss = 1.7622
I1018 10:03:46.102092 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.834435 (* 1 = 0.834435 loss)
I1018 10:03:46.102095 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.927769 (* 1 = 0.927769 loss)
I1018 10:03:46.102099 11069 solver.cpp:571] Iteration 11500, lr = 0.001
I1018 10:03:53.624384 11069 solver.cpp:242] Iteration 11520, loss = 0.286022
I1018 10:03:53.624409 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0776235 (* 1 = 0.0776235 loss)
I1018 10:03:53.624414 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208398 (* 1 = 0.208398 loss)
I1018 10:03:53.624418 11069 solver.cpp:571] Iteration 11520, lr = 0.001
I1018 10:04:01.110608 11069 solver.cpp:242] Iteration 11540, loss = 1.50776
I1018 10:04:01.110633 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.708175 (* 1 = 0.708175 loss)
I1018 10:04:01.110637 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.799588 (* 1 = 0.799588 loss)
I1018 10:04:01.110641 11069 solver.cpp:571] Iteration 11540, lr = 0.001
I1018 10:04:08.637763 11069 solver.cpp:242] Iteration 11560, loss = 0.282972
I1018 10:04:08.637787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103684 (* 1 = 0.103684 loss)
I1018 10:04:08.637792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179288 (* 1 = 0.179288 loss)
I1018 10:04:08.637796 11069 solver.cpp:571] Iteration 11560, lr = 0.001
I1018 10:04:16.078131 11069 solver.cpp:242] Iteration 11580, loss = 0.153606
I1018 10:04:16.078155 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.039204 (* 1 = 0.039204 loss)
I1018 10:04:16.078161 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.114402 (* 1 = 0.114402 loss)
I1018 10:04:16.078164 11069 solver.cpp:571] Iteration 11580, lr = 0.001
speed: 0.376s / iter
I1018 10:04:23.594985 11069 solver.cpp:242] Iteration 11600, loss = 0.620368
I1018 10:04:23.595010 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181862 (* 1 = 0.181862 loss)
I1018 10:04:23.595015 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.438507 (* 1 = 0.438507 loss)
I1018 10:04:23.595019 11069 solver.cpp:571] Iteration 11600, lr = 0.001
I1018 10:04:31.089912 11069 solver.cpp:242] Iteration 11620, loss = 0.829393
I1018 10:04:31.089937 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.229272 (* 1 = 0.229272 loss)
I1018 10:04:31.089942 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.600121 (* 1 = 0.600121 loss)
I1018 10:04:31.089946 11069 solver.cpp:571] Iteration 11620, lr = 0.001
I1018 10:04:38.625344 11069 solver.cpp:242] Iteration 11640, loss = 0.533334
I1018 10:04:38.625370 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143077 (* 1 = 0.143077 loss)
I1018 10:04:38.625373 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.390257 (* 1 = 0.390257 loss)
I1018 10:04:38.625377 11069 solver.cpp:571] Iteration 11640, lr = 0.001
I1018 10:04:46.077201 11069 solver.cpp:242] Iteration 11660, loss = 0.182638
I1018 10:04:46.077226 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0334983 (* 1 = 0.0334983 loss)
I1018 10:04:46.077231 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.14914 (* 1 = 0.14914 loss)
I1018 10:04:46.077235 11069 solver.cpp:571] Iteration 11660, lr = 0.001
I1018 10:04:53.544387 11069 solver.cpp:242] Iteration 11680, loss = 0.370674
I1018 10:04:53.544412 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0789485 (* 1 = 0.0789485 loss)
I1018 10:04:53.544417 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.291726 (* 1 = 0.291726 loss)
I1018 10:04:53.544421 11069 solver.cpp:571] Iteration 11680, lr = 0.001
I1018 10:05:01.085477 11069 solver.cpp:242] Iteration 11700, loss = 0.706819
I1018 10:05:01.085502 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.220996 (* 1 = 0.220996 loss)
I1018 10:05:01.085506 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.485823 (* 1 = 0.485823 loss)
I1018 10:05:01.085510 11069 solver.cpp:571] Iteration 11700, lr = 0.001
I1018 10:05:08.556506 11069 solver.cpp:242] Iteration 11720, loss = 0.435831
I1018 10:05:08.556530 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0975291 (* 1 = 0.0975291 loss)
I1018 10:05:08.556535 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.338302 (* 1 = 0.338302 loss)
I1018 10:05:08.556540 11069 solver.cpp:571] Iteration 11720, lr = 0.001
I1018 10:05:15.982579 11069 solver.cpp:242] Iteration 11740, loss = 0.373187
I1018 10:05:15.982604 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108568 (* 1 = 0.108568 loss)
I1018 10:05:15.982609 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264619 (* 1 = 0.264619 loss)
I1018 10:05:15.982614 11069 solver.cpp:571] Iteration 11740, lr = 0.001
I1018 10:05:23.457718 11069 solver.cpp:242] Iteration 11760, loss = 0.420969
I1018 10:05:23.457744 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.125862 (* 1 = 0.125862 loss)
I1018 10:05:23.457749 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.295107 (* 1 = 0.295107 loss)
I1018 10:05:23.457753 11069 solver.cpp:571] Iteration 11760, lr = 0.001
I1018 10:05:30.958075 11069 solver.cpp:242] Iteration 11780, loss = 0.770501
I1018 10:05:30.958098 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.149335 (* 1 = 0.149335 loss)
I1018 10:05:30.958103 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.621166 (* 1 = 0.621166 loss)
I1018 10:05:30.958107 11069 solver.cpp:571] Iteration 11780, lr = 0.001
speed: 0.376s / iter
I1018 10:05:38.433701 11069 solver.cpp:242] Iteration 11800, loss = 0.343622
I1018 10:05:38.433725 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0962094 (* 1 = 0.0962094 loss)
I1018 10:05:38.433730 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.247413 (* 1 = 0.247413 loss)
I1018 10:05:38.433734 11069 solver.cpp:571] Iteration 11800, lr = 0.001
I1018 10:05:45.957571 11069 solver.cpp:242] Iteration 11820, loss = 0.337484
I1018 10:05:45.957595 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0822539 (* 1 = 0.0822539 loss)
I1018 10:05:45.957600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.25523 (* 1 = 0.25523 loss)
I1018 10:05:45.957604 11069 solver.cpp:571] Iteration 11820, lr = 0.001
I1018 10:05:53.515061 11069 solver.cpp:242] Iteration 11840, loss = 0.209998
I1018 10:05:53.515085 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.061827 (* 1 = 0.061827 loss)
I1018 10:05:53.515090 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148171 (* 1 = 0.148171 loss)
I1018 10:05:53.515094 11069 solver.cpp:571] Iteration 11840, lr = 0.001
I1018 10:06:01.053988 11069 solver.cpp:242] Iteration 11860, loss = 0.714172
I1018 10:06:01.054013 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203897 (* 1 = 0.203897 loss)
I1018 10:06:01.054018 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.510275 (* 1 = 0.510275 loss)
I1018 10:06:01.054021 11069 solver.cpp:571] Iteration 11860, lr = 0.001
I1018 10:06:08.566424 11069 solver.cpp:242] Iteration 11880, loss = 0.241862
I1018 10:06:08.566449 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.056945 (* 1 = 0.056945 loss)
I1018 10:06:08.566453 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.184917 (* 1 = 0.184917 loss)
I1018 10:06:08.566457 11069 solver.cpp:571] Iteration 11880, lr = 0.001
I1018 10:06:16.058022 11069 solver.cpp:242] Iteration 11900, loss = 0.395157
I1018 10:06:16.058048 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0871477 (* 1 = 0.0871477 loss)
I1018 10:06:16.058053 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.308009 (* 1 = 0.308009 loss)
I1018 10:06:16.058056 11069 solver.cpp:571] Iteration 11900, lr = 0.001
I1018 10:06:23.609194 11069 solver.cpp:242] Iteration 11920, loss = 0.529311
I1018 10:06:23.609218 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.127667 (* 1 = 0.127667 loss)
I1018 10:06:23.609223 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.401643 (* 1 = 0.401643 loss)
I1018 10:06:23.609227 11069 solver.cpp:571] Iteration 11920, lr = 0.001
I1018 10:06:31.120909 11069 solver.cpp:242] Iteration 11940, loss = 0.448845
I1018 10:06:31.120934 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152746 (* 1 = 0.152746 loss)
I1018 10:06:31.120939 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296099 (* 1 = 0.296099 loss)
I1018 10:06:31.120942 11069 solver.cpp:571] Iteration 11940, lr = 0.001
I1018 10:06:38.627756 11069 solver.cpp:242] Iteration 11960, loss = 0.954745
I1018 10:06:38.627781 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.388374 (* 1 = 0.388374 loss)
I1018 10:06:38.627786 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.566372 (* 1 = 0.566372 loss)
I1018 10:06:38.627790 11069 solver.cpp:571] Iteration 11960, lr = 0.001
I1018 10:06:46.129412 11069 solver.cpp:242] Iteration 11980, loss = 0.938629
I1018 10:06:46.129437 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.267923 (* 1 = 0.267923 loss)
I1018 10:06:46.129441 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.670707 (* 1 = 0.670707 loss)
I1018 10:06:46.129446 11069 solver.cpp:571] Iteration 11980, lr = 0.001
speed: 0.376s / iter
I1018 10:06:53.549669 11069 solver.cpp:242] Iteration 12000, loss = 0.161021
I1018 10:06:53.549693 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0315754 (* 1 = 0.0315754 loss)
I1018 10:06:53.549698 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.129446 (* 1 = 0.129446 loss)
I1018 10:06:53.549702 11069 solver.cpp:571] Iteration 12000, lr = 0.001
I1018 10:07:01.023391 11069 solver.cpp:242] Iteration 12020, loss = 0.50511
I1018 10:07:01.023416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.125402 (* 1 = 0.125402 loss)
I1018 10:07:01.023422 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.379708 (* 1 = 0.379708 loss)
I1018 10:07:01.023425 11069 solver.cpp:571] Iteration 12020, lr = 0.001
I1018 10:07:08.541612 11069 solver.cpp:242] Iteration 12040, loss = 0.492736
I1018 10:07:08.541635 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.130539 (* 1 = 0.130539 loss)
I1018 10:07:08.541640 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.362196 (* 1 = 0.362196 loss)
I1018 10:07:08.541645 11069 solver.cpp:571] Iteration 12040, lr = 0.001
I1018 10:07:15.975706 11069 solver.cpp:242] Iteration 12060, loss = 0.290385
I1018 10:07:15.975731 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0777741 (* 1 = 0.0777741 loss)
I1018 10:07:15.975735 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212611 (* 1 = 0.212611 loss)
I1018 10:07:15.975739 11069 solver.cpp:571] Iteration 12060, lr = 0.001
I1018 10:07:23.515336 11069 solver.cpp:242] Iteration 12080, loss = 0.293794
I1018 10:07:23.515360 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0776075 (* 1 = 0.0776075 loss)
I1018 10:07:23.515364 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216186 (* 1 = 0.216186 loss)
I1018 10:07:23.515369 11069 solver.cpp:571] Iteration 12080, lr = 0.001
I1018 10:07:30.988060 11069 solver.cpp:242] Iteration 12100, loss = 0.397974
I1018 10:07:30.988085 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105126 (* 1 = 0.105126 loss)
I1018 10:07:30.988090 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.292848 (* 1 = 0.292848 loss)
I1018 10:07:30.988095 11069 solver.cpp:571] Iteration 12100, lr = 0.001
I1018 10:07:38.422914 11069 solver.cpp:242] Iteration 12120, loss = 0.234397
I1018 10:07:38.422940 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0419393 (* 1 = 0.0419393 loss)
I1018 10:07:38.422945 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.192458 (* 1 = 0.192458 loss)
I1018 10:07:38.422950 11069 solver.cpp:571] Iteration 12120, lr = 0.001
I1018 10:07:45.957612 11069 solver.cpp:242] Iteration 12140, loss = 0.340092
I1018 10:07:45.957638 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.085353 (* 1 = 0.085353 loss)
I1018 10:07:45.957641 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254739 (* 1 = 0.254739 loss)
I1018 10:07:45.957646 11069 solver.cpp:571] Iteration 12140, lr = 0.001
I1018 10:07:53.490972 11069 solver.cpp:242] Iteration 12160, loss = 0.170249
I1018 10:07:53.490998 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0234452 (* 1 = 0.0234452 loss)
I1018 10:07:53.491003 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.146803 (* 1 = 0.146803 loss)
I1018 10:07:53.491008 11069 solver.cpp:571] Iteration 12160, lr = 0.001
I1018 10:08:01.005890 11069 solver.cpp:242] Iteration 12180, loss = 0.114575
I1018 10:08:01.005915 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0295083 (* 1 = 0.0295083 loss)
I1018 10:08:01.005920 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0850669 (* 1 = 0.0850669 loss)
I1018 10:08:01.005924 11069 solver.cpp:571] Iteration 12180, lr = 0.001
speed: 0.376s / iter
I1018 10:08:08.483292 11069 solver.cpp:242] Iteration 12200, loss = 0.274726
I1018 10:08:08.483320 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0537101 (* 1 = 0.0537101 loss)
I1018 10:08:08.483325 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.221016 (* 1 = 0.221016 loss)
I1018 10:08:08.483330 11069 solver.cpp:571] Iteration 12200, lr = 0.001
I1018 10:08:16.068912 11069 solver.cpp:242] Iteration 12220, loss = 0.257267
I1018 10:08:16.068938 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0832546 (* 1 = 0.0832546 loss)
I1018 10:08:16.068943 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.174012 (* 1 = 0.174012 loss)
I1018 10:08:16.068948 11069 solver.cpp:571] Iteration 12220, lr = 0.001
I1018 10:08:23.617280 11069 solver.cpp:242] Iteration 12240, loss = 0.30448
I1018 10:08:23.617333 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0644293 (* 1 = 0.0644293 loss)
I1018 10:08:23.617338 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.24005 (* 1 = 0.24005 loss)
I1018 10:08:23.617353 11069 solver.cpp:571] Iteration 12240, lr = 0.001
I1018 10:08:31.227108 11069 solver.cpp:242] Iteration 12260, loss = 1.04213
I1018 10:08:31.227133 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.283378 (* 1 = 0.283378 loss)
I1018 10:08:31.227138 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.758755 (* 1 = 0.758755 loss)
I1018 10:08:31.227141 11069 solver.cpp:571] Iteration 12260, lr = 0.001
I1018 10:08:38.742727 11069 solver.cpp:242] Iteration 12280, loss = 0.648758
I1018 10:08:38.742753 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.194485 (* 1 = 0.194485 loss)
I1018 10:08:38.742758 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.454273 (* 1 = 0.454273 loss)
I1018 10:08:38.742761 11069 solver.cpp:571] Iteration 12280, lr = 0.001
I1018 10:08:46.271663 11069 solver.cpp:242] Iteration 12300, loss = 0.402119
I1018 10:08:46.271687 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.162018 (* 1 = 0.162018 loss)
I1018 10:08:46.271692 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.240101 (* 1 = 0.240101 loss)
I1018 10:08:46.271697 11069 solver.cpp:571] Iteration 12300, lr = 0.001
I1018 10:08:53.771505 11069 solver.cpp:242] Iteration 12320, loss = 0.735732
I1018 10:08:53.771530 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212485 (* 1 = 0.212485 loss)
I1018 10:08:53.771534 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.523247 (* 1 = 0.523247 loss)
I1018 10:08:53.771538 11069 solver.cpp:571] Iteration 12320, lr = 0.001
I1018 10:09:01.391386 11069 solver.cpp:242] Iteration 12340, loss = 0.571544
I1018 10:09:01.391412 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.187885 (* 1 = 0.187885 loss)
I1018 10:09:01.391415 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.383659 (* 1 = 0.383659 loss)
I1018 10:09:01.391420 11069 solver.cpp:571] Iteration 12340, lr = 0.001
I1018 10:09:08.907258 11069 solver.cpp:242] Iteration 12360, loss = 0.884346
I1018 10:09:08.907284 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.233382 (* 1 = 0.233382 loss)
I1018 10:09:08.907289 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.650964 (* 1 = 0.650964 loss)
I1018 10:09:08.907292 11069 solver.cpp:571] Iteration 12360, lr = 0.001
I1018 10:09:16.470891 11069 solver.cpp:242] Iteration 12380, loss = 0.368185
I1018 10:09:16.470916 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104843 (* 1 = 0.104843 loss)
I1018 10:09:16.470921 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.263343 (* 1 = 0.263343 loss)
I1018 10:09:16.470924 11069 solver.cpp:571] Iteration 12380, lr = 0.001
speed: 0.376s / iter
I1018 10:09:23.929697 11069 solver.cpp:242] Iteration 12400, loss = 1.0563
I1018 10:09:23.929720 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.285815 (* 1 = 0.285815 loss)
I1018 10:09:23.929724 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.770488 (* 1 = 0.770488 loss)
I1018 10:09:23.929728 11069 solver.cpp:571] Iteration 12400, lr = 0.001
I1018 10:09:31.469514 11069 solver.cpp:242] Iteration 12420, loss = 1.01549
I1018 10:09:31.469539 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.370289 (* 1 = 0.370289 loss)
I1018 10:09:31.469544 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.645204 (* 1 = 0.645204 loss)
I1018 10:09:31.469547 11069 solver.cpp:571] Iteration 12420, lr = 0.001
I1018 10:09:39.018786 11069 solver.cpp:242] Iteration 12440, loss = 0.189677
I1018 10:09:39.018811 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0387353 (* 1 = 0.0387353 loss)
I1018 10:09:39.018816 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.150942 (* 1 = 0.150942 loss)
I1018 10:09:39.018821 11069 solver.cpp:571] Iteration 12440, lr = 0.001
I1018 10:09:46.480908 11069 solver.cpp:242] Iteration 12460, loss = 0.535651
I1018 10:09:46.480932 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147282 (* 1 = 0.147282 loss)
I1018 10:09:46.480937 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.38837 (* 1 = 0.38837 loss)
I1018 10:09:46.480942 11069 solver.cpp:571] Iteration 12460, lr = 0.001
I1018 10:09:54.092479 11069 solver.cpp:242] Iteration 12480, loss = 0.278497
I1018 10:09:54.092505 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0720934 (* 1 = 0.0720934 loss)
I1018 10:09:54.092510 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.206404 (* 1 = 0.206404 loss)
I1018 10:09:54.092514 11069 solver.cpp:571] Iteration 12480, lr = 0.001
I1018 10:10:01.683279 11069 solver.cpp:242] Iteration 12500, loss = 0.15395
I1018 10:10:01.683301 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0417448 (* 1 = 0.0417448 loss)
I1018 10:10:01.683306 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.112205 (* 1 = 0.112205 loss)
I1018 10:10:01.683310 11069 solver.cpp:571] Iteration 12500, lr = 0.001
I1018 10:10:09.213234 11069 solver.cpp:242] Iteration 12520, loss = 0.363628
I1018 10:10:09.213258 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.079315 (* 1 = 0.079315 loss)
I1018 10:10:09.213263 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.284313 (* 1 = 0.284313 loss)
I1018 10:10:09.213268 11069 solver.cpp:571] Iteration 12520, lr = 0.001
I1018 10:10:16.754659 11069 solver.cpp:242] Iteration 12540, loss = 0.30073
I1018 10:10:16.754684 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0791105 (* 1 = 0.0791105 loss)
I1018 10:10:16.754689 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.221619 (* 1 = 0.221619 loss)
I1018 10:10:16.754693 11069 solver.cpp:571] Iteration 12540, lr = 0.001
I1018 10:10:24.194175 11069 solver.cpp:242] Iteration 12560, loss = 0.581796
I1018 10:10:24.194200 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0907159 (* 1 = 0.0907159 loss)
I1018 10:10:24.194205 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.49108 (* 1 = 0.49108 loss)
I1018 10:10:24.194209 11069 solver.cpp:571] Iteration 12560, lr = 0.001
I1018 10:10:31.661012 11069 solver.cpp:242] Iteration 12580, loss = 0.397977
I1018 10:10:31.661037 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1774 (* 1 = 0.1774 loss)
I1018 10:10:31.661041 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.220577 (* 1 = 0.220577 loss)
I1018 10:10:31.661046 11069 solver.cpp:571] Iteration 12580, lr = 0.001
speed: 0.376s / iter
I1018 10:10:39.233391 11069 solver.cpp:242] Iteration 12600, loss = 0.572893
I1018 10:10:39.233414 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100252 (* 1 = 0.100252 loss)
I1018 10:10:39.233419 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.472642 (* 1 = 0.472642 loss)
I1018 10:10:39.233423 11069 solver.cpp:571] Iteration 12600, lr = 0.001
I1018 10:10:46.768393 11069 solver.cpp:242] Iteration 12620, loss = 0.526314
I1018 10:10:46.768416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142284 (* 1 = 0.142284 loss)
I1018 10:10:46.768420 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.38403 (* 1 = 0.38403 loss)
I1018 10:10:46.768424 11069 solver.cpp:571] Iteration 12620, lr = 0.001
I1018 10:10:54.317755 11069 solver.cpp:242] Iteration 12640, loss = 0.961354
I1018 10:10:54.317780 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241082 (* 1 = 0.241082 loss)
I1018 10:10:54.317785 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.720273 (* 1 = 0.720273 loss)
I1018 10:10:54.317788 11069 solver.cpp:571] Iteration 12640, lr = 0.001
I1018 10:11:01.879964 11069 solver.cpp:242] Iteration 12660, loss = 0.889928
I1018 10:11:01.879987 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.325813 (* 1 = 0.325813 loss)
I1018 10:11:01.879992 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.564115 (* 1 = 0.564115 loss)
I1018 10:11:01.879995 11069 solver.cpp:571] Iteration 12660, lr = 0.001
I1018 10:11:09.421149 11069 solver.cpp:242] Iteration 12680, loss = 0.521174
I1018 10:11:09.421174 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.233106 (* 1 = 0.233106 loss)
I1018 10:11:09.421177 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.288068 (* 1 = 0.288068 loss)
I1018 10:11:09.421181 11069 solver.cpp:571] Iteration 12680, lr = 0.001
I1018 10:11:16.878283 11069 solver.cpp:242] Iteration 12700, loss = 0.333116
I1018 10:11:16.878306 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0721963 (* 1 = 0.0721963 loss)
I1018 10:11:16.878311 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.260919 (* 1 = 0.260919 loss)
I1018 10:11:16.878315 11069 solver.cpp:571] Iteration 12700, lr = 0.001
I1018 10:11:24.455317 11069 solver.cpp:242] Iteration 12720, loss = 0.738474
I1018 10:11:24.455340 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.226677 (* 1 = 0.226677 loss)
I1018 10:11:24.455344 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.511797 (* 1 = 0.511797 loss)
I1018 10:11:24.455348 11069 solver.cpp:571] Iteration 12720, lr = 0.001
I1018 10:11:31.951997 11069 solver.cpp:242] Iteration 12740, loss = 0.949362
I1018 10:11:31.952023 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.245837 (* 1 = 0.245837 loss)
I1018 10:11:31.952028 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.703525 (* 1 = 0.703525 loss)
I1018 10:11:31.952031 11069 solver.cpp:571] Iteration 12740, lr = 0.001
I1018 10:11:39.461693 11069 solver.cpp:242] Iteration 12760, loss = 0.337333
I1018 10:11:39.461717 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.133806 (* 1 = 0.133806 loss)
I1018 10:11:39.461722 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.203527 (* 1 = 0.203527 loss)
I1018 10:11:39.461726 11069 solver.cpp:571] Iteration 12760, lr = 0.001
I1018 10:11:46.970738 11069 solver.cpp:242] Iteration 12780, loss = 0.56385
I1018 10:11:46.970762 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122211 (* 1 = 0.122211 loss)
I1018 10:11:46.970767 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.441639 (* 1 = 0.441639 loss)
I1018 10:11:46.970772 11069 solver.cpp:571] Iteration 12780, lr = 0.001
speed: 0.376s / iter
I1018 10:11:54.463995 11069 solver.cpp:242] Iteration 12800, loss = 0.28831
I1018 10:11:54.464021 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0599993 (* 1 = 0.0599993 loss)
I1018 10:11:54.464026 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.228311 (* 1 = 0.228311 loss)
I1018 10:11:54.464030 11069 solver.cpp:571] Iteration 12800, lr = 0.001
I1018 10:12:01.999058 11069 solver.cpp:242] Iteration 12820, loss = 0.516306
I1018 10:12:01.999083 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.160321 (* 1 = 0.160321 loss)
I1018 10:12:01.999086 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.355985 (* 1 = 0.355985 loss)
I1018 10:12:01.999090 11069 solver.cpp:571] Iteration 12820, lr = 0.001
I1018 10:12:09.520217 11069 solver.cpp:242] Iteration 12840, loss = 1.58497
I1018 10:12:09.520241 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.699597 (* 1 = 0.699597 loss)
I1018 10:12:09.520246 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.885378 (* 1 = 0.885378 loss)
I1018 10:12:09.520251 11069 solver.cpp:571] Iteration 12840, lr = 0.001
I1018 10:12:17.045748 11069 solver.cpp:242] Iteration 12860, loss = 1.49387
I1018 10:12:17.045774 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.721629 (* 1 = 0.721629 loss)
I1018 10:12:17.045779 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.772245 (* 1 = 0.772245 loss)
I1018 10:12:17.045783 11069 solver.cpp:571] Iteration 12860, lr = 0.001
I1018 10:12:24.458027 11069 solver.cpp:242] Iteration 12880, loss = 0.747059
I1018 10:12:24.458051 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.187528 (* 1 = 0.187528 loss)
I1018 10:12:24.458056 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.55953 (* 1 = 0.55953 loss)
I1018 10:12:24.458060 11069 solver.cpp:571] Iteration 12880, lr = 0.001
I1018 10:12:32.022060 11069 solver.cpp:242] Iteration 12900, loss = 0.353529
I1018 10:12:32.022085 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0843964 (* 1 = 0.0843964 loss)
I1018 10:12:32.022089 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269133 (* 1 = 0.269133 loss)
I1018 10:12:32.022094 11069 solver.cpp:571] Iteration 12900, lr = 0.001
I1018 10:12:39.569331 11069 solver.cpp:242] Iteration 12920, loss = 0.232102
I1018 10:12:39.569356 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0872508 (* 1 = 0.0872508 loss)
I1018 10:12:39.569360 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144851 (* 1 = 0.144851 loss)
I1018 10:12:39.569365 11069 solver.cpp:571] Iteration 12920, lr = 0.001
I1018 10:12:47.060520 11069 solver.cpp:242] Iteration 12940, loss = 0.408573
I1018 10:12:47.060545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116053 (* 1 = 0.116053 loss)
I1018 10:12:47.060549 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.29252 (* 1 = 0.29252 loss)
I1018 10:12:47.060554 11069 solver.cpp:571] Iteration 12940, lr = 0.001
I1018 10:12:54.523133 11069 solver.cpp:242] Iteration 12960, loss = 0.869729
I1018 10:12:54.523159 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.29517 (* 1 = 0.29517 loss)
I1018 10:12:54.523164 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.574559 (* 1 = 0.574559 loss)
I1018 10:12:54.523167 11069 solver.cpp:571] Iteration 12960, lr = 0.001
I1018 10:13:01.993746 11069 solver.cpp:242] Iteration 12980, loss = 0.426639
I1018 10:13:01.993770 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.156962 (* 1 = 0.156962 loss)
I1018 10:13:01.993774 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269677 (* 1 = 0.269677 loss)
I1018 10:13:01.993778 11069 solver.cpp:571] Iteration 12980, lr = 0.001
speed: 0.376s / iter
I1018 10:13:09.562530 11069 solver.cpp:242] Iteration 13000, loss = 0.225833
I1018 10:13:09.562556 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.062024 (* 1 = 0.062024 loss)
I1018 10:13:09.562561 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.163809 (* 1 = 0.163809 loss)
I1018 10:13:09.562564 11069 solver.cpp:571] Iteration 13000, lr = 0.001
I1018 10:13:17.080409 11069 solver.cpp:242] Iteration 13020, loss = 1.12658
I1018 10:13:17.080433 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.448765 (* 1 = 0.448765 loss)
I1018 10:13:17.080437 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.677817 (* 1 = 0.677817 loss)
I1018 10:13:17.080441 11069 solver.cpp:571] Iteration 13020, lr = 0.001
I1018 10:13:24.630686 11069 solver.cpp:242] Iteration 13040, loss = 0.199269
I1018 10:13:24.630710 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0386625 (* 1 = 0.0386625 loss)
I1018 10:13:24.630715 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.160606 (* 1 = 0.160606 loss)
I1018 10:13:24.630719 11069 solver.cpp:571] Iteration 13040, lr = 0.001
I1018 10:13:32.215354 11069 solver.cpp:242] Iteration 13060, loss = 0.502687
I1018 10:13:32.215378 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152525 (* 1 = 0.152525 loss)
I1018 10:13:32.215382 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.350162 (* 1 = 0.350162 loss)
I1018 10:13:32.215386 11069 solver.cpp:571] Iteration 13060, lr = 0.001
I1018 10:13:39.617750 11069 solver.cpp:242] Iteration 13080, loss = 0.579865
I1018 10:13:39.617774 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147851 (* 1 = 0.147851 loss)
I1018 10:13:39.617779 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.432014 (* 1 = 0.432014 loss)
I1018 10:13:39.617784 11069 solver.cpp:571] Iteration 13080, lr = 0.001
I1018 10:13:47.126623 11069 solver.cpp:242] Iteration 13100, loss = 0.872405
I1018 10:13:47.126647 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.299949 (* 1 = 0.299949 loss)
I1018 10:13:47.126652 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.572456 (* 1 = 0.572456 loss)
I1018 10:13:47.126657 11069 solver.cpp:571] Iteration 13100, lr = 0.001
I1018 10:13:54.618237 11069 solver.cpp:242] Iteration 13120, loss = 0.381096
I1018 10:13:54.618263 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.091493 (* 1 = 0.091493 loss)
I1018 10:13:54.618266 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.289603 (* 1 = 0.289603 loss)
I1018 10:13:54.618270 11069 solver.cpp:571] Iteration 13120, lr = 0.001
I1018 10:14:02.124105 11069 solver.cpp:242] Iteration 13140, loss = 0.274542
I1018 10:14:02.124130 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0527654 (* 1 = 0.0527654 loss)
I1018 10:14:02.124135 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.221777 (* 1 = 0.221777 loss)
I1018 10:14:02.124140 11069 solver.cpp:571] Iteration 13140, lr = 0.001
I1018 10:14:09.627992 11069 solver.cpp:242] Iteration 13160, loss = 0.701487
I1018 10:14:09.628018 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.262867 (* 1 = 0.262867 loss)
I1018 10:14:09.628022 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.43862 (* 1 = 0.43862 loss)
I1018 10:14:09.628026 11069 solver.cpp:571] Iteration 13160, lr = 0.001
I1018 10:14:17.106474 11069 solver.cpp:242] Iteration 13180, loss = 0.169256
I1018 10:14:17.106498 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0787998 (* 1 = 0.0787998 loss)
I1018 10:14:17.106503 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0904566 (* 1 = 0.0904566 loss)
I1018 10:14:17.106508 11069 solver.cpp:571] Iteration 13180, lr = 0.001
speed: 0.376s / iter
I1018 10:14:24.615947 11069 solver.cpp:242] Iteration 13200, loss = 0.342748
I1018 10:14:24.615972 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0657256 (* 1 = 0.0657256 loss)
I1018 10:14:24.615977 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.277023 (* 1 = 0.277023 loss)
I1018 10:14:24.615980 11069 solver.cpp:571] Iteration 13200, lr = 0.001
I1018 10:14:32.166270 11069 solver.cpp:242] Iteration 13220, loss = 0.23973
I1018 10:14:32.166304 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0308779 (* 1 = 0.0308779 loss)
I1018 10:14:32.166308 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208852 (* 1 = 0.208852 loss)
I1018 10:14:32.166312 11069 solver.cpp:571] Iteration 13220, lr = 0.001
I1018 10:14:39.713731 11069 solver.cpp:242] Iteration 13240, loss = 0.156566
I1018 10:14:39.713754 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0377866 (* 1 = 0.0377866 loss)
I1018 10:14:39.713759 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.118779 (* 1 = 0.118779 loss)
I1018 10:14:39.713763 11069 solver.cpp:571] Iteration 13240, lr = 0.001
I1018 10:14:47.281486 11069 solver.cpp:242] Iteration 13260, loss = 0.548421
I1018 10:14:47.281509 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200678 (* 1 = 0.200678 loss)
I1018 10:14:47.281514 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.347743 (* 1 = 0.347743 loss)
I1018 10:14:47.281517 11069 solver.cpp:571] Iteration 13260, lr = 0.001
I1018 10:14:54.926152 11069 solver.cpp:242] Iteration 13280, loss = 0.408971
I1018 10:14:54.926177 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.106913 (* 1 = 0.106913 loss)
I1018 10:14:54.926182 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.302058 (* 1 = 0.302058 loss)
I1018 10:14:54.926185 11069 solver.cpp:571] Iteration 13280, lr = 0.001
I1018 10:15:02.490808 11069 solver.cpp:242] Iteration 13300, loss = 0.230272
I1018 10:15:02.490831 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0781719 (* 1 = 0.0781719 loss)
I1018 10:15:02.490836 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.1521 (* 1 = 0.1521 loss)
I1018 10:15:02.490840 11069 solver.cpp:571] Iteration 13300, lr = 0.001
I1018 10:15:10.092844 11069 solver.cpp:242] Iteration 13320, loss = 0.539431
I1018 10:15:10.092867 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137195 (* 1 = 0.137195 loss)
I1018 10:15:10.092872 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.402236 (* 1 = 0.402236 loss)
I1018 10:15:10.092876 11069 solver.cpp:571] Iteration 13320, lr = 0.001
I1018 10:15:17.633036 11069 solver.cpp:242] Iteration 13340, loss = 0.458228
I1018 10:15:17.633062 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11604 (* 1 = 0.11604 loss)
I1018 10:15:17.633066 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342188 (* 1 = 0.342188 loss)
I1018 10:15:17.633070 11069 solver.cpp:571] Iteration 13340, lr = 0.001
I1018 10:15:24.929987 11069 solver.cpp:242] Iteration 13360, loss = 0.22174
I1018 10:15:24.930013 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.056323 (* 1 = 0.056323 loss)
I1018 10:15:24.930018 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165417 (* 1 = 0.165417 loss)
I1018 10:15:24.930022 11069 solver.cpp:571] Iteration 13360, lr = 0.001
I1018 10:15:32.326643 11069 solver.cpp:242] Iteration 13380, loss = 1.408
I1018 10:15:32.326668 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.587328 (* 1 = 0.587328 loss)
I1018 10:15:32.326673 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.820669 (* 1 = 0.820669 loss)
I1018 10:15:32.326676 11069 solver.cpp:571] Iteration 13380, lr = 0.001
speed: 0.376s / iter
I1018 10:15:39.481616 11069 solver.cpp:242] Iteration 13400, loss = 0.838776
I1018 10:15:39.481642 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.229635 (* 1 = 0.229635 loss)
I1018 10:15:39.481647 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.60914 (* 1 = 0.60914 loss)
I1018 10:15:39.481650 11069 solver.cpp:571] Iteration 13400, lr = 0.001
I1018 10:15:46.549336 11069 solver.cpp:242] Iteration 13420, loss = 1.61182
I1018 10:15:46.549362 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.847883 (* 1 = 0.847883 loss)
I1018 10:15:46.549366 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.763938 (* 1 = 0.763938 loss)
I1018 10:15:46.549371 11069 solver.cpp:571] Iteration 13420, lr = 0.001
I1018 10:15:54.001453 11069 solver.cpp:242] Iteration 13440, loss = 0.38619
I1018 10:15:54.001478 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.121498 (* 1 = 0.121498 loss)
I1018 10:15:54.001483 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264692 (* 1 = 0.264692 loss)
I1018 10:15:54.001487 11069 solver.cpp:571] Iteration 13440, lr = 0.001
I1018 10:16:01.180491 11069 solver.cpp:242] Iteration 13460, loss = 0.575155
I1018 10:16:01.180517 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212413 (* 1 = 0.212413 loss)
I1018 10:16:01.180522 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.362742 (* 1 = 0.362742 loss)
I1018 10:16:01.180526 11069 solver.cpp:571] Iteration 13460, lr = 0.001
I1018 10:16:08.274457 11069 solver.cpp:242] Iteration 13480, loss = 0.963225
I1018 10:16:08.274483 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.321585 (* 1 = 0.321585 loss)
I1018 10:16:08.274487 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.641639 (* 1 = 0.641639 loss)
I1018 10:16:08.274492 11069 solver.cpp:571] Iteration 13480, lr = 0.001
I1018 10:16:15.839521 11069 solver.cpp:242] Iteration 13500, loss = 0.922083
I1018 10:16:15.839547 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.268559 (* 1 = 0.268559 loss)
I1018 10:16:15.839551 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.653524 (* 1 = 0.653524 loss)
I1018 10:16:15.839555 11069 solver.cpp:571] Iteration 13500, lr = 0.001
I1018 10:16:23.050642 11069 solver.cpp:242] Iteration 13520, loss = 0.360816
I1018 10:16:23.050668 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152892 (* 1 = 0.152892 loss)
I1018 10:16:23.050671 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.207924 (* 1 = 0.207924 loss)
I1018 10:16:23.050675 11069 solver.cpp:571] Iteration 13520, lr = 0.001
I1018 10:16:30.595170 11069 solver.cpp:242] Iteration 13540, loss = 0.782278
I1018 10:16:30.595194 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150368 (* 1 = 0.150368 loss)
I1018 10:16:30.595198 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.63191 (* 1 = 0.63191 loss)
I1018 10:16:30.595202 11069 solver.cpp:571] Iteration 13540, lr = 0.001
I1018 10:16:38.227943 11069 solver.cpp:242] Iteration 13560, loss = 0.516605
I1018 10:16:38.227969 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152305 (* 1 = 0.152305 loss)
I1018 10:16:38.227973 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3643 (* 1 = 0.3643 loss)
I1018 10:16:38.227977 11069 solver.cpp:571] Iteration 13560, lr = 0.001
I1018 10:16:45.794839 11069 solver.cpp:242] Iteration 13580, loss = 0.56351
I1018 10:16:45.794864 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.16025 (* 1 = 0.16025 loss)
I1018 10:16:45.794869 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.40326 (* 1 = 0.40326 loss)
I1018 10:16:45.794873 11069 solver.cpp:571] Iteration 13580, lr = 0.001
speed: 0.376s / iter
I1018 10:16:53.082546 11069 solver.cpp:242] Iteration 13600, loss = 1.18601
I1018 10:16:53.082571 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.478825 (* 1 = 0.478825 loss)
I1018 10:16:53.082576 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.707185 (* 1 = 0.707185 loss)
I1018 10:16:53.082581 11069 solver.cpp:571] Iteration 13600, lr = 0.001
I1018 10:17:00.730820 11069 solver.cpp:242] Iteration 13620, loss = 0.381795
I1018 10:17:00.730846 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0832464 (* 1 = 0.0832464 loss)
I1018 10:17:00.730851 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.298549 (* 1 = 0.298549 loss)
I1018 10:17:00.730855 11069 solver.cpp:571] Iteration 13620, lr = 0.001
I1018 10:17:08.314734 11069 solver.cpp:242] Iteration 13640, loss = 0.262726
I1018 10:17:08.314760 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0728549 (* 1 = 0.0728549 loss)
I1018 10:17:08.314765 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189871 (* 1 = 0.189871 loss)
I1018 10:17:08.314769 11069 solver.cpp:571] Iteration 13640, lr = 0.001
I1018 10:17:15.876638 11069 solver.cpp:242] Iteration 13660, loss = 1.00679
I1018 10:17:15.876663 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.297521 (* 1 = 0.297521 loss)
I1018 10:17:15.876668 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.709266 (* 1 = 0.709266 loss)
I1018 10:17:15.876672 11069 solver.cpp:571] Iteration 13660, lr = 0.001
I1018 10:17:23.406952 11069 solver.cpp:242] Iteration 13680, loss = 1.45356
I1018 10:17:23.406977 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.444034 (* 1 = 0.444034 loss)
I1018 10:17:23.406982 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.00953 (* 1 = 1.00953 loss)
I1018 10:17:23.406986 11069 solver.cpp:571] Iteration 13680, lr = 0.001
I1018 10:17:31.031278 11069 solver.cpp:242] Iteration 13700, loss = 0.707076
I1018 10:17:31.031303 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.230205 (* 1 = 0.230205 loss)
I1018 10:17:31.031307 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.476871 (* 1 = 0.476871 loss)
I1018 10:17:31.031311 11069 solver.cpp:571] Iteration 13700, lr = 0.001
I1018 10:17:38.634806 11069 solver.cpp:242] Iteration 13720, loss = 0.23333
I1018 10:17:38.634830 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.047052 (* 1 = 0.047052 loss)
I1018 10:17:38.634835 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.186278 (* 1 = 0.186278 loss)
I1018 10:17:38.634840 11069 solver.cpp:571] Iteration 13720, lr = 0.001
I1018 10:17:46.210103 11069 solver.cpp:242] Iteration 13740, loss = 0.367952
I1018 10:17:46.210127 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.020837 (* 1 = 0.020837 loss)
I1018 10:17:46.210132 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.347115 (* 1 = 0.347115 loss)
I1018 10:17:46.210136 11069 solver.cpp:571] Iteration 13740, lr = 0.001
I1018 10:17:53.846336 11069 solver.cpp:242] Iteration 13760, loss = 0.814896
I1018 10:17:53.846362 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.19151 (* 1 = 0.19151 loss)
I1018 10:17:53.846366 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.623386 (* 1 = 0.623386 loss)
I1018 10:17:53.846370 11069 solver.cpp:571] Iteration 13760, lr = 0.001
I1018 10:18:01.482630 11069 solver.cpp:242] Iteration 13780, loss = 0.277542
I1018 10:18:01.482656 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.071399 (* 1 = 0.071399 loss)
I1018 10:18:01.482659 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.206143 (* 1 = 0.206143 loss)
I1018 10:18:01.482663 11069 solver.cpp:571] Iteration 13780, lr = 0.001
speed: 0.376s / iter
I1018 10:18:09.047554 11069 solver.cpp:242] Iteration 13800, loss = 0.632727
I1018 10:18:09.047580 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.211038 (* 1 = 0.211038 loss)
I1018 10:18:09.047583 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.421689 (* 1 = 0.421689 loss)
I1018 10:18:09.047588 11069 solver.cpp:571] Iteration 13800, lr = 0.001
I1018 10:18:16.674219 11069 solver.cpp:242] Iteration 13820, loss = 1.07516
I1018 10:18:16.674244 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.340653 (* 1 = 0.340653 loss)
I1018 10:18:16.674249 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.734509 (* 1 = 0.734509 loss)
I1018 10:18:16.674253 11069 solver.cpp:571] Iteration 13820, lr = 0.001
I1018 10:18:24.269618 11069 solver.cpp:242] Iteration 13840, loss = 0.20849
I1018 10:18:24.269644 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0707303 (* 1 = 0.0707303 loss)
I1018 10:18:24.269647 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13776 (* 1 = 0.13776 loss)
I1018 10:18:24.269652 11069 solver.cpp:571] Iteration 13840, lr = 0.001
I1018 10:18:31.913166 11069 solver.cpp:242] Iteration 13860, loss = 0.667067
I1018 10:18:31.913190 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.176331 (* 1 = 0.176331 loss)
I1018 10:18:31.913194 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.490736 (* 1 = 0.490736 loss)
I1018 10:18:31.913198 11069 solver.cpp:571] Iteration 13860, lr = 0.001
I1018 10:18:39.576746 11069 solver.cpp:242] Iteration 13880, loss = 0.368701
I1018 10:18:39.576782 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123217 (* 1 = 0.123217 loss)
I1018 10:18:39.576797 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.245484 (* 1 = 0.245484 loss)
I1018 10:18:39.576800 11069 solver.cpp:571] Iteration 13880, lr = 0.001
I1018 10:18:47.234071 11069 solver.cpp:242] Iteration 13900, loss = 0.59049
I1018 10:18:47.234096 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177224 (* 1 = 0.177224 loss)
I1018 10:18:47.234099 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.413266 (* 1 = 0.413266 loss)
I1018 10:18:47.234103 11069 solver.cpp:571] Iteration 13900, lr = 0.001
I1018 10:18:54.751935 11069 solver.cpp:242] Iteration 13920, loss = 0.428411
I1018 10:18:54.751960 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.134789 (* 1 = 0.134789 loss)
I1018 10:18:54.751965 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.293621 (* 1 = 0.293621 loss)
I1018 10:18:54.751968 11069 solver.cpp:571] Iteration 13920, lr = 0.001
I1018 10:19:02.286788 11069 solver.cpp:242] Iteration 13940, loss = 0.328342
I1018 10:19:02.286813 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114169 (* 1 = 0.114169 loss)
I1018 10:19:02.286818 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.214173 (* 1 = 0.214173 loss)
I1018 10:19:02.286823 11069 solver.cpp:571] Iteration 13940, lr = 0.001
I1018 10:19:09.945092 11069 solver.cpp:242] Iteration 13960, loss = 0.718929
I1018 10:19:09.945117 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.166289 (* 1 = 0.166289 loss)
I1018 10:19:09.945122 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.55264 (* 1 = 0.55264 loss)
I1018 10:19:09.945127 11069 solver.cpp:571] Iteration 13960, lr = 0.001
I1018 10:19:17.564018 11069 solver.cpp:242] Iteration 13980, loss = 0.71289
I1018 10:19:17.564043 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.218763 (* 1 = 0.218763 loss)
I1018 10:19:17.564049 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.494127 (* 1 = 0.494127 loss)
I1018 10:19:17.564052 11069 solver.cpp:571] Iteration 13980, lr = 0.001
speed: 0.376s / iter
I1018 10:19:25.063809 11069 solver.cpp:242] Iteration 14000, loss = 0.708953
I1018 10:19:25.063835 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.249786 (* 1 = 0.249786 loss)
I1018 10:19:25.063839 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.459167 (* 1 = 0.459167 loss)
I1018 10:19:25.063843 11069 solver.cpp:571] Iteration 14000, lr = 0.001
I1018 10:19:32.726169 11069 solver.cpp:242] Iteration 14020, loss = 0.223936
I1018 10:19:32.726193 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0442156 (* 1 = 0.0442156 loss)
I1018 10:19:32.726198 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179721 (* 1 = 0.179721 loss)
I1018 10:19:32.726202 11069 solver.cpp:571] Iteration 14020, lr = 0.001
I1018 10:19:40.379173 11069 solver.cpp:242] Iteration 14040, loss = 0.26948
I1018 10:19:40.379199 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0459018 (* 1 = 0.0459018 loss)
I1018 10:19:40.379204 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.223579 (* 1 = 0.223579 loss)
I1018 10:19:40.379207 11069 solver.cpp:571] Iteration 14040, lr = 0.001
I1018 10:19:48.027000 11069 solver.cpp:242] Iteration 14060, loss = 0.260359
I1018 10:19:48.027024 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0521141 (* 1 = 0.0521141 loss)
I1018 10:19:48.027029 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208244 (* 1 = 0.208244 loss)
I1018 10:19:48.027034 11069 solver.cpp:571] Iteration 14060, lr = 0.001
I1018 10:19:55.684608 11069 solver.cpp:242] Iteration 14080, loss = 0.324222
I1018 10:19:55.684634 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0835566 (* 1 = 0.0835566 loss)
I1018 10:19:55.684638 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.240665 (* 1 = 0.240665 loss)
I1018 10:19:55.684643 11069 solver.cpp:571] Iteration 14080, lr = 0.001
I1018 10:20:03.306578 11069 solver.cpp:242] Iteration 14100, loss = 0.201328
I1018 10:20:03.306603 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0676342 (* 1 = 0.0676342 loss)
I1018 10:20:03.306608 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133694 (* 1 = 0.133694 loss)
I1018 10:20:03.306612 11069 solver.cpp:571] Iteration 14100, lr = 0.001
I1018 10:20:10.996912 11069 solver.cpp:242] Iteration 14120, loss = 0.320432
I1018 10:20:10.996938 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108006 (* 1 = 0.108006 loss)
I1018 10:20:10.996942 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212426 (* 1 = 0.212426 loss)
I1018 10:20:10.996947 11069 solver.cpp:571] Iteration 14120, lr = 0.001
I1018 10:20:18.589627 11069 solver.cpp:242] Iteration 14140, loss = 0.158889
I1018 10:20:18.589653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0369328 (* 1 = 0.0369328 loss)
I1018 10:20:18.589658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.121956 (* 1 = 0.121956 loss)
I1018 10:20:18.589661 11069 solver.cpp:571] Iteration 14140, lr = 0.001
I1018 10:20:26.179021 11069 solver.cpp:242] Iteration 14160, loss = 0.307847
I1018 10:20:26.179046 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113033 (* 1 = 0.113033 loss)
I1018 10:20:26.179050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194814 (* 1 = 0.194814 loss)
I1018 10:20:26.179055 11069 solver.cpp:571] Iteration 14160, lr = 0.001
I1018 10:20:33.678894 11069 solver.cpp:242] Iteration 14180, loss = 1.22357
I1018 10:20:33.678920 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.413118 (* 1 = 0.413118 loss)
I1018 10:20:33.678925 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.810456 (* 1 = 0.810456 loss)
I1018 10:20:33.678928 11069 solver.cpp:571] Iteration 14180, lr = 0.001
speed: 0.376s / iter
I1018 10:20:41.257088 11069 solver.cpp:242] Iteration 14200, loss = 0.199438
I1018 10:20:41.257112 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0581055 (* 1 = 0.0581055 loss)
I1018 10:20:41.257117 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141333 (* 1 = 0.141333 loss)
I1018 10:20:41.257122 11069 solver.cpp:571] Iteration 14200, lr = 0.001
I1018 10:20:48.919492 11069 solver.cpp:242] Iteration 14220, loss = 0.313286
I1018 10:20:48.919517 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0590809 (* 1 = 0.0590809 loss)
I1018 10:20:48.919520 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254205 (* 1 = 0.254205 loss)
I1018 10:20:48.919524 11069 solver.cpp:571] Iteration 14220, lr = 0.001
I1018 10:20:56.462543 11069 solver.cpp:242] Iteration 14240, loss = 0.897327
I1018 10:20:56.462568 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.31695 (* 1 = 0.31695 loss)
I1018 10:20:56.462573 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.580377 (* 1 = 0.580377 loss)
I1018 10:20:56.462576 11069 solver.cpp:571] Iteration 14240, lr = 0.001
I1018 10:21:04.077949 11069 solver.cpp:242] Iteration 14260, loss = 0.199015
I1018 10:21:04.077975 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0722794 (* 1 = 0.0722794 loss)
I1018 10:21:04.077980 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126736 (* 1 = 0.126736 loss)
I1018 10:21:04.077983 11069 solver.cpp:571] Iteration 14260, lr = 0.001
I1018 10:21:11.659258 11069 solver.cpp:242] Iteration 14280, loss = 1.06187
I1018 10:21:11.659284 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.350524 (* 1 = 0.350524 loss)
I1018 10:21:11.659289 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.711346 (* 1 = 0.711346 loss)
I1018 10:21:11.659293 11069 solver.cpp:571] Iteration 14280, lr = 0.001
I1018 10:21:19.316341 11069 solver.cpp:242] Iteration 14300, loss = 0.176546
I1018 10:21:19.316368 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0682659 (* 1 = 0.0682659 loss)
I1018 10:21:19.316373 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.10828 (* 1 = 0.10828 loss)
I1018 10:21:19.316378 11069 solver.cpp:571] Iteration 14300, lr = 0.001
I1018 10:21:26.953959 11069 solver.cpp:242] Iteration 14320, loss = 0.921621
I1018 10:21:26.953985 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.315004 (* 1 = 0.315004 loss)
I1018 10:21:26.953990 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.606618 (* 1 = 0.606618 loss)
I1018 10:21:26.953994 11069 solver.cpp:571] Iteration 14320, lr = 0.001
I1018 10:21:34.534992 11069 solver.cpp:242] Iteration 14340, loss = 0.961959
I1018 10:21:34.535017 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241479 (* 1 = 0.241479 loss)
I1018 10:21:34.535023 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.720479 (* 1 = 0.720479 loss)
I1018 10:21:34.535027 11069 solver.cpp:571] Iteration 14340, lr = 0.001
I1018 10:21:42.006091 11069 solver.cpp:242] Iteration 14360, loss = 0.446828
I1018 10:21:42.006116 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.109456 (* 1 = 0.109456 loss)
I1018 10:21:42.006121 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.337372 (* 1 = 0.337372 loss)
I1018 10:21:42.006125 11069 solver.cpp:571] Iteration 14360, lr = 0.001
I1018 10:21:49.694181 11069 solver.cpp:242] Iteration 14380, loss = 0.184777
I1018 10:21:49.694207 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0489503 (* 1 = 0.0489503 loss)
I1018 10:21:49.694212 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.135827 (* 1 = 0.135827 loss)
I1018 10:21:49.694216 11069 solver.cpp:571] Iteration 14380, lr = 0.001
speed: 0.376s / iter
I1018 10:21:57.271256 11069 solver.cpp:242] Iteration 14400, loss = 0.886485
I1018 10:21:57.271281 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240267 (* 1 = 0.240267 loss)
I1018 10:21:57.271286 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.646218 (* 1 = 0.646218 loss)
I1018 10:21:57.271291 11069 solver.cpp:571] Iteration 14400, lr = 0.001
I1018 10:22:04.842375 11069 solver.cpp:242] Iteration 14420, loss = 0.643074
I1018 10:22:04.842399 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.178732 (* 1 = 0.178732 loss)
I1018 10:22:04.842404 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.464342 (* 1 = 0.464342 loss)
I1018 10:22:04.842407 11069 solver.cpp:571] Iteration 14420, lr = 0.001
I1018 10:22:12.357347 11069 solver.cpp:242] Iteration 14440, loss = 0.309508
I1018 10:22:12.357372 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0670153 (* 1 = 0.0670153 loss)
I1018 10:22:12.357377 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242493 (* 1 = 0.242493 loss)
I1018 10:22:12.357380 11069 solver.cpp:571] Iteration 14440, lr = 0.001
I1018 10:22:19.959298 11069 solver.cpp:242] Iteration 14460, loss = 0.680368
I1018 10:22:19.959326 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.21538 (* 1 = 0.21538 loss)
I1018 10:22:19.959331 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.464988 (* 1 = 0.464988 loss)
I1018 10:22:19.959336 11069 solver.cpp:571] Iteration 14460, lr = 0.001
I1018 10:22:27.612781 11069 solver.cpp:242] Iteration 14480, loss = 1.14706
I1018 10:22:27.612805 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.410352 (* 1 = 0.410352 loss)
I1018 10:22:27.612809 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.736712 (* 1 = 0.736712 loss)
I1018 10:22:27.612813 11069 solver.cpp:571] Iteration 14480, lr = 0.001
I1018 10:22:35.277420 11069 solver.cpp:242] Iteration 14500, loss = 0.721467
I1018 10:22:35.277444 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.257587 (* 1 = 0.257587 loss)
I1018 10:22:35.277449 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.46388 (* 1 = 0.46388 loss)
I1018 10:22:35.277453 11069 solver.cpp:571] Iteration 14500, lr = 0.001
I1018 10:22:42.855370 11069 solver.cpp:242] Iteration 14520, loss = 1.20719
I1018 10:22:42.855393 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.403449 (* 1 = 0.403449 loss)
I1018 10:22:42.855398 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.803742 (* 1 = 0.803742 loss)
I1018 10:22:42.855402 11069 solver.cpp:571] Iteration 14520, lr = 0.001
I1018 10:22:50.494455 11069 solver.cpp:242] Iteration 14540, loss = 0.365069
I1018 10:22:50.494480 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0591723 (* 1 = 0.0591723 loss)
I1018 10:22:50.494484 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.305897 (* 1 = 0.305897 loss)
I1018 10:22:50.494488 11069 solver.cpp:571] Iteration 14540, lr = 0.001
I1018 10:22:58.148465 11069 solver.cpp:242] Iteration 14560, loss = 0.406984
I1018 10:22:58.148491 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120645 (* 1 = 0.120645 loss)
I1018 10:22:58.148497 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.286339 (* 1 = 0.286339 loss)
I1018 10:22:58.148501 11069 solver.cpp:571] Iteration 14560, lr = 0.001
I1018 10:23:05.710146 11069 solver.cpp:242] Iteration 14580, loss = 0.576455
I1018 10:23:05.710172 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171075 (* 1 = 0.171075 loss)
I1018 10:23:05.710176 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.40538 (* 1 = 0.40538 loss)
I1018 10:23:05.710180 11069 solver.cpp:571] Iteration 14580, lr = 0.001
speed: 0.376s / iter
I1018 10:23:13.296795 11069 solver.cpp:242] Iteration 14600, loss = 0.167026
I1018 10:23:13.296820 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0251504 (* 1 = 0.0251504 loss)
I1018 10:23:13.296825 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141875 (* 1 = 0.141875 loss)
I1018 10:23:13.296829 11069 solver.cpp:571] Iteration 14600, lr = 0.001
I1018 10:23:20.895006 11069 solver.cpp:242] Iteration 14620, loss = 2.31821
I1018 10:23:20.895031 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.900526 (* 1 = 0.900526 loss)
I1018 10:23:20.895036 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.41769 (* 1 = 1.41769 loss)
I1018 10:23:20.895040 11069 solver.cpp:571] Iteration 14620, lr = 0.001
I1018 10:23:28.563673 11069 solver.cpp:242] Iteration 14640, loss = 0.34804
I1018 10:23:28.563699 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0501408 (* 1 = 0.0501408 loss)
I1018 10:23:28.563704 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.297899 (* 1 = 0.297899 loss)
I1018 10:23:28.563707 11069 solver.cpp:571] Iteration 14640, lr = 0.001
I1018 10:23:36.184331 11069 solver.cpp:242] Iteration 14660, loss = 0.771219
I1018 10:23:36.184356 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203361 (* 1 = 0.203361 loss)
I1018 10:23:36.184361 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.567857 (* 1 = 0.567857 loss)
I1018 10:23:36.184365 11069 solver.cpp:571] Iteration 14660, lr = 0.001
I1018 10:23:43.885411 11069 solver.cpp:242] Iteration 14680, loss = 0.199144
I1018 10:23:43.885437 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0292583 (* 1 = 0.0292583 loss)
I1018 10:23:43.885440 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.169886 (* 1 = 0.169886 loss)
I1018 10:23:43.885444 11069 solver.cpp:571] Iteration 14680, lr = 0.001
I1018 10:23:51.469244 11069 solver.cpp:242] Iteration 14700, loss = 0.39217
I1018 10:23:51.469269 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.148274 (* 1 = 0.148274 loss)
I1018 10:23:51.469274 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.243895 (* 1 = 0.243895 loss)
I1018 10:23:51.469279 11069 solver.cpp:571] Iteration 14700, lr = 0.001
I1018 10:23:59.054188 11069 solver.cpp:242] Iteration 14720, loss = 0.717477
I1018 10:23:59.054213 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.231965 (* 1 = 0.231965 loss)
I1018 10:23:59.054216 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.485512 (* 1 = 0.485512 loss)
I1018 10:23:59.054220 11069 solver.cpp:571] Iteration 14720, lr = 0.001
I1018 10:24:06.659379 11069 solver.cpp:242] Iteration 14740, loss = 1.71835
I1018 10:24:06.659404 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.913503 (* 1 = 0.913503 loss)
I1018 10:24:06.659409 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.804847 (* 1 = 0.804847 loss)
I1018 10:24:06.659415 11069 solver.cpp:571] Iteration 14740, lr = 0.001
I1018 10:24:14.293872 11069 solver.cpp:242] Iteration 14760, loss = 0.309392
I1018 10:24:14.293896 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0922792 (* 1 = 0.0922792 loss)
I1018 10:24:14.293901 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.217113 (* 1 = 0.217113 loss)
I1018 10:24:14.293905 11069 solver.cpp:571] Iteration 14760, lr = 0.001
I1018 10:24:21.830811 11069 solver.cpp:242] Iteration 14780, loss = 0.411662
I1018 10:24:21.830835 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.096646 (* 1 = 0.096646 loss)
I1018 10:24:21.830840 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.315016 (* 1 = 0.315016 loss)
I1018 10:24:21.830844 11069 solver.cpp:571] Iteration 14780, lr = 0.001
speed: 0.376s / iter
I1018 10:24:29.414103 11069 solver.cpp:242] Iteration 14800, loss = 2.05497
I1018 10:24:29.414126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.26299 (* 1 = 1.26299 loss)
I1018 10:24:29.414130 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.79198 (* 1 = 0.79198 loss)
I1018 10:24:29.414135 11069 solver.cpp:571] Iteration 14800, lr = 0.001
I1018 10:24:37.012579 11069 solver.cpp:242] Iteration 14820, loss = 0.136295
I1018 10:24:37.012605 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0357101 (* 1 = 0.0357101 loss)
I1018 10:24:37.012609 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.100585 (* 1 = 0.100585 loss)
I1018 10:24:37.012614 11069 solver.cpp:571] Iteration 14820, lr = 0.001
I1018 10:24:44.681119 11069 solver.cpp:242] Iteration 14840, loss = 0.803949
I1018 10:24:44.681143 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.281791 (* 1 = 0.281791 loss)
I1018 10:24:44.681149 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.522158 (* 1 = 0.522158 loss)
I1018 10:24:44.681152 11069 solver.cpp:571] Iteration 14840, lr = 0.001
I1018 10:24:52.276598 11069 solver.cpp:242] Iteration 14860, loss = 0.300002
I1018 10:24:52.276624 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0412141 (* 1 = 0.0412141 loss)
I1018 10:24:52.276628 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.258787 (* 1 = 0.258787 loss)
I1018 10:24:52.276633 11069 solver.cpp:571] Iteration 14860, lr = 0.001
I1018 10:24:59.891142 11069 solver.cpp:242] Iteration 14880, loss = 0.916252
I1018 10:24:59.891168 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.27928 (* 1 = 0.27928 loss)
I1018 10:24:59.891172 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.636972 (* 1 = 0.636972 loss)
I1018 10:24:59.891176 11069 solver.cpp:571] Iteration 14880, lr = 0.001
I1018 10:25:07.567656 11069 solver.cpp:242] Iteration 14900, loss = 0.4259
I1018 10:25:07.567682 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0744699 (* 1 = 0.0744699 loss)
I1018 10:25:07.567687 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35143 (* 1 = 0.35143 loss)
I1018 10:25:07.567692 11069 solver.cpp:571] Iteration 14900, lr = 0.001
I1018 10:25:15.175526 11069 solver.cpp:242] Iteration 14920, loss = 0.1294
I1018 10:25:15.175551 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0288535 (* 1 = 0.0288535 loss)
I1018 10:25:15.175556 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.100547 (* 1 = 0.100547 loss)
I1018 10:25:15.175560 11069 solver.cpp:571] Iteration 14920, lr = 0.001
I1018 10:25:22.818709 11069 solver.cpp:242] Iteration 14940, loss = 0.270834
I1018 10:25:22.818737 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0434117 (* 1 = 0.0434117 loss)
I1018 10:25:22.818740 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.227422 (* 1 = 0.227422 loss)
I1018 10:25:22.818744 11069 solver.cpp:571] Iteration 14940, lr = 0.001
I1018 10:25:30.403652 11069 solver.cpp:242] Iteration 14960, loss = 0.474619
I1018 10:25:30.403676 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0811746 (* 1 = 0.0811746 loss)
I1018 10:25:30.403681 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.393445 (* 1 = 0.393445 loss)
I1018 10:25:30.403686 11069 solver.cpp:571] Iteration 14960, lr = 0.001
I1018 10:25:37.971969 11069 solver.cpp:242] Iteration 14980, loss = 0.671268
I1018 10:25:37.971994 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240743 (* 1 = 0.240743 loss)
I1018 10:25:37.971999 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.430525 (* 1 = 0.430525 loss)
I1018 10:25:37.972003 11069 solver.cpp:571] Iteration 14980, lr = 0.001
speed: 0.376s / iter
I1018 10:25:45.504200 11069 solver.cpp:242] Iteration 15000, loss = 0.93269
I1018 10:25:45.504225 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.330219 (* 1 = 0.330219 loss)
I1018 10:25:45.504230 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.602471 (* 1 = 0.602471 loss)
I1018 10:25:45.504235 11069 solver.cpp:571] Iteration 15000, lr = 0.001
I1018 10:25:53.232090 11069 solver.cpp:242] Iteration 15020, loss = 0.281076
I1018 10:25:53.232116 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0434213 (* 1 = 0.0434213 loss)
I1018 10:25:53.232120 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.237655 (* 1 = 0.237655 loss)
I1018 10:25:53.232125 11069 solver.cpp:571] Iteration 15020, lr = 0.001
I1018 10:26:00.850908 11069 solver.cpp:242] Iteration 15040, loss = 0.793173
I1018 10:26:00.850932 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.226899 (* 1 = 0.226899 loss)
I1018 10:26:00.850937 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.566274 (* 1 = 0.566274 loss)
I1018 10:26:00.850941 11069 solver.cpp:571] Iteration 15040, lr = 0.001
I1018 10:26:08.452142 11069 solver.cpp:242] Iteration 15060, loss = 0.389729
I1018 10:26:08.452167 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0944665 (* 1 = 0.0944665 loss)
I1018 10:26:08.452170 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.295262 (* 1 = 0.295262 loss)
I1018 10:26:08.452174 11069 solver.cpp:571] Iteration 15060, lr = 0.001
I1018 10:26:15.961206 11069 solver.cpp:242] Iteration 15080, loss = 0.581424
I1018 10:26:15.961231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171201 (* 1 = 0.171201 loss)
I1018 10:26:15.961236 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.410223 (* 1 = 0.410223 loss)
I1018 10:26:15.961241 11069 solver.cpp:571] Iteration 15080, lr = 0.001
I1018 10:26:23.534268 11069 solver.cpp:242] Iteration 15100, loss = 0.249645
I1018 10:26:23.534293 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0496126 (* 1 = 0.0496126 loss)
I1018 10:26:23.534297 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.200032 (* 1 = 0.200032 loss)
I1018 10:26:23.534301 11069 solver.cpp:571] Iteration 15100, lr = 0.001
I1018 10:26:31.182725 11069 solver.cpp:242] Iteration 15120, loss = 0.586115
I1018 10:26:31.182750 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150463 (* 1 = 0.150463 loss)
I1018 10:26:31.182755 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.435652 (* 1 = 0.435652 loss)
I1018 10:26:31.182760 11069 solver.cpp:571] Iteration 15120, lr = 0.001
I1018 10:26:38.813910 11069 solver.cpp:242] Iteration 15140, loss = 0.266787
I1018 10:26:38.813935 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0173609 (* 1 = 0.0173609 loss)
I1018 10:26:38.813941 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249426 (* 1 = 0.249426 loss)
I1018 10:26:38.813944 11069 solver.cpp:571] Iteration 15140, lr = 0.001
I1018 10:26:46.430192 11069 solver.cpp:242] Iteration 15160, loss = 0.632476
I1018 10:26:46.430217 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.15379 (* 1 = 0.15379 loss)
I1018 10:26:46.430222 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.478686 (* 1 = 0.478686 loss)
I1018 10:26:46.430225 11069 solver.cpp:571] Iteration 15160, lr = 0.001
I1018 10:26:54.037694 11069 solver.cpp:242] Iteration 15180, loss = 0.497366
I1018 10:26:54.037719 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.179726 (* 1 = 0.179726 loss)
I1018 10:26:54.037724 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.31764 (* 1 = 0.31764 loss)
I1018 10:26:54.037729 11069 solver.cpp:571] Iteration 15180, lr = 0.001
speed: 0.376s / iter
I1018 10:27:01.616156 11069 solver.cpp:242] Iteration 15200, loss = 0.57696
I1018 10:27:01.616179 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181176 (* 1 = 0.181176 loss)
I1018 10:27:01.616184 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.395784 (* 1 = 0.395784 loss)
I1018 10:27:01.616189 11069 solver.cpp:571] Iteration 15200, lr = 0.001
I1018 10:27:09.323926 11069 solver.cpp:242] Iteration 15220, loss = 0.650211
I1018 10:27:09.323951 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.233164 (* 1 = 0.233164 loss)
I1018 10:27:09.323956 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.417047 (* 1 = 0.417047 loss)
I1018 10:27:09.323959 11069 solver.cpp:571] Iteration 15220, lr = 0.001
I1018 10:27:16.890806 11069 solver.cpp:242] Iteration 15240, loss = 0.812321
I1018 10:27:16.890832 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.264366 (* 1 = 0.264366 loss)
I1018 10:27:16.890836 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.547956 (* 1 = 0.547956 loss)
I1018 10:27:16.890841 11069 solver.cpp:571] Iteration 15240, lr = 0.001
I1018 10:27:24.457703 11069 solver.cpp:242] Iteration 15260, loss = 0.309218
I1018 10:27:24.457727 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0855888 (* 1 = 0.0855888 loss)
I1018 10:27:24.457732 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22363 (* 1 = 0.22363 loss)
I1018 10:27:24.457736 11069 solver.cpp:571] Iteration 15260, lr = 0.001
I1018 10:27:32.165313 11069 solver.cpp:242] Iteration 15280, loss = 0.309868
I1018 10:27:32.165338 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113734 (* 1 = 0.113734 loss)
I1018 10:27:32.165343 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.196134 (* 1 = 0.196134 loss)
I1018 10:27:32.165346 11069 solver.cpp:571] Iteration 15280, lr = 0.001
I1018 10:27:39.868288 11069 solver.cpp:242] Iteration 15300, loss = 0.957761
I1018 10:27:39.868312 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.400445 (* 1 = 0.400445 loss)
I1018 10:27:39.868316 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.557316 (* 1 = 0.557316 loss)
I1018 10:27:39.868320 11069 solver.cpp:571] Iteration 15300, lr = 0.001
I1018 10:27:47.502470 11069 solver.cpp:242] Iteration 15320, loss = 0.872692
I1018 10:27:47.502495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.327748 (* 1 = 0.327748 loss)
I1018 10:27:47.502499 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.544944 (* 1 = 0.544944 loss)
I1018 10:27:47.502503 11069 solver.cpp:571] Iteration 15320, lr = 0.001
I1018 10:27:55.116605 11069 solver.cpp:242] Iteration 15340, loss = 0.353129
I1018 10:27:55.116629 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122332 (* 1 = 0.122332 loss)
I1018 10:27:55.116634 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.230796 (* 1 = 0.230796 loss)
I1018 10:27:55.116638 11069 solver.cpp:571] Iteration 15340, lr = 0.001
I1018 10:28:02.662698 11069 solver.cpp:242] Iteration 15360, loss = 0.867876
I1018 10:28:02.662724 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.322119 (* 1 = 0.322119 loss)
I1018 10:28:02.662729 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.545756 (* 1 = 0.545756 loss)
I1018 10:28:02.662732 11069 solver.cpp:571] Iteration 15360, lr = 0.001
I1018 10:28:10.234015 11069 solver.cpp:242] Iteration 15380, loss = 0.594099
I1018 10:28:10.234040 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1052 (* 1 = 0.1052 loss)
I1018 10:28:10.234045 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.488899 (* 1 = 0.488899 loss)
I1018 10:28:10.234050 11069 solver.cpp:571] Iteration 15380, lr = 0.001
speed: 0.376s / iter
I1018 10:28:17.869207 11069 solver.cpp:242] Iteration 15400, loss = 0.485944
I1018 10:28:17.869231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123999 (* 1 = 0.123999 loss)
I1018 10:28:17.869236 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.361945 (* 1 = 0.361945 loss)
I1018 10:28:17.869240 11069 solver.cpp:571] Iteration 15400, lr = 0.001
I1018 10:28:25.518251 11069 solver.cpp:242] Iteration 15420, loss = 0.242293
I1018 10:28:25.518276 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0448341 (* 1 = 0.0448341 loss)
I1018 10:28:25.518281 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197459 (* 1 = 0.197459 loss)
I1018 10:28:25.518285 11069 solver.cpp:571] Iteration 15420, lr = 0.001
I1018 10:28:33.293213 11069 solver.cpp:242] Iteration 15440, loss = 0.817677
I1018 10:28:33.293238 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.270349 (* 1 = 0.270349 loss)
I1018 10:28:33.293243 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.547328 (* 1 = 0.547328 loss)
I1018 10:28:33.293247 11069 solver.cpp:571] Iteration 15440, lr = 0.001
I1018 10:28:40.822151 11069 solver.cpp:242] Iteration 15460, loss = 0.610039
I1018 10:28:40.822177 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.166564 (* 1 = 0.166564 loss)
I1018 10:28:40.822181 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.443475 (* 1 = 0.443475 loss)
I1018 10:28:40.822185 11069 solver.cpp:571] Iteration 15460, lr = 0.001
I1018 10:28:48.401163 11069 solver.cpp:242] Iteration 15480, loss = 0.782265
I1018 10:28:48.401187 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241799 (* 1 = 0.241799 loss)
I1018 10:28:48.401191 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.540466 (* 1 = 0.540466 loss)
I1018 10:28:48.401196 11069 solver.cpp:571] Iteration 15480, lr = 0.001
I1018 10:28:55.931586 11069 solver.cpp:242] Iteration 15500, loss = 0.708204
I1018 10:28:55.931610 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.233419 (* 1 = 0.233419 loss)
I1018 10:28:55.931615 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.474785 (* 1 = 0.474785 loss)
I1018 10:28:55.931619 11069 solver.cpp:571] Iteration 15500, lr = 0.001
I1018 10:29:03.559101 11069 solver.cpp:242] Iteration 15520, loss = 1.61625
I1018 10:29:03.559126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.552295 (* 1 = 0.552295 loss)
I1018 10:29:03.559131 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.06396 (* 1 = 1.06396 loss)
I1018 10:29:03.559135 11069 solver.cpp:571] Iteration 15520, lr = 0.001
I1018 10:29:11.156934 11069 solver.cpp:242] Iteration 15540, loss = 0.379942
I1018 10:29:11.156960 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.098182 (* 1 = 0.098182 loss)
I1018 10:29:11.156965 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.28176 (* 1 = 0.28176 loss)
I1018 10:29:11.156968 11069 solver.cpp:571] Iteration 15540, lr = 0.001
I1018 10:29:18.727215 11069 solver.cpp:242] Iteration 15560, loss = 0.744934
I1018 10:29:18.727239 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.227043 (* 1 = 0.227043 loss)
I1018 10:29:18.727244 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.517892 (* 1 = 0.517892 loss)
I1018 10:29:18.727248 11069 solver.cpp:571] Iteration 15560, lr = 0.001
I1018 10:29:26.402990 11069 solver.cpp:242] Iteration 15580, loss = 1.53662
I1018 10:29:26.403015 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.636003 (* 1 = 0.636003 loss)
I1018 10:29:26.403019 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.90062 (* 1 = 0.90062 loss)
I1018 10:29:26.403024 11069 solver.cpp:571] Iteration 15580, lr = 0.001
speed: 0.376s / iter
I1018 10:29:34.011036 11069 solver.cpp:242] Iteration 15600, loss = 0.208857
I1018 10:29:34.011062 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0629237 (* 1 = 0.0629237 loss)
I1018 10:29:34.011066 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.145934 (* 1 = 0.145934 loss)
I1018 10:29:34.011070 11069 solver.cpp:571] Iteration 15600, lr = 0.001
I1018 10:29:41.556911 11069 solver.cpp:242] Iteration 15620, loss = 0.285914
I1018 10:29:41.556937 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0551971 (* 1 = 0.0551971 loss)
I1018 10:29:41.556941 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.230717 (* 1 = 0.230717 loss)
I1018 10:29:41.556946 11069 solver.cpp:571] Iteration 15620, lr = 0.001
I1018 10:29:49.145925 11069 solver.cpp:242] Iteration 15640, loss = 0.825584
I1018 10:29:49.145949 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.258252 (* 1 = 0.258252 loss)
I1018 10:29:49.145954 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.567332 (* 1 = 0.567332 loss)
I1018 10:29:49.145958 11069 solver.cpp:571] Iteration 15640, lr = 0.001
I1018 10:29:56.816138 11069 solver.cpp:242] Iteration 15660, loss = 0.332809
I1018 10:29:56.816162 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0556735 (* 1 = 0.0556735 loss)
I1018 10:29:56.816166 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.277135 (* 1 = 0.277135 loss)
I1018 10:29:56.816171 11069 solver.cpp:571] Iteration 15660, lr = 0.001
I1018 10:30:04.499372 11069 solver.cpp:242] Iteration 15680, loss = 1.02617
I1018 10:30:04.499397 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.250436 (* 1 = 0.250436 loss)
I1018 10:30:04.499402 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.775739 (* 1 = 0.775739 loss)
I1018 10:30:04.499406 11069 solver.cpp:571] Iteration 15680, lr = 0.001
I1018 10:30:12.049727 11069 solver.cpp:242] Iteration 15700, loss = 0.738048
I1018 10:30:12.049752 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.198903 (* 1 = 0.198903 loss)
I1018 10:30:12.049757 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.539144 (* 1 = 0.539144 loss)
I1018 10:30:12.049760 11069 solver.cpp:571] Iteration 15700, lr = 0.001
I1018 10:30:19.657889 11069 solver.cpp:242] Iteration 15720, loss = 0.216128
I1018 10:30:19.657914 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0495176 (* 1 = 0.0495176 loss)
I1018 10:30:19.657919 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166611 (* 1 = 0.166611 loss)
I1018 10:30:19.657923 11069 solver.cpp:571] Iteration 15720, lr = 0.001
I1018 10:30:27.321137 11069 solver.cpp:242] Iteration 15740, loss = 0.618726
I1018 10:30:27.321161 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.192686 (* 1 = 0.192686 loss)
I1018 10:30:27.321166 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.42604 (* 1 = 0.42604 loss)
I1018 10:30:27.321171 11069 solver.cpp:571] Iteration 15740, lr = 0.001
I1018 10:30:34.980514 11069 solver.cpp:242] Iteration 15760, loss = 0.21216
I1018 10:30:34.980538 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0637295 (* 1 = 0.0637295 loss)
I1018 10:30:34.980543 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148431 (* 1 = 0.148431 loss)
I1018 10:30:34.980548 11069 solver.cpp:571] Iteration 15760, lr = 0.001
I1018 10:30:42.654805 11069 solver.cpp:242] Iteration 15780, loss = 0.675698
I1018 10:30:42.654830 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.179919 (* 1 = 0.179919 loss)
I1018 10:30:42.654835 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495779 (* 1 = 0.495779 loss)
I1018 10:30:42.654839 11069 solver.cpp:571] Iteration 15780, lr = 0.001
speed: 0.376s / iter
I1018 10:30:50.215543 11069 solver.cpp:242] Iteration 15800, loss = 0.200145
I1018 10:30:50.215569 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0531923 (* 1 = 0.0531923 loss)
I1018 10:30:50.215572 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.146953 (* 1 = 0.146953 loss)
I1018 10:30:50.215577 11069 solver.cpp:571] Iteration 15800, lr = 0.001
I1018 10:30:57.866710 11069 solver.cpp:242] Iteration 15820, loss = 1.35163
I1018 10:30:57.866734 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.508834 (* 1 = 0.508834 loss)
I1018 10:30:57.866739 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.842795 (* 1 = 0.842795 loss)
I1018 10:30:57.866744 11069 solver.cpp:571] Iteration 15820, lr = 0.001
I1018 10:31:05.563119 11069 solver.cpp:242] Iteration 15840, loss = 0.929815
I1018 10:31:05.563143 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210855 (* 1 = 0.210855 loss)
I1018 10:31:05.563148 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.71896 (* 1 = 0.71896 loss)
I1018 10:31:05.563153 11069 solver.cpp:571] Iteration 15840, lr = 0.001
I1018 10:31:13.161763 11069 solver.cpp:242] Iteration 15860, loss = 1.44989
I1018 10:31:13.161788 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.59567 (* 1 = 0.59567 loss)
I1018 10:31:13.161792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.85422 (* 1 = 0.85422 loss)
I1018 10:31:13.161797 11069 solver.cpp:571] Iteration 15860, lr = 0.001
I1018 10:31:20.758004 11069 solver.cpp:242] Iteration 15880, loss = 0.655885
I1018 10:31:20.758030 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.209453 (* 1 = 0.209453 loss)
I1018 10:31:20.758034 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.446431 (* 1 = 0.446431 loss)
I1018 10:31:20.758038 11069 solver.cpp:571] Iteration 15880, lr = 0.001
I1018 10:31:28.485687 11069 solver.cpp:242] Iteration 15900, loss = 0.489216
I1018 10:31:28.485710 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181294 (* 1 = 0.181294 loss)
I1018 10:31:28.485715 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.307922 (* 1 = 0.307922 loss)
I1018 10:31:28.485719 11069 solver.cpp:571] Iteration 15900, lr = 0.001
I1018 10:31:36.153514 11069 solver.cpp:242] Iteration 15920, loss = 0.428109
I1018 10:31:36.153539 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100428 (* 1 = 0.100428 loss)
I1018 10:31:36.153543 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.327681 (* 1 = 0.327681 loss)
I1018 10:31:36.153548 11069 solver.cpp:571] Iteration 15920, lr = 0.001
I1018 10:31:43.787684 11069 solver.cpp:242] Iteration 15940, loss = 0.281897
I1018 10:31:43.787709 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115258 (* 1 = 0.115258 loss)
I1018 10:31:43.787714 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166639 (* 1 = 0.166639 loss)
I1018 10:31:43.787719 11069 solver.cpp:571] Iteration 15940, lr = 0.001
I1018 10:31:51.386307 11069 solver.cpp:242] Iteration 15960, loss = 0.140347
I1018 10:31:51.386332 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0542679 (* 1 = 0.0542679 loss)
I1018 10:31:51.386337 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0860791 (* 1 = 0.0860791 loss)
I1018 10:31:51.386340 11069 solver.cpp:571] Iteration 15960, lr = 0.001
I1018 10:31:58.958881 11069 solver.cpp:242] Iteration 15980, loss = 0.576804
I1018 10:31:58.958906 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.201761 (* 1 = 0.201761 loss)
I1018 10:31:58.958911 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.375043 (* 1 = 0.375043 loss)
I1018 10:31:58.958915 11069 solver.cpp:571] Iteration 15980, lr = 0.001
speed: 0.376s / iter
I1018 10:32:06.501513 11069 solver.cpp:242] Iteration 16000, loss = 0.271165
I1018 10:32:06.501540 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0520505 (* 1 = 0.0520505 loss)
I1018 10:32:06.501544 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.219114 (* 1 = 0.219114 loss)
I1018 10:32:06.501549 11069 solver.cpp:571] Iteration 16000, lr = 0.001
I1018 10:32:14.112848 11069 solver.cpp:242] Iteration 16020, loss = 0.691037
I1018 10:32:14.112872 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.217199 (* 1 = 0.217199 loss)
I1018 10:32:14.112877 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473838 (* 1 = 0.473838 loss)
I1018 10:32:14.112881 11069 solver.cpp:571] Iteration 16020, lr = 0.001
I1018 10:32:21.688941 11069 solver.cpp:242] Iteration 16040, loss = 0.516437
I1018 10:32:21.688966 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.148411 (* 1 = 0.148411 loss)
I1018 10:32:21.688969 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.368026 (* 1 = 0.368026 loss)
I1018 10:32:21.688973 11069 solver.cpp:571] Iteration 16040, lr = 0.001
I1018 10:32:29.263069 11069 solver.cpp:242] Iteration 16060, loss = 0.585896
I1018 10:32:29.263094 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151552 (* 1 = 0.151552 loss)
I1018 10:32:29.263099 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.434344 (* 1 = 0.434344 loss)
I1018 10:32:29.263103 11069 solver.cpp:571] Iteration 16060, lr = 0.001
I1018 10:32:36.903151 11069 solver.cpp:242] Iteration 16080, loss = 0.387309
I1018 10:32:36.903177 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104507 (* 1 = 0.104507 loss)
I1018 10:32:36.903182 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.282803 (* 1 = 0.282803 loss)
I1018 10:32:36.903185 11069 solver.cpp:571] Iteration 16080, lr = 0.001
I1018 10:32:44.551009 11069 solver.cpp:242] Iteration 16100, loss = 0.316133
I1018 10:32:44.551034 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0705249 (* 1 = 0.0705249 loss)
I1018 10:32:44.551039 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.245608 (* 1 = 0.245608 loss)
I1018 10:32:44.551043 11069 solver.cpp:571] Iteration 16100, lr = 0.001
I1018 10:32:52.182517 11069 solver.cpp:242] Iteration 16120, loss = 0.519931
I1018 10:32:52.182540 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.16477 (* 1 = 0.16477 loss)
I1018 10:32:52.182544 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35516 (* 1 = 0.35516 loss)
I1018 10:32:52.182548 11069 solver.cpp:571] Iteration 16120, lr = 0.001
I1018 10:32:59.754552 11069 solver.cpp:242] Iteration 16140, loss = 0.682457
I1018 10:32:59.754577 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.211777 (* 1 = 0.211777 loss)
I1018 10:32:59.754582 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.47068 (* 1 = 0.47068 loss)
I1018 10:32:59.754586 11069 solver.cpp:571] Iteration 16140, lr = 0.001
I1018 10:33:07.374827 11069 solver.cpp:242] Iteration 16160, loss = 0.814033
I1018 10:33:07.374852 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.229853 (* 1 = 0.229853 loss)
I1018 10:33:07.374856 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.58418 (* 1 = 0.58418 loss)
I1018 10:33:07.374861 11069 solver.cpp:571] Iteration 16160, lr = 0.001
I1018 10:33:14.988011 11069 solver.cpp:242] Iteration 16180, loss = 0.201298
I1018 10:33:14.988036 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0635509 (* 1 = 0.0635509 loss)
I1018 10:33:14.988041 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137747 (* 1 = 0.137747 loss)
I1018 10:33:14.988045 11069 solver.cpp:571] Iteration 16180, lr = 0.001
speed: 0.376s / iter
I1018 10:33:22.544694 11069 solver.cpp:242] Iteration 16200, loss = 0.204131
I1018 10:33:22.544719 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0542922 (* 1 = 0.0542922 loss)
I1018 10:33:22.544723 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149839 (* 1 = 0.149839 loss)
I1018 10:33:22.544728 11069 solver.cpp:571] Iteration 16200, lr = 0.001
I1018 10:33:30.142945 11069 solver.cpp:242] Iteration 16220, loss = 0.384923
I1018 10:33:30.142968 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13878 (* 1 = 0.13878 loss)
I1018 10:33:30.142973 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.246142 (* 1 = 0.246142 loss)
I1018 10:33:30.142977 11069 solver.cpp:571] Iteration 16220, lr = 0.001
I1018 10:33:37.764981 11069 solver.cpp:242] Iteration 16240, loss = 0.51779
I1018 10:33:37.765007 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.12819 (* 1 = 0.12819 loss)
I1018 10:33:37.765012 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3896 (* 1 = 0.3896 loss)
I1018 10:33:37.765014 11069 solver.cpp:571] Iteration 16240, lr = 0.001
I1018 10:33:45.369268 11069 solver.cpp:242] Iteration 16260, loss = 0.148722
I1018 10:33:45.369293 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0392433 (* 1 = 0.0392433 loss)
I1018 10:33:45.369298 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.109479 (* 1 = 0.109479 loss)
I1018 10:33:45.369302 11069 solver.cpp:571] Iteration 16260, lr = 0.001
I1018 10:33:53.025149 11069 solver.cpp:242] Iteration 16280, loss = 1.4338
I1018 10:33:53.025176 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.614898 (* 1 = 0.614898 loss)
I1018 10:33:53.025179 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.818907 (* 1 = 0.818907 loss)
I1018 10:33:53.025184 11069 solver.cpp:571] Iteration 16280, lr = 0.001
I1018 10:34:00.635182 11069 solver.cpp:242] Iteration 16300, loss = 0.295235
I1018 10:34:00.635208 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0710544 (* 1 = 0.0710544 loss)
I1018 10:34:00.635212 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224181 (* 1 = 0.224181 loss)
I1018 10:34:00.635217 11069 solver.cpp:571] Iteration 16300, lr = 0.001
I1018 10:34:08.253051 11069 solver.cpp:242] Iteration 16320, loss = 0.844372
I1018 10:34:08.253075 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.229067 (* 1 = 0.229067 loss)
I1018 10:34:08.253080 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.615306 (* 1 = 0.615306 loss)
I1018 10:34:08.253084 11069 solver.cpp:571] Iteration 16320, lr = 0.001
I1018 10:34:15.905568 11069 solver.cpp:242] Iteration 16340, loss = 0.663721
I1018 10:34:15.905594 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244461 (* 1 = 0.244461 loss)
I1018 10:34:15.905599 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.41926 (* 1 = 0.41926 loss)
I1018 10:34:15.905603 11069 solver.cpp:571] Iteration 16340, lr = 0.001
I1018 10:34:23.534329 11069 solver.cpp:242] Iteration 16360, loss = 0.20449
I1018 10:34:23.534354 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0549973 (* 1 = 0.0549973 loss)
I1018 10:34:23.534360 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149493 (* 1 = 0.149493 loss)
I1018 10:34:23.534364 11069 solver.cpp:571] Iteration 16360, lr = 0.001
I1018 10:34:31.110221 11069 solver.cpp:242] Iteration 16380, loss = 0.222072
I1018 10:34:31.110247 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0457363 (* 1 = 0.0457363 loss)
I1018 10:34:31.110252 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.176335 (* 1 = 0.176335 loss)
I1018 10:34:31.110256 11069 solver.cpp:571] Iteration 16380, lr = 0.001
speed: 0.376s / iter
I1018 10:34:38.664413 11069 solver.cpp:242] Iteration 16400, loss = 0.28089
I1018 10:34:38.664438 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0782126 (* 1 = 0.0782126 loss)
I1018 10:34:38.664443 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.202678 (* 1 = 0.202678 loss)
I1018 10:34:38.664446 11069 solver.cpp:571] Iteration 16400, lr = 0.001
I1018 10:34:46.243126 11069 solver.cpp:242] Iteration 16420, loss = 0.297682
I1018 10:34:46.243150 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.082294 (* 1 = 0.082294 loss)
I1018 10:34:46.243155 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.215388 (* 1 = 0.215388 loss)
I1018 10:34:46.243160 11069 solver.cpp:571] Iteration 16420, lr = 0.001
I1018 10:34:53.865872 11069 solver.cpp:242] Iteration 16440, loss = 0.794696
I1018 10:34:53.865897 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.254787 (* 1 = 0.254787 loss)
I1018 10:34:53.865902 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.539909 (* 1 = 0.539909 loss)
I1018 10:34:53.865907 11069 solver.cpp:571] Iteration 16440, lr = 0.001
I1018 10:35:01.398185 11069 solver.cpp:242] Iteration 16460, loss = 0.680625
I1018 10:35:01.398211 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147584 (* 1 = 0.147584 loss)
I1018 10:35:01.398216 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.533042 (* 1 = 0.533042 loss)
I1018 10:35:01.398221 11069 solver.cpp:571] Iteration 16460, lr = 0.001
I1018 10:35:08.961146 11069 solver.cpp:242] Iteration 16480, loss = 1.35457
I1018 10:35:08.961171 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.517558 (* 1 = 0.517558 loss)
I1018 10:35:08.961175 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.837014 (* 1 = 0.837014 loss)
I1018 10:35:08.961180 11069 solver.cpp:571] Iteration 16480, lr = 0.001
I1018 10:35:16.608438 11069 solver.cpp:242] Iteration 16500, loss = 1.1756
I1018 10:35:16.608464 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.325923 (* 1 = 0.325923 loss)
I1018 10:35:16.608469 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.849678 (* 1 = 0.849678 loss)
I1018 10:35:16.608472 11069 solver.cpp:571] Iteration 16500, lr = 0.001
I1018 10:35:24.191916 11069 solver.cpp:242] Iteration 16520, loss = 0.494944
I1018 10:35:24.191941 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0968667 (* 1 = 0.0968667 loss)
I1018 10:35:24.191946 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.398078 (* 1 = 0.398078 loss)
I1018 10:35:24.191949 11069 solver.cpp:571] Iteration 16520, lr = 0.001
I1018 10:35:31.831790 11069 solver.cpp:242] Iteration 16540, loss = 1.20787
I1018 10:35:31.831815 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.521189 (* 1 = 0.521189 loss)
I1018 10:35:31.831820 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.686682 (* 1 = 0.686682 loss)
I1018 10:35:31.831825 11069 solver.cpp:571] Iteration 16540, lr = 0.001
I1018 10:35:39.450088 11069 solver.cpp:242] Iteration 16560, loss = 0.513421
I1018 10:35:39.450111 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161242 (* 1 = 0.161242 loss)
I1018 10:35:39.450116 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.352179 (* 1 = 0.352179 loss)
I1018 10:35:39.450120 11069 solver.cpp:571] Iteration 16560, lr = 0.001
I1018 10:35:47.127082 11069 solver.cpp:242] Iteration 16580, loss = 0.250883
I1018 10:35:47.127109 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0581505 (* 1 = 0.0581505 loss)
I1018 10:35:47.127112 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.192733 (* 1 = 0.192733 loss)
I1018 10:35:47.127116 11069 solver.cpp:571] Iteration 16580, lr = 0.001
speed: 0.377s / iter
I1018 10:35:54.656121 11069 solver.cpp:242] Iteration 16600, loss = 0.423183
I1018 10:35:54.656144 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.141916 (* 1 = 0.141916 loss)
I1018 10:35:54.656149 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.281267 (* 1 = 0.281267 loss)
I1018 10:35:54.656153 11069 solver.cpp:571] Iteration 16600, lr = 0.001
I1018 10:36:02.263581 11069 solver.cpp:242] Iteration 16620, loss = 0.309614
I1018 10:36:02.263607 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0520821 (* 1 = 0.0520821 loss)
I1018 10:36:02.263612 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.257532 (* 1 = 0.257532 loss)
I1018 10:36:02.263617 11069 solver.cpp:571] Iteration 16620, lr = 0.001
I1018 10:36:09.886055 11069 solver.cpp:242] Iteration 16640, loss = 0.320838
I1018 10:36:09.886080 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0485909 (* 1 = 0.0485909 loss)
I1018 10:36:09.886085 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.272247 (* 1 = 0.272247 loss)
I1018 10:36:09.886090 11069 solver.cpp:571] Iteration 16640, lr = 0.001
I1018 10:36:17.446372 11069 solver.cpp:242] Iteration 16660, loss = 0.48876
I1018 10:36:17.446396 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.178809 (* 1 = 0.178809 loss)
I1018 10:36:17.446401 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.309951 (* 1 = 0.309951 loss)
I1018 10:36:17.446405 11069 solver.cpp:571] Iteration 16660, lr = 0.001
I1018 10:36:25.109473 11069 solver.cpp:242] Iteration 16680, loss = 0.213018
I1018 10:36:25.109499 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0319075 (* 1 = 0.0319075 loss)
I1018 10:36:25.109504 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.181111 (* 1 = 0.181111 loss)
I1018 10:36:25.109508 11069 solver.cpp:571] Iteration 16680, lr = 0.001
I1018 10:36:32.688441 11069 solver.cpp:242] Iteration 16700, loss = 0.240216
I1018 10:36:32.688467 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0571032 (* 1 = 0.0571032 loss)
I1018 10:36:32.688472 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.183113 (* 1 = 0.183113 loss)
I1018 10:36:32.688475 11069 solver.cpp:571] Iteration 16700, lr = 0.001
I1018 10:36:40.296037 11069 solver.cpp:242] Iteration 16720, loss = 0.336458
I1018 10:36:40.296061 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0791428 (* 1 = 0.0791428 loss)
I1018 10:36:40.296066 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.257315 (* 1 = 0.257315 loss)
I1018 10:36:40.296069 11069 solver.cpp:571] Iteration 16720, lr = 0.001
I1018 10:36:47.944705 11069 solver.cpp:242] Iteration 16740, loss = 1.01722
I1018 10:36:47.944730 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.264465 (* 1 = 0.264465 loss)
I1018 10:36:47.944735 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.752759 (* 1 = 0.752759 loss)
I1018 10:36:47.944738 11069 solver.cpp:571] Iteration 16740, lr = 0.001
I1018 10:36:55.504693 11069 solver.cpp:242] Iteration 16760, loss = 1.10515
I1018 10:36:55.504719 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.449988 (* 1 = 0.449988 loss)
I1018 10:36:55.504724 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.655165 (* 1 = 0.655165 loss)
I1018 10:36:55.504727 11069 solver.cpp:571] Iteration 16760, lr = 0.001
I1018 10:37:03.139401 11069 solver.cpp:242] Iteration 16780, loss = 0.736731
I1018 10:37:03.139427 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.17373 (* 1 = 0.17373 loss)
I1018 10:37:03.139432 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.563001 (* 1 = 0.563001 loss)
I1018 10:37:03.139436 11069 solver.cpp:571] Iteration 16780, lr = 0.001
speed: 0.377s / iter
I1018 10:37:10.717916 11069 solver.cpp:242] Iteration 16800, loss = 0.184066
I1018 10:37:10.717942 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0239189 (* 1 = 0.0239189 loss)
I1018 10:37:10.717947 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.160147 (* 1 = 0.160147 loss)
I1018 10:37:10.717952 11069 solver.cpp:571] Iteration 16800, lr = 0.001
I1018 10:37:18.329460 11069 solver.cpp:242] Iteration 16820, loss = 0.742013
I1018 10:37:18.329485 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.19214 (* 1 = 0.19214 loss)
I1018 10:37:18.329490 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.549872 (* 1 = 0.549872 loss)
I1018 10:37:18.329494 11069 solver.cpp:571] Iteration 16820, lr = 0.001
I1018 10:37:26.001375 11069 solver.cpp:242] Iteration 16840, loss = 0.229416
I1018 10:37:26.001400 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0424711 (* 1 = 0.0424711 loss)
I1018 10:37:26.001405 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.186945 (* 1 = 0.186945 loss)
I1018 10:37:26.001410 11069 solver.cpp:571] Iteration 16840, lr = 0.001
I1018 10:37:33.589658 11069 solver.cpp:242] Iteration 16860, loss = 0.953058
I1018 10:37:33.589684 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.329142 (* 1 = 0.329142 loss)
I1018 10:37:33.589689 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.623917 (* 1 = 0.623917 loss)
I1018 10:37:33.589692 11069 solver.cpp:571] Iteration 16860, lr = 0.001
I1018 10:37:41.237424 11069 solver.cpp:242] Iteration 16880, loss = 0.356322
I1018 10:37:41.237448 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0897627 (* 1 = 0.0897627 loss)
I1018 10:37:41.237452 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.266559 (* 1 = 0.266559 loss)
I1018 10:37:41.237457 11069 solver.cpp:571] Iteration 16880, lr = 0.001
I1018 10:37:48.815266 11069 solver.cpp:242] Iteration 16900, loss = 0.493159
I1018 10:37:48.815291 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0818037 (* 1 = 0.0818037 loss)
I1018 10:37:48.815295 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.411355 (* 1 = 0.411355 loss)
I1018 10:37:48.815300 11069 solver.cpp:571] Iteration 16900, lr = 0.001
I1018 10:37:56.428886 11069 solver.cpp:242] Iteration 16920, loss = 0.545884
I1018 10:37:56.428912 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.198079 (* 1 = 0.198079 loss)
I1018 10:37:56.428916 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.347805 (* 1 = 0.347805 loss)
I1018 10:37:56.428920 11069 solver.cpp:571] Iteration 16920, lr = 0.001
I1018 10:38:04.028082 11069 solver.cpp:242] Iteration 16940, loss = 0.932086
I1018 10:38:04.028108 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.228723 (* 1 = 0.228723 loss)
I1018 10:38:04.028112 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.703363 (* 1 = 0.703363 loss)
I1018 10:38:04.028116 11069 solver.cpp:571] Iteration 16940, lr = 0.001
I1018 10:38:11.647637 11069 solver.cpp:242] Iteration 16960, loss = 1.10559
I1018 10:38:11.647662 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.431092 (* 1 = 0.431092 loss)
I1018 10:38:11.647667 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.674496 (* 1 = 0.674496 loss)
I1018 10:38:11.647671 11069 solver.cpp:571] Iteration 16960, lr = 0.001
I1018 10:38:19.293376 11069 solver.cpp:242] Iteration 16980, loss = 0.29757
I1018 10:38:19.293402 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0708667 (* 1 = 0.0708667 loss)
I1018 10:38:19.293407 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.226704 (* 1 = 0.226704 loss)
I1018 10:38:19.293411 11069 solver.cpp:571] Iteration 16980, lr = 0.001
speed: 0.377s / iter
I1018 10:38:26.804941 11069 solver.cpp:242] Iteration 17000, loss = 0.247098
I1018 10:38:26.804966 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0660933 (* 1 = 0.0660933 loss)
I1018 10:38:26.804971 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.181004 (* 1 = 0.181004 loss)
I1018 10:38:26.804975 11069 solver.cpp:571] Iteration 17000, lr = 0.001
I1018 10:38:34.476876 11069 solver.cpp:242] Iteration 17020, loss = 0.687333
I1018 10:38:34.476902 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.175363 (* 1 = 0.175363 loss)
I1018 10:38:34.476907 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.51197 (* 1 = 0.51197 loss)
I1018 10:38:34.476912 11069 solver.cpp:571] Iteration 17020, lr = 0.001
I1018 10:38:42.142710 11069 solver.cpp:242] Iteration 17040, loss = 0.356835
I1018 10:38:42.142736 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0786243 (* 1 = 0.0786243 loss)
I1018 10:38:42.142741 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27821 (* 1 = 0.27821 loss)
I1018 10:38:42.142745 11069 solver.cpp:571] Iteration 17040, lr = 0.001
I1018 10:38:49.723099 11069 solver.cpp:242] Iteration 17060, loss = 0.449012
I1018 10:38:49.723126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.12009 (* 1 = 0.12009 loss)
I1018 10:38:49.723131 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.328922 (* 1 = 0.328922 loss)
I1018 10:38:49.723135 11069 solver.cpp:571] Iteration 17060, lr = 0.001
I1018 10:38:57.334919 11069 solver.cpp:242] Iteration 17080, loss = 0.427824
I1018 10:38:57.334944 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103776 (* 1 = 0.103776 loss)
I1018 10:38:57.334949 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.324048 (* 1 = 0.324048 loss)
I1018 10:38:57.334954 11069 solver.cpp:571] Iteration 17080, lr = 0.001
I1018 10:39:04.892590 11069 solver.cpp:242] Iteration 17100, loss = 0.362713
I1018 10:39:04.892616 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104232 (* 1 = 0.104232 loss)
I1018 10:39:04.892621 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.258482 (* 1 = 0.258482 loss)
I1018 10:39:04.892626 11069 solver.cpp:571] Iteration 17100, lr = 0.001
I1018 10:39:12.570420 11069 solver.cpp:242] Iteration 17120, loss = 0.249423
I1018 10:39:12.570446 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.101643 (* 1 = 0.101643 loss)
I1018 10:39:12.570451 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.147781 (* 1 = 0.147781 loss)
I1018 10:39:12.570454 11069 solver.cpp:571] Iteration 17120, lr = 0.001
I1018 10:39:20.101925 11069 solver.cpp:242] Iteration 17140, loss = 0.560781
I1018 10:39:20.101949 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.182015 (* 1 = 0.182015 loss)
I1018 10:39:20.101954 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.378766 (* 1 = 0.378766 loss)
I1018 10:39:20.101958 11069 solver.cpp:571] Iteration 17140, lr = 0.001
I1018 10:39:27.771075 11069 solver.cpp:242] Iteration 17160, loss = 0.462599
I1018 10:39:27.771101 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.141473 (* 1 = 0.141473 loss)
I1018 10:39:27.771106 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.321126 (* 1 = 0.321126 loss)
I1018 10:39:27.771111 11069 solver.cpp:571] Iteration 17160, lr = 0.001
I1018 10:39:35.458194 11069 solver.cpp:242] Iteration 17180, loss = 0.183844
I1018 10:39:35.458220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0427304 (* 1 = 0.0427304 loss)
I1018 10:39:35.458225 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141114 (* 1 = 0.141114 loss)
I1018 10:39:35.458230 11069 solver.cpp:571] Iteration 17180, lr = 0.001
speed: 0.377s / iter
I1018 10:39:43.028687 11069 solver.cpp:242] Iteration 17200, loss = 1.67758
I1018 10:39:43.028713 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.573249 (* 1 = 0.573249 loss)
I1018 10:39:43.028718 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.10433 (* 1 = 1.10433 loss)
I1018 10:39:43.028723 11069 solver.cpp:571] Iteration 17200, lr = 0.001
I1018 10:39:50.724340 11069 solver.cpp:242] Iteration 17220, loss = 0.160272
I1018 10:39:50.724365 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0187299 (* 1 = 0.0187299 loss)
I1018 10:39:50.724370 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141542 (* 1 = 0.141542 loss)
I1018 10:39:50.724375 11069 solver.cpp:571] Iteration 17220, lr = 0.001
I1018 10:39:58.232662 11069 solver.cpp:242] Iteration 17240, loss = 0.886476
I1018 10:39:58.232687 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.303041 (* 1 = 0.303041 loss)
I1018 10:39:58.232692 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.583434 (* 1 = 0.583434 loss)
I1018 10:39:58.232697 11069 solver.cpp:571] Iteration 17240, lr = 0.001
I1018 10:40:05.735635 11069 solver.cpp:242] Iteration 17260, loss = 0.305944
I1018 10:40:05.735661 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.052116 (* 1 = 0.052116 loss)
I1018 10:40:05.735666 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.253828 (* 1 = 0.253828 loss)
I1018 10:40:05.735671 11069 solver.cpp:571] Iteration 17260, lr = 0.001
I1018 10:40:13.398058 11069 solver.cpp:242] Iteration 17280, loss = 0.267728
I1018 10:40:13.398084 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0771455 (* 1 = 0.0771455 loss)
I1018 10:40:13.398088 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.190582 (* 1 = 0.190582 loss)
I1018 10:40:13.398093 11069 solver.cpp:571] Iteration 17280, lr = 0.001
I1018 10:40:21.088233 11069 solver.cpp:242] Iteration 17300, loss = 0.625743
I1018 10:40:21.088259 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.202254 (* 1 = 0.202254 loss)
I1018 10:40:21.088264 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.423488 (* 1 = 0.423488 loss)
I1018 10:40:21.088268 11069 solver.cpp:571] Iteration 17300, lr = 0.001
I1018 10:40:28.727252 11069 solver.cpp:242] Iteration 17320, loss = 0.114242
I1018 10:40:28.727279 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.025825 (* 1 = 0.025825 loss)
I1018 10:40:28.727285 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0884167 (* 1 = 0.0884167 loss)
I1018 10:40:28.727289 11069 solver.cpp:571] Iteration 17320, lr = 0.001
I1018 10:40:36.328153 11069 solver.cpp:242] Iteration 17340, loss = 0.552344
I1018 10:40:36.328178 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153177 (* 1 = 0.153177 loss)
I1018 10:40:36.328183 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.399166 (* 1 = 0.399166 loss)
I1018 10:40:36.328188 11069 solver.cpp:571] Iteration 17340, lr = 0.001
I1018 10:40:43.940603 11069 solver.cpp:242] Iteration 17360, loss = 0.315563
I1018 10:40:43.940629 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0533363 (* 1 = 0.0533363 loss)
I1018 10:40:43.940634 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.262227 (* 1 = 0.262227 loss)
I1018 10:40:43.940639 11069 solver.cpp:571] Iteration 17360, lr = 0.001
I1018 10:40:51.552531 11069 solver.cpp:242] Iteration 17380, loss = 0.384478
I1018 10:40:51.552557 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0774671 (* 1 = 0.0774671 loss)
I1018 10:40:51.552561 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.307011 (* 1 = 0.307011 loss)
I1018 10:40:51.552567 11069 solver.cpp:571] Iteration 17380, lr = 0.001
speed: 0.377s / iter
I1018 10:40:59.078037 11069 solver.cpp:242] Iteration 17400, loss = 0.337693
I1018 10:40:59.078063 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0813389 (* 1 = 0.0813389 loss)
I1018 10:40:59.078068 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.256354 (* 1 = 0.256354 loss)
I1018 10:40:59.078071 11069 solver.cpp:571] Iteration 17400, lr = 0.001
I1018 10:41:06.686952 11069 solver.cpp:242] Iteration 17420, loss = 1.03148
I1018 10:41:06.686978 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.311097 (* 1 = 0.311097 loss)
I1018 10:41:06.686983 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.720378 (* 1 = 0.720378 loss)
I1018 10:41:06.686988 11069 solver.cpp:571] Iteration 17420, lr = 0.001
I1018 10:41:14.392380 11069 solver.cpp:242] Iteration 17440, loss = 0.277071
I1018 10:41:14.392406 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0712927 (* 1 = 0.0712927 loss)
I1018 10:41:14.392410 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205778 (* 1 = 0.205778 loss)
I1018 10:41:14.392416 11069 solver.cpp:571] Iteration 17440, lr = 0.001
I1018 10:41:21.979681 11069 solver.cpp:242] Iteration 17460, loss = 0.637081
I1018 10:41:21.979706 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120924 (* 1 = 0.120924 loss)
I1018 10:41:21.979710 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.516157 (* 1 = 0.516157 loss)
I1018 10:41:21.979715 11069 solver.cpp:571] Iteration 17460, lr = 0.001
I1018 10:41:29.576525 11069 solver.cpp:242] Iteration 17480, loss = 0.786084
I1018 10:41:29.576550 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.234376 (* 1 = 0.234376 loss)
I1018 10:41:29.576555 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.551709 (* 1 = 0.551709 loss)
I1018 10:41:29.576560 11069 solver.cpp:571] Iteration 17480, lr = 0.001
I1018 10:41:37.274523 11069 solver.cpp:242] Iteration 17500, loss = 0.618748
I1018 10:41:37.274549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.192541 (* 1 = 0.192541 loss)
I1018 10:41:37.274552 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.426207 (* 1 = 0.426207 loss)
I1018 10:41:37.274557 11069 solver.cpp:571] Iteration 17500, lr = 0.001
I1018 10:41:44.925688 11069 solver.cpp:242] Iteration 17520, loss = 1.40615
I1018 10:41:44.925714 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.600371 (* 1 = 0.600371 loss)
I1018 10:41:44.925719 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.80578 (* 1 = 0.80578 loss)
I1018 10:41:44.925724 11069 solver.cpp:571] Iteration 17520, lr = 0.001
I1018 10:41:52.568148 11069 solver.cpp:242] Iteration 17540, loss = 0.51833
I1018 10:41:52.568173 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.156035 (* 1 = 0.156035 loss)
I1018 10:41:52.568178 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.362296 (* 1 = 0.362296 loss)
I1018 10:41:52.568183 11069 solver.cpp:571] Iteration 17540, lr = 0.001
I1018 10:42:00.231225 11069 solver.cpp:242] Iteration 17560, loss = 0.483071
I1018 10:42:00.231250 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.154507 (* 1 = 0.154507 loss)
I1018 10:42:00.231254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.328564 (* 1 = 0.328564 loss)
I1018 10:42:00.231258 11069 solver.cpp:571] Iteration 17560, lr = 0.001
I1018 10:42:07.908469 11069 solver.cpp:242] Iteration 17580, loss = 0.245339
I1018 10:42:07.908495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0673102 (* 1 = 0.0673102 loss)
I1018 10:42:07.908501 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178028 (* 1 = 0.178028 loss)
I1018 10:42:07.908505 11069 solver.cpp:571] Iteration 17580, lr = 0.001
speed: 0.377s / iter
I1018 10:42:15.532322 11069 solver.cpp:242] Iteration 17600, loss = 0.310714
I1018 10:42:15.532348 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0721332 (* 1 = 0.0721332 loss)
I1018 10:42:15.532353 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.23858 (* 1 = 0.23858 loss)
I1018 10:42:15.532357 11069 solver.cpp:571] Iteration 17600, lr = 0.001
I1018 10:42:23.189237 11069 solver.cpp:242] Iteration 17620, loss = 0.906931
I1018 10:42:23.189262 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.251363 (* 1 = 0.251363 loss)
I1018 10:42:23.189267 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.655568 (* 1 = 0.655568 loss)
I1018 10:42:23.189271 11069 solver.cpp:571] Iteration 17620, lr = 0.001
I1018 10:42:30.706617 11069 solver.cpp:242] Iteration 17640, loss = 1.09824
I1018 10:42:30.706643 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.339118 (* 1 = 0.339118 loss)
I1018 10:42:30.706647 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.759118 (* 1 = 0.759118 loss)
I1018 10:42:30.706652 11069 solver.cpp:571] Iteration 17640, lr = 0.001
I1018 10:42:38.306864 11069 solver.cpp:242] Iteration 17660, loss = 0.583899
I1018 10:42:38.306890 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159295 (* 1 = 0.159295 loss)
I1018 10:42:38.306893 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.424604 (* 1 = 0.424604 loss)
I1018 10:42:38.306898 11069 solver.cpp:571] Iteration 17660, lr = 0.001
I1018 10:42:45.934715 11069 solver.cpp:242] Iteration 17680, loss = 0.331382
I1018 10:42:45.934741 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0988875 (* 1 = 0.0988875 loss)
I1018 10:42:45.934746 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232494 (* 1 = 0.232494 loss)
I1018 10:42:45.934751 11069 solver.cpp:571] Iteration 17680, lr = 0.001
I1018 10:42:53.567157 11069 solver.cpp:242] Iteration 17700, loss = 0.57319
I1018 10:42:53.567183 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171378 (* 1 = 0.171378 loss)
I1018 10:42:53.567188 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.401813 (* 1 = 0.401813 loss)
I1018 10:42:53.567191 11069 solver.cpp:571] Iteration 17700, lr = 0.001
I1018 10:43:01.120862 11069 solver.cpp:242] Iteration 17720, loss = 0.846375
I1018 10:43:01.120887 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.223627 (* 1 = 0.223627 loss)
I1018 10:43:01.120893 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.622748 (* 1 = 0.622748 loss)
I1018 10:43:01.120898 11069 solver.cpp:571] Iteration 17720, lr = 0.001
I1018 10:43:08.757781 11069 solver.cpp:242] Iteration 17740, loss = 0.279424
I1018 10:43:08.757807 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0843319 (* 1 = 0.0843319 loss)
I1018 10:43:08.757812 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195092 (* 1 = 0.195092 loss)
I1018 10:43:08.757815 11069 solver.cpp:571] Iteration 17740, lr = 0.001
I1018 10:43:16.310084 11069 solver.cpp:242] Iteration 17760, loss = 0.650306
I1018 10:43:16.310109 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.209533 (* 1 = 0.209533 loss)
I1018 10:43:16.310114 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.440773 (* 1 = 0.440773 loss)
I1018 10:43:16.310118 11069 solver.cpp:571] Iteration 17760, lr = 0.001
I1018 10:43:24.012881 11069 solver.cpp:242] Iteration 17780, loss = 0.480888
I1018 10:43:24.012907 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152712 (* 1 = 0.152712 loss)
I1018 10:43:24.012912 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.328176 (* 1 = 0.328176 loss)
I1018 10:43:24.012917 11069 solver.cpp:571] Iteration 17780, lr = 0.001
speed: 0.377s / iter
I1018 10:43:31.650820 11069 solver.cpp:242] Iteration 17800, loss = 0.882027
I1018 10:43:31.650846 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.267271 (* 1 = 0.267271 loss)
I1018 10:43:31.650851 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.614756 (* 1 = 0.614756 loss)
I1018 10:43:31.650854 11069 solver.cpp:571] Iteration 17800, lr = 0.001
I1018 10:43:39.233197 11069 solver.cpp:242] Iteration 17820, loss = 0.208275
I1018 10:43:39.233222 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0500925 (* 1 = 0.0500925 loss)
I1018 10:43:39.233227 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.158183 (* 1 = 0.158183 loss)
I1018 10:43:39.233232 11069 solver.cpp:571] Iteration 17820, lr = 0.001
I1018 10:43:46.810832 11069 solver.cpp:242] Iteration 17840, loss = 1.50368
I1018 10:43:46.810856 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.490563 (* 1 = 0.490563 loss)
I1018 10:43:46.810861 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.01311 (* 1 = 1.01311 loss)
I1018 10:43:46.810865 11069 solver.cpp:571] Iteration 17840, lr = 0.001
I1018 10:43:54.349519 11069 solver.cpp:242] Iteration 17860, loss = 0.662948
I1018 10:43:54.349545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137687 (* 1 = 0.137687 loss)
I1018 10:43:54.349550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.52526 (* 1 = 0.52526 loss)
I1018 10:43:54.349553 11069 solver.cpp:571] Iteration 17860, lr = 0.001
I1018 10:44:01.921613 11069 solver.cpp:242] Iteration 17880, loss = 0.243263
I1018 10:44:01.921636 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0618083 (* 1 = 0.0618083 loss)
I1018 10:44:01.921641 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.181455 (* 1 = 0.181455 loss)
I1018 10:44:01.921645 11069 solver.cpp:571] Iteration 17880, lr = 0.001
I1018 10:44:09.647737 11069 solver.cpp:242] Iteration 17900, loss = 0.35257
I1018 10:44:09.647763 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114174 (* 1 = 0.114174 loss)
I1018 10:44:09.647768 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.238397 (* 1 = 0.238397 loss)
I1018 10:44:09.647773 11069 solver.cpp:571] Iteration 17900, lr = 0.001
I1018 10:44:17.324029 11069 solver.cpp:242] Iteration 17920, loss = 0.987005
I1018 10:44:17.324055 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.336972 (* 1 = 0.336972 loss)
I1018 10:44:17.324060 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.650033 (* 1 = 0.650033 loss)
I1018 10:44:17.324065 11069 solver.cpp:571] Iteration 17920, lr = 0.001
I1018 10:44:24.920686 11069 solver.cpp:242] Iteration 17940, loss = 0.796032
I1018 10:44:24.920711 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.289691 (* 1 = 0.289691 loss)
I1018 10:44:24.920717 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.506342 (* 1 = 0.506342 loss)
I1018 10:44:24.920720 11069 solver.cpp:571] Iteration 17940, lr = 0.001
I1018 10:44:32.549471 11069 solver.cpp:242] Iteration 17960, loss = 0.465463
I1018 10:44:32.549497 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1299 (* 1 = 0.1299 loss)
I1018 10:44:32.549502 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.335563 (* 1 = 0.335563 loss)
I1018 10:44:32.549507 11069 solver.cpp:571] Iteration 17960, lr = 0.001
I1018 10:44:40.235247 11069 solver.cpp:242] Iteration 17980, loss = 0.531323
I1018 10:44:40.235271 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142317 (* 1 = 0.142317 loss)
I1018 10:44:40.235276 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.389005 (* 1 = 0.389005 loss)
I1018 10:44:40.235280 11069 solver.cpp:571] Iteration 17980, lr = 0.001
speed: 0.377s / iter
I1018 10:44:47.761690 11069 solver.cpp:242] Iteration 18000, loss = 0.280578
I1018 10:44:47.761715 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100151 (* 1 = 0.100151 loss)
I1018 10:44:47.761720 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.180426 (* 1 = 0.180426 loss)
I1018 10:44:47.761724 11069 solver.cpp:571] Iteration 18000, lr = 0.001
I1018 10:44:55.392793 11069 solver.cpp:242] Iteration 18020, loss = 1.08419
I1018 10:44:55.392818 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.360143 (* 1 = 0.360143 loss)
I1018 10:44:55.392823 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.724051 (* 1 = 0.724051 loss)
I1018 10:44:55.392828 11069 solver.cpp:571] Iteration 18020, lr = 0.001
I1018 10:45:02.967330 11069 solver.cpp:242] Iteration 18040, loss = 0.135711
I1018 10:45:02.967356 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0281394 (* 1 = 0.0281394 loss)
I1018 10:45:02.967361 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.107571 (* 1 = 0.107571 loss)
I1018 10:45:02.967365 11069 solver.cpp:571] Iteration 18040, lr = 0.001
I1018 10:45:10.625275 11069 solver.cpp:242] Iteration 18060, loss = 0.491331
I1018 10:45:10.625300 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153824 (* 1 = 0.153824 loss)
I1018 10:45:10.625305 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.337507 (* 1 = 0.337507 loss)
I1018 10:45:10.625309 11069 solver.cpp:571] Iteration 18060, lr = 0.001
I1018 10:45:18.274322 11069 solver.cpp:242] Iteration 18080, loss = 0.182578
I1018 10:45:18.274348 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306068 (* 1 = 0.0306068 loss)
I1018 10:45:18.274353 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.151971 (* 1 = 0.151971 loss)
I1018 10:45:18.274356 11069 solver.cpp:571] Iteration 18080, lr = 0.001
I1018 10:45:25.879945 11069 solver.cpp:242] Iteration 18100, loss = 0.990801
I1018 10:45:25.879971 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.335983 (* 1 = 0.335983 loss)
I1018 10:45:25.879976 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.654818 (* 1 = 0.654818 loss)
I1018 10:45:25.879979 11069 solver.cpp:571] Iteration 18100, lr = 0.001
I1018 10:45:33.507642 11069 solver.cpp:242] Iteration 18120, loss = 0.49801
I1018 10:45:33.507668 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.112016 (* 1 = 0.112016 loss)
I1018 10:45:33.507673 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.385994 (* 1 = 0.385994 loss)
I1018 10:45:33.507676 11069 solver.cpp:571] Iteration 18120, lr = 0.001
I1018 10:45:41.089562 11069 solver.cpp:242] Iteration 18140, loss = 0.28137
I1018 10:45:41.089587 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0963931 (* 1 = 0.0963931 loss)
I1018 10:45:41.089592 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.184977 (* 1 = 0.184977 loss)
I1018 10:45:41.089596 11069 solver.cpp:571] Iteration 18140, lr = 0.001
I1018 10:45:48.673583 11069 solver.cpp:242] Iteration 18160, loss = 0.178034
I1018 10:45:48.673609 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0404843 (* 1 = 0.0404843 loss)
I1018 10:45:48.673614 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13755 (* 1 = 0.13755 loss)
I1018 10:45:48.673619 11069 solver.cpp:571] Iteration 18160, lr = 0.001
I1018 10:45:56.284744 11069 solver.cpp:242] Iteration 18180, loss = 0.350399
I1018 10:45:56.284768 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105781 (* 1 = 0.105781 loss)
I1018 10:45:56.284773 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.244618 (* 1 = 0.244618 loss)
I1018 10:45:56.284777 11069 solver.cpp:571] Iteration 18180, lr = 0.001
speed: 0.377s / iter
I1018 10:46:03.839193 11069 solver.cpp:242] Iteration 18200, loss = 0.569528
I1018 10:46:03.839220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103654 (* 1 = 0.103654 loss)
I1018 10:46:03.839224 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.465874 (* 1 = 0.465874 loss)
I1018 10:46:03.839228 11069 solver.cpp:571] Iteration 18200, lr = 0.001
I1018 10:46:11.317490 11069 solver.cpp:242] Iteration 18220, loss = 0.965036
I1018 10:46:11.317515 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.341668 (* 1 = 0.341668 loss)
I1018 10:46:11.317520 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.623369 (* 1 = 0.623369 loss)
I1018 10:46:11.317524 11069 solver.cpp:571] Iteration 18220, lr = 0.001
I1018 10:46:18.945348 11069 solver.cpp:242] Iteration 18240, loss = 1.11092
I1018 10:46:18.945374 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.446624 (* 1 = 0.446624 loss)
I1018 10:46:18.945379 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664298 (* 1 = 0.664298 loss)
I1018 10:46:18.945384 11069 solver.cpp:571] Iteration 18240, lr = 0.001
I1018 10:46:26.472970 11069 solver.cpp:242] Iteration 18260, loss = 1.34624
I1018 10:46:26.472995 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.462105 (* 1 = 0.462105 loss)
I1018 10:46:26.473000 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.88413 (* 1 = 0.88413 loss)
I1018 10:46:26.473003 11069 solver.cpp:571] Iteration 18260, lr = 0.001
I1018 10:46:34.146337 11069 solver.cpp:242] Iteration 18280, loss = 1.39802
I1018 10:46:34.146363 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.52774 (* 1 = 0.52774 loss)
I1018 10:46:34.146366 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.87028 (* 1 = 0.87028 loss)
I1018 10:46:34.146370 11069 solver.cpp:571] Iteration 18280, lr = 0.001
I1018 10:46:41.744294 11069 solver.cpp:242] Iteration 18300, loss = 0.918057
I1018 10:46:41.744320 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.338838 (* 1 = 0.338838 loss)
I1018 10:46:41.744325 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.579219 (* 1 = 0.579219 loss)
I1018 10:46:41.744329 11069 solver.cpp:571] Iteration 18300, lr = 0.001
I1018 10:46:49.345424 11069 solver.cpp:242] Iteration 18320, loss = 0.41177
I1018 10:46:49.345450 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.126471 (* 1 = 0.126471 loss)
I1018 10:46:49.345455 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.285299 (* 1 = 0.285299 loss)
I1018 10:46:49.345459 11069 solver.cpp:571] Iteration 18320, lr = 0.001
I1018 10:46:56.901881 11069 solver.cpp:242] Iteration 18340, loss = 0.504426
I1018 10:46:56.901906 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.163293 (* 1 = 0.163293 loss)
I1018 10:46:56.901911 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.341133 (* 1 = 0.341133 loss)
I1018 10:46:56.901916 11069 solver.cpp:571] Iteration 18340, lr = 0.001
I1018 10:47:04.542819 11069 solver.cpp:242] Iteration 18360, loss = 0.217282
I1018 10:47:04.542845 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529928 (* 1 = 0.0529928 loss)
I1018 10:47:04.542850 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.16429 (* 1 = 0.16429 loss)
I1018 10:47:04.542855 11069 solver.cpp:571] Iteration 18360, lr = 0.001
I1018 10:47:12.160102 11069 solver.cpp:242] Iteration 18380, loss = 0.263247
I1018 10:47:12.160128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0451106 (* 1 = 0.0451106 loss)
I1018 10:47:12.160133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218137 (* 1 = 0.218137 loss)
I1018 10:47:12.160137 11069 solver.cpp:571] Iteration 18380, lr = 0.001
speed: 0.377s / iter
I1018 10:47:19.742691 11069 solver.cpp:242] Iteration 18400, loss = 0.240628
I1018 10:47:19.742717 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0838502 (* 1 = 0.0838502 loss)
I1018 10:47:19.742722 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.156778 (* 1 = 0.156778 loss)
I1018 10:47:19.742727 11069 solver.cpp:571] Iteration 18400, lr = 0.001
I1018 10:47:27.368726 11069 solver.cpp:242] Iteration 18420, loss = 0.83599
I1018 10:47:27.368752 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.274734 (* 1 = 0.274734 loss)
I1018 10:47:27.368757 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.561255 (* 1 = 0.561255 loss)
I1018 10:47:27.368762 11069 solver.cpp:571] Iteration 18420, lr = 0.001
I1018 10:47:34.969367 11069 solver.cpp:242] Iteration 18440, loss = 0.866903
I1018 10:47:34.969391 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.248543 (* 1 = 0.248543 loss)
I1018 10:47:34.969396 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.61836 (* 1 = 0.61836 loss)
I1018 10:47:34.969400 11069 solver.cpp:571] Iteration 18440, lr = 0.001
I1018 10:47:42.653029 11069 solver.cpp:242] Iteration 18460, loss = 1.30781
I1018 10:47:42.653055 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.642138 (* 1 = 0.642138 loss)
I1018 10:47:42.653060 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.665669 (* 1 = 0.665669 loss)
I1018 10:47:42.653064 11069 solver.cpp:571] Iteration 18460, lr = 0.001
I1018 10:47:50.229740 11069 solver.cpp:242] Iteration 18480, loss = 0.147306
I1018 10:47:50.229766 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0299102 (* 1 = 0.0299102 loss)
I1018 10:47:50.229770 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.117395 (* 1 = 0.117395 loss)
I1018 10:47:50.229774 11069 solver.cpp:571] Iteration 18480, lr = 0.001
I1018 10:47:57.814357 11069 solver.cpp:242] Iteration 18500, loss = 0.213962
I1018 10:47:57.814384 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0338495 (* 1 = 0.0338495 loss)
I1018 10:47:57.814389 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.180113 (* 1 = 0.180113 loss)
I1018 10:47:57.814393 11069 solver.cpp:571] Iteration 18500, lr = 0.001
I1018 10:48:05.361063 11069 solver.cpp:242] Iteration 18520, loss = 0.973517
I1018 10:48:05.361088 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.263118 (* 1 = 0.263118 loss)
I1018 10:48:05.361093 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.710399 (* 1 = 0.710399 loss)
I1018 10:48:05.361098 11069 solver.cpp:571] Iteration 18520, lr = 0.001
I1018 10:48:13.006469 11069 solver.cpp:242] Iteration 18540, loss = 0.455157
I1018 10:48:13.006495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0888723 (* 1 = 0.0888723 loss)
I1018 10:48:13.006501 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.366285 (* 1 = 0.366285 loss)
I1018 10:48:13.006505 11069 solver.cpp:571] Iteration 18540, lr = 0.001
I1018 10:48:20.689829 11069 solver.cpp:242] Iteration 18560, loss = 0.251234
I1018 10:48:20.689855 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.073719 (* 1 = 0.073719 loss)
I1018 10:48:20.689860 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177515 (* 1 = 0.177515 loss)
I1018 10:48:20.689864 11069 solver.cpp:571] Iteration 18560, lr = 0.001
I1018 10:48:28.295627 11069 solver.cpp:242] Iteration 18580, loss = 0.144817
I1018 10:48:28.295653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0383956 (* 1 = 0.0383956 loss)
I1018 10:48:28.295658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.106422 (* 1 = 0.106422 loss)
I1018 10:48:28.295662 11069 solver.cpp:571] Iteration 18580, lr = 0.001
speed: 0.377s / iter
I1018 10:48:35.864711 11069 solver.cpp:242] Iteration 18600, loss = 0.31725
I1018 10:48:35.864737 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0844151 (* 1 = 0.0844151 loss)
I1018 10:48:35.864742 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232835 (* 1 = 0.232835 loss)
I1018 10:48:35.864745 11069 solver.cpp:571] Iteration 18600, lr = 0.001
I1018 10:48:43.462641 11069 solver.cpp:242] Iteration 18620, loss = 0.755841
I1018 10:48:43.462666 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.26015 (* 1 = 0.26015 loss)
I1018 10:48:43.462672 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495691 (* 1 = 0.495691 loss)
I1018 10:48:43.462677 11069 solver.cpp:571] Iteration 18620, lr = 0.001
I1018 10:48:51.165194 11069 solver.cpp:242] Iteration 18640, loss = 0.276043
I1018 10:48:51.165220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0609573 (* 1 = 0.0609573 loss)
I1018 10:48:51.165225 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.215086 (* 1 = 0.215086 loss)
I1018 10:48:51.165230 11069 solver.cpp:571] Iteration 18640, lr = 0.001
I1018 10:48:58.799075 11069 solver.cpp:242] Iteration 18660, loss = 0.154736
I1018 10:48:58.799101 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0457298 (* 1 = 0.0457298 loss)
I1018 10:48:58.799106 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.109006 (* 1 = 0.109006 loss)
I1018 10:48:58.799111 11069 solver.cpp:571] Iteration 18660, lr = 0.001
I1018 10:49:06.384470 11069 solver.cpp:242] Iteration 18680, loss = 0.0792118
I1018 10:49:06.384496 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0141686 (* 1 = 0.0141686 loss)
I1018 10:49:06.384502 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0650432 (* 1 = 0.0650432 loss)
I1018 10:49:06.384506 11069 solver.cpp:571] Iteration 18680, lr = 0.001
I1018 10:49:13.963780 11069 solver.cpp:242] Iteration 18700, loss = 0.838306
I1018 10:49:13.963806 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.264812 (* 1 = 0.264812 loss)
I1018 10:49:13.963810 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.573495 (* 1 = 0.573495 loss)
I1018 10:49:13.963815 11069 solver.cpp:571] Iteration 18700, lr = 0.001
I1018 10:49:21.554857 11069 solver.cpp:242] Iteration 18720, loss = 0.999114
I1018 10:49:21.554882 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.330952 (* 1 = 0.330952 loss)
I1018 10:49:21.554886 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.668162 (* 1 = 0.668162 loss)
I1018 10:49:21.554891 11069 solver.cpp:571] Iteration 18720, lr = 0.001
I1018 10:49:29.197720 11069 solver.cpp:242] Iteration 18740, loss = 0.706781
I1018 10:49:29.197744 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161035 (* 1 = 0.161035 loss)
I1018 10:49:29.197749 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.545746 (* 1 = 0.545746 loss)
I1018 10:49:29.197753 11069 solver.cpp:571] Iteration 18740, lr = 0.001
I1018 10:49:36.871230 11069 solver.cpp:242] Iteration 18760, loss = 0.214214
I1018 10:49:36.871258 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0372089 (* 1 = 0.0372089 loss)
I1018 10:49:36.871263 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177005 (* 1 = 0.177005 loss)
I1018 10:49:36.871266 11069 solver.cpp:571] Iteration 18760, lr = 0.001
I1018 10:49:44.516813 11069 solver.cpp:242] Iteration 18780, loss = 0.337493
I1018 10:49:44.516837 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0661252 (* 1 = 0.0661252 loss)
I1018 10:49:44.516842 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.271368 (* 1 = 0.271368 loss)
I1018 10:49:44.516846 11069 solver.cpp:571] Iteration 18780, lr = 0.001
speed: 0.377s / iter
I1018 10:49:52.079424 11069 solver.cpp:242] Iteration 18800, loss = 1.07446
I1018 10:49:52.079450 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.361656 (* 1 = 0.361656 loss)
I1018 10:49:52.079455 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.712805 (* 1 = 0.712805 loss)
I1018 10:49:52.079460 11069 solver.cpp:571] Iteration 18800, lr = 0.001
I1018 10:49:59.657604 11069 solver.cpp:242] Iteration 18820, loss = 0.200805
I1018 10:49:59.657630 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0459456 (* 1 = 0.0459456 loss)
I1018 10:49:59.657635 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.15486 (* 1 = 0.15486 loss)
I1018 10:49:59.657639 11069 solver.cpp:571] Iteration 18820, lr = 0.001
I1018 10:50:07.311285 11069 solver.cpp:242] Iteration 18840, loss = 0.224813
I1018 10:50:07.311311 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0454348 (* 1 = 0.0454348 loss)
I1018 10:50:07.311319 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179378 (* 1 = 0.179378 loss)
I1018 10:50:07.311324 11069 solver.cpp:571] Iteration 18840, lr = 0.001
I1018 10:50:14.965848 11069 solver.cpp:242] Iteration 18860, loss = 0.406979
I1018 10:50:14.965873 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.146836 (* 1 = 0.146836 loss)
I1018 10:50:14.965878 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.260143 (* 1 = 0.260143 loss)
I1018 10:50:14.965883 11069 solver.cpp:571] Iteration 18860, lr = 0.001
I1018 10:50:22.563383 11069 solver.cpp:242] Iteration 18880, loss = 0.915311
I1018 10:50:22.563410 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.270573 (* 1 = 0.270573 loss)
I1018 10:50:22.563415 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.644738 (* 1 = 0.644738 loss)
I1018 10:50:22.563418 11069 solver.cpp:571] Iteration 18880, lr = 0.001
I1018 10:50:30.161286 11069 solver.cpp:242] Iteration 18900, loss = 0.498322
I1018 10:50:30.161310 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114889 (* 1 = 0.114889 loss)
I1018 10:50:30.161315 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.383433 (* 1 = 0.383433 loss)
I1018 10:50:30.161319 11069 solver.cpp:571] Iteration 18900, lr = 0.001
I1018 10:50:37.790680 11069 solver.cpp:242] Iteration 18920, loss = 0.411244
I1018 10:50:37.790706 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0935327 (* 1 = 0.0935327 loss)
I1018 10:50:37.790710 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.317711 (* 1 = 0.317711 loss)
I1018 10:50:37.790715 11069 solver.cpp:571] Iteration 18920, lr = 0.001
I1018 10:50:45.332017 11069 solver.cpp:242] Iteration 18940, loss = 0.137563
I1018 10:50:45.332043 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0376315 (* 1 = 0.0376315 loss)
I1018 10:50:45.332048 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0999314 (* 1 = 0.0999314 loss)
I1018 10:50:45.332053 11069 solver.cpp:571] Iteration 18940, lr = 0.001
I1018 10:50:52.988395 11069 solver.cpp:242] Iteration 18960, loss = 0.923119
I1018 10:50:52.988420 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.274141 (* 1 = 0.274141 loss)
I1018 10:50:52.988425 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.648978 (* 1 = 0.648978 loss)
I1018 10:50:52.988430 11069 solver.cpp:571] Iteration 18960, lr = 0.001
I1018 10:51:00.632849 11069 solver.cpp:242] Iteration 18980, loss = 0.408727
I1018 10:51:00.632874 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120488 (* 1 = 0.120488 loss)
I1018 10:51:00.632879 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.288239 (* 1 = 0.288239 loss)
I1018 10:51:00.632884 11069 solver.cpp:571] Iteration 18980, lr = 0.001
speed: 0.377s / iter
I1018 10:51:08.203810 11069 solver.cpp:242] Iteration 19000, loss = 0.306325
I1018 10:51:08.203837 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0832532 (* 1 = 0.0832532 loss)
I1018 10:51:08.203842 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.223071 (* 1 = 0.223071 loss)
I1018 10:51:08.203846 11069 solver.cpp:571] Iteration 19000, lr = 0.001
I1018 10:51:15.876178 11069 solver.cpp:242] Iteration 19020, loss = 0.288453
I1018 10:51:15.876202 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0356406 (* 1 = 0.0356406 loss)
I1018 10:51:15.876209 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.252813 (* 1 = 0.252813 loss)
I1018 10:51:15.876212 11069 solver.cpp:571] Iteration 19020, lr = 0.001
I1018 10:51:23.493373 11069 solver.cpp:242] Iteration 19040, loss = 1.14491
I1018 10:51:23.493398 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.416851 (* 1 = 0.416851 loss)
I1018 10:51:23.493403 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.728058 (* 1 = 0.728058 loss)
I1018 10:51:23.493407 11069 solver.cpp:571] Iteration 19040, lr = 0.001
I1018 10:51:31.106021 11069 solver.cpp:242] Iteration 19060, loss = 0.139915
I1018 10:51:31.106047 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306745 (* 1 = 0.0306745 loss)
I1018 10:51:31.106052 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.10924 (* 1 = 0.10924 loss)
I1018 10:51:31.106056 11069 solver.cpp:571] Iteration 19060, lr = 0.001
I1018 10:51:38.626368 11069 solver.cpp:242] Iteration 19080, loss = 0.280132
I1018 10:51:38.626394 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0723112 (* 1 = 0.0723112 loss)
I1018 10:51:38.626399 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.207821 (* 1 = 0.207821 loss)
I1018 10:51:38.626404 11069 solver.cpp:571] Iteration 19080, lr = 0.001
I1018 10:51:46.193974 11069 solver.cpp:242] Iteration 19100, loss = 0.214952
I1018 10:51:46.194000 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0461124 (* 1 = 0.0461124 loss)
I1018 10:51:46.194005 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.168839 (* 1 = 0.168839 loss)
I1018 10:51:46.194010 11069 solver.cpp:571] Iteration 19100, lr = 0.001
I1018 10:51:53.832309 11069 solver.cpp:242] Iteration 19120, loss = 1.06557
I1018 10:51:53.832334 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.280181 (* 1 = 0.280181 loss)
I1018 10:51:53.832339 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.78539 (* 1 = 0.78539 loss)
I1018 10:51:53.832342 11069 solver.cpp:571] Iteration 19120, lr = 0.001
I1018 10:52:01.510534 11069 solver.cpp:242] Iteration 19140, loss = 0.491962
I1018 10:52:01.510558 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115243 (* 1 = 0.115243 loss)
I1018 10:52:01.510563 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.37672 (* 1 = 0.37672 loss)
I1018 10:52:01.510568 11069 solver.cpp:571] Iteration 19140, lr = 0.001
I1018 10:52:09.131814 11069 solver.cpp:242] Iteration 19160, loss = 1.41324
I1018 10:52:09.131840 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.473709 (* 1 = 0.473709 loss)
I1018 10:52:09.131845 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.939532 (* 1 = 0.939532 loss)
I1018 10:52:09.131850 11069 solver.cpp:571] Iteration 19160, lr = 0.001
I1018 10:52:16.787413 11069 solver.cpp:242] Iteration 19180, loss = 0.437059
I1018 10:52:16.787438 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0737623 (* 1 = 0.0737623 loss)
I1018 10:52:16.787443 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.363297 (* 1 = 0.363297 loss)
I1018 10:52:16.787448 11069 solver.cpp:571] Iteration 19180, lr = 0.001
speed: 0.377s / iter
I1018 10:52:24.394604 11069 solver.cpp:242] Iteration 19200, loss = 0.180818
I1018 10:52:24.394630 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0362697 (* 1 = 0.0362697 loss)
I1018 10:52:24.394634 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144549 (* 1 = 0.144549 loss)
I1018 10:52:24.394639 11069 solver.cpp:571] Iteration 19200, lr = 0.001
I1018 10:52:31.965625 11069 solver.cpp:242] Iteration 19220, loss = 0.610487
I1018 10:52:31.965651 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.272157 (* 1 = 0.272157 loss)
I1018 10:52:31.965656 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.33833 (* 1 = 0.33833 loss)
I1018 10:52:31.965659 11069 solver.cpp:571] Iteration 19220, lr = 0.001
I1018 10:52:39.554069 11069 solver.cpp:242] Iteration 19240, loss = 1.10498
I1018 10:52:39.554095 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.411192 (* 1 = 0.411192 loss)
I1018 10:52:39.554100 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.693793 (* 1 = 0.693793 loss)
I1018 10:52:39.554105 11069 solver.cpp:571] Iteration 19240, lr = 0.001
I1018 10:52:47.290129 11069 solver.cpp:242] Iteration 19260, loss = 0.20079
I1018 10:52:47.290156 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0483969 (* 1 = 0.0483969 loss)
I1018 10:52:47.290161 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.152393 (* 1 = 0.152393 loss)
I1018 10:52:47.290166 11069 solver.cpp:571] Iteration 19260, lr = 0.001
I1018 10:52:54.791859 11069 solver.cpp:242] Iteration 19280, loss = 0.149682
I1018 10:52:54.791884 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0516059 (* 1 = 0.0516059 loss)
I1018 10:52:54.791889 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0980765 (* 1 = 0.0980765 loss)
I1018 10:52:54.791894 11069 solver.cpp:571] Iteration 19280, lr = 0.001
I1018 10:53:02.414870 11069 solver.cpp:242] Iteration 19300, loss = 0.286052
I1018 10:53:02.414896 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0495143 (* 1 = 0.0495143 loss)
I1018 10:53:02.414901 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.236537 (* 1 = 0.236537 loss)
I1018 10:53:02.414906 11069 solver.cpp:571] Iteration 19300, lr = 0.001
I1018 10:53:10.041604 11069 solver.cpp:242] Iteration 19320, loss = 0.275921
I1018 10:53:10.041630 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.027596 (* 1 = 0.027596 loss)
I1018 10:53:10.041635 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.248325 (* 1 = 0.248325 loss)
I1018 10:53:10.041640 11069 solver.cpp:571] Iteration 19320, lr = 0.001
I1018 10:53:17.679239 11069 solver.cpp:242] Iteration 19340, loss = 1.0999
I1018 10:53:17.679265 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.349464 (* 1 = 0.349464 loss)
I1018 10:53:17.679270 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.75044 (* 1 = 0.75044 loss)
I1018 10:53:17.679275 11069 solver.cpp:571] Iteration 19340, lr = 0.001
I1018 10:53:25.288246 11069 solver.cpp:242] Iteration 19360, loss = 1.05716
I1018 10:53:25.288272 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.422189 (* 1 = 0.422189 loss)
I1018 10:53:25.288277 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.634967 (* 1 = 0.634967 loss)
I1018 10:53:25.288282 11069 solver.cpp:571] Iteration 19360, lr = 0.001
I1018 10:53:32.946415 11069 solver.cpp:242] Iteration 19380, loss = 1.68723
I1018 10:53:32.946441 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.777247 (* 1 = 0.777247 loss)
I1018 10:53:32.946446 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.909981 (* 1 = 0.909981 loss)
I1018 10:53:32.946450 11069 solver.cpp:571] Iteration 19380, lr = 0.001
speed: 0.377s / iter
I1018 10:53:40.356868 11069 solver.cpp:242] Iteration 19400, loss = 1.68999
I1018 10:53:40.356894 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.81974 (* 1 = 0.81974 loss)
I1018 10:53:40.356899 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.87025 (* 1 = 0.87025 loss)
I1018 10:53:40.356902 11069 solver.cpp:571] Iteration 19400, lr = 0.001
I1018 10:53:47.945477 11069 solver.cpp:242] Iteration 19420, loss = 0.230273
I1018 10:53:47.945502 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0406404 (* 1 = 0.0406404 loss)
I1018 10:53:47.945507 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189633 (* 1 = 0.189633 loss)
I1018 10:53:47.945511 11069 solver.cpp:571] Iteration 19420, lr = 0.001
I1018 10:53:55.427919 11069 solver.cpp:242] Iteration 19440, loss = 0.371605
I1018 10:53:55.427945 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0972142 (* 1 = 0.0972142 loss)
I1018 10:53:55.427950 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27439 (* 1 = 0.27439 loss)
I1018 10:53:55.427955 11069 solver.cpp:571] Iteration 19440, lr = 0.001
I1018 10:54:03.097375 11069 solver.cpp:242] Iteration 19460, loss = 1.38658
I1018 10:54:03.097403 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.500597 (* 1 = 0.500597 loss)
I1018 10:54:03.097407 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.885987 (* 1 = 0.885987 loss)
I1018 10:54:03.097411 11069 solver.cpp:571] Iteration 19460, lr = 0.001
I1018 10:54:10.681067 11069 solver.cpp:242] Iteration 19480, loss = 0.680347
I1018 10:54:10.681093 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.223842 (* 1 = 0.223842 loss)
I1018 10:54:10.681098 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.456505 (* 1 = 0.456505 loss)
I1018 10:54:10.681102 11069 solver.cpp:571] Iteration 19480, lr = 0.001
I1018 10:54:18.244653 11069 solver.cpp:242] Iteration 19500, loss = 0.758086
I1018 10:54:18.244679 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.21725 (* 1 = 0.21725 loss)
I1018 10:54:18.244684 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.540836 (* 1 = 0.540836 loss)
I1018 10:54:18.244688 11069 solver.cpp:571] Iteration 19500, lr = 0.001
I1018 10:54:25.776098 11069 solver.cpp:242] Iteration 19520, loss = 0.255383
I1018 10:54:25.776124 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0612655 (* 1 = 0.0612655 loss)
I1018 10:54:25.776129 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194118 (* 1 = 0.194118 loss)
I1018 10:54:25.776134 11069 solver.cpp:571] Iteration 19520, lr = 0.001
I1018 10:54:33.369519 11069 solver.cpp:242] Iteration 19540, loss = 1.06579
I1018 10:54:33.369545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.290202 (* 1 = 0.290202 loss)
I1018 10:54:33.369549 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.775587 (* 1 = 0.775587 loss)
I1018 10:54:33.369554 11069 solver.cpp:571] Iteration 19540, lr = 0.001
I1018 10:54:41.032649 11069 solver.cpp:242] Iteration 19560, loss = 0.249847
I1018 10:54:41.032673 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.070238 (* 1 = 0.070238 loss)
I1018 10:54:41.032678 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179609 (* 1 = 0.179609 loss)
I1018 10:54:41.032683 11069 solver.cpp:571] Iteration 19560, lr = 0.001
I1018 10:54:48.693815 11069 solver.cpp:242] Iteration 19580, loss = 0.199062
I1018 10:54:48.693841 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0457419 (* 1 = 0.0457419 loss)
I1018 10:54:48.693846 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.15332 (* 1 = 0.15332 loss)
I1018 10:54:48.693851 11069 solver.cpp:571] Iteration 19580, lr = 0.001
speed: 0.377s / iter
I1018 10:54:56.294669 11069 solver.cpp:242] Iteration 19600, loss = 0.126867
I1018 10:54:56.294694 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306138 (* 1 = 0.0306138 loss)
I1018 10:54:56.294699 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0962536 (* 1 = 0.0962536 loss)
I1018 10:54:56.294704 11069 solver.cpp:571] Iteration 19600, lr = 0.001
I1018 10:55:04.000275 11069 solver.cpp:242] Iteration 19620, loss = 0.777365
I1018 10:55:04.000301 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244211 (* 1 = 0.244211 loss)
I1018 10:55:04.000305 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.533154 (* 1 = 0.533154 loss)
I1018 10:55:04.000310 11069 solver.cpp:571] Iteration 19620, lr = 0.001
I1018 10:55:11.632886 11069 solver.cpp:242] Iteration 19640, loss = 0.267372
I1018 10:55:11.632911 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0882834 (* 1 = 0.0882834 loss)
I1018 10:55:11.632916 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179088 (* 1 = 0.179088 loss)
I1018 10:55:11.632920 11069 solver.cpp:571] Iteration 19640, lr = 0.001
I1018 10:55:19.163285 11069 solver.cpp:242] Iteration 19660, loss = 0.262695
I1018 10:55:19.163311 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0717581 (* 1 = 0.0717581 loss)
I1018 10:55:19.163318 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.190936 (* 1 = 0.190936 loss)
I1018 10:55:19.163322 11069 solver.cpp:571] Iteration 19660, lr = 0.001
I1018 10:55:26.917138 11069 solver.cpp:242] Iteration 19680, loss = 0.174511
I1018 10:55:26.917165 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0504254 (* 1 = 0.0504254 loss)
I1018 10:55:26.917170 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.124085 (* 1 = 0.124085 loss)
I1018 10:55:26.917173 11069 solver.cpp:571] Iteration 19680, lr = 0.001
I1018 10:55:34.571552 11069 solver.cpp:242] Iteration 19700, loss = 0.366689
I1018 10:55:34.571578 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100782 (* 1 = 0.100782 loss)
I1018 10:55:34.571583 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265907 (* 1 = 0.265907 loss)
I1018 10:55:34.571586 11069 solver.cpp:571] Iteration 19700, lr = 0.001
I1018 10:55:42.257366 11069 solver.cpp:242] Iteration 19720, loss = 0.388801
I1018 10:55:42.257391 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11481 (* 1 = 0.11481 loss)
I1018 10:55:42.257396 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.273991 (* 1 = 0.273991 loss)
I1018 10:55:42.257401 11069 solver.cpp:571] Iteration 19720, lr = 0.001
I1018 10:55:49.883714 11069 solver.cpp:242] Iteration 19740, loss = 0.191799
I1018 10:55:49.883740 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.049953 (* 1 = 0.049953 loss)
I1018 10:55:49.883745 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141846 (* 1 = 0.141846 loss)
I1018 10:55:49.883749 11069 solver.cpp:571] Iteration 19740, lr = 0.001
I1018 10:55:57.478977 11069 solver.cpp:242] Iteration 19760, loss = 1.17052
I1018 10:55:57.479002 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.416597 (* 1 = 0.416597 loss)
I1018 10:55:57.479007 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.75392 (* 1 = 0.75392 loss)
I1018 10:55:57.479012 11069 solver.cpp:571] Iteration 19760, lr = 0.001
I1018 10:56:05.186518 11069 solver.cpp:242] Iteration 19780, loss = 0.419526
I1018 10:56:05.186544 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115034 (* 1 = 0.115034 loss)
I1018 10:56:05.186549 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.304492 (* 1 = 0.304492 loss)
I1018 10:56:05.186554 11069 solver.cpp:571] Iteration 19780, lr = 0.001
speed: 0.377s / iter
I1018 10:56:12.831861 11069 solver.cpp:242] Iteration 19800, loss = 0.325891
I1018 10:56:12.831885 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0805892 (* 1 = 0.0805892 loss)
I1018 10:56:12.831892 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.245302 (* 1 = 0.245302 loss)
I1018 10:56:12.831895 11069 solver.cpp:571] Iteration 19800, lr = 0.001
I1018 10:56:20.464375 11069 solver.cpp:242] Iteration 19820, loss = 0.191012
I1018 10:56:20.464401 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0471776 (* 1 = 0.0471776 loss)
I1018 10:56:20.464406 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.143834 (* 1 = 0.143834 loss)
I1018 10:56:20.464411 11069 solver.cpp:571] Iteration 19820, lr = 0.001
I1018 10:56:28.195093 11069 solver.cpp:242] Iteration 19840, loss = 1.00122
I1018 10:56:28.195119 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.270294 (* 1 = 0.270294 loss)
I1018 10:56:28.195124 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.730926 (* 1 = 0.730926 loss)
I1018 10:56:28.195128 11069 solver.cpp:571] Iteration 19840, lr = 0.001
I1018 10:56:35.883486 11069 solver.cpp:242] Iteration 19860, loss = 1.05914
I1018 10:56:35.883512 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.245774 (* 1 = 0.245774 loss)
I1018 10:56:35.883517 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.813371 (* 1 = 0.813371 loss)
I1018 10:56:35.883522 11069 solver.cpp:571] Iteration 19860, lr = 0.001
I1018 10:56:43.598259 11069 solver.cpp:242] Iteration 19880, loss = 0.436053
I1018 10:56:43.598284 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11007 (* 1 = 0.11007 loss)
I1018 10:56:43.598290 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.325983 (* 1 = 0.325983 loss)
I1018 10:56:43.598294 11069 solver.cpp:571] Iteration 19880, lr = 0.001
I1018 10:56:51.236670 11069 solver.cpp:242] Iteration 19900, loss = 0.841151
I1018 10:56:51.236692 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.197807 (* 1 = 0.197807 loss)
I1018 10:56:51.236698 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.643343 (* 1 = 0.643343 loss)
I1018 10:56:51.236702 11069 solver.cpp:571] Iteration 19900, lr = 0.001
I1018 10:56:58.896847 11069 solver.cpp:242] Iteration 19920, loss = 0.181635
I1018 10:56:58.896873 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0505056 (* 1 = 0.0505056 loss)
I1018 10:56:58.896878 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13113 (* 1 = 0.13113 loss)
I1018 10:56:58.896883 11069 solver.cpp:571] Iteration 19920, lr = 0.001
I1018 10:57:06.448205 11069 solver.cpp:242] Iteration 19940, loss = 0.653533
I1018 10:57:06.448231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.184144 (* 1 = 0.184144 loss)
I1018 10:57:06.448236 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.469389 (* 1 = 0.469389 loss)
I1018 10:57:06.448240 11069 solver.cpp:571] Iteration 19940, lr = 0.001
I1018 10:57:14.138664 11069 solver.cpp:242] Iteration 19960, loss = 1.00438
I1018 10:57:14.138690 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.296486 (* 1 = 0.296486 loss)
I1018 10:57:14.138695 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.707895 (* 1 = 0.707895 loss)
I1018 10:57:14.138700 11069 solver.cpp:571] Iteration 19960, lr = 0.001
I1018 10:57:21.823562 11069 solver.cpp:242] Iteration 19980, loss = 1.9278
I1018 10:57:21.823588 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.812635 (* 1 = 0.812635 loss)
I1018 10:57:21.823593 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.11516 (* 1 = 1.11516 loss)
I1018 10:57:21.823598 11069 solver.cpp:571] Iteration 19980, lr = 0.001
speed: 0.377s / iter
Wrote snapshot to: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_fast_rcnn_stage2_iter_20000.caffemodel
I1018 10:57:30.812494 11069 solver.cpp:242] Iteration 20000, loss = 0.235781
I1018 10:57:30.812518 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0851713 (* 1 = 0.0851713 loss)
I1018 10:57:30.812522 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.150609 (* 1 = 0.150609 loss)
I1018 10:57:30.812526 11069 solver.cpp:571] Iteration 20000, lr = 0.001
I1018 10:57:38.160933 11069 solver.cpp:242] Iteration 20020, loss = 0.333552
I1018 10:57:38.160959 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11957 (* 1 = 0.11957 loss)
I1018 10:57:38.160964 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.213982 (* 1 = 0.213982 loss)
I1018 10:57:38.160967 11069 solver.cpp:571] Iteration 20020, lr = 0.001
I1018 10:57:45.733841 11069 solver.cpp:242] Iteration 20040, loss = 0.27916
I1018 10:57:45.733867 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557092 (* 1 = 0.0557092 loss)
I1018 10:57:45.733872 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.223451 (* 1 = 0.223451 loss)
I1018 10:57:45.733876 11069 solver.cpp:571] Iteration 20040, lr = 0.001
I1018 10:57:53.384361 11069 solver.cpp:242] Iteration 20060, loss = 0.303822
I1018 10:57:53.384387 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0862414 (* 1 = 0.0862414 loss)
I1018 10:57:53.384392 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21758 (* 1 = 0.21758 loss)
I1018 10:57:53.384397 11069 solver.cpp:571] Iteration 20060, lr = 0.001
I1018 10:58:01.107584 11069 solver.cpp:242] Iteration 20080, loss = 0.460964
I1018 10:58:01.107610 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177287 (* 1 = 0.177287 loss)
I1018 10:58:01.107615 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.283677 (* 1 = 0.283677 loss)
I1018 10:58:01.107620 11069 solver.cpp:571] Iteration 20080, lr = 0.001
I1018 10:58:08.799397 11069 solver.cpp:242] Iteration 20100, loss = 0.585094
I1018 10:58:08.799424 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.194275 (* 1 = 0.194275 loss)
I1018 10:58:08.799430 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.39082 (* 1 = 0.39082 loss)
I1018 10:58:08.799434 11069 solver.cpp:571] Iteration 20100, lr = 0.001
I1018 10:58:16.347054 11069 solver.cpp:242] Iteration 20120, loss = 0.23806
I1018 10:58:16.347080 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0863972 (* 1 = 0.0863972 loss)
I1018 10:58:16.347085 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.151663 (* 1 = 0.151663 loss)
I1018 10:58:16.347090 11069 solver.cpp:571] Iteration 20120, lr = 0.001
I1018 10:58:23.931170 11069 solver.cpp:242] Iteration 20140, loss = 1.09786
I1018 10:58:23.931196 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.285098 (* 1 = 0.285098 loss)
I1018 10:58:23.931201 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.812763 (* 1 = 0.812763 loss)
I1018 10:58:23.931205 11069 solver.cpp:571] Iteration 20140, lr = 0.001
I1018 10:58:31.600783 11069 solver.cpp:242] Iteration 20160, loss = 0.570121
I1018 10:58:31.600810 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161271 (* 1 = 0.161271 loss)
I1018 10:58:31.600814 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.40885 (* 1 = 0.40885 loss)
I1018 10:58:31.600818 11069 solver.cpp:571] Iteration 20160, lr = 0.001
I1018 10:58:39.233482 11069 solver.cpp:242] Iteration 20180, loss = 0.974513
I1018 10:58:39.233508 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.239647 (* 1 = 0.239647 loss)
I1018 10:58:39.233513 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.734865 (* 1 = 0.734865 loss)
I1018 10:58:39.233517 11069 solver.cpp:571] Iteration 20180, lr = 0.001
speed: 0.377s / iter
I1018 10:58:46.786263 11069 solver.cpp:242] Iteration 20200, loss = 0.177775
I1018 10:58:46.786309 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0623987 (* 1 = 0.0623987 loss)
I1018 10:58:46.786314 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.115376 (* 1 = 0.115376 loss)
I1018 10:58:46.786319 11069 solver.cpp:571] Iteration 20200, lr = 0.001
I1018 10:58:54.461590 11069 solver.cpp:242] Iteration 20220, loss = 0.155265
I1018 10:58:54.461616 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0266481 (* 1 = 0.0266481 loss)
I1018 10:58:54.461621 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.128617 (* 1 = 0.128617 loss)
I1018 10:58:54.461625 11069 solver.cpp:571] Iteration 20220, lr = 0.001
I1018 10:59:02.043843 11069 solver.cpp:242] Iteration 20240, loss = 0.78935
I1018 10:59:02.043869 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.201162 (* 1 = 0.201162 loss)
I1018 10:59:02.043874 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.588188 (* 1 = 0.588188 loss)
I1018 10:59:02.043879 11069 solver.cpp:571] Iteration 20240, lr = 0.001
I1018 10:59:09.660102 11069 solver.cpp:242] Iteration 20260, loss = 0.618342
I1018 10:59:09.660127 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150989 (* 1 = 0.150989 loss)
I1018 10:59:09.660132 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.467353 (* 1 = 0.467353 loss)
I1018 10:59:09.660136 11069 solver.cpp:571] Iteration 20260, lr = 0.001
I1018 10:59:17.210085 11069 solver.cpp:242] Iteration 20280, loss = 0.198855
I1018 10:59:17.210113 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0594441 (* 1 = 0.0594441 loss)
I1018 10:59:17.210117 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.139411 (* 1 = 0.139411 loss)
I1018 10:59:17.210122 11069 solver.cpp:571] Iteration 20280, lr = 0.001
I1018 10:59:24.920390 11069 solver.cpp:242] Iteration 20300, loss = 0.492901
I1018 10:59:24.920416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.080575 (* 1 = 0.080575 loss)
I1018 10:59:24.920423 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.412326 (* 1 = 0.412326 loss)
I1018 10:59:24.920426 11069 solver.cpp:571] Iteration 20300, lr = 0.001
I1018 10:59:32.565660 11069 solver.cpp:242] Iteration 20320, loss = 0.94061
I1018 10:59:32.565686 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.386093 (* 1 = 0.386093 loss)
I1018 10:59:32.565691 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.554517 (* 1 = 0.554517 loss)
I1018 10:59:32.565696 11069 solver.cpp:571] Iteration 20320, lr = 0.001
I1018 10:59:40.157150 11069 solver.cpp:242] Iteration 20340, loss = 0.495253
I1018 10:59:40.157173 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113955 (* 1 = 0.113955 loss)
I1018 10:59:40.157178 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.381298 (* 1 = 0.381298 loss)
I1018 10:59:40.157182 11069 solver.cpp:571] Iteration 20340, lr = 0.001
I1018 10:59:47.827766 11069 solver.cpp:242] Iteration 20360, loss = 0.951725
I1018 10:59:47.827793 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.393317 (* 1 = 0.393317 loss)
I1018 10:59:47.827798 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.558408 (* 1 = 0.558408 loss)
I1018 10:59:47.827802 11069 solver.cpp:571] Iteration 20360, lr = 0.001
I1018 10:59:55.549831 11069 solver.cpp:242] Iteration 20380, loss = 0.130007
I1018 10:59:55.549857 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0232791 (* 1 = 0.0232791 loss)
I1018 10:59:55.549863 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.106728 (* 1 = 0.106728 loss)
I1018 10:59:55.549867 11069 solver.cpp:571] Iteration 20380, lr = 0.001
speed: 0.377s / iter
I1018 11:00:03.051064 11069 solver.cpp:242] Iteration 20400, loss = 0.387274
I1018 11:00:03.051089 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0692737 (* 1 = 0.0692737 loss)
I1018 11:00:03.051093 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.318001 (* 1 = 0.318001 loss)
I1018 11:00:03.051098 11069 solver.cpp:571] Iteration 20400, lr = 0.001
I1018 11:00:10.597811 11069 solver.cpp:242] Iteration 20420, loss = 0.178416
I1018 11:00:10.597837 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0518806 (* 1 = 0.0518806 loss)
I1018 11:00:10.597842 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126535 (* 1 = 0.126535 loss)
I1018 11:00:10.597846 11069 solver.cpp:571] Iteration 20420, lr = 0.001
I1018 11:00:18.181767 11069 solver.cpp:242] Iteration 20440, loss = 0.414856
I1018 11:00:18.181793 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150134 (* 1 = 0.150134 loss)
I1018 11:00:18.181799 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264722 (* 1 = 0.264722 loss)
I1018 11:00:18.181803 11069 solver.cpp:571] Iteration 20440, lr = 0.001
I1018 11:00:25.749649 11069 solver.cpp:242] Iteration 20460, loss = 0.195877
I1018 11:00:25.749675 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0717698 (* 1 = 0.0717698 loss)
I1018 11:00:25.749680 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.124107 (* 1 = 0.124107 loss)
I1018 11:00:25.749685 11069 solver.cpp:571] Iteration 20460, lr = 0.001
I1018 11:00:33.435976 11069 solver.cpp:242] Iteration 20480, loss = 0.888719
I1018 11:00:33.436022 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.278513 (* 1 = 0.278513 loss)
I1018 11:00:33.436027 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.610206 (* 1 = 0.610206 loss)
I1018 11:00:33.436030 11069 solver.cpp:571] Iteration 20480, lr = 0.001
I1018 11:00:41.136096 11069 solver.cpp:242] Iteration 20500, loss = 0.730698
I1018 11:00:41.136121 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.335438 (* 1 = 0.335438 loss)
I1018 11:00:41.136126 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.39526 (* 1 = 0.39526 loss)
I1018 11:00:41.136129 11069 solver.cpp:571] Iteration 20500, lr = 0.001
I1018 11:00:48.758159 11069 solver.cpp:242] Iteration 20520, loss = 0.112009
I1018 11:00:48.758185 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0451869 (* 1 = 0.0451869 loss)
I1018 11:00:48.758190 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0668221 (* 1 = 0.0668221 loss)
I1018 11:00:48.758194 11069 solver.cpp:571] Iteration 20520, lr = 0.001
I1018 11:00:56.357522 11069 solver.cpp:242] Iteration 20540, loss = 0.479511
I1018 11:00:56.357548 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158989 (* 1 = 0.158989 loss)
I1018 11:00:56.357553 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.320521 (* 1 = 0.320521 loss)
I1018 11:00:56.357558 11069 solver.cpp:571] Iteration 20540, lr = 0.001
I1018 11:01:03.937189 11069 solver.cpp:242] Iteration 20560, loss = 0.767727
I1018 11:01:03.937216 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.264319 (* 1 = 0.264319 loss)
I1018 11:01:03.937221 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.503408 (* 1 = 0.503408 loss)
I1018 11:01:03.937225 11069 solver.cpp:571] Iteration 20560, lr = 0.001
I1018 11:01:11.609328 11069 solver.cpp:242] Iteration 20580, loss = 1.88436
I1018 11:01:11.609352 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.17579 (* 1 = 1.17579 loss)
I1018 11:01:11.609357 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.708575 (* 1 = 0.708575 loss)
I1018 11:01:11.609362 11069 solver.cpp:571] Iteration 20580, lr = 0.001
speed: 0.377s / iter
I1018 11:01:19.281139 11069 solver.cpp:242] Iteration 20600, loss = 0.163351
I1018 11:01:19.281165 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0224927 (* 1 = 0.0224927 loss)
I1018 11:01:19.281170 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140858 (* 1 = 0.140858 loss)
I1018 11:01:19.281175 11069 solver.cpp:571] Iteration 20600, lr = 0.001
I1018 11:01:26.870911 11069 solver.cpp:242] Iteration 20620, loss = 0.959433
I1018 11:01:26.870937 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.30183 (* 1 = 0.30183 loss)
I1018 11:01:26.870942 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.657603 (* 1 = 0.657603 loss)
I1018 11:01:26.870946 11069 solver.cpp:571] Iteration 20620, lr = 0.001
I1018 11:01:34.453622 11069 solver.cpp:242] Iteration 20640, loss = 1.03649
I1018 11:01:34.453649 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.312341 (* 1 = 0.312341 loss)
I1018 11:01:34.453652 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.724151 (* 1 = 0.724151 loss)
I1018 11:01:34.453656 11069 solver.cpp:571] Iteration 20640, lr = 0.001
I1018 11:01:42.104202 11069 solver.cpp:242] Iteration 20660, loss = 0.398154
I1018 11:01:42.104228 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.125641 (* 1 = 0.125641 loss)
I1018 11:01:42.104233 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.272513 (* 1 = 0.272513 loss)
I1018 11:01:42.104238 11069 solver.cpp:571] Iteration 20660, lr = 0.001
I1018 11:01:49.775900 11069 solver.cpp:242] Iteration 20680, loss = 0.142686
I1018 11:01:49.775926 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0544256 (* 1 = 0.0544256 loss)
I1018 11:01:49.775931 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0882601 (* 1 = 0.0882601 loss)
I1018 11:01:49.775936 11069 solver.cpp:571] Iteration 20680, lr = 0.001
I1018 11:01:57.430560 11069 solver.cpp:242] Iteration 20700, loss = 0.311132
I1018 11:01:57.430588 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.065254 (* 1 = 0.065254 loss)
I1018 11:01:57.430593 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.245878 (* 1 = 0.245878 loss)
I1018 11:01:57.430596 11069 solver.cpp:571] Iteration 20700, lr = 0.001
I1018 11:02:04.989562 11069 solver.cpp:242] Iteration 20720, loss = 0.747336
I1018 11:02:04.989588 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.245478 (* 1 = 0.245478 loss)
I1018 11:02:04.989593 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.501858 (* 1 = 0.501858 loss)
I1018 11:02:04.989598 11069 solver.cpp:571] Iteration 20720, lr = 0.001
I1018 11:02:12.603994 11069 solver.cpp:242] Iteration 20740, loss = 1.05958
I1018 11:02:12.604020 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.313852 (* 1 = 0.313852 loss)
I1018 11:02:12.604025 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.745724 (* 1 = 0.745724 loss)
I1018 11:02:12.604029 11069 solver.cpp:571] Iteration 20740, lr = 0.001
I1018 11:02:20.231040 11069 solver.cpp:242] Iteration 20760, loss = 0.73497
I1018 11:02:20.231065 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.224643 (* 1 = 0.224643 loss)
I1018 11:02:20.231070 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.510326 (* 1 = 0.510326 loss)
I1018 11:02:20.231073 11069 solver.cpp:571] Iteration 20760, lr = 0.001
I1018 11:02:27.908080 11069 solver.cpp:242] Iteration 20780, loss = 0.454261
I1018 11:02:27.908105 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.127117 (* 1 = 0.127117 loss)
I1018 11:02:27.908110 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.327144 (* 1 = 0.327144 loss)
I1018 11:02:27.908115 11069 solver.cpp:571] Iteration 20780, lr = 0.001
speed: 0.377s / iter
I1018 11:02:35.497568 11069 solver.cpp:242] Iteration 20800, loss = 0.788171
I1018 11:02:35.497593 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.289468 (* 1 = 0.289468 loss)
I1018 11:02:35.497598 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.498703 (* 1 = 0.498703 loss)
I1018 11:02:35.497602 11069 solver.cpp:571] Iteration 20800, lr = 0.001
I1018 11:02:43.062551 11069 solver.cpp:242] Iteration 20820, loss = 1.54276
I1018 11:02:43.062577 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.484994 (* 1 = 0.484994 loss)
I1018 11:02:43.062582 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.05777 (* 1 = 1.05777 loss)
I1018 11:02:43.062587 11069 solver.cpp:571] Iteration 20820, lr = 0.001
I1018 11:02:50.705360 11069 solver.cpp:242] Iteration 20840, loss = 0.662431
I1018 11:02:50.705387 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.197278 (* 1 = 0.197278 loss)
I1018 11:02:50.705392 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.465153 (* 1 = 0.465153 loss)
I1018 11:02:50.705396 11069 solver.cpp:571] Iteration 20840, lr = 0.001
I1018 11:02:58.308205 11069 solver.cpp:242] Iteration 20860, loss = 0.333869
I1018 11:02:58.308230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0804147 (* 1 = 0.0804147 loss)
I1018 11:02:58.308235 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.253454 (* 1 = 0.253454 loss)
I1018 11:02:58.308239 11069 solver.cpp:571] Iteration 20860, lr = 0.001
I1018 11:03:05.918712 11069 solver.cpp:242] Iteration 20880, loss = 1.17196
I1018 11:03:05.918738 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.376238 (* 1 = 0.376238 loss)
I1018 11:03:05.918743 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.795718 (* 1 = 0.795718 loss)
I1018 11:03:05.918747 11069 solver.cpp:571] Iteration 20880, lr = 0.001
I1018 11:03:13.632748 11069 solver.cpp:242] Iteration 20900, loss = 0.929662
I1018 11:03:13.632774 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.280214 (* 1 = 0.280214 loss)
I1018 11:03:13.632779 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.649448 (* 1 = 0.649448 loss)
I1018 11:03:13.632784 11069 solver.cpp:571] Iteration 20900, lr = 0.001
I1018 11:03:21.259554 11069 solver.cpp:242] Iteration 20920, loss = 0.217522
I1018 11:03:21.259579 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.08441 (* 1 = 0.08441 loss)
I1018 11:03:21.259584 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133112 (* 1 = 0.133112 loss)
I1018 11:03:21.259589 11069 solver.cpp:571] Iteration 20920, lr = 0.001
I1018 11:03:28.906541 11069 solver.cpp:242] Iteration 20940, loss = 0.242124
I1018 11:03:28.906568 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0412172 (* 1 = 0.0412172 loss)
I1018 11:03:28.906572 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.200907 (* 1 = 0.200907 loss)
I1018 11:03:28.906576 11069 solver.cpp:571] Iteration 20940, lr = 0.001
I1018 11:03:36.559965 11069 solver.cpp:242] Iteration 20960, loss = 0.527598
I1018 11:03:36.559991 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151459 (* 1 = 0.151459 loss)
I1018 11:03:36.559996 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.376139 (* 1 = 0.376139 loss)
I1018 11:03:36.560000 11069 solver.cpp:571] Iteration 20960, lr = 0.001
I1018 11:03:44.156750 11069 solver.cpp:242] Iteration 20980, loss = 0.361912
I1018 11:03:44.156772 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.08498 (* 1 = 0.08498 loss)
I1018 11:03:44.156777 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.276932 (* 1 = 0.276932 loss)
I1018 11:03:44.156782 11069 solver.cpp:571] Iteration 20980, lr = 0.001
speed: 0.377s / iter
I1018 11:03:51.710209 11069 solver.cpp:242] Iteration 21000, loss = 0.237877
I1018 11:03:51.710235 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100655 (* 1 = 0.100655 loss)
I1018 11:03:51.710240 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137222 (* 1 = 0.137222 loss)
I1018 11:03:51.710245 11069 solver.cpp:571] Iteration 21000, lr = 0.001
I1018 11:03:59.378820 11069 solver.cpp:242] Iteration 21020, loss = 0.203505
I1018 11:03:59.378847 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0683559 (* 1 = 0.0683559 loss)
I1018 11:03:59.378852 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.135149 (* 1 = 0.135149 loss)
I1018 11:03:59.378856 11069 solver.cpp:571] Iteration 21020, lr = 0.001
I1018 11:04:07.022297 11069 solver.cpp:242] Iteration 21040, loss = 0.129385
I1018 11:04:07.022325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0458735 (* 1 = 0.0458735 loss)
I1018 11:04:07.022330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0835119 (* 1 = 0.0835119 loss)
I1018 11:04:07.022333 11069 solver.cpp:571] Iteration 21040, lr = 0.001
I1018 11:04:14.643471 11069 solver.cpp:242] Iteration 21060, loss = 1.15125
I1018 11:04:14.643496 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.531489 (* 1 = 0.531489 loss)
I1018 11:04:14.643501 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.619758 (* 1 = 0.619758 loss)
I1018 11:04:14.643506 11069 solver.cpp:571] Iteration 21060, lr = 0.001
I1018 11:04:22.294610 11069 solver.cpp:242] Iteration 21080, loss = 0.389654
I1018 11:04:22.294636 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0981986 (* 1 = 0.0981986 loss)
I1018 11:04:22.294641 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.291456 (* 1 = 0.291456 loss)
I1018 11:04:22.294646 11069 solver.cpp:571] Iteration 21080, lr = 0.001
I1018 11:04:29.911309 11069 solver.cpp:242] Iteration 21100, loss = 1.04897
I1018 11:04:29.911339 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.358817 (* 1 = 0.358817 loss)
I1018 11:04:29.911344 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.690156 (* 1 = 0.690156 loss)
I1018 11:04:29.911348 11069 solver.cpp:571] Iteration 21100, lr = 0.001
I1018 11:04:37.529688 11069 solver.cpp:242] Iteration 21120, loss = 0.336332
I1018 11:04:37.529714 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0487408 (* 1 = 0.0487408 loss)
I1018 11:04:37.529718 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.287592 (* 1 = 0.287592 loss)
I1018 11:04:37.529723 11069 solver.cpp:571] Iteration 21120, lr = 0.001
I1018 11:04:45.165045 11069 solver.cpp:242] Iteration 21140, loss = 0.225821
I1018 11:04:45.165071 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0376604 (* 1 = 0.0376604 loss)
I1018 11:04:45.165076 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18816 (* 1 = 0.18816 loss)
I1018 11:04:45.165081 11069 solver.cpp:571] Iteration 21140, lr = 0.001
I1018 11:04:52.909524 11069 solver.cpp:242] Iteration 21160, loss = 0.128603
I1018 11:04:52.909549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0314025 (* 1 = 0.0314025 loss)
I1018 11:04:52.909554 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0972008 (* 1 = 0.0972008 loss)
I1018 11:04:52.909559 11069 solver.cpp:571] Iteration 21160, lr = 0.001
I1018 11:05:00.490265 11069 solver.cpp:242] Iteration 21180, loss = 0.845764
I1018 11:05:00.490290 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210475 (* 1 = 0.210475 loss)
I1018 11:05:00.490295 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.635289 (* 1 = 0.635289 loss)
I1018 11:05:00.490299 11069 solver.cpp:571] Iteration 21180, lr = 0.001
speed: 0.377s / iter
I1018 11:05:08.092911 11069 solver.cpp:242] Iteration 21200, loss = 0.560191
I1018 11:05:08.092936 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164854 (* 1 = 0.164854 loss)
I1018 11:05:08.092941 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.395337 (* 1 = 0.395337 loss)
I1018 11:05:08.092945 11069 solver.cpp:571] Iteration 21200, lr = 0.001
I1018 11:05:15.743487 11069 solver.cpp:242] Iteration 21220, loss = 0.664075
I1018 11:05:15.743513 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.127839 (* 1 = 0.127839 loss)
I1018 11:05:15.743518 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.536235 (* 1 = 0.536235 loss)
I1018 11:05:15.743522 11069 solver.cpp:571] Iteration 21220, lr = 0.001
I1018 11:05:23.349086 11069 solver.cpp:242] Iteration 21240, loss = 0.2544
I1018 11:05:23.349112 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529908 (* 1 = 0.0529908 loss)
I1018 11:05:23.349117 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.201409 (* 1 = 0.201409 loss)
I1018 11:05:23.349122 11069 solver.cpp:571] Iteration 21240, lr = 0.001
I1018 11:05:30.998950 11069 solver.cpp:242] Iteration 21260, loss = 0.236396
I1018 11:05:30.998978 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0569949 (* 1 = 0.0569949 loss)
I1018 11:05:30.998983 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179402 (* 1 = 0.179402 loss)
I1018 11:05:30.998987 11069 solver.cpp:571] Iteration 21260, lr = 0.001
I1018 11:05:38.630715 11069 solver.cpp:242] Iteration 21280, loss = 0.189057
I1018 11:05:38.630741 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.052268 (* 1 = 0.052268 loss)
I1018 11:05:38.630746 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136789 (* 1 = 0.136789 loss)
I1018 11:05:38.630750 11069 solver.cpp:571] Iteration 21280, lr = 0.001
I1018 11:05:46.242053 11069 solver.cpp:242] Iteration 21300, loss = 0.264371
I1018 11:05:46.242080 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0690795 (* 1 = 0.0690795 loss)
I1018 11:05:46.242085 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195292 (* 1 = 0.195292 loss)
I1018 11:05:46.242090 11069 solver.cpp:571] Iteration 21300, lr = 0.001
I1018 11:05:53.864343 11069 solver.cpp:242] Iteration 21320, loss = 0.300683
I1018 11:05:53.864369 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0840212 (* 1 = 0.0840212 loss)
I1018 11:05:53.864374 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216662 (* 1 = 0.216662 loss)
I1018 11:05:53.864379 11069 solver.cpp:571] Iteration 21320, lr = 0.001
I1018 11:06:01.470950 11069 solver.cpp:242] Iteration 21340, loss = 0.341525
I1018 11:06:01.470976 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113335 (* 1 = 0.113335 loss)
I1018 11:06:01.470981 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22819 (* 1 = 0.22819 loss)
I1018 11:06:01.470985 11069 solver.cpp:571] Iteration 21340, lr = 0.001
I1018 11:06:09.100116 11069 solver.cpp:242] Iteration 21360, loss = 0.136456
I1018 11:06:09.100142 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0499396 (* 1 = 0.0499396 loss)
I1018 11:06:09.100147 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0865164 (* 1 = 0.0865164 loss)
I1018 11:06:09.100152 11069 solver.cpp:571] Iteration 21360, lr = 0.001
I1018 11:06:16.643187 11069 solver.cpp:242] Iteration 21380, loss = 0.361167
I1018 11:06:16.643213 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0805598 (* 1 = 0.0805598 loss)
I1018 11:06:16.643218 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280608 (* 1 = 0.280608 loss)
I1018 11:06:16.643221 11069 solver.cpp:571] Iteration 21380, lr = 0.001
speed: 0.377s / iter
I1018 11:06:24.214270 11069 solver.cpp:242] Iteration 21400, loss = 0.539724
I1018 11:06:24.214296 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.193972 (* 1 = 0.193972 loss)
I1018 11:06:24.214301 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.345752 (* 1 = 0.345752 loss)
I1018 11:06:24.214305 11069 solver.cpp:571] Iteration 21400, lr = 0.001
I1018 11:06:31.824025 11069 solver.cpp:242] Iteration 21420, loss = 0.25027
I1018 11:06:31.824053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0464128 (* 1 = 0.0464128 loss)
I1018 11:06:31.824057 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.203857 (* 1 = 0.203857 loss)
I1018 11:06:31.824062 11069 solver.cpp:571] Iteration 21420, lr = 0.001
I1018 11:06:39.467831 11069 solver.cpp:242] Iteration 21440, loss = 0.871175
I1018 11:06:39.467859 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128197 (* 1 = 0.128197 loss)
I1018 11:06:39.467864 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.742978 (* 1 = 0.742978 loss)
I1018 11:06:39.467867 11069 solver.cpp:571] Iteration 21440, lr = 0.001
I1018 11:06:47.019120 11069 solver.cpp:242] Iteration 21460, loss = 0.305846
I1018 11:06:47.019146 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108847 (* 1 = 0.108847 loss)
I1018 11:06:47.019152 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.196999 (* 1 = 0.196999 loss)
I1018 11:06:47.019156 11069 solver.cpp:571] Iteration 21460, lr = 0.001
I1018 11:06:54.585753 11069 solver.cpp:242] Iteration 21480, loss = 0.163199
I1018 11:06:54.585789 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0470944 (* 1 = 0.0470944 loss)
I1018 11:06:54.585794 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116104 (* 1 = 0.116104 loss)
I1018 11:06:54.585798 11069 solver.cpp:571] Iteration 21480, lr = 0.001
I1018 11:07:02.146157 11069 solver.cpp:242] Iteration 21500, loss = 0.890678
I1018 11:07:02.146183 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.289164 (* 1 = 0.289164 loss)
I1018 11:07:02.146188 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.601514 (* 1 = 0.601514 loss)
I1018 11:07:02.146193 11069 solver.cpp:571] Iteration 21500, lr = 0.001
I1018 11:07:09.817598 11069 solver.cpp:242] Iteration 21520, loss = 0.15767
I1018 11:07:09.817625 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0467121 (* 1 = 0.0467121 loss)
I1018 11:07:09.817629 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.110958 (* 1 = 0.110958 loss)
I1018 11:07:09.817634 11069 solver.cpp:571] Iteration 21520, lr = 0.001
I1018 11:07:17.545588 11069 solver.cpp:242] Iteration 21540, loss = 0.278878
I1018 11:07:17.545614 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0497754 (* 1 = 0.0497754 loss)
I1018 11:07:17.545620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.229102 (* 1 = 0.229102 loss)
I1018 11:07:17.545624 11069 solver.cpp:571] Iteration 21540, lr = 0.001
I1018 11:07:25.167340 11069 solver.cpp:242] Iteration 21560, loss = 0.195696
I1018 11:07:25.167366 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0795641 (* 1 = 0.0795641 loss)
I1018 11:07:25.167371 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116132 (* 1 = 0.116132 loss)
I1018 11:07:25.167376 11069 solver.cpp:571] Iteration 21560, lr = 0.001
I1018 11:07:32.721460 11069 solver.cpp:242] Iteration 21580, loss = 1.16419
I1018 11:07:32.721487 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.412636 (* 1 = 0.412636 loss)
I1018 11:07:32.721492 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.751554 (* 1 = 0.751554 loss)
I1018 11:07:32.721495 11069 solver.cpp:571] Iteration 21580, lr = 0.001
speed: 0.378s / iter
I1018 11:07:40.280091 11069 solver.cpp:242] Iteration 21600, loss = 0.548761
I1018 11:07:40.280117 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212932 (* 1 = 0.212932 loss)
I1018 11:07:40.280122 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.335829 (* 1 = 0.335829 loss)
I1018 11:07:40.280127 11069 solver.cpp:571] Iteration 21600, lr = 0.001
I1018 11:07:47.921509 11069 solver.cpp:242] Iteration 21620, loss = 1.14108
I1018 11:07:47.921535 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.525661 (* 1 = 0.525661 loss)
I1018 11:07:47.921540 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.615419 (* 1 = 0.615419 loss)
I1018 11:07:47.921545 11069 solver.cpp:571] Iteration 21620, lr = 0.001
I1018 11:07:55.563058 11069 solver.cpp:242] Iteration 21640, loss = 0.388848
I1018 11:07:55.563086 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0958963 (* 1 = 0.0958963 loss)
I1018 11:07:55.563091 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.292952 (* 1 = 0.292952 loss)
I1018 11:07:55.563094 11069 solver.cpp:571] Iteration 21640, lr = 0.001
I1018 11:08:03.199065 11069 solver.cpp:242] Iteration 21660, loss = 0.36744
I1018 11:08:03.199092 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0812622 (* 1 = 0.0812622 loss)
I1018 11:08:03.199097 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.286178 (* 1 = 0.286178 loss)
I1018 11:08:03.199101 11069 solver.cpp:571] Iteration 21660, lr = 0.001
I1018 11:08:10.807799 11069 solver.cpp:242] Iteration 21680, loss = 0.723147
I1018 11:08:10.807826 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.268727 (* 1 = 0.268727 loss)
I1018 11:08:10.807831 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.45442 (* 1 = 0.45442 loss)
I1018 11:08:10.807834 11069 solver.cpp:571] Iteration 21680, lr = 0.001
I1018 11:08:18.437966 11069 solver.cpp:242] Iteration 21700, loss = 0.477711
I1018 11:08:18.437993 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0964773 (* 1 = 0.0964773 loss)
I1018 11:08:18.437997 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.381234 (* 1 = 0.381234 loss)
I1018 11:08:18.438001 11069 solver.cpp:571] Iteration 21700, lr = 0.001
I1018 11:08:26.091207 11069 solver.cpp:242] Iteration 21720, loss = 0.168576
I1018 11:08:26.091233 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.025819 (* 1 = 0.025819 loss)
I1018 11:08:26.091238 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.142757 (* 1 = 0.142757 loss)
I1018 11:08:26.091243 11069 solver.cpp:571] Iteration 21720, lr = 0.001
I1018 11:08:33.698710 11069 solver.cpp:242] Iteration 21740, loss = 1.50537
I1018 11:08:33.698736 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.655191 (* 1 = 0.655191 loss)
I1018 11:08:33.698741 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.850184 (* 1 = 0.850184 loss)
I1018 11:08:33.698745 11069 solver.cpp:571] Iteration 21740, lr = 0.001
I1018 11:08:41.301080 11069 solver.cpp:242] Iteration 21760, loss = 0.0934387
I1018 11:08:41.301107 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0293955 (* 1 = 0.0293955 loss)
I1018 11:08:41.301112 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0640433 (* 1 = 0.0640433 loss)
I1018 11:08:41.301116 11069 solver.cpp:571] Iteration 21760, lr = 0.001
I1018 11:08:48.873122 11069 solver.cpp:242] Iteration 21780, loss = 0.314359
I1018 11:08:48.873149 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0956819 (* 1 = 0.0956819 loss)
I1018 11:08:48.873154 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218677 (* 1 = 0.218677 loss)
I1018 11:08:48.873158 11069 solver.cpp:571] Iteration 21780, lr = 0.001
speed: 0.378s / iter
I1018 11:08:56.464759 11069 solver.cpp:242] Iteration 21800, loss = 0.650042
I1018 11:08:56.464787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135066 (* 1 = 0.135066 loss)
I1018 11:08:56.464792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.514976 (* 1 = 0.514976 loss)
I1018 11:08:56.464795 11069 solver.cpp:571] Iteration 21800, lr = 0.001
I1018 11:09:04.090540 11069 solver.cpp:242] Iteration 21820, loss = 0.52266
I1018 11:09:04.090566 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171319 (* 1 = 0.171319 loss)
I1018 11:09:04.090572 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.351341 (* 1 = 0.351341 loss)
I1018 11:09:04.090576 11069 solver.cpp:571] Iteration 21820, lr = 0.001
I1018 11:09:11.760376 11069 solver.cpp:242] Iteration 21840, loss = 0.579748
I1018 11:09:11.760401 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151405 (* 1 = 0.151405 loss)
I1018 11:09:11.760406 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.428342 (* 1 = 0.428342 loss)
I1018 11:09:11.760411 11069 solver.cpp:571] Iteration 21840, lr = 0.001
I1018 11:09:19.397395 11069 solver.cpp:242] Iteration 21860, loss = 0.231251
I1018 11:09:19.397420 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0577606 (* 1 = 0.0577606 loss)
I1018 11:09:19.397425 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.173491 (* 1 = 0.173491 loss)
I1018 11:09:19.397429 11069 solver.cpp:571] Iteration 21860, lr = 0.001
I1018 11:09:26.986618 11069 solver.cpp:242] Iteration 21880, loss = 0.451679
I1018 11:09:26.986642 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142815 (* 1 = 0.142815 loss)
I1018 11:09:26.986647 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.308864 (* 1 = 0.308864 loss)
I1018 11:09:26.986651 11069 solver.cpp:571] Iteration 21880, lr = 0.001
I1018 11:09:34.621026 11069 solver.cpp:242] Iteration 21900, loss = 0.163085
I1018 11:09:34.621053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0414606 (* 1 = 0.0414606 loss)
I1018 11:09:34.621058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.121625 (* 1 = 0.121625 loss)
I1018 11:09:34.621063 11069 solver.cpp:571] Iteration 21900, lr = 0.001
I1018 11:09:42.268813 11069 solver.cpp:242] Iteration 21920, loss = 0.321646
I1018 11:09:42.268841 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0531245 (* 1 = 0.0531245 loss)
I1018 11:09:42.268846 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.268522 (* 1 = 0.268522 loss)
I1018 11:09:42.268849 11069 solver.cpp:571] Iteration 21920, lr = 0.001
I1018 11:09:49.917688 11069 solver.cpp:242] Iteration 21940, loss = 0.349151
I1018 11:09:49.917714 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0582118 (* 1 = 0.0582118 loss)
I1018 11:09:49.917719 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.290939 (* 1 = 0.290939 loss)
I1018 11:09:49.917724 11069 solver.cpp:571] Iteration 21940, lr = 0.001
I1018 11:09:57.386574 11069 solver.cpp:242] Iteration 21960, loss = 1.05308
I1018 11:09:57.386601 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.441776 (* 1 = 0.441776 loss)
I1018 11:09:57.386606 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.611308 (* 1 = 0.611308 loss)
I1018 11:09:57.386610 11069 solver.cpp:571] Iteration 21960, lr = 0.001
I1018 11:10:04.921979 11069 solver.cpp:242] Iteration 21980, loss = 0.576695
I1018 11:10:04.922005 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135725 (* 1 = 0.135725 loss)
I1018 11:10:04.922010 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.44097 (* 1 = 0.44097 loss)
I1018 11:10:04.922015 11069 solver.cpp:571] Iteration 21980, lr = 0.001
speed: 0.378s / iter
I1018 11:10:12.490531 11069 solver.cpp:242] Iteration 22000, loss = 0.973013
I1018 11:10:12.490557 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.305592 (* 1 = 0.305592 loss)
I1018 11:10:12.490562 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.667421 (* 1 = 0.667421 loss)
I1018 11:10:12.490566 11069 solver.cpp:571] Iteration 22000, lr = 0.001
I1018 11:10:20.044083 11069 solver.cpp:242] Iteration 22020, loss = 0.207334
I1018 11:10:20.044108 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0394965 (* 1 = 0.0394965 loss)
I1018 11:10:20.044113 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.167838 (* 1 = 0.167838 loss)
I1018 11:10:20.044117 11069 solver.cpp:571] Iteration 22020, lr = 0.001
I1018 11:10:27.601656 11069 solver.cpp:242] Iteration 22040, loss = 0.645373
I1018 11:10:27.601682 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200999 (* 1 = 0.200999 loss)
I1018 11:10:27.601687 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.444374 (* 1 = 0.444374 loss)
I1018 11:10:27.601691 11069 solver.cpp:571] Iteration 22040, lr = 0.001
I1018 11:10:35.274550 11069 solver.cpp:242] Iteration 22060, loss = 0.669482
I1018 11:10:35.274576 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.174189 (* 1 = 0.174189 loss)
I1018 11:10:35.274581 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495293 (* 1 = 0.495293 loss)
I1018 11:10:35.274585 11069 solver.cpp:571] Iteration 22060, lr = 0.001
I1018 11:10:42.918684 11069 solver.cpp:242] Iteration 22080, loss = 0.666054
I1018 11:10:42.918711 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.219662 (* 1 = 0.219662 loss)
I1018 11:10:42.918717 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.446392 (* 1 = 0.446392 loss)
I1018 11:10:42.918721 11069 solver.cpp:571] Iteration 22080, lr = 0.001
I1018 11:10:50.525532 11069 solver.cpp:242] Iteration 22100, loss = 0.196288
I1018 11:10:50.525557 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479401 (* 1 = 0.0479401 loss)
I1018 11:10:50.525563 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148348 (* 1 = 0.148348 loss)
I1018 11:10:50.525566 11069 solver.cpp:571] Iteration 22100, lr = 0.001
I1018 11:10:57.996734 11069 solver.cpp:242] Iteration 22120, loss = 0.319824
I1018 11:10:57.996760 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0544336 (* 1 = 0.0544336 loss)
I1018 11:10:57.996765 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.26539 (* 1 = 0.26539 loss)
I1018 11:10:57.996769 11069 solver.cpp:571] Iteration 22120, lr = 0.001
I1018 11:11:05.648041 11069 solver.cpp:242] Iteration 22140, loss = 1.18899
I1018 11:11:05.648066 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.504657 (* 1 = 0.504657 loss)
I1018 11:11:05.648072 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.684331 (* 1 = 0.684331 loss)
I1018 11:11:05.648077 11069 solver.cpp:571] Iteration 22140, lr = 0.001
I1018 11:11:13.253865 11069 solver.cpp:242] Iteration 22160, loss = 0.526957
I1018 11:11:13.253891 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.195938 (* 1 = 0.195938 loss)
I1018 11:11:13.253896 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.331019 (* 1 = 0.331019 loss)
I1018 11:11:13.253901 11069 solver.cpp:571] Iteration 22160, lr = 0.001
I1018 11:11:20.799646 11069 solver.cpp:242] Iteration 22180, loss = 0.213175
I1018 11:11:20.799674 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.049023 (* 1 = 0.049023 loss)
I1018 11:11:20.799679 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.164152 (* 1 = 0.164152 loss)
I1018 11:11:20.799684 11069 solver.cpp:571] Iteration 22180, lr = 0.001
speed: 0.378s / iter
I1018 11:11:28.430425 11069 solver.cpp:242] Iteration 22200, loss = 1.14474
I1018 11:11:28.430452 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.439223 (* 1 = 0.439223 loss)
I1018 11:11:28.430457 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.705513 (* 1 = 0.705513 loss)
I1018 11:11:28.430461 11069 solver.cpp:571] Iteration 22200, lr = 0.001
I1018 11:11:36.070876 11069 solver.cpp:242] Iteration 22220, loss = 0.469179
I1018 11:11:36.070902 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.113867 (* 1 = 0.113867 loss)
I1018 11:11:36.070909 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.355312 (* 1 = 0.355312 loss)
I1018 11:11:36.070912 11069 solver.cpp:571] Iteration 22220, lr = 0.001
I1018 11:11:43.713569 11069 solver.cpp:242] Iteration 22240, loss = 1.60111
I1018 11:11:43.713595 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.614683 (* 1 = 0.614683 loss)
I1018 11:11:43.713599 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.986428 (* 1 = 0.986428 loss)
I1018 11:11:43.713604 11069 solver.cpp:571] Iteration 22240, lr = 0.001
I1018 11:11:51.358183 11069 solver.cpp:242] Iteration 22260, loss = 0.805713
I1018 11:11:51.358211 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.25945 (* 1 = 0.25945 loss)
I1018 11:11:51.358216 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.546263 (* 1 = 0.546263 loss)
I1018 11:11:51.358219 11069 solver.cpp:571] Iteration 22260, lr = 0.001
I1018 11:11:58.991024 11069 solver.cpp:242] Iteration 22280, loss = 0.130211
I1018 11:11:58.991050 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.052896 (* 1 = 0.052896 loss)
I1018 11:11:58.991055 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0773147 (* 1 = 0.0773147 loss)
I1018 11:11:58.991060 11069 solver.cpp:571] Iteration 22280, lr = 0.001
I1018 11:12:06.616248 11069 solver.cpp:242] Iteration 22300, loss = 0.843512
I1018 11:12:06.616274 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.273205 (* 1 = 0.273205 loss)
I1018 11:12:06.616279 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.570307 (* 1 = 0.570307 loss)
I1018 11:12:06.616284 11069 solver.cpp:571] Iteration 22300, lr = 0.001
I1018 11:12:14.250923 11069 solver.cpp:242] Iteration 22320, loss = 1.14522
I1018 11:12:14.250949 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.404024 (* 1 = 0.404024 loss)
I1018 11:12:14.250955 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.741194 (* 1 = 0.741194 loss)
I1018 11:12:14.250959 11069 solver.cpp:571] Iteration 22320, lr = 0.001
I1018 11:12:21.925842 11069 solver.cpp:242] Iteration 22340, loss = 0.25431
I1018 11:12:21.925868 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.050271 (* 1 = 0.050271 loss)
I1018 11:12:21.925873 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204039 (* 1 = 0.204039 loss)
I1018 11:12:21.925876 11069 solver.cpp:571] Iteration 22340, lr = 0.001
I1018 11:12:29.604352 11069 solver.cpp:242] Iteration 22360, loss = 0.867429
I1018 11:12:29.604378 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.224772 (* 1 = 0.224772 loss)
I1018 11:12:29.604383 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.642658 (* 1 = 0.642658 loss)
I1018 11:12:29.604388 11069 solver.cpp:571] Iteration 22360, lr = 0.001
I1018 11:12:37.296797 11069 solver.cpp:242] Iteration 22380, loss = 1.67593
I1018 11:12:37.296821 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.720182 (* 1 = 0.720182 loss)
I1018 11:12:37.296826 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.95575 (* 1 = 0.95575 loss)
I1018 11:12:37.296831 11069 solver.cpp:571] Iteration 22380, lr = 0.001
speed: 0.378s / iter
I1018 11:12:44.867259 11069 solver.cpp:242] Iteration 22400, loss = 0.162868
I1018 11:12:44.867285 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0288144 (* 1 = 0.0288144 loss)
I1018 11:12:44.867290 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.134053 (* 1 = 0.134053 loss)
I1018 11:12:44.867293 11069 solver.cpp:571] Iteration 22400, lr = 0.001
I1018 11:12:52.585448 11069 solver.cpp:242] Iteration 22420, loss = 0.780781
I1018 11:12:52.585474 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.245905 (* 1 = 0.245905 loss)
I1018 11:12:52.585479 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.534876 (* 1 = 0.534876 loss)
I1018 11:12:52.585482 11069 solver.cpp:571] Iteration 22420, lr = 0.001
I1018 11:13:00.186954 11069 solver.cpp:242] Iteration 22440, loss = 0.657533
I1018 11:13:00.186977 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.14771 (* 1 = 0.14771 loss)
I1018 11:13:00.186982 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.509823 (* 1 = 0.509823 loss)
I1018 11:13:00.186987 11069 solver.cpp:571] Iteration 22440, lr = 0.001
I1018 11:13:07.812512 11069 solver.cpp:242] Iteration 22460, loss = 0.237745
I1018 11:13:07.812538 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0549739 (* 1 = 0.0549739 loss)
I1018 11:13:07.812543 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182772 (* 1 = 0.182772 loss)
I1018 11:13:07.812548 11069 solver.cpp:571] Iteration 22460, lr = 0.001
I1018 11:13:15.432277 11069 solver.cpp:242] Iteration 22480, loss = 0.188937
I1018 11:13:15.432303 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0569558 (* 1 = 0.0569558 loss)
I1018 11:13:15.432308 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131982 (* 1 = 0.131982 loss)
I1018 11:13:15.432312 11069 solver.cpp:571] Iteration 22480, lr = 0.001
I1018 11:13:23.042660 11069 solver.cpp:242] Iteration 22500, loss = 0.194633
I1018 11:13:23.042687 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0631958 (* 1 = 0.0631958 loss)
I1018 11:13:23.042692 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131437 (* 1 = 0.131437 loss)
I1018 11:13:23.042697 11069 solver.cpp:571] Iteration 22500, lr = 0.001
I1018 11:13:30.726145 11069 solver.cpp:242] Iteration 22520, loss = 0.359797
I1018 11:13:30.726171 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1112 (* 1 = 0.1112 loss)
I1018 11:13:30.726176 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.248597 (* 1 = 0.248597 loss)
I1018 11:13:30.726181 11069 solver.cpp:571] Iteration 22520, lr = 0.001
I1018 11:13:38.286036 11069 solver.cpp:242] Iteration 22540, loss = 0.893443
I1018 11:13:38.286062 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.312555 (* 1 = 0.312555 loss)
I1018 11:13:38.286067 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.580887 (* 1 = 0.580887 loss)
I1018 11:13:38.286070 11069 solver.cpp:571] Iteration 22540, lr = 0.001
I1018 11:13:45.962400 11069 solver.cpp:242] Iteration 22560, loss = 0.858009
I1018 11:13:45.962426 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.295479 (* 1 = 0.295479 loss)
I1018 11:13:45.962431 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.56253 (* 1 = 0.56253 loss)
I1018 11:13:45.962435 11069 solver.cpp:571] Iteration 22560, lr = 0.001
I1018 11:13:53.573448 11069 solver.cpp:242] Iteration 22580, loss = 0.175102
I1018 11:13:53.573473 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0525067 (* 1 = 0.0525067 loss)
I1018 11:13:53.573479 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.122595 (* 1 = 0.122595 loss)
I1018 11:13:53.573483 11069 solver.cpp:571] Iteration 22580, lr = 0.001
speed: 0.378s / iter
I1018 11:14:01.194722 11069 solver.cpp:242] Iteration 22600, loss = 0.151476
I1018 11:14:01.194749 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.066268 (* 1 = 0.066268 loss)
I1018 11:14:01.194756 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0852077 (* 1 = 0.0852077 loss)
I1018 11:14:01.194759 11069 solver.cpp:571] Iteration 22600, lr = 0.001
I1018 11:14:08.737336 11069 solver.cpp:242] Iteration 22620, loss = 0.210341
I1018 11:14:08.737363 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0350472 (* 1 = 0.0350472 loss)
I1018 11:14:08.737368 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.175294 (* 1 = 0.175294 loss)
I1018 11:14:08.737372 11069 solver.cpp:571] Iteration 22620, lr = 0.001
I1018 11:14:16.343853 11069 solver.cpp:242] Iteration 22640, loss = 0.855501
I1018 11:14:16.343879 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.325305 (* 1 = 0.325305 loss)
I1018 11:14:16.343884 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.530196 (* 1 = 0.530196 loss)
I1018 11:14:16.343888 11069 solver.cpp:571] Iteration 22640, lr = 0.001
I1018 11:14:23.925148 11069 solver.cpp:242] Iteration 22660, loss = 0.236192
I1018 11:14:23.925174 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0763851 (* 1 = 0.0763851 loss)
I1018 11:14:23.925179 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159807 (* 1 = 0.159807 loss)
I1018 11:14:23.925184 11069 solver.cpp:571] Iteration 22660, lr = 0.001
I1018 11:14:31.489033 11069 solver.cpp:242] Iteration 22680, loss = 0.244765
I1018 11:14:31.489058 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0793369 (* 1 = 0.0793369 loss)
I1018 11:14:31.489063 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165428 (* 1 = 0.165428 loss)
I1018 11:14:31.489068 11069 solver.cpp:571] Iteration 22680, lr = 0.001
I1018 11:14:39.171457 11069 solver.cpp:242] Iteration 22700, loss = 0.239793
I1018 11:14:39.171483 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0417019 (* 1 = 0.0417019 loss)
I1018 11:14:39.171488 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.198091 (* 1 = 0.198091 loss)
I1018 11:14:39.171492 11069 solver.cpp:571] Iteration 22700, lr = 0.001
I1018 11:14:46.754050 11069 solver.cpp:242] Iteration 22720, loss = 0.244439
I1018 11:14:46.754076 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0882476 (* 1 = 0.0882476 loss)
I1018 11:14:46.754081 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.156191 (* 1 = 0.156191 loss)
I1018 11:14:46.754086 11069 solver.cpp:571] Iteration 22720, lr = 0.001
I1018 11:14:54.418925 11069 solver.cpp:242] Iteration 22740, loss = 0.562632
I1018 11:14:54.418951 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.228505 (* 1 = 0.228505 loss)
I1018 11:14:54.418956 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.334127 (* 1 = 0.334127 loss)
I1018 11:14:54.418959 11069 solver.cpp:571] Iteration 22740, lr = 0.001
I1018 11:15:02.094261 11069 solver.cpp:242] Iteration 22760, loss = 0.328135
I1018 11:15:02.094286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0664983 (* 1 = 0.0664983 loss)
I1018 11:15:02.094291 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.261637 (* 1 = 0.261637 loss)
I1018 11:15:02.094296 11069 solver.cpp:571] Iteration 22760, lr = 0.001
I1018 11:15:09.729285 11069 solver.cpp:242] Iteration 22780, loss = 0.164859
I1018 11:15:09.729312 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0386166 (* 1 = 0.0386166 loss)
I1018 11:15:09.729317 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126242 (* 1 = 0.126242 loss)
I1018 11:15:09.729322 11069 solver.cpp:571] Iteration 22780, lr = 0.001
speed: 0.378s / iter
I1018 11:15:17.360486 11069 solver.cpp:242] Iteration 22800, loss = 0.302597
I1018 11:15:17.360512 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.073302 (* 1 = 0.073302 loss)
I1018 11:15:17.360517 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.229295 (* 1 = 0.229295 loss)
I1018 11:15:17.360520 11069 solver.cpp:571] Iteration 22800, lr = 0.001
I1018 11:15:24.961827 11069 solver.cpp:242] Iteration 22820, loss = 0.54783
I1018 11:15:24.961853 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153319 (* 1 = 0.153319 loss)
I1018 11:15:24.961858 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.39451 (* 1 = 0.39451 loss)
I1018 11:15:24.961861 11069 solver.cpp:571] Iteration 22820, lr = 0.001
I1018 11:15:32.574968 11069 solver.cpp:242] Iteration 22840, loss = 0.824808
I1018 11:15:32.574993 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.266265 (* 1 = 0.266265 loss)
I1018 11:15:32.574998 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.558543 (* 1 = 0.558543 loss)
I1018 11:15:32.575002 11069 solver.cpp:571] Iteration 22840, lr = 0.001
I1018 11:15:40.199265 11069 solver.cpp:242] Iteration 22860, loss = 0.291349
I1018 11:15:40.199291 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0990721 (* 1 = 0.0990721 loss)
I1018 11:15:40.199295 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.192277 (* 1 = 0.192277 loss)
I1018 11:15:40.199301 11069 solver.cpp:571] Iteration 22860, lr = 0.001
I1018 11:15:47.844218 11069 solver.cpp:242] Iteration 22880, loss = 0.361491
I1018 11:15:47.844244 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0885639 (* 1 = 0.0885639 loss)
I1018 11:15:47.844249 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.272927 (* 1 = 0.272927 loss)
I1018 11:15:47.844254 11069 solver.cpp:571] Iteration 22880, lr = 0.001
I1018 11:15:55.485152 11069 solver.cpp:242] Iteration 22900, loss = 1.89327
I1018 11:15:55.485177 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.782456 (* 1 = 0.782456 loss)
I1018 11:15:55.485183 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.11082 (* 1 = 1.11082 loss)
I1018 11:15:55.485188 11069 solver.cpp:571] Iteration 22900, lr = 0.001
I1018 11:16:03.067044 11069 solver.cpp:242] Iteration 22920, loss = 0.776148
I1018 11:16:03.067070 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.313115 (* 1 = 0.313115 loss)
I1018 11:16:03.067075 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.463033 (* 1 = 0.463033 loss)
I1018 11:16:03.067080 11069 solver.cpp:571] Iteration 22920, lr = 0.001
I1018 11:16:10.707628 11069 solver.cpp:242] Iteration 22940, loss = 0.186084
I1018 11:16:10.707654 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0467135 (* 1 = 0.0467135 loss)
I1018 11:16:10.707659 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.139371 (* 1 = 0.139371 loss)
I1018 11:16:10.707664 11069 solver.cpp:571] Iteration 22940, lr = 0.001
I1018 11:16:18.378876 11069 solver.cpp:242] Iteration 22960, loss = 0.295005
I1018 11:16:18.378903 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100566 (* 1 = 0.100566 loss)
I1018 11:16:18.378908 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194439 (* 1 = 0.194439 loss)
I1018 11:16:18.378912 11069 solver.cpp:571] Iteration 22960, lr = 0.001
I1018 11:16:25.979892 11069 solver.cpp:242] Iteration 22980, loss = 1.20236
I1018 11:16:25.979918 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.363125 (* 1 = 0.363125 loss)
I1018 11:16:25.979923 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.83923 (* 1 = 0.83923 loss)
I1018 11:16:25.979928 11069 solver.cpp:571] Iteration 22980, lr = 0.001
speed: 0.378s / iter
I1018 11:16:33.562105 11069 solver.cpp:242] Iteration 23000, loss = 0.825611
I1018 11:16:33.562130 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.299455 (* 1 = 0.299455 loss)
I1018 11:16:33.562135 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.526156 (* 1 = 0.526156 loss)
I1018 11:16:33.562139 11069 solver.cpp:571] Iteration 23000, lr = 0.001
I1018 11:16:41.291923 11069 solver.cpp:242] Iteration 23020, loss = 0.248885
I1018 11:16:41.291950 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0497386 (* 1 = 0.0497386 loss)
I1018 11:16:41.291956 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.199147 (* 1 = 0.199147 loss)
I1018 11:16:41.291961 11069 solver.cpp:571] Iteration 23020, lr = 0.001
I1018 11:16:48.960767 11069 solver.cpp:242] Iteration 23040, loss = 0.429146
I1018 11:16:48.960793 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0499497 (* 1 = 0.0499497 loss)
I1018 11:16:48.960798 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.379196 (* 1 = 0.379196 loss)
I1018 11:16:48.960803 11069 solver.cpp:571] Iteration 23040, lr = 0.001
I1018 11:16:56.538774 11069 solver.cpp:242] Iteration 23060, loss = 0.419911
I1018 11:16:56.538800 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0945462 (* 1 = 0.0945462 loss)
I1018 11:16:56.538805 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.325365 (* 1 = 0.325365 loss)
I1018 11:16:56.538808 11069 solver.cpp:571] Iteration 23060, lr = 0.001
I1018 11:17:03.592456 11069 solver.cpp:242] Iteration 23080, loss = 0.829403
I1018 11:17:03.592481 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.263494 (* 1 = 0.263494 loss)
I1018 11:17:03.592486 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.565909 (* 1 = 0.565909 loss)
I1018 11:17:03.592490 11069 solver.cpp:571] Iteration 23080, lr = 0.001
I1018 11:17:10.850687 11069 solver.cpp:242] Iteration 23100, loss = 0.670295
I1018 11:17:10.850713 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159055 (* 1 = 0.159055 loss)
I1018 11:17:10.850718 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.51124 (* 1 = 0.51124 loss)
I1018 11:17:10.850723 11069 solver.cpp:571] Iteration 23100, lr = 0.001
I1018 11:17:17.954274 11069 solver.cpp:242] Iteration 23120, loss = 0.942815
I1018 11:17:17.954299 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.259954 (* 1 = 0.259954 loss)
I1018 11:17:17.954304 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.682861 (* 1 = 0.682861 loss)
I1018 11:17:17.954309 11069 solver.cpp:571] Iteration 23120, lr = 0.001
I1018 11:17:24.943871 11069 solver.cpp:242] Iteration 23140, loss = 0.250217
I1018 11:17:24.943897 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0531638 (* 1 = 0.0531638 loss)
I1018 11:17:24.943902 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197054 (* 1 = 0.197054 loss)
I1018 11:17:24.943907 11069 solver.cpp:571] Iteration 23140, lr = 0.001
I1018 11:17:32.251605 11069 solver.cpp:242] Iteration 23160, loss = 0.209239
I1018 11:17:32.251628 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0790015 (* 1 = 0.0790015 loss)
I1018 11:17:32.251633 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.130237 (* 1 = 0.130237 loss)
I1018 11:17:32.251637 11069 solver.cpp:571] Iteration 23160, lr = 0.001
I1018 11:17:39.769806 11069 solver.cpp:242] Iteration 23180, loss = 0.402209
I1018 11:17:39.769832 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.132722 (* 1 = 0.132722 loss)
I1018 11:17:39.769837 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269487 (* 1 = 0.269487 loss)
I1018 11:17:39.769841 11069 solver.cpp:571] Iteration 23180, lr = 0.001
speed: 0.378s / iter
I1018 11:17:47.173425 11069 solver.cpp:242] Iteration 23200, loss = 0.303452
I1018 11:17:47.173451 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0879533 (* 1 = 0.0879533 loss)
I1018 11:17:47.173456 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.215499 (* 1 = 0.215499 loss)
I1018 11:17:47.173460 11069 solver.cpp:571] Iteration 23200, lr = 0.001
I1018 11:17:54.488852 11069 solver.cpp:242] Iteration 23220, loss = 1.28049
I1018 11:17:54.488878 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.383012 (* 1 = 0.383012 loss)
I1018 11:17:54.488883 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.897475 (* 1 = 0.897475 loss)
I1018 11:17:54.488888 11069 solver.cpp:571] Iteration 23220, lr = 0.001
I1018 11:18:02.086299 11069 solver.cpp:242] Iteration 23240, loss = 0.710279
I1018 11:18:02.086325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.16264 (* 1 = 0.16264 loss)
I1018 11:18:02.086330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.547639 (* 1 = 0.547639 loss)
I1018 11:18:02.086334 11069 solver.cpp:571] Iteration 23240, lr = 0.001
I1018 11:18:09.352488 11069 solver.cpp:242] Iteration 23260, loss = 0.291101
I1018 11:18:09.352512 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0313068 (* 1 = 0.0313068 loss)
I1018 11:18:09.352517 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259794 (* 1 = 0.259794 loss)
I1018 11:18:09.352521 11069 solver.cpp:571] Iteration 23260, lr = 0.001
I1018 11:18:16.951712 11069 solver.cpp:242] Iteration 23280, loss = 0.225038
I1018 11:18:16.951738 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0615473 (* 1 = 0.0615473 loss)
I1018 11:18:16.951743 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.163491 (* 1 = 0.163491 loss)
I1018 11:18:16.951748 11069 solver.cpp:571] Iteration 23280, lr = 0.001
I1018 11:18:24.362090 11069 solver.cpp:242] Iteration 23300, loss = 1.20437
I1018 11:18:24.362118 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.432023 (* 1 = 0.432023 loss)
I1018 11:18:24.362123 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.772351 (* 1 = 0.772351 loss)
I1018 11:18:24.362126 11069 solver.cpp:571] Iteration 23300, lr = 0.001
I1018 11:18:31.862190 11069 solver.cpp:242] Iteration 23320, loss = 0.368525
I1018 11:18:31.862216 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.117112 (* 1 = 0.117112 loss)
I1018 11:18:31.862221 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.251413 (* 1 = 0.251413 loss)
I1018 11:18:31.862226 11069 solver.cpp:571] Iteration 23320, lr = 0.001
I1018 11:18:39.452026 11069 solver.cpp:242] Iteration 23340, loss = 1.3259
I1018 11:18:39.452051 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.503675 (* 1 = 0.503675 loss)
I1018 11:18:39.452056 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.822228 (* 1 = 0.822228 loss)
I1018 11:18:39.452060 11069 solver.cpp:571] Iteration 23340, lr = 0.001
I1018 11:18:46.630905 11069 solver.cpp:242] Iteration 23360, loss = 0.23694
I1018 11:18:46.630930 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0560662 (* 1 = 0.0560662 loss)
I1018 11:18:46.630935 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.180874 (* 1 = 0.180874 loss)
I1018 11:18:46.630939 11069 solver.cpp:571] Iteration 23360, lr = 0.001
I1018 11:18:53.925142 11069 solver.cpp:242] Iteration 23380, loss = 0.866021
I1018 11:18:53.925168 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.242856 (* 1 = 0.242856 loss)
I1018 11:18:53.925173 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.623165 (* 1 = 0.623165 loss)
I1018 11:18:53.925176 11069 solver.cpp:571] Iteration 23380, lr = 0.001
speed: 0.378s / iter
I1018 11:19:01.389459 11069 solver.cpp:242] Iteration 23400, loss = 0.497068
I1018 11:19:01.389484 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.206636 (* 1 = 0.206636 loss)
I1018 11:19:01.389489 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.290432 (* 1 = 0.290432 loss)
I1018 11:19:01.389493 11069 solver.cpp:571] Iteration 23400, lr = 0.001
I1018 11:19:09.039950 11069 solver.cpp:242] Iteration 23420, loss = 1.14172
I1018 11:19:09.039976 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.359716 (* 1 = 0.359716 loss)
I1018 11:19:09.039981 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.782006 (* 1 = 0.782006 loss)
I1018 11:19:09.039986 11069 solver.cpp:571] Iteration 23420, lr = 0.001
I1018 11:19:16.393894 11069 solver.cpp:242] Iteration 23440, loss = 0.604035
I1018 11:19:16.393920 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115456 (* 1 = 0.115456 loss)
I1018 11:19:16.393925 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.488579 (* 1 = 0.488579 loss)
I1018 11:19:16.393930 11069 solver.cpp:571] Iteration 23440, lr = 0.001
I1018 11:19:24.037983 11069 solver.cpp:242] Iteration 23460, loss = 0.49395
I1018 11:19:24.038010 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168186 (* 1 = 0.168186 loss)
I1018 11:19:24.038015 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.325765 (* 1 = 0.325765 loss)
I1018 11:19:24.038019 11069 solver.cpp:571] Iteration 23460, lr = 0.001
I1018 11:19:31.717133 11069 solver.cpp:242] Iteration 23480, loss = 1.17022
I1018 11:19:31.717159 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.466988 (* 1 = 0.466988 loss)
I1018 11:19:31.717164 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.703236 (* 1 = 0.703236 loss)
I1018 11:19:31.717169 11069 solver.cpp:571] Iteration 23480, lr = 0.001
I1018 11:19:39.210675 11069 solver.cpp:242] Iteration 23500, loss = 0.263179
I1018 11:19:39.210700 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0813693 (* 1 = 0.0813693 loss)
I1018 11:19:39.210705 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18181 (* 1 = 0.18181 loss)
I1018 11:19:39.210710 11069 solver.cpp:571] Iteration 23500, lr = 0.001
I1018 11:19:46.678916 11069 solver.cpp:242] Iteration 23520, loss = 0.813604
I1018 11:19:46.678942 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.310869 (* 1 = 0.310869 loss)
I1018 11:19:46.678947 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.502735 (* 1 = 0.502735 loss)
I1018 11:19:46.678951 11069 solver.cpp:571] Iteration 23520, lr = 0.001
I1018 11:19:53.547260 11069 solver.cpp:242] Iteration 23540, loss = 0.182379
I1018 11:19:53.547286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0567256 (* 1 = 0.0567256 loss)
I1018 11:19:53.547291 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.125654 (* 1 = 0.125654 loss)
I1018 11:19:53.547294 11069 solver.cpp:571] Iteration 23540, lr = 0.001
I1018 11:20:00.781577 11069 solver.cpp:242] Iteration 23560, loss = 0.744251
I1018 11:20:00.781601 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.277133 (* 1 = 0.277133 loss)
I1018 11:20:00.781606 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.467118 (* 1 = 0.467118 loss)
I1018 11:20:00.781610 11069 solver.cpp:571] Iteration 23560, lr = 0.001
I1018 11:20:08.175515 11069 solver.cpp:242] Iteration 23580, loss = 0.0187715
I1018 11:20:08.175542 11069 solver.cpp:258]     Train net output #0: loss_bbox = 6.10743e-05 (* 1 = 6.10743e-05 loss)
I1018 11:20:08.175547 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0187104 (* 1 = 0.0187104 loss)
I1018 11:20:08.175551 11069 solver.cpp:571] Iteration 23580, lr = 0.001
speed: 0.378s / iter
I1018 11:20:15.586284 11069 solver.cpp:242] Iteration 23600, loss = 0.177208
I1018 11:20:15.586313 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0325741 (* 1 = 0.0325741 loss)
I1018 11:20:15.586318 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144634 (* 1 = 0.144634 loss)
I1018 11:20:15.586321 11069 solver.cpp:571] Iteration 23600, lr = 0.001
I1018 11:20:22.860483 11069 solver.cpp:242] Iteration 23620, loss = 0.257166
I1018 11:20:22.860509 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103122 (* 1 = 0.103122 loss)
I1018 11:20:22.860514 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.154044 (* 1 = 0.154044 loss)
I1018 11:20:22.860518 11069 solver.cpp:571] Iteration 23620, lr = 0.001
I1018 11:20:30.547461 11069 solver.cpp:242] Iteration 23640, loss = 0.32627
I1018 11:20:30.547487 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0752308 (* 1 = 0.0752308 loss)
I1018 11:20:30.547492 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.25104 (* 1 = 0.25104 loss)
I1018 11:20:30.547495 11069 solver.cpp:571] Iteration 23640, lr = 0.001
I1018 11:20:38.084543 11069 solver.cpp:242] Iteration 23660, loss = 1.37126
I1018 11:20:38.084570 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.352752 (* 1 = 0.352752 loss)
I1018 11:20:38.084575 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.01851 (* 1 = 1.01851 loss)
I1018 11:20:38.084579 11069 solver.cpp:571] Iteration 23660, lr = 0.001
I1018 11:20:45.696904 11069 solver.cpp:242] Iteration 23680, loss = 0.281581
I1018 11:20:45.696930 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0854417 (* 1 = 0.0854417 loss)
I1018 11:20:45.696935 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.196139 (* 1 = 0.196139 loss)
I1018 11:20:45.696939 11069 solver.cpp:571] Iteration 23680, lr = 0.001
I1018 11:20:53.306898 11069 solver.cpp:242] Iteration 23700, loss = 0.214699
I1018 11:20:53.306924 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0679384 (* 1 = 0.0679384 loss)
I1018 11:20:53.306929 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.14676 (* 1 = 0.14676 loss)
I1018 11:20:53.306934 11069 solver.cpp:571] Iteration 23700, lr = 0.001
I1018 11:21:00.879238 11069 solver.cpp:242] Iteration 23720, loss = 0.308905
I1018 11:21:00.879264 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0799488 (* 1 = 0.0799488 loss)
I1018 11:21:00.879269 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.228956 (* 1 = 0.228956 loss)
I1018 11:21:00.879274 11069 solver.cpp:571] Iteration 23720, lr = 0.001
I1018 11:21:08.466064 11069 solver.cpp:242] Iteration 23740, loss = 0.194228
I1018 11:21:08.466091 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.037316 (* 1 = 0.037316 loss)
I1018 11:21:08.466096 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.156912 (* 1 = 0.156912 loss)
I1018 11:21:08.466100 11069 solver.cpp:571] Iteration 23740, lr = 0.001
I1018 11:21:16.118721 11069 solver.cpp:242] Iteration 23760, loss = 0.589086
I1018 11:21:16.118746 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.19582 (* 1 = 0.19582 loss)
I1018 11:21:16.118752 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.393266 (* 1 = 0.393266 loss)
I1018 11:21:16.118757 11069 solver.cpp:571] Iteration 23760, lr = 0.001
I1018 11:21:23.759871 11069 solver.cpp:242] Iteration 23780, loss = 0.228286
I1018 11:21:23.759897 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0389469 (* 1 = 0.0389469 loss)
I1018 11:21:23.759902 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189339 (* 1 = 0.189339 loss)
I1018 11:21:23.759907 11069 solver.cpp:571] Iteration 23780, lr = 0.001
speed: 0.378s / iter
I1018 11:21:31.329566 11069 solver.cpp:242] Iteration 23800, loss = 0.689952
I1018 11:21:31.329591 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210459 (* 1 = 0.210459 loss)
I1018 11:21:31.329596 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.479493 (* 1 = 0.479493 loss)
I1018 11:21:31.329601 11069 solver.cpp:571] Iteration 23800, lr = 0.001
I1018 11:21:38.929265 11069 solver.cpp:242] Iteration 23820, loss = 0.196431
I1018 11:21:38.929292 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0455127 (* 1 = 0.0455127 loss)
I1018 11:21:38.929297 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.150919 (* 1 = 0.150919 loss)
I1018 11:21:38.929301 11069 solver.cpp:571] Iteration 23820, lr = 0.001
I1018 11:21:46.610833 11069 solver.cpp:242] Iteration 23840, loss = 0.233481
I1018 11:21:46.610859 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0707889 (* 1 = 0.0707889 loss)
I1018 11:21:46.610864 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.162692 (* 1 = 0.162692 loss)
I1018 11:21:46.610869 11069 solver.cpp:571] Iteration 23840, lr = 0.001
I1018 11:21:54.222223 11069 solver.cpp:242] Iteration 23860, loss = 0.450185
I1018 11:21:54.222249 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170386 (* 1 = 0.170386 loss)
I1018 11:21:54.222254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.279798 (* 1 = 0.279798 loss)
I1018 11:21:54.222259 11069 solver.cpp:571] Iteration 23860, lr = 0.001
I1018 11:22:01.669661 11069 solver.cpp:242] Iteration 23880, loss = 1.29414
I1018 11:22:01.669685 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.417154 (* 1 = 0.417154 loss)
I1018 11:22:01.669690 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.876986 (* 1 = 0.876986 loss)
I1018 11:22:01.669694 11069 solver.cpp:571] Iteration 23880, lr = 0.001
I1018 11:22:09.319631 11069 solver.cpp:242] Iteration 23900, loss = 0.709879
I1018 11:22:09.319658 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.187427 (* 1 = 0.187427 loss)
I1018 11:22:09.319663 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.522452 (* 1 = 0.522452 loss)
I1018 11:22:09.319666 11069 solver.cpp:571] Iteration 23900, lr = 0.001
I1018 11:22:16.961112 11069 solver.cpp:242] Iteration 23920, loss = 0.320058
I1018 11:22:16.961138 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.101214 (* 1 = 0.101214 loss)
I1018 11:22:16.961143 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218843 (* 1 = 0.218843 loss)
I1018 11:22:16.961148 11069 solver.cpp:571] Iteration 23920, lr = 0.001
I1018 11:22:24.650355 11069 solver.cpp:242] Iteration 23940, loss = 0.754879
I1018 11:22:24.650382 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210887 (* 1 = 0.210887 loss)
I1018 11:22:24.650387 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.543991 (* 1 = 0.543991 loss)
I1018 11:22:24.650391 11069 solver.cpp:571] Iteration 23940, lr = 0.001
I1018 11:22:32.307225 11069 solver.cpp:242] Iteration 23960, loss = 0.342358
I1018 11:22:32.307251 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.093743 (* 1 = 0.093743 loss)
I1018 11:22:32.307256 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.248614 (* 1 = 0.248614 loss)
I1018 11:22:32.307260 11069 solver.cpp:571] Iteration 23960, lr = 0.001
I1018 11:22:39.786674 11069 solver.cpp:242] Iteration 23980, loss = 0.444532
I1018 11:22:39.786700 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.189364 (* 1 = 0.189364 loss)
I1018 11:22:39.786705 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.255168 (* 1 = 0.255168 loss)
I1018 11:22:39.786708 11069 solver.cpp:571] Iteration 23980, lr = 0.001
speed: 0.378s / iter
I1018 11:22:47.447908 11069 solver.cpp:242] Iteration 24000, loss = 1.11992
I1018 11:22:47.447933 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.419425 (* 1 = 0.419425 loss)
I1018 11:22:47.447939 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.700496 (* 1 = 0.700496 loss)
I1018 11:22:47.447943 11069 solver.cpp:571] Iteration 24000, lr = 0.001
I1018 11:22:55.095295 11069 solver.cpp:242] Iteration 24020, loss = 0.787182
I1018 11:22:55.095325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.265423 (* 1 = 0.265423 loss)
I1018 11:22:55.095330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.521759 (* 1 = 0.521759 loss)
I1018 11:22:55.095335 11069 solver.cpp:571] Iteration 24020, lr = 0.001
I1018 11:23:02.641785 11069 solver.cpp:242] Iteration 24040, loss = 0.708961
I1018 11:23:02.641813 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.209713 (* 1 = 0.209713 loss)
I1018 11:23:02.641818 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.499248 (* 1 = 0.499248 loss)
I1018 11:23:02.641821 11069 solver.cpp:571] Iteration 24040, lr = 0.001
I1018 11:23:10.349010 11069 solver.cpp:242] Iteration 24060, loss = 0.555049
I1018 11:23:10.349035 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168134 (* 1 = 0.168134 loss)
I1018 11:23:10.349040 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.386914 (* 1 = 0.386914 loss)
I1018 11:23:10.349045 11069 solver.cpp:571] Iteration 24060, lr = 0.001
I1018 11:23:17.910199 11069 solver.cpp:242] Iteration 24080, loss = 0.491361
I1018 11:23:17.910224 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158627 (* 1 = 0.158627 loss)
I1018 11:23:17.910229 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.332734 (* 1 = 0.332734 loss)
I1018 11:23:17.910233 11069 solver.cpp:571] Iteration 24080, lr = 0.001
I1018 11:23:25.606264 11069 solver.cpp:242] Iteration 24100, loss = 0.246467
I1018 11:23:25.606290 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0689494 (* 1 = 0.0689494 loss)
I1018 11:23:25.606295 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177517 (* 1 = 0.177517 loss)
I1018 11:23:25.606299 11069 solver.cpp:571] Iteration 24100, lr = 0.001
I1018 11:23:33.244519 11069 solver.cpp:242] Iteration 24120, loss = 0.413733
I1018 11:23:33.244545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0993134 (* 1 = 0.0993134 loss)
I1018 11:23:33.244550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.314419 (* 1 = 0.314419 loss)
I1018 11:23:33.244554 11069 solver.cpp:571] Iteration 24120, lr = 0.001
I1018 11:23:40.807824 11069 solver.cpp:242] Iteration 24140, loss = 0.982041
I1018 11:23:40.807850 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.347474 (* 1 = 0.347474 loss)
I1018 11:23:40.807854 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.634567 (* 1 = 0.634567 loss)
I1018 11:23:40.807859 11069 solver.cpp:571] Iteration 24140, lr = 0.001
I1018 11:23:48.398902 11069 solver.cpp:242] Iteration 24160, loss = 0.13559
I1018 11:23:48.398928 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0388254 (* 1 = 0.0388254 loss)
I1018 11:23:48.398933 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0967644 (* 1 = 0.0967644 loss)
I1018 11:23:48.398938 11069 solver.cpp:571] Iteration 24160, lr = 0.001
I1018 11:23:56.155875 11069 solver.cpp:242] Iteration 24180, loss = 0.257156
I1018 11:23:56.155901 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0681061 (* 1 = 0.0681061 loss)
I1018 11:23:56.155907 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18905 (* 1 = 0.18905 loss)
I1018 11:23:56.155911 11069 solver.cpp:571] Iteration 24180, lr = 0.001
speed: 0.378s / iter
I1018 11:24:03.777541 11069 solver.cpp:242] Iteration 24200, loss = 1.09661
I1018 11:24:03.777566 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.365701 (* 1 = 0.365701 loss)
I1018 11:24:03.777570 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.730911 (* 1 = 0.730911 loss)
I1018 11:24:03.777575 11069 solver.cpp:571] Iteration 24200, lr = 0.001
I1018 11:24:11.426447 11069 solver.cpp:242] Iteration 24220, loss = 0.399661
I1018 11:24:11.426472 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139868 (* 1 = 0.139868 loss)
I1018 11:24:11.426477 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259793 (* 1 = 0.259793 loss)
I1018 11:24:11.426481 11069 solver.cpp:571] Iteration 24220, lr = 0.001
I1018 11:24:19.054111 11069 solver.cpp:242] Iteration 24240, loss = 0.724662
I1018 11:24:19.054136 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.288996 (* 1 = 0.288996 loss)
I1018 11:24:19.054141 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.435666 (* 1 = 0.435666 loss)
I1018 11:24:19.054146 11069 solver.cpp:571] Iteration 24240, lr = 0.001
I1018 11:24:26.568132 11069 solver.cpp:242] Iteration 24260, loss = 0.281538
I1018 11:24:26.568158 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0967681 (* 1 = 0.0967681 loss)
I1018 11:24:26.568163 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18477 (* 1 = 0.18477 loss)
I1018 11:24:26.568167 11069 solver.cpp:571] Iteration 24260, lr = 0.001
I1018 11:24:34.253110 11069 solver.cpp:242] Iteration 24280, loss = 0.0630099
I1018 11:24:34.253137 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0373717 (* 1 = 0.0373717 loss)
I1018 11:24:34.253142 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0256382 (* 1 = 0.0256382 loss)
I1018 11:24:34.253147 11069 solver.cpp:571] Iteration 24280, lr = 0.001
I1018 11:24:41.910118 11069 solver.cpp:242] Iteration 24300, loss = 1.20239
I1018 11:24:41.910145 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.425753 (* 1 = 0.425753 loss)
I1018 11:24:41.910151 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.776635 (* 1 = 0.776635 loss)
I1018 11:24:41.910154 11069 solver.cpp:571] Iteration 24300, lr = 0.001
I1018 11:24:49.492135 11069 solver.cpp:242] Iteration 24320, loss = 0.243569
I1018 11:24:49.492161 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0947401 (* 1 = 0.0947401 loss)
I1018 11:24:49.492166 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148829 (* 1 = 0.148829 loss)
I1018 11:24:49.492171 11069 solver.cpp:571] Iteration 24320, lr = 0.001
I1018 11:24:57.082326 11069 solver.cpp:242] Iteration 24340, loss = 0.389191
I1018 11:24:57.082352 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0994229 (* 1 = 0.0994229 loss)
I1018 11:24:57.082357 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.289768 (* 1 = 0.289768 loss)
I1018 11:24:57.082361 11069 solver.cpp:571] Iteration 24340, lr = 0.001
I1018 11:25:04.682763 11069 solver.cpp:242] Iteration 24360, loss = 0.1462
I1018 11:25:04.682790 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0289746 (* 1 = 0.0289746 loss)
I1018 11:25:04.682796 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.117225 (* 1 = 0.117225 loss)
I1018 11:25:04.682801 11069 solver.cpp:571] Iteration 24360, lr = 0.001
I1018 11:25:12.287802 11069 solver.cpp:242] Iteration 24380, loss = 0.189153
I1018 11:25:12.287828 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.034614 (* 1 = 0.034614 loss)
I1018 11:25:12.287833 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.154539 (* 1 = 0.154539 loss)
I1018 11:25:12.287838 11069 solver.cpp:571] Iteration 24380, lr = 0.001
speed: 0.378s / iter
I1018 11:25:19.936879 11069 solver.cpp:242] Iteration 24400, loss = 0.831043
I1018 11:25:19.936905 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203712 (* 1 = 0.203712 loss)
I1018 11:25:19.936910 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.627331 (* 1 = 0.627331 loss)
I1018 11:25:19.936914 11069 solver.cpp:571] Iteration 24400, lr = 0.001
I1018 11:25:27.573052 11069 solver.cpp:242] Iteration 24420, loss = 2.04546
I1018 11:25:27.573078 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.962224 (* 1 = 0.962224 loss)
I1018 11:25:27.573083 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.08324 (* 1 = 1.08324 loss)
I1018 11:25:27.573088 11069 solver.cpp:571] Iteration 24420, lr = 0.001
I1018 11:25:35.230204 11069 solver.cpp:242] Iteration 24440, loss = 0.998913
I1018 11:25:35.230231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.266567 (* 1 = 0.266567 loss)
I1018 11:25:35.230235 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.732345 (* 1 = 0.732345 loss)
I1018 11:25:35.230239 11069 solver.cpp:571] Iteration 24440, lr = 0.001
I1018 11:25:42.816675 11069 solver.cpp:242] Iteration 24460, loss = 0.388437
I1018 11:25:42.816701 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164892 (* 1 = 0.164892 loss)
I1018 11:25:42.816706 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.223545 (* 1 = 0.223545 loss)
I1018 11:25:42.816710 11069 solver.cpp:571] Iteration 24460, lr = 0.001
I1018 11:25:50.387217 11069 solver.cpp:242] Iteration 24480, loss = 1.12105
I1018 11:25:50.387243 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.326387 (* 1 = 0.326387 loss)
I1018 11:25:50.387248 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.794661 (* 1 = 0.794661 loss)
I1018 11:25:50.387253 11069 solver.cpp:571] Iteration 24480, lr = 0.001
I1018 11:25:58.070966 11069 solver.cpp:242] Iteration 24500, loss = 0.181696
I1018 11:25:58.070994 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0454575 (* 1 = 0.0454575 loss)
I1018 11:25:58.070999 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136238 (* 1 = 0.136238 loss)
I1018 11:25:58.071003 11069 solver.cpp:571] Iteration 24500, lr = 0.001
I1018 11:26:05.622179 11069 solver.cpp:242] Iteration 24520, loss = 0.260262
I1018 11:26:05.622206 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0754425 (* 1 = 0.0754425 loss)
I1018 11:26:05.622211 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18482 (* 1 = 0.18482 loss)
I1018 11:26:05.622215 11069 solver.cpp:571] Iteration 24520, lr = 0.001
I1018 11:26:13.294701 11069 solver.cpp:242] Iteration 24540, loss = 0.664842
I1018 11:26:13.294728 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.118626 (* 1 = 0.118626 loss)
I1018 11:26:13.294733 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.546216 (* 1 = 0.546216 loss)
I1018 11:26:13.294736 11069 solver.cpp:571] Iteration 24540, lr = 0.001
I1018 11:26:20.935410 11069 solver.cpp:242] Iteration 24560, loss = 0.332753
I1018 11:26:20.935434 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0988285 (* 1 = 0.0988285 loss)
I1018 11:26:20.935439 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.233924 (* 1 = 0.233924 loss)
I1018 11:26:20.935444 11069 solver.cpp:571] Iteration 24560, lr = 0.001
I1018 11:26:28.651028 11069 solver.cpp:242] Iteration 24580, loss = 0.291263
I1018 11:26:28.651053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0733054 (* 1 = 0.0733054 loss)
I1018 11:26:28.651058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.217957 (* 1 = 0.217957 loss)
I1018 11:26:28.651063 11069 solver.cpp:571] Iteration 24580, lr = 0.001
speed: 0.378s / iter
I1018 11:26:36.305387 11069 solver.cpp:242] Iteration 24600, loss = 0.797096
I1018 11:26:36.305413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.279193 (* 1 = 0.279193 loss)
I1018 11:26:36.305418 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.517904 (* 1 = 0.517904 loss)
I1018 11:26:36.305421 11069 solver.cpp:571] Iteration 24600, lr = 0.001
I1018 11:26:43.853721 11069 solver.cpp:242] Iteration 24620, loss = 0.689853
I1018 11:26:43.853747 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.197623 (* 1 = 0.197623 loss)
I1018 11:26:43.853752 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.49223 (* 1 = 0.49223 loss)
I1018 11:26:43.853757 11069 solver.cpp:571] Iteration 24620, lr = 0.001
I1018 11:26:51.470564 11069 solver.cpp:242] Iteration 24640, loss = 0.403702
I1018 11:26:51.470590 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.109447 (* 1 = 0.109447 loss)
I1018 11:26:51.470595 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.294255 (* 1 = 0.294255 loss)
I1018 11:26:51.470599 11069 solver.cpp:571] Iteration 24640, lr = 0.001
I1018 11:26:59.102207 11069 solver.cpp:242] Iteration 24660, loss = 0.450058
I1018 11:26:59.102233 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.160836 (* 1 = 0.160836 loss)
I1018 11:26:59.102238 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.289222 (* 1 = 0.289222 loss)
I1018 11:26:59.102243 11069 solver.cpp:571] Iteration 24660, lr = 0.001
I1018 11:27:06.791903 11069 solver.cpp:242] Iteration 24680, loss = 1.1816
I1018 11:27:06.791929 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.376244 (* 1 = 0.376244 loss)
I1018 11:27:06.791934 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.805357 (* 1 = 0.805357 loss)
I1018 11:27:06.791939 11069 solver.cpp:571] Iteration 24680, lr = 0.001
I1018 11:27:14.403589 11069 solver.cpp:242] Iteration 24700, loss = 0.22507
I1018 11:27:14.403615 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0696164 (* 1 = 0.0696164 loss)
I1018 11:27:14.403620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.155454 (* 1 = 0.155454 loss)
I1018 11:27:14.403625 11069 solver.cpp:571] Iteration 24700, lr = 0.001
I1018 11:27:22.062314 11069 solver.cpp:242] Iteration 24720, loss = 0.314713
I1018 11:27:22.062340 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0606576 (* 1 = 0.0606576 loss)
I1018 11:27:22.062345 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254055 (* 1 = 0.254055 loss)
I1018 11:27:22.062350 11069 solver.cpp:571] Iteration 24720, lr = 0.001
I1018 11:27:29.684377 11069 solver.cpp:242] Iteration 24740, loss = 0.39891
I1018 11:27:29.684403 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159567 (* 1 = 0.159567 loss)
I1018 11:27:29.684408 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.239343 (* 1 = 0.239343 loss)
I1018 11:27:29.684413 11069 solver.cpp:571] Iteration 24740, lr = 0.001
I1018 11:27:37.294463 11069 solver.cpp:242] Iteration 24760, loss = 1.43398
I1018 11:27:37.294489 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.694405 (* 1 = 0.694405 loss)
I1018 11:27:37.294494 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.73958 (* 1 = 0.73958 loss)
I1018 11:27:37.294498 11069 solver.cpp:571] Iteration 24760, lr = 0.001
I1018 11:27:44.926795 11069 solver.cpp:242] Iteration 24780, loss = 0.28253
I1018 11:27:44.926820 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0646805 (* 1 = 0.0646805 loss)
I1018 11:27:44.926825 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21785 (* 1 = 0.21785 loss)
I1018 11:27:44.926828 11069 solver.cpp:571] Iteration 24780, lr = 0.001
speed: 0.378s / iter
I1018 11:27:52.531707 11069 solver.cpp:242] Iteration 24800, loss = 0.214692
I1018 11:27:52.531733 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.055957 (* 1 = 0.055957 loss)
I1018 11:27:52.531738 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.158735 (* 1 = 0.158735 loss)
I1018 11:27:52.531743 11069 solver.cpp:571] Iteration 24800, lr = 0.001
I1018 11:28:00.198130 11069 solver.cpp:242] Iteration 24820, loss = 0.168336
I1018 11:28:00.198153 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.037145 (* 1 = 0.037145 loss)
I1018 11:28:00.198158 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131191 (* 1 = 0.131191 loss)
I1018 11:28:00.198163 11069 solver.cpp:571] Iteration 24820, lr = 0.001
I1018 11:28:07.847751 11069 solver.cpp:242] Iteration 24840, loss = 0.213714
I1018 11:28:07.847777 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0797761 (* 1 = 0.0797761 loss)
I1018 11:28:07.847782 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133938 (* 1 = 0.133938 loss)
I1018 11:28:07.847797 11069 solver.cpp:571] Iteration 24840, lr = 0.001
I1018 11:28:15.415105 11069 solver.cpp:242] Iteration 24860, loss = 0.493105
I1018 11:28:15.415132 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123731 (* 1 = 0.123731 loss)
I1018 11:28:15.415138 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.369374 (* 1 = 0.369374 loss)
I1018 11:28:15.415143 11069 solver.cpp:571] Iteration 24860, lr = 0.001
I1018 11:28:23.014561 11069 solver.cpp:242] Iteration 24880, loss = 0.442212
I1018 11:28:23.014587 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0906781 (* 1 = 0.0906781 loss)
I1018 11:28:23.014592 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.351533 (* 1 = 0.351533 loss)
I1018 11:28:23.014597 11069 solver.cpp:571] Iteration 24880, lr = 0.001
I1018 11:28:30.653862 11069 solver.cpp:242] Iteration 24900, loss = 0.170019
I1018 11:28:30.653889 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0262783 (* 1 = 0.0262783 loss)
I1018 11:28:30.653894 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.14374 (* 1 = 0.14374 loss)
I1018 11:28:30.653898 11069 solver.cpp:571] Iteration 24900, lr = 0.001
I1018 11:28:38.238134 11069 solver.cpp:242] Iteration 24920, loss = 0.262585
I1018 11:28:38.238159 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704839 (* 1 = 0.0704839 loss)
I1018 11:28:38.238165 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.192101 (* 1 = 0.192101 loss)
I1018 11:28:38.238169 11069 solver.cpp:571] Iteration 24920, lr = 0.001
I1018 11:28:45.906519 11069 solver.cpp:242] Iteration 24940, loss = 0.248089
I1018 11:28:45.906545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0584581 (* 1 = 0.0584581 loss)
I1018 11:28:45.906550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189631 (* 1 = 0.189631 loss)
I1018 11:28:45.906554 11069 solver.cpp:571] Iteration 24940, lr = 0.001
I1018 11:28:53.516559 11069 solver.cpp:242] Iteration 24960, loss = 0.350138
I1018 11:28:53.516585 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.155245 (* 1 = 0.155245 loss)
I1018 11:28:53.516590 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194893 (* 1 = 0.194893 loss)
I1018 11:28:53.516595 11069 solver.cpp:571] Iteration 24960, lr = 0.001
I1018 11:29:01.142938 11069 solver.cpp:242] Iteration 24980, loss = 1.19242
I1018 11:29:01.142966 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.560622 (* 1 = 0.560622 loss)
I1018 11:29:01.142971 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.631794 (* 1 = 0.631794 loss)
I1018 11:29:01.142976 11069 solver.cpp:571] Iteration 24980, lr = 0.001
speed: 0.378s / iter
I1018 11:29:08.280261 11069 solver.cpp:242] Iteration 25000, loss = 0.423746
I1018 11:29:08.280287 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.169621 (* 1 = 0.169621 loss)
I1018 11:29:08.280292 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254125 (* 1 = 0.254125 loss)
I1018 11:29:08.280297 11069 solver.cpp:571] Iteration 25000, lr = 0.001
I1018 11:29:15.114926 11069 solver.cpp:242] Iteration 25020, loss = 0.324361
I1018 11:29:15.114951 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0752069 (* 1 = 0.0752069 loss)
I1018 11:29:15.114956 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249154 (* 1 = 0.249154 loss)
I1018 11:29:15.114960 11069 solver.cpp:571] Iteration 25020, lr = 0.001
I1018 11:29:22.023466 11069 solver.cpp:242] Iteration 25040, loss = 1.1818
I1018 11:29:22.023494 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.467872 (* 1 = 0.467872 loss)
I1018 11:29:22.023497 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.713928 (* 1 = 0.713928 loss)
I1018 11:29:22.023502 11069 solver.cpp:571] Iteration 25040, lr = 0.001
I1018 11:29:29.136946 11069 solver.cpp:242] Iteration 25060, loss = 0.472848
I1018 11:29:29.136971 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203822 (* 1 = 0.203822 loss)
I1018 11:29:29.136976 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269026 (* 1 = 0.269026 loss)
I1018 11:29:29.136981 11069 solver.cpp:571] Iteration 25060, lr = 0.001
I1018 11:29:36.397570 11069 solver.cpp:242] Iteration 25080, loss = 0.161296
I1018 11:29:36.397596 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0257404 (* 1 = 0.0257404 loss)
I1018 11:29:36.397600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.135556 (* 1 = 0.135556 loss)
I1018 11:29:36.397604 11069 solver.cpp:571] Iteration 25080, lr = 0.001
I1018 11:29:44.079509 11069 solver.cpp:242] Iteration 25100, loss = 0.401142
I1018 11:29:44.079535 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0986926 (* 1 = 0.0986926 loss)
I1018 11:29:44.079540 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.30245 (* 1 = 0.30245 loss)
I1018 11:29:44.079545 11069 solver.cpp:571] Iteration 25100, lr = 0.001
I1018 11:29:51.726917 11069 solver.cpp:242] Iteration 25120, loss = 0.3318
I1018 11:29:51.726943 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135904 (* 1 = 0.135904 loss)
I1018 11:29:51.726948 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195896 (* 1 = 0.195896 loss)
I1018 11:29:51.726951 11069 solver.cpp:571] Iteration 25120, lr = 0.001
I1018 11:29:59.407799 11069 solver.cpp:242] Iteration 25140, loss = 0.257073
I1018 11:29:59.407825 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0798197 (* 1 = 0.0798197 loss)
I1018 11:29:59.407830 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177254 (* 1 = 0.177254 loss)
I1018 11:29:59.407835 11069 solver.cpp:571] Iteration 25140, lr = 0.001
I1018 11:30:07.064484 11069 solver.cpp:242] Iteration 25160, loss = 0.65491
I1018 11:30:07.064509 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.204418 (* 1 = 0.204418 loss)
I1018 11:30:07.064514 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.450491 (* 1 = 0.450491 loss)
I1018 11:30:07.064519 11069 solver.cpp:571] Iteration 25160, lr = 0.001
I1018 11:30:14.707274 11069 solver.cpp:242] Iteration 25180, loss = 0.949882
I1018 11:30:14.707311 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.277608 (* 1 = 0.277608 loss)
I1018 11:30:14.707319 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.672275 (* 1 = 0.672275 loss)
I1018 11:30:14.707335 11069 solver.cpp:571] Iteration 25180, lr = 0.001
speed: 0.378s / iter
I1018 11:30:22.293905 11069 solver.cpp:242] Iteration 25200, loss = 0.292657
I1018 11:30:22.293931 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0537966 (* 1 = 0.0537966 loss)
I1018 11:30:22.293936 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.23886 (* 1 = 0.23886 loss)
I1018 11:30:22.293941 11069 solver.cpp:571] Iteration 25200, lr = 0.001
I1018 11:30:29.974262 11069 solver.cpp:242] Iteration 25220, loss = 0.205983
I1018 11:30:29.974287 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0527562 (* 1 = 0.0527562 loss)
I1018 11:30:29.974293 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.153227 (* 1 = 0.153227 loss)
I1018 11:30:29.974298 11069 solver.cpp:571] Iteration 25220, lr = 0.001
I1018 11:30:37.553210 11069 solver.cpp:242] Iteration 25240, loss = 0.293612
I1018 11:30:37.553236 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.118514 (* 1 = 0.118514 loss)
I1018 11:30:37.553241 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.175098 (* 1 = 0.175098 loss)
I1018 11:30:37.553244 11069 solver.cpp:571] Iteration 25240, lr = 0.001
I1018 11:30:45.216995 11069 solver.cpp:242] Iteration 25260, loss = 0.376099
I1018 11:30:45.217021 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116298 (* 1 = 0.116298 loss)
I1018 11:30:45.217026 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259801 (* 1 = 0.259801 loss)
I1018 11:30:45.217031 11069 solver.cpp:571] Iteration 25260, lr = 0.001
I1018 11:30:52.866165 11069 solver.cpp:242] Iteration 25280, loss = 0.789646
I1018 11:30:52.866191 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.230492 (* 1 = 0.230492 loss)
I1018 11:30:52.866196 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.559154 (* 1 = 0.559154 loss)
I1018 11:30:52.866201 11069 solver.cpp:571] Iteration 25280, lr = 0.001
I1018 11:31:00.525867 11069 solver.cpp:242] Iteration 25300, loss = 0.305965
I1018 11:31:00.525893 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108846 (* 1 = 0.108846 loss)
I1018 11:31:00.525899 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197119 (* 1 = 0.197119 loss)
I1018 11:31:00.525903 11069 solver.cpp:571] Iteration 25300, lr = 0.001
I1018 11:31:08.258296 11069 solver.cpp:242] Iteration 25320, loss = 0.2321
I1018 11:31:08.258322 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0951429 (* 1 = 0.0951429 loss)
I1018 11:31:08.258327 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136957 (* 1 = 0.136957 loss)
I1018 11:31:08.258332 11069 solver.cpp:571] Iteration 25320, lr = 0.001
I1018 11:31:15.886065 11069 solver.cpp:242] Iteration 25340, loss = 0.312024
I1018 11:31:15.886090 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0469987 (* 1 = 0.0469987 loss)
I1018 11:31:15.886096 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265025 (* 1 = 0.265025 loss)
I1018 11:31:15.886099 11069 solver.cpp:571] Iteration 25340, lr = 0.001
I1018 11:31:23.521395 11069 solver.cpp:242] Iteration 25360, loss = 0.541978
I1018 11:31:23.521421 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0954318 (* 1 = 0.0954318 loss)
I1018 11:31:23.521426 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.446546 (* 1 = 0.446546 loss)
I1018 11:31:23.521430 11069 solver.cpp:571] Iteration 25360, lr = 0.001
I1018 11:31:31.169723 11069 solver.cpp:242] Iteration 25380, loss = 0.544402
I1018 11:31:31.169750 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181683 (* 1 = 0.181683 loss)
I1018 11:31:31.169755 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.36272 (* 1 = 0.36272 loss)
I1018 11:31:31.169760 11069 solver.cpp:571] Iteration 25380, lr = 0.001
speed: 0.378s / iter
I1018 11:31:38.692359 11069 solver.cpp:242] Iteration 25400, loss = 0.451323
I1018 11:31:38.692386 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0657345 (* 1 = 0.0657345 loss)
I1018 11:31:38.692391 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.385589 (* 1 = 0.385589 loss)
I1018 11:31:38.692395 11069 solver.cpp:571] Iteration 25400, lr = 0.001
I1018 11:31:46.338850 11069 solver.cpp:242] Iteration 25420, loss = 0.352866
I1018 11:31:46.338876 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0563945 (* 1 = 0.0563945 loss)
I1018 11:31:46.338881 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296471 (* 1 = 0.296471 loss)
I1018 11:31:46.338886 11069 solver.cpp:571] Iteration 25420, lr = 0.001
I1018 11:31:53.936987 11069 solver.cpp:242] Iteration 25440, loss = 0.343755
I1018 11:31:53.937013 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100127 (* 1 = 0.100127 loss)
I1018 11:31:53.937018 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.243628 (* 1 = 0.243628 loss)
I1018 11:31:53.937022 11069 solver.cpp:571] Iteration 25440, lr = 0.001
I1018 11:32:01.573545 11069 solver.cpp:242] Iteration 25460, loss = 0.51794
I1018 11:32:01.573570 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.187045 (* 1 = 0.187045 loss)
I1018 11:32:01.573575 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.330895 (* 1 = 0.330895 loss)
I1018 11:32:01.573578 11069 solver.cpp:571] Iteration 25460, lr = 0.001
I1018 11:32:09.207857 11069 solver.cpp:242] Iteration 25480, loss = 0.239095
I1018 11:32:09.207885 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0514616 (* 1 = 0.0514616 loss)
I1018 11:32:09.207890 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.187634 (* 1 = 0.187634 loss)
I1018 11:32:09.207895 11069 solver.cpp:571] Iteration 25480, lr = 0.001
I1018 11:32:16.964033 11069 solver.cpp:242] Iteration 25500, loss = 0.227018
I1018 11:32:16.964059 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0461676 (* 1 = 0.0461676 loss)
I1018 11:32:16.964064 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18085 (* 1 = 0.18085 loss)
I1018 11:32:16.964068 11069 solver.cpp:571] Iteration 25500, lr = 0.001
I1018 11:32:24.569818 11069 solver.cpp:242] Iteration 25520, loss = 0.399041
I1018 11:32:24.569844 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139302 (* 1 = 0.139302 loss)
I1018 11:32:24.569849 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259738 (* 1 = 0.259738 loss)
I1018 11:32:24.569854 11069 solver.cpp:571] Iteration 25520, lr = 0.001
I1018 11:32:32.182554 11069 solver.cpp:242] Iteration 25540, loss = 0.21748
I1018 11:32:32.182580 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0482897 (* 1 = 0.0482897 loss)
I1018 11:32:32.182585 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.169191 (* 1 = 0.169191 loss)
I1018 11:32:32.182590 11069 solver.cpp:571] Iteration 25540, lr = 0.001
I1018 11:32:39.939113 11069 solver.cpp:242] Iteration 25560, loss = 1.23512
I1018 11:32:39.939138 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.528445 (* 1 = 0.528445 loss)
I1018 11:32:39.939143 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.706679 (* 1 = 0.706679 loss)
I1018 11:32:39.939147 11069 solver.cpp:571] Iteration 25560, lr = 0.001
I1018 11:32:47.516134 11069 solver.cpp:242] Iteration 25580, loss = 0.0522754
I1018 11:32:47.516160 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0127717 (* 1 = 0.0127717 loss)
I1018 11:32:47.516165 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0395037 (* 1 = 0.0395037 loss)
I1018 11:32:47.516170 11069 solver.cpp:571] Iteration 25580, lr = 0.001
speed: 0.378s / iter
I1018 11:32:55.042606 11069 solver.cpp:242] Iteration 25600, loss = 0.588119
I1018 11:32:55.042632 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.129738 (* 1 = 0.129738 loss)
I1018 11:32:55.042637 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.458381 (* 1 = 0.458381 loss)
I1018 11:32:55.042642 11069 solver.cpp:571] Iteration 25600, lr = 0.001
I1018 11:33:02.707460 11069 solver.cpp:242] Iteration 25620, loss = 0.266837
I1018 11:33:02.707486 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0481413 (* 1 = 0.0481413 loss)
I1018 11:33:02.707491 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218696 (* 1 = 0.218696 loss)
I1018 11:33:02.707496 11069 solver.cpp:571] Iteration 25620, lr = 0.001
I1018 11:33:10.287822 11069 solver.cpp:242] Iteration 25640, loss = 0.357665
I1018 11:33:10.287845 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0685207 (* 1 = 0.0685207 loss)
I1018 11:33:10.287850 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.289145 (* 1 = 0.289145 loss)
I1018 11:33:10.287854 11069 solver.cpp:571] Iteration 25640, lr = 0.001
I1018 11:33:17.943797 11069 solver.cpp:242] Iteration 25660, loss = 0.793468
I1018 11:33:17.943823 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.169332 (* 1 = 0.169332 loss)
I1018 11:33:17.943828 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.624136 (* 1 = 0.624136 loss)
I1018 11:33:17.943832 11069 solver.cpp:571] Iteration 25660, lr = 0.001
I1018 11:33:25.593873 11069 solver.cpp:242] Iteration 25680, loss = 0.82676
I1018 11:33:25.593899 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.246829 (* 1 = 0.246829 loss)
I1018 11:33:25.593904 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.579931 (* 1 = 0.579931 loss)
I1018 11:33:25.593909 11069 solver.cpp:571] Iteration 25680, lr = 0.001
I1018 11:33:33.222486 11069 solver.cpp:242] Iteration 25700, loss = 0.2035
I1018 11:33:33.222513 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0635454 (* 1 = 0.0635454 loss)
I1018 11:33:33.222517 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.139955 (* 1 = 0.139955 loss)
I1018 11:33:33.222522 11069 solver.cpp:571] Iteration 25700, lr = 0.001
I1018 11:33:40.915546 11069 solver.cpp:242] Iteration 25720, loss = 0.248841
I1018 11:33:40.915571 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0470719 (* 1 = 0.0470719 loss)
I1018 11:33:40.915575 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.201769 (* 1 = 0.201769 loss)
I1018 11:33:40.915580 11069 solver.cpp:571] Iteration 25720, lr = 0.001
I1018 11:33:48.500519 11069 solver.cpp:242] Iteration 25740, loss = 0.739918
I1018 11:33:48.500545 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.257105 (* 1 = 0.257105 loss)
I1018 11:33:48.500550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.482813 (* 1 = 0.482813 loss)
I1018 11:33:48.500555 11069 solver.cpp:571] Iteration 25740, lr = 0.001
I1018 11:33:56.125012 11069 solver.cpp:242] Iteration 25760, loss = 0.158038
I1018 11:33:56.125039 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0349322 (* 1 = 0.0349322 loss)
I1018 11:33:56.125044 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123106 (* 1 = 0.123106 loss)
I1018 11:33:56.125048 11069 solver.cpp:571] Iteration 25760, lr = 0.001
I1018 11:34:03.808143 11069 solver.cpp:242] Iteration 25780, loss = 0.327102
I1018 11:34:03.808169 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0617333 (* 1 = 0.0617333 loss)
I1018 11:34:03.808174 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265369 (* 1 = 0.265369 loss)
I1018 11:34:03.808178 11069 solver.cpp:571] Iteration 25780, lr = 0.001
speed: 0.378s / iter
I1018 11:34:11.341043 11069 solver.cpp:242] Iteration 25800, loss = 0.251742
I1018 11:34:11.341069 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0778734 (* 1 = 0.0778734 loss)
I1018 11:34:11.341074 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.173869 (* 1 = 0.173869 loss)
I1018 11:34:11.341078 11069 solver.cpp:571] Iteration 25800, lr = 0.001
I1018 11:34:18.888304 11069 solver.cpp:242] Iteration 25820, loss = 1.05738
I1018 11:34:18.888330 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.442757 (* 1 = 0.442757 loss)
I1018 11:34:18.888335 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.614627 (* 1 = 0.614627 loss)
I1018 11:34:18.888339 11069 solver.cpp:571] Iteration 25820, lr = 0.001
I1018 11:34:26.424129 11069 solver.cpp:242] Iteration 25840, loss = 0.383983
I1018 11:34:26.424155 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128354 (* 1 = 0.128354 loss)
I1018 11:34:26.424160 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.255629 (* 1 = 0.255629 loss)
I1018 11:34:26.424165 11069 solver.cpp:571] Iteration 25840, lr = 0.001
I1018 11:34:34.027894 11069 solver.cpp:242] Iteration 25860, loss = 0.675273
I1018 11:34:34.027918 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241864 (* 1 = 0.241864 loss)
I1018 11:34:34.027923 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.433409 (* 1 = 0.433409 loss)
I1018 11:34:34.027927 11069 solver.cpp:571] Iteration 25860, lr = 0.001
I1018 11:34:41.646199 11069 solver.cpp:242] Iteration 25880, loss = 1.28008
I1018 11:34:41.646225 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.56536 (* 1 = 0.56536 loss)
I1018 11:34:41.646230 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.71472 (* 1 = 0.71472 loss)
I1018 11:34:41.646234 11069 solver.cpp:571] Iteration 25880, lr = 0.001
I1018 11:34:49.161741 11069 solver.cpp:242] Iteration 25900, loss = 0.413939
I1018 11:34:49.161767 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116945 (* 1 = 0.116945 loss)
I1018 11:34:49.161772 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296994 (* 1 = 0.296994 loss)
I1018 11:34:49.161777 11069 solver.cpp:571] Iteration 25900, lr = 0.001
I1018 11:34:56.735919 11069 solver.cpp:242] Iteration 25920, loss = 0.176097
I1018 11:34:56.735945 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.037554 (* 1 = 0.037554 loss)
I1018 11:34:56.735950 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.138543 (* 1 = 0.138543 loss)
I1018 11:34:56.735955 11069 solver.cpp:571] Iteration 25920, lr = 0.001
I1018 11:35:04.505378 11069 solver.cpp:242] Iteration 25940, loss = 0.266664
I1018 11:35:04.505404 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0871005 (* 1 = 0.0871005 loss)
I1018 11:35:04.505409 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179564 (* 1 = 0.179564 loss)
I1018 11:35:04.505414 11069 solver.cpp:571] Iteration 25940, lr = 0.001
I1018 11:35:12.220204 11069 solver.cpp:242] Iteration 25960, loss = 0.45718
I1018 11:35:12.220230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137522 (* 1 = 0.137522 loss)
I1018 11:35:12.220235 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.319657 (* 1 = 0.319657 loss)
I1018 11:35:12.220239 11069 solver.cpp:571] Iteration 25960, lr = 0.001
I1018 11:35:19.843343 11069 solver.cpp:242] Iteration 25980, loss = 0.43278
I1018 11:35:19.843369 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161232 (* 1 = 0.161232 loss)
I1018 11:35:19.843374 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.271548 (* 1 = 0.271548 loss)
I1018 11:35:19.843379 11069 solver.cpp:571] Iteration 25980, lr = 0.001
speed: 0.378s / iter
I1018 11:35:27.419864 11069 solver.cpp:242] Iteration 26000, loss = 0.249689
I1018 11:35:27.419889 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0888613 (* 1 = 0.0888613 loss)
I1018 11:35:27.419894 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.160828 (* 1 = 0.160828 loss)
I1018 11:35:27.419899 11069 solver.cpp:571] Iteration 26000, lr = 0.001
I1018 11:35:35.071298 11069 solver.cpp:242] Iteration 26020, loss = 0.348416
I1018 11:35:35.071328 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0843311 (* 1 = 0.0843311 loss)
I1018 11:35:35.071334 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264084 (* 1 = 0.264084 loss)
I1018 11:35:35.071338 11069 solver.cpp:571] Iteration 26020, lr = 0.001
I1018 11:35:42.768383 11069 solver.cpp:242] Iteration 26040, loss = 1.19297
I1018 11:35:42.768409 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.549151 (* 1 = 0.549151 loss)
I1018 11:35:42.768414 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.643822 (* 1 = 0.643822 loss)
I1018 11:35:42.768417 11069 solver.cpp:571] Iteration 26040, lr = 0.001
I1018 11:35:50.455667 11069 solver.cpp:242] Iteration 26060, loss = 0.570472
I1018 11:35:50.455691 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.188915 (* 1 = 0.188915 loss)
I1018 11:35:50.455696 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.381558 (* 1 = 0.381558 loss)
I1018 11:35:50.455700 11069 solver.cpp:571] Iteration 26060, lr = 0.001
I1018 11:35:58.080778 11069 solver.cpp:242] Iteration 26080, loss = 0.168084
I1018 11:35:58.080804 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0514451 (* 1 = 0.0514451 loss)
I1018 11:35:58.080809 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116639 (* 1 = 0.116639 loss)
I1018 11:35:58.080814 11069 solver.cpp:571] Iteration 26080, lr = 0.001
I1018 11:36:05.732772 11069 solver.cpp:242] Iteration 26100, loss = 0.525172
I1018 11:36:05.732798 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177014 (* 1 = 0.177014 loss)
I1018 11:36:05.732803 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.348158 (* 1 = 0.348158 loss)
I1018 11:36:05.732807 11069 solver.cpp:571] Iteration 26100, lr = 0.001
I1018 11:36:13.339642 11069 solver.cpp:242] Iteration 26120, loss = 0.229126
I1018 11:36:13.339666 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.064243 (* 1 = 0.064243 loss)
I1018 11:36:13.339670 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.164883 (* 1 = 0.164883 loss)
I1018 11:36:13.339675 11069 solver.cpp:571] Iteration 26120, lr = 0.001
I1018 11:36:20.956542 11069 solver.cpp:242] Iteration 26140, loss = 1.52315
I1018 11:36:20.956567 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.623231 (* 1 = 0.623231 loss)
I1018 11:36:20.956571 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.899916 (* 1 = 0.899916 loss)
I1018 11:36:20.956576 11069 solver.cpp:571] Iteration 26140, lr = 0.001
I1018 11:36:28.583334 11069 solver.cpp:242] Iteration 26160, loss = 0.398138
I1018 11:36:28.583360 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.126505 (* 1 = 0.126505 loss)
I1018 11:36:28.583364 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.271632 (* 1 = 0.271632 loss)
I1018 11:36:28.583369 11069 solver.cpp:571] Iteration 26160, lr = 0.001
I1018 11:36:36.259629 11069 solver.cpp:242] Iteration 26180, loss = 0.95997
I1018 11:36:36.259654 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.337354 (* 1 = 0.337354 loss)
I1018 11:36:36.259660 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.622616 (* 1 = 0.622616 loss)
I1018 11:36:36.259663 11069 solver.cpp:571] Iteration 26180, lr = 0.001
speed: 0.378s / iter
I1018 11:36:43.750615 11069 solver.cpp:242] Iteration 26200, loss = 0.128904
I1018 11:36:43.750643 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0343426 (* 1 = 0.0343426 loss)
I1018 11:36:43.750648 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0945617 (* 1 = 0.0945617 loss)
I1018 11:36:43.750653 11069 solver.cpp:571] Iteration 26200, lr = 0.001
I1018 11:36:51.352664 11069 solver.cpp:242] Iteration 26220, loss = 0.753889
I1018 11:36:51.352690 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.162483 (* 1 = 0.162483 loss)
I1018 11:36:51.352695 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.591406 (* 1 = 0.591406 loss)
I1018 11:36:51.352699 11069 solver.cpp:571] Iteration 26220, lr = 0.001
I1018 11:36:59.016008 11069 solver.cpp:242] Iteration 26240, loss = 0.159604
I1018 11:36:59.016034 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0509685 (* 1 = 0.0509685 loss)
I1018 11:36:59.016039 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.108636 (* 1 = 0.108636 loss)
I1018 11:36:59.016044 11069 solver.cpp:571] Iteration 26240, lr = 0.001
I1018 11:37:06.719450 11069 solver.cpp:242] Iteration 26260, loss = 0.606682
I1018 11:37:06.719476 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.148705 (* 1 = 0.148705 loss)
I1018 11:37:06.719481 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.457977 (* 1 = 0.457977 loss)
I1018 11:37:06.719485 11069 solver.cpp:571] Iteration 26260, lr = 0.001
I1018 11:37:14.334708 11069 solver.cpp:242] Iteration 26280, loss = 0.151721
I1018 11:37:14.334733 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.066029 (* 1 = 0.066029 loss)
I1018 11:37:14.334738 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0856924 (* 1 = 0.0856924 loss)
I1018 11:37:14.334743 11069 solver.cpp:571] Iteration 26280, lr = 0.001
I1018 11:37:21.913733 11069 solver.cpp:242] Iteration 26300, loss = 0.692447
I1018 11:37:21.913758 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.235245 (* 1 = 0.235245 loss)
I1018 11:37:21.913763 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.457202 (* 1 = 0.457202 loss)
I1018 11:37:21.913769 11069 solver.cpp:571] Iteration 26300, lr = 0.001
I1018 11:37:29.570053 11069 solver.cpp:242] Iteration 26320, loss = 1.1491
I1018 11:37:29.570080 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.39539 (* 1 = 0.39539 loss)
I1018 11:37:29.570086 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.753712 (* 1 = 0.753712 loss)
I1018 11:37:29.570089 11069 solver.cpp:571] Iteration 26320, lr = 0.001
I1018 11:37:37.263027 11069 solver.cpp:242] Iteration 26340, loss = 0.351403
I1018 11:37:37.263053 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.118362 (* 1 = 0.118362 loss)
I1018 11:37:37.263058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.233042 (* 1 = 0.233042 loss)
I1018 11:37:37.263062 11069 solver.cpp:571] Iteration 26340, lr = 0.001
I1018 11:37:44.833518 11069 solver.cpp:242] Iteration 26360, loss = 1.6057
I1018 11:37:44.833544 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.632966 (* 1 = 0.632966 loss)
I1018 11:37:44.833550 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.972736 (* 1 = 0.972736 loss)
I1018 11:37:44.833554 11069 solver.cpp:571] Iteration 26360, lr = 0.001
I1018 11:37:52.506315 11069 solver.cpp:242] Iteration 26380, loss = 1.92613
I1018 11:37:52.506341 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.897821 (* 1 = 0.897821 loss)
I1018 11:37:52.506346 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.02831 (* 1 = 1.02831 loss)
I1018 11:37:52.506350 11069 solver.cpp:571] Iteration 26380, lr = 0.001
speed: 0.378s / iter
I1018 11:38:00.053205 11069 solver.cpp:242] Iteration 26400, loss = 0.465479
I1018 11:38:00.053230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.112699 (* 1 = 0.112699 loss)
I1018 11:38:00.053234 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35278 (* 1 = 0.35278 loss)
I1018 11:38:00.053238 11069 solver.cpp:571] Iteration 26400, lr = 0.001
I1018 11:38:07.564908 11069 solver.cpp:242] Iteration 26420, loss = 0.182779
I1018 11:38:07.564934 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0176006 (* 1 = 0.0176006 loss)
I1018 11:38:07.564937 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165178 (* 1 = 0.165178 loss)
I1018 11:38:07.564942 11069 solver.cpp:571] Iteration 26420, lr = 0.001
I1018 11:38:15.220304 11069 solver.cpp:242] Iteration 26440, loss = 0.322166
I1018 11:38:15.220329 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123763 (* 1 = 0.123763 loss)
I1018 11:38:15.220333 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.198403 (* 1 = 0.198403 loss)
I1018 11:38:15.220337 11069 solver.cpp:571] Iteration 26440, lr = 0.001
I1018 11:38:22.775164 11069 solver.cpp:242] Iteration 26460, loss = 0.213848
I1018 11:38:22.775192 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0547393 (* 1 = 0.0547393 loss)
I1018 11:38:22.775197 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159109 (* 1 = 0.159109 loss)
I1018 11:38:22.775202 11069 solver.cpp:571] Iteration 26460, lr = 0.001
I1018 11:38:30.374958 11069 solver.cpp:242] Iteration 26480, loss = 0.496724
I1018 11:38:30.374982 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.185168 (* 1 = 0.185168 loss)
I1018 11:38:30.374987 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.311555 (* 1 = 0.311555 loss)
I1018 11:38:30.374991 11069 solver.cpp:571] Iteration 26480, lr = 0.001
I1018 11:38:38.006222 11069 solver.cpp:242] Iteration 26500, loss = 0.29872
I1018 11:38:38.006248 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0609754 (* 1 = 0.0609754 loss)
I1018 11:38:38.006254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.237745 (* 1 = 0.237745 loss)
I1018 11:38:38.006258 11069 solver.cpp:571] Iteration 26500, lr = 0.001
I1018 11:38:45.632064 11069 solver.cpp:242] Iteration 26520, loss = 1.06559
I1018 11:38:45.632091 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.494516 (* 1 = 0.494516 loss)
I1018 11:38:45.632096 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.571076 (* 1 = 0.571076 loss)
I1018 11:38:45.632099 11069 solver.cpp:571] Iteration 26520, lr = 0.001
I1018 11:38:53.274211 11069 solver.cpp:242] Iteration 26540, loss = 0.189864
I1018 11:38:53.274237 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0549716 (* 1 = 0.0549716 loss)
I1018 11:38:53.274242 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.134892 (* 1 = 0.134892 loss)
I1018 11:38:53.274246 11069 solver.cpp:571] Iteration 26540, lr = 0.001
I1018 11:39:00.869658 11069 solver.cpp:242] Iteration 26560, loss = 0.963266
I1018 11:39:00.869684 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.257519 (* 1 = 0.257519 loss)
I1018 11:39:00.869689 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.705747 (* 1 = 0.705747 loss)
I1018 11:39:00.869693 11069 solver.cpp:571] Iteration 26560, lr = 0.001
I1018 11:39:08.517161 11069 solver.cpp:242] Iteration 26580, loss = 0.628755
I1018 11:39:08.517189 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.155334 (* 1 = 0.155334 loss)
I1018 11:39:08.517194 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473421 (* 1 = 0.473421 loss)
I1018 11:39:08.517199 11069 solver.cpp:571] Iteration 26580, lr = 0.001
speed: 0.378s / iter
I1018 11:39:16.116783 11069 solver.cpp:242] Iteration 26600, loss = 0.13856
I1018 11:39:16.116809 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0414791 (* 1 = 0.0414791 loss)
I1018 11:39:16.116814 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0970808 (* 1 = 0.0970808 loss)
I1018 11:39:16.116819 11069 solver.cpp:571] Iteration 26600, lr = 0.001
I1018 11:39:23.759613 11069 solver.cpp:242] Iteration 26620, loss = 0.380457
I1018 11:39:23.759639 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0752047 (* 1 = 0.0752047 loss)
I1018 11:39:23.759644 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.305252 (* 1 = 0.305252 loss)
I1018 11:39:23.759649 11069 solver.cpp:571] Iteration 26620, lr = 0.001
I1018 11:39:31.396265 11069 solver.cpp:242] Iteration 26640, loss = 1.61321
I1018 11:39:31.396289 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.585035 (* 1 = 0.585035 loss)
I1018 11:39:31.396294 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.02818 (* 1 = 1.02818 loss)
I1018 11:39:31.396298 11069 solver.cpp:571] Iteration 26640, lr = 0.001
I1018 11:39:39.036275 11069 solver.cpp:242] Iteration 26660, loss = 0.191288
I1018 11:39:39.036303 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0542988 (* 1 = 0.0542988 loss)
I1018 11:39:39.036308 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136989 (* 1 = 0.136989 loss)
I1018 11:39:39.036311 11069 solver.cpp:571] Iteration 26660, lr = 0.001
I1018 11:39:46.747362 11069 solver.cpp:242] Iteration 26680, loss = 0.659943
I1018 11:39:46.747388 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.216332 (* 1 = 0.216332 loss)
I1018 11:39:46.747392 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.443611 (* 1 = 0.443611 loss)
I1018 11:39:46.747397 11069 solver.cpp:571] Iteration 26680, lr = 0.001
I1018 11:39:54.433825 11069 solver.cpp:242] Iteration 26700, loss = 1.19045
I1018 11:39:54.433851 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.315409 (* 1 = 0.315409 loss)
I1018 11:39:54.433856 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.87504 (* 1 = 0.87504 loss)
I1018 11:39:54.433861 11069 solver.cpp:571] Iteration 26700, lr = 0.001
I1018 11:40:02.044865 11069 solver.cpp:242] Iteration 26720, loss = 0.395738
I1018 11:40:02.044891 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0923523 (* 1 = 0.0923523 loss)
I1018 11:40:02.044896 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.303385 (* 1 = 0.303385 loss)
I1018 11:40:02.044900 11069 solver.cpp:571] Iteration 26720, lr = 0.001
I1018 11:40:09.664983 11069 solver.cpp:242] Iteration 26740, loss = 0.747909
I1018 11:40:09.665009 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.165718 (* 1 = 0.165718 loss)
I1018 11:40:09.665014 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.582191 (* 1 = 0.582191 loss)
I1018 11:40:09.665019 11069 solver.cpp:571] Iteration 26740, lr = 0.001
I1018 11:40:17.304795 11069 solver.cpp:242] Iteration 26760, loss = 1.33184
I1018 11:40:17.304823 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.481918 (* 1 = 0.481918 loss)
I1018 11:40:17.304828 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.849922 (* 1 = 0.849922 loss)
I1018 11:40:17.304832 11069 solver.cpp:571] Iteration 26760, lr = 0.001
I1018 11:40:24.950995 11069 solver.cpp:242] Iteration 26780, loss = 0.275187
I1018 11:40:24.951021 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0753146 (* 1 = 0.0753146 loss)
I1018 11:40:24.951026 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.199872 (* 1 = 0.199872 loss)
I1018 11:40:24.951030 11069 solver.cpp:571] Iteration 26780, lr = 0.001
speed: 0.378s / iter
I1018 11:40:32.543983 11069 solver.cpp:242] Iteration 26800, loss = 0.243539
I1018 11:40:32.544010 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0575424 (* 1 = 0.0575424 loss)
I1018 11:40:32.544015 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.185996 (* 1 = 0.185996 loss)
I1018 11:40:32.544020 11069 solver.cpp:571] Iteration 26800, lr = 0.001
I1018 11:40:40.261028 11069 solver.cpp:242] Iteration 26820, loss = 0.977419
I1018 11:40:40.261051 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.363062 (* 1 = 0.363062 loss)
I1018 11:40:40.261056 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.614357 (* 1 = 0.614357 loss)
I1018 11:40:40.261060 11069 solver.cpp:571] Iteration 26820, lr = 0.001
I1018 11:40:47.987284 11069 solver.cpp:242] Iteration 26840, loss = 0.268228
I1018 11:40:47.987310 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.079446 (* 1 = 0.079446 loss)
I1018 11:40:47.987318 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.188782 (* 1 = 0.188782 loss)
I1018 11:40:47.987323 11069 solver.cpp:571] Iteration 26840, lr = 0.001
I1018 11:40:55.613312 11069 solver.cpp:242] Iteration 26860, loss = 0.542251
I1018 11:40:55.613337 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153834 (* 1 = 0.153834 loss)
I1018 11:40:55.613343 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.388417 (* 1 = 0.388417 loss)
I1018 11:40:55.613348 11069 solver.cpp:571] Iteration 26860, lr = 0.001
I1018 11:41:03.308073 11069 solver.cpp:242] Iteration 26880, loss = 0.357686
I1018 11:41:03.308099 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0497721 (* 1 = 0.0497721 loss)
I1018 11:41:03.308104 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.307914 (* 1 = 0.307914 loss)
I1018 11:41:03.308109 11069 solver.cpp:571] Iteration 26880, lr = 0.001
I1018 11:41:10.931077 11069 solver.cpp:242] Iteration 26900, loss = 1.46326
I1018 11:41:10.931103 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.700255 (* 1 = 0.700255 loss)
I1018 11:41:10.931108 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.763002 (* 1 = 0.763002 loss)
I1018 11:41:10.931113 11069 solver.cpp:571] Iteration 26900, lr = 0.001
I1018 11:41:18.506786 11069 solver.cpp:242] Iteration 26920, loss = 1.21131
I1018 11:41:18.506813 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.396761 (* 1 = 0.396761 loss)
I1018 11:41:18.506817 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.814545 (* 1 = 0.814545 loss)
I1018 11:41:18.506821 11069 solver.cpp:571] Iteration 26920, lr = 0.001
I1018 11:41:26.033555 11069 solver.cpp:242] Iteration 26940, loss = 0.302597
I1018 11:41:26.033582 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0703034 (* 1 = 0.0703034 loss)
I1018 11:41:26.033587 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232294 (* 1 = 0.232294 loss)
I1018 11:41:26.033591 11069 solver.cpp:571] Iteration 26940, lr = 0.001
I1018 11:41:33.679044 11069 solver.cpp:242] Iteration 26960, loss = 0.879488
I1018 11:41:33.679071 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.259473 (* 1 = 0.259473 loss)
I1018 11:41:33.679075 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.620015 (* 1 = 0.620015 loss)
I1018 11:41:33.679080 11069 solver.cpp:571] Iteration 26960, lr = 0.001
I1018 11:41:41.349735 11069 solver.cpp:242] Iteration 26980, loss = 0.229456
I1018 11:41:41.349761 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103045 (* 1 = 0.103045 loss)
I1018 11:41:41.349766 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126411 (* 1 = 0.126411 loss)
I1018 11:41:41.349771 11069 solver.cpp:571] Iteration 26980, lr = 0.001
speed: 0.378s / iter
I1018 11:41:48.902289 11069 solver.cpp:242] Iteration 27000, loss = 0.352097
I1018 11:41:48.902314 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0486052 (* 1 = 0.0486052 loss)
I1018 11:41:48.902319 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.303492 (* 1 = 0.303492 loss)
I1018 11:41:48.902323 11069 solver.cpp:571] Iteration 27000, lr = 0.001
I1018 11:41:56.551108 11069 solver.cpp:242] Iteration 27020, loss = 0.2601
I1018 11:41:56.551136 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0598931 (* 1 = 0.0598931 loss)
I1018 11:41:56.551141 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.200207 (* 1 = 0.200207 loss)
I1018 11:41:56.551146 11069 solver.cpp:571] Iteration 27020, lr = 0.001
I1018 11:42:04.106843 11069 solver.cpp:242] Iteration 27040, loss = 0.892379
I1018 11:42:04.106870 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.285861 (* 1 = 0.285861 loss)
I1018 11:42:04.106875 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.606518 (* 1 = 0.606518 loss)
I1018 11:42:04.106879 11069 solver.cpp:571] Iteration 27040, lr = 0.001
I1018 11:42:11.674540 11069 solver.cpp:242] Iteration 27060, loss = 1.22272
I1018 11:42:11.674566 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.501156 (* 1 = 0.501156 loss)
I1018 11:42:11.674571 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.721567 (* 1 = 0.721567 loss)
I1018 11:42:11.674576 11069 solver.cpp:571] Iteration 27060, lr = 0.001
I1018 11:42:19.245103 11069 solver.cpp:242] Iteration 27080, loss = 1.28805
I1018 11:42:19.245128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.532881 (* 1 = 0.532881 loss)
I1018 11:42:19.245133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.75517 (* 1 = 0.75517 loss)
I1018 11:42:19.245138 11069 solver.cpp:571] Iteration 27080, lr = 0.001
I1018 11:42:26.963639 11069 solver.cpp:242] Iteration 27100, loss = 0.134688
I1018 11:42:26.963665 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0346003 (* 1 = 0.0346003 loss)
I1018 11:42:26.963670 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.100088 (* 1 = 0.100088 loss)
I1018 11:42:26.963675 11069 solver.cpp:571] Iteration 27100, lr = 0.001
I1018 11:42:34.562299 11069 solver.cpp:242] Iteration 27120, loss = 0.30732
I1018 11:42:34.562325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0947758 (* 1 = 0.0947758 loss)
I1018 11:42:34.562330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212544 (* 1 = 0.212544 loss)
I1018 11:42:34.562333 11069 solver.cpp:571] Iteration 27120, lr = 0.001
I1018 11:42:42.254231 11069 solver.cpp:242] Iteration 27140, loss = 0.240563
I1018 11:42:42.254258 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0703853 (* 1 = 0.0703853 loss)
I1018 11:42:42.254263 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.170177 (* 1 = 0.170177 loss)
I1018 11:42:42.254267 11069 solver.cpp:571] Iteration 27140, lr = 0.001
I1018 11:42:49.886659 11069 solver.cpp:242] Iteration 27160, loss = 0.399571
I1018 11:42:49.886685 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108325 (* 1 = 0.108325 loss)
I1018 11:42:49.886690 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.291247 (* 1 = 0.291247 loss)
I1018 11:42:49.886695 11069 solver.cpp:571] Iteration 27160, lr = 0.001
I1018 11:42:57.564699 11069 solver.cpp:242] Iteration 27180, loss = 0.49316
I1018 11:42:57.564726 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.127932 (* 1 = 0.127932 loss)
I1018 11:42:57.564731 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.365228 (* 1 = 0.365228 loss)
I1018 11:42:57.564735 11069 solver.cpp:571] Iteration 27180, lr = 0.001
speed: 0.378s / iter
I1018 11:43:05.140262 11069 solver.cpp:242] Iteration 27200, loss = 1.32928
I1018 11:43:05.140290 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.549988 (* 1 = 0.549988 loss)
I1018 11:43:05.140295 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.779291 (* 1 = 0.779291 loss)
I1018 11:43:05.140298 11069 solver.cpp:571] Iteration 27200, lr = 0.001
I1018 11:43:12.712784 11069 solver.cpp:242] Iteration 27220, loss = 0.970576
I1018 11:43:12.712810 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.321421 (* 1 = 0.321421 loss)
I1018 11:43:12.712815 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.649156 (* 1 = 0.649156 loss)
I1018 11:43:12.712818 11069 solver.cpp:571] Iteration 27220, lr = 0.001
I1018 11:43:20.461014 11069 solver.cpp:242] Iteration 27240, loss = 0.477215
I1018 11:43:20.461040 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120577 (* 1 = 0.120577 loss)
I1018 11:43:20.461045 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.356638 (* 1 = 0.356638 loss)
I1018 11:43:20.461048 11069 solver.cpp:571] Iteration 27240, lr = 0.001
I1018 11:43:28.129582 11069 solver.cpp:242] Iteration 27260, loss = 0.144925
I1018 11:43:28.129608 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0220383 (* 1 = 0.0220383 loss)
I1018 11:43:28.129614 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.122887 (* 1 = 0.122887 loss)
I1018 11:43:28.129618 11069 solver.cpp:571] Iteration 27260, lr = 0.001
I1018 11:43:35.782505 11069 solver.cpp:242] Iteration 27280, loss = 0.120675
I1018 11:43:35.782531 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0203211 (* 1 = 0.0203211 loss)
I1018 11:43:35.782536 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.100354 (* 1 = 0.100354 loss)
I1018 11:43:35.782541 11069 solver.cpp:571] Iteration 27280, lr = 0.001
I1018 11:43:43.351272 11069 solver.cpp:242] Iteration 27300, loss = 1.66207
I1018 11:43:43.351299 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.802521 (* 1 = 0.802521 loss)
I1018 11:43:43.351303 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.859549 (* 1 = 0.859549 loss)
I1018 11:43:43.351307 11069 solver.cpp:571] Iteration 27300, lr = 0.001
I1018 11:43:50.970932 11069 solver.cpp:242] Iteration 27320, loss = 0.46486
I1018 11:43:50.970959 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150444 (* 1 = 0.150444 loss)
I1018 11:43:50.970964 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.314416 (* 1 = 0.314416 loss)
I1018 11:43:50.970968 11069 solver.cpp:571] Iteration 27320, lr = 0.001
I1018 11:43:58.652140 11069 solver.cpp:242] Iteration 27340, loss = 0.261603
I1018 11:43:58.652165 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0577764 (* 1 = 0.0577764 loss)
I1018 11:43:58.652170 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.203827 (* 1 = 0.203827 loss)
I1018 11:43:58.652174 11069 solver.cpp:571] Iteration 27340, lr = 0.001
I1018 11:44:06.321856 11069 solver.cpp:242] Iteration 27360, loss = 0.829232
I1018 11:44:06.321883 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.295145 (* 1 = 0.295145 loss)
I1018 11:44:06.321888 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.534086 (* 1 = 0.534086 loss)
I1018 11:44:06.321892 11069 solver.cpp:571] Iteration 27360, lr = 0.001
I1018 11:44:13.937968 11069 solver.cpp:242] Iteration 27380, loss = 0.465787
I1018 11:44:13.937994 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0800646 (* 1 = 0.0800646 loss)
I1018 11:44:13.937997 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.385723 (* 1 = 0.385723 loss)
I1018 11:44:13.938002 11069 solver.cpp:571] Iteration 27380, lr = 0.001
speed: 0.378s / iter
I1018 11:44:21.518010 11069 solver.cpp:242] Iteration 27400, loss = 0.37041
I1018 11:44:21.518035 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0991855 (* 1 = 0.0991855 loss)
I1018 11:44:21.518041 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.271225 (* 1 = 0.271225 loss)
I1018 11:44:21.518045 11069 solver.cpp:571] Iteration 27400, lr = 0.001
I1018 11:44:29.150315 11069 solver.cpp:242] Iteration 27420, loss = 0.852322
I1018 11:44:29.150341 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.269444 (* 1 = 0.269444 loss)
I1018 11:44:29.150346 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.582878 (* 1 = 0.582878 loss)
I1018 11:44:29.150351 11069 solver.cpp:571] Iteration 27420, lr = 0.001
I1018 11:44:36.790387 11069 solver.cpp:242] Iteration 27440, loss = 0.219155
I1018 11:44:36.790413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0603066 (* 1 = 0.0603066 loss)
I1018 11:44:36.790418 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.158848 (* 1 = 0.158848 loss)
I1018 11:44:36.790422 11069 solver.cpp:571] Iteration 27440, lr = 0.001
I1018 11:44:44.387476 11069 solver.cpp:242] Iteration 27460, loss = 0.855707
I1018 11:44:44.387501 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.320297 (* 1 = 0.320297 loss)
I1018 11:44:44.387506 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.53541 (* 1 = 0.53541 loss)
I1018 11:44:44.387511 11069 solver.cpp:571] Iteration 27460, lr = 0.001
I1018 11:44:51.956354 11069 solver.cpp:242] Iteration 27480, loss = 0.117703
I1018 11:44:51.956379 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0224854 (* 1 = 0.0224854 loss)
I1018 11:44:51.956384 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0952181 (* 1 = 0.0952181 loss)
I1018 11:44:51.956388 11069 solver.cpp:571] Iteration 27480, lr = 0.001
I1018 11:44:59.579289 11069 solver.cpp:242] Iteration 27500, loss = 0.116863
I1018 11:44:59.579319 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0312838 (* 1 = 0.0312838 loss)
I1018 11:44:59.579324 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0855791 (* 1 = 0.0855791 loss)
I1018 11:44:59.579329 11069 solver.cpp:571] Iteration 27500, lr = 0.001
I1018 11:45:07.212096 11069 solver.cpp:242] Iteration 27520, loss = 0.302902
I1018 11:45:07.212123 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0901961 (* 1 = 0.0901961 loss)
I1018 11:45:07.212127 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212706 (* 1 = 0.212706 loss)
I1018 11:45:07.212131 11069 solver.cpp:571] Iteration 27520, lr = 0.001
I1018 11:45:14.930119 11069 solver.cpp:242] Iteration 27540, loss = 0.666352
I1018 11:45:14.930143 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.197066 (* 1 = 0.197066 loss)
I1018 11:45:14.930148 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.469287 (* 1 = 0.469287 loss)
I1018 11:45:14.930152 11069 solver.cpp:571] Iteration 27540, lr = 0.001
I1018 11:45:22.538677 11069 solver.cpp:242] Iteration 27560, loss = 0.167465
I1018 11:45:22.538702 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306897 (* 1 = 0.0306897 loss)
I1018 11:45:22.538707 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136775 (* 1 = 0.136775 loss)
I1018 11:45:22.538710 11069 solver.cpp:571] Iteration 27560, lr = 0.001
I1018 11:45:30.183418 11069 solver.cpp:242] Iteration 27580, loss = 0.30141
I1018 11:45:30.183441 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0827718 (* 1 = 0.0827718 loss)
I1018 11:45:30.183446 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.218639 (* 1 = 0.218639 loss)
I1018 11:45:30.183450 11069 solver.cpp:571] Iteration 27580, lr = 0.001
speed: 0.378s / iter
I1018 11:45:37.786285 11069 solver.cpp:242] Iteration 27600, loss = 1.06761
I1018 11:45:37.786309 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.343053 (* 1 = 0.343053 loss)
I1018 11:45:37.786314 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.724557 (* 1 = 0.724557 loss)
I1018 11:45:37.786319 11069 solver.cpp:571] Iteration 27600, lr = 0.001
I1018 11:45:45.365926 11069 solver.cpp:242] Iteration 27620, loss = 0.699326
I1018 11:45:45.365952 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.29604 (* 1 = 0.29604 loss)
I1018 11:45:45.365957 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.403286 (* 1 = 0.403286 loss)
I1018 11:45:45.365960 11069 solver.cpp:571] Iteration 27620, lr = 0.001
I1018 11:45:53.001202 11069 solver.cpp:242] Iteration 27640, loss = 0.59455
I1018 11:45:53.001229 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.217247 (* 1 = 0.217247 loss)
I1018 11:45:53.001233 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.377303 (* 1 = 0.377303 loss)
I1018 11:45:53.001238 11069 solver.cpp:571] Iteration 27640, lr = 0.001
I1018 11:46:00.748893 11069 solver.cpp:242] Iteration 27660, loss = 1.21824
I1018 11:46:00.748919 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.507031 (* 1 = 0.507031 loss)
I1018 11:46:00.748924 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.711211 (* 1 = 0.711211 loss)
I1018 11:46:00.748929 11069 solver.cpp:571] Iteration 27660, lr = 0.001
I1018 11:46:08.379720 11069 solver.cpp:242] Iteration 27680, loss = 0.245764
I1018 11:46:08.379746 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0365581 (* 1 = 0.0365581 loss)
I1018 11:46:08.379751 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.209206 (* 1 = 0.209206 loss)
I1018 11:46:08.379756 11069 solver.cpp:571] Iteration 27680, lr = 0.001
I1018 11:46:16.025961 11069 solver.cpp:242] Iteration 27700, loss = 0.0519023
I1018 11:46:16.025988 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0209624 (* 1 = 0.0209624 loss)
I1018 11:46:16.025993 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0309399 (* 1 = 0.0309399 loss)
I1018 11:46:16.025997 11069 solver.cpp:571] Iteration 27700, lr = 0.001
I1018 11:46:23.567572 11069 solver.cpp:242] Iteration 27720, loss = 0.150723
I1018 11:46:23.567597 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0505794 (* 1 = 0.0505794 loss)
I1018 11:46:23.567601 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.100143 (* 1 = 0.100143 loss)
I1018 11:46:23.567606 11069 solver.cpp:571] Iteration 27720, lr = 0.001
I1018 11:46:31.286202 11069 solver.cpp:242] Iteration 27740, loss = 0.186545
I1018 11:46:31.286227 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.055444 (* 1 = 0.055444 loss)
I1018 11:46:31.286232 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131101 (* 1 = 0.131101 loss)
I1018 11:46:31.286237 11069 solver.cpp:571] Iteration 27740, lr = 0.001
I1018 11:46:38.903625 11069 solver.cpp:242] Iteration 27760, loss = 0.168143
I1018 11:46:38.903650 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0564908 (* 1 = 0.0564908 loss)
I1018 11:46:38.903656 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.111652 (* 1 = 0.111652 loss)
I1018 11:46:38.903659 11069 solver.cpp:571] Iteration 27760, lr = 0.001
I1018 11:46:46.560679 11069 solver.cpp:242] Iteration 27780, loss = 1.38518
I1018 11:46:46.560705 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.540749 (* 1 = 0.540749 loss)
I1018 11:46:46.560710 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.844427 (* 1 = 0.844427 loss)
I1018 11:46:46.560714 11069 solver.cpp:571] Iteration 27780, lr = 0.001
speed: 0.378s / iter
I1018 11:46:54.179850 11069 solver.cpp:242] Iteration 27800, loss = 0.293235
I1018 11:46:54.179877 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0660101 (* 1 = 0.0660101 loss)
I1018 11:46:54.179882 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.227225 (* 1 = 0.227225 loss)
I1018 11:46:54.179885 11069 solver.cpp:571] Iteration 27800, lr = 0.001
I1018 11:47:01.827163 11069 solver.cpp:242] Iteration 27820, loss = 1.68418
I1018 11:47:01.827188 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.486877 (* 1 = 0.486877 loss)
I1018 11:47:01.827193 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.1973 (* 1 = 1.1973 loss)
I1018 11:47:01.827196 11069 solver.cpp:571] Iteration 27820, lr = 0.001
I1018 11:47:09.373407 11069 solver.cpp:242] Iteration 27840, loss = 0.455119
I1018 11:47:09.373435 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.100549 (* 1 = 0.100549 loss)
I1018 11:47:09.373440 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35457 (* 1 = 0.35457 loss)
I1018 11:47:09.373443 11069 solver.cpp:571] Iteration 27840, lr = 0.001
I1018 11:47:17.032982 11069 solver.cpp:242] Iteration 27860, loss = 0.602772
I1018 11:47:17.033006 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.14963 (* 1 = 0.14963 loss)
I1018 11:47:17.033011 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.453141 (* 1 = 0.453141 loss)
I1018 11:47:17.033015 11069 solver.cpp:571] Iteration 27860, lr = 0.001
I1018 11:47:24.735352 11069 solver.cpp:242] Iteration 27880, loss = 0.466114
I1018 11:47:24.735378 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0871442 (* 1 = 0.0871442 loss)
I1018 11:47:24.735383 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.37897 (* 1 = 0.37897 loss)
I1018 11:47:24.735388 11069 solver.cpp:571] Iteration 27880, lr = 0.001
I1018 11:47:32.369047 11069 solver.cpp:242] Iteration 27900, loss = 0.630441
I1018 11:47:32.369073 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240822 (* 1 = 0.240822 loss)
I1018 11:47:32.369078 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.389618 (* 1 = 0.389618 loss)
I1018 11:47:32.369082 11069 solver.cpp:571] Iteration 27900, lr = 0.001
I1018 11:47:39.942605 11069 solver.cpp:242] Iteration 27920, loss = 0.235809
I1018 11:47:39.942631 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0646378 (* 1 = 0.0646378 loss)
I1018 11:47:39.942636 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.171171 (* 1 = 0.171171 loss)
I1018 11:47:39.942641 11069 solver.cpp:571] Iteration 27920, lr = 0.001
I1018 11:47:47.528589 11069 solver.cpp:242] Iteration 27940, loss = 0.588353
I1018 11:47:47.528615 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.19022 (* 1 = 0.19022 loss)
I1018 11:47:47.528620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.398134 (* 1 = 0.398134 loss)
I1018 11:47:47.528625 11069 solver.cpp:571] Iteration 27940, lr = 0.001
I1018 11:47:55.208673 11069 solver.cpp:242] Iteration 27960, loss = 0.312406
I1018 11:47:55.208699 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0470497 (* 1 = 0.0470497 loss)
I1018 11:47:55.208704 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265356 (* 1 = 0.265356 loss)
I1018 11:47:55.208709 11069 solver.cpp:571] Iteration 27960, lr = 0.001
I1018 11:48:02.913290 11069 solver.cpp:242] Iteration 27980, loss = 0.297241
I1018 11:48:02.913316 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0996341 (* 1 = 0.0996341 loss)
I1018 11:48:02.913321 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197607 (* 1 = 0.197607 loss)
I1018 11:48:02.913326 11069 solver.cpp:571] Iteration 27980, lr = 0.001
speed: 0.378s / iter
I1018 11:48:10.620488 11069 solver.cpp:242] Iteration 28000, loss = 0.291437
I1018 11:48:10.620514 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0833706 (* 1 = 0.0833706 loss)
I1018 11:48:10.620519 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208066 (* 1 = 0.208066 loss)
I1018 11:48:10.620523 11069 solver.cpp:571] Iteration 28000, lr = 0.001
I1018 11:48:18.241444 11069 solver.cpp:242] Iteration 28020, loss = 0.944224
I1018 11:48:18.241480 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.298515 (* 1 = 0.298515 loss)
I1018 11:48:18.241495 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.645709 (* 1 = 0.645709 loss)
I1018 11:48:18.241499 11069 solver.cpp:571] Iteration 28020, lr = 0.001
I1018 11:48:25.936908 11069 solver.cpp:242] Iteration 28040, loss = 0.17246
I1018 11:48:25.936935 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0384695 (* 1 = 0.0384695 loss)
I1018 11:48:25.936940 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133991 (* 1 = 0.133991 loss)
I1018 11:48:25.936945 11069 solver.cpp:571] Iteration 28040, lr = 0.001
I1018 11:48:33.544193 11069 solver.cpp:242] Iteration 28060, loss = 0.313438
I1018 11:48:33.544219 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0887555 (* 1 = 0.0887555 loss)
I1018 11:48:33.544224 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224683 (* 1 = 0.224683 loss)
I1018 11:48:33.544229 11069 solver.cpp:571] Iteration 28060, lr = 0.001
I1018 11:48:41.185750 11069 solver.cpp:242] Iteration 28080, loss = 0.286384
I1018 11:48:41.185775 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0906639 (* 1 = 0.0906639 loss)
I1018 11:48:41.185780 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195721 (* 1 = 0.195721 loss)
I1018 11:48:41.185784 11069 solver.cpp:571] Iteration 28080, lr = 0.001
I1018 11:48:48.865388 11069 solver.cpp:242] Iteration 28100, loss = 0.364429
I1018 11:48:48.865414 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103662 (* 1 = 0.103662 loss)
I1018 11:48:48.865419 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.260767 (* 1 = 0.260767 loss)
I1018 11:48:48.865423 11069 solver.cpp:571] Iteration 28100, lr = 0.001
I1018 11:48:56.456902 11069 solver.cpp:242] Iteration 28120, loss = 0.283657
I1018 11:48:56.456928 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0492268 (* 1 = 0.0492268 loss)
I1018 11:48:56.456933 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.234431 (* 1 = 0.234431 loss)
I1018 11:48:56.456936 11069 solver.cpp:571] Iteration 28120, lr = 0.001
I1018 11:49:04.104341 11069 solver.cpp:242] Iteration 28140, loss = 1.53679
I1018 11:49:04.104367 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.769249 (* 1 = 0.769249 loss)
I1018 11:49:04.104372 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.767542 (* 1 = 0.767542 loss)
I1018 11:49:04.104377 11069 solver.cpp:571] Iteration 28140, lr = 0.001
I1018 11:49:11.821033 11069 solver.cpp:242] Iteration 28160, loss = 0.533417
I1018 11:49:11.821058 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.137524 (* 1 = 0.137524 loss)
I1018 11:49:11.821063 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.395893 (* 1 = 0.395893 loss)
I1018 11:49:11.821069 11069 solver.cpp:571] Iteration 28160, lr = 0.001
I1018 11:49:19.411124 11069 solver.cpp:242] Iteration 28180, loss = 0.700496
I1018 11:49:19.411150 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205139 (* 1 = 0.205139 loss)
I1018 11:49:19.411155 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495357 (* 1 = 0.495357 loss)
I1018 11:49:19.411159 11069 solver.cpp:571] Iteration 28180, lr = 0.001
speed: 0.378s / iter
I1018 11:49:26.971855 11069 solver.cpp:242] Iteration 28200, loss = 0.474683
I1018 11:49:26.971880 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.129792 (* 1 = 0.129792 loss)
I1018 11:49:26.971885 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.344892 (* 1 = 0.344892 loss)
I1018 11:49:26.971890 11069 solver.cpp:571] Iteration 28200, lr = 0.001
I1018 11:49:34.656673 11069 solver.cpp:242] Iteration 28220, loss = 0.582548
I1018 11:49:34.656699 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.174958 (* 1 = 0.174958 loss)
I1018 11:49:34.656704 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.40759 (* 1 = 0.40759 loss)
I1018 11:49:34.656708 11069 solver.cpp:571] Iteration 28220, lr = 0.001
I1018 11:49:42.323118 11069 solver.cpp:242] Iteration 28240, loss = 0.77655
I1018 11:49:42.323143 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.253428 (* 1 = 0.253428 loss)
I1018 11:49:42.323148 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.523122 (* 1 = 0.523122 loss)
I1018 11:49:42.323153 11069 solver.cpp:571] Iteration 28240, lr = 0.001
I1018 11:49:50.021307 11069 solver.cpp:242] Iteration 28260, loss = 1.45504
I1018 11:49:50.021332 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.59165 (* 1 = 0.59165 loss)
I1018 11:49:50.021337 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.863393 (* 1 = 0.863393 loss)
I1018 11:49:50.021340 11069 solver.cpp:571] Iteration 28260, lr = 0.001
I1018 11:49:57.749593 11069 solver.cpp:242] Iteration 28280, loss = 0.294757
I1018 11:49:57.749619 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0388264 (* 1 = 0.0388264 loss)
I1018 11:49:57.749624 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.25593 (* 1 = 0.25593 loss)
I1018 11:49:57.749627 11069 solver.cpp:571] Iteration 28280, lr = 0.001
I1018 11:50:05.407016 11069 solver.cpp:242] Iteration 28300, loss = 2.23491
I1018 11:50:05.407042 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.991986 (* 1 = 0.991986 loss)
I1018 11:50:05.407047 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.24292 (* 1 = 1.24292 loss)
I1018 11:50:05.407050 11069 solver.cpp:571] Iteration 28300, lr = 0.001
I1018 11:50:13.017088 11069 solver.cpp:242] Iteration 28320, loss = 0.155807
I1018 11:50:13.017114 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0371147 (* 1 = 0.0371147 loss)
I1018 11:50:13.017118 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.118693 (* 1 = 0.118693 loss)
I1018 11:50:13.017123 11069 solver.cpp:571] Iteration 28320, lr = 0.001
I1018 11:50:20.738785 11069 solver.cpp:242] Iteration 28340, loss = 0.466561
I1018 11:50:20.738811 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.124016 (* 1 = 0.124016 loss)
I1018 11:50:20.738816 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342545 (* 1 = 0.342545 loss)
I1018 11:50:20.738819 11069 solver.cpp:571] Iteration 28340, lr = 0.001
I1018 11:50:28.414652 11069 solver.cpp:242] Iteration 28360, loss = 0.174214
I1018 11:50:28.414677 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0364695 (* 1 = 0.0364695 loss)
I1018 11:50:28.414681 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137745 (* 1 = 0.137745 loss)
I1018 11:50:28.414685 11069 solver.cpp:571] Iteration 28360, lr = 0.001
I1018 11:50:35.894732 11069 solver.cpp:242] Iteration 28380, loss = 0.74341
I1018 11:50:35.894757 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.3145 (* 1 = 0.3145 loss)
I1018 11:50:35.894762 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.42891 (* 1 = 0.42891 loss)
I1018 11:50:35.894765 11069 solver.cpp:571] Iteration 28380, lr = 0.001
speed: 0.378s / iter
I1018 11:50:43.505934 11069 solver.cpp:242] Iteration 28400, loss = 0.178878
I1018 11:50:43.505959 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.038142 (* 1 = 0.038142 loss)
I1018 11:50:43.505964 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140736 (* 1 = 0.140736 loss)
I1018 11:50:43.505967 11069 solver.cpp:571] Iteration 28400, lr = 0.001
I1018 11:50:51.269992 11069 solver.cpp:242] Iteration 28420, loss = 0.565347
I1018 11:50:51.270017 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116129 (* 1 = 0.116129 loss)
I1018 11:50:51.270021 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.449217 (* 1 = 0.449217 loss)
I1018 11:50:51.270026 11069 solver.cpp:571] Iteration 28420, lr = 0.001
I1018 11:50:58.858507 11069 solver.cpp:242] Iteration 28440, loss = 0.163583
I1018 11:50:58.858532 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0209159 (* 1 = 0.0209159 loss)
I1018 11:50:58.858537 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.142667 (* 1 = 0.142667 loss)
I1018 11:50:58.858541 11069 solver.cpp:571] Iteration 28440, lr = 0.001
I1018 11:51:06.445039 11069 solver.cpp:242] Iteration 28460, loss = 0.824307
I1018 11:51:06.445065 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.299966 (* 1 = 0.299966 loss)
I1018 11:51:06.445068 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.524341 (* 1 = 0.524341 loss)
I1018 11:51:06.445072 11069 solver.cpp:571] Iteration 28460, lr = 0.001
I1018 11:51:14.117198 11069 solver.cpp:242] Iteration 28480, loss = 0.343617
I1018 11:51:14.117223 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.130337 (* 1 = 0.130337 loss)
I1018 11:51:14.117228 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21328 (* 1 = 0.21328 loss)
I1018 11:51:14.117231 11069 solver.cpp:571] Iteration 28480, lr = 0.001
I1018 11:51:21.745702 11069 solver.cpp:242] Iteration 28500, loss = 1.05784
I1018 11:51:21.745728 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.305949 (* 1 = 0.305949 loss)
I1018 11:51:21.745733 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.75189 (* 1 = 0.75189 loss)
I1018 11:51:21.745736 11069 solver.cpp:571] Iteration 28500, lr = 0.001
I1018 11:51:29.387749 11069 solver.cpp:242] Iteration 28520, loss = 1.89952
I1018 11:51:29.387775 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.827691 (* 1 = 0.827691 loss)
I1018 11:51:29.387780 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.07183 (* 1 = 1.07183 loss)
I1018 11:51:29.387784 11069 solver.cpp:571] Iteration 28520, lr = 0.001
I1018 11:51:36.977272 11069 solver.cpp:242] Iteration 28540, loss = 0.28413
I1018 11:51:36.977296 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0891709 (* 1 = 0.0891709 loss)
I1018 11:51:36.977301 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194959 (* 1 = 0.194959 loss)
I1018 11:51:36.977305 11069 solver.cpp:571] Iteration 28540, lr = 0.001
I1018 11:51:44.649615 11069 solver.cpp:242] Iteration 28560, loss = 0.199155
I1018 11:51:44.649639 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0466695 (* 1 = 0.0466695 loss)
I1018 11:51:44.649644 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.152485 (* 1 = 0.152485 loss)
I1018 11:51:44.649648 11069 solver.cpp:571] Iteration 28560, lr = 0.001
I1018 11:51:52.061130 11069 solver.cpp:242] Iteration 28580, loss = 0.260054
I1018 11:51:52.061156 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0341848 (* 1 = 0.0341848 loss)
I1018 11:51:52.061159 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.225869 (* 1 = 0.225869 loss)
I1018 11:51:52.061163 11069 solver.cpp:571] Iteration 28580, lr = 0.001
speed: 0.378s / iter
I1018 11:51:59.645035 11069 solver.cpp:242] Iteration 28600, loss = 0.29546
I1018 11:51:59.645061 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0867653 (* 1 = 0.0867653 loss)
I1018 11:51:59.645066 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208694 (* 1 = 0.208694 loss)
I1018 11:51:59.645071 11069 solver.cpp:571] Iteration 28600, lr = 0.001
I1018 11:52:07.235047 11069 solver.cpp:242] Iteration 28620, loss = 1.48616
I1018 11:52:07.235075 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.50808 (* 1 = 0.50808 loss)
I1018 11:52:07.235080 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.978082 (* 1 = 0.978082 loss)
I1018 11:52:07.235085 11069 solver.cpp:571] Iteration 28620, lr = 0.001
I1018 11:52:14.949283 11069 solver.cpp:242] Iteration 28640, loss = 0.217095
I1018 11:52:14.949309 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0751329 (* 1 = 0.0751329 loss)
I1018 11:52:14.949314 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141962 (* 1 = 0.141962 loss)
I1018 11:52:14.949319 11069 solver.cpp:571] Iteration 28640, lr = 0.001
I1018 11:52:22.613351 11069 solver.cpp:242] Iteration 28660, loss = 1.88216
I1018 11:52:22.613378 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.879804 (* 1 = 0.879804 loss)
I1018 11:52:22.613382 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.00235 (* 1 = 1.00235 loss)
I1018 11:52:22.613386 11069 solver.cpp:571] Iteration 28660, lr = 0.001
I1018 11:52:30.222370 11069 solver.cpp:242] Iteration 28680, loss = 0.440686
I1018 11:52:30.222395 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.134664 (* 1 = 0.134664 loss)
I1018 11:52:30.222399 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.306022 (* 1 = 0.306022 loss)
I1018 11:52:30.222404 11069 solver.cpp:571] Iteration 28680, lr = 0.001
I1018 11:52:37.881429 11069 solver.cpp:242] Iteration 28700, loss = 0.496784
I1018 11:52:37.881455 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181753 (* 1 = 0.181753 loss)
I1018 11:52:37.881460 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.315031 (* 1 = 0.315031 loss)
I1018 11:52:37.881464 11069 solver.cpp:571] Iteration 28700, lr = 0.001
I1018 11:52:45.495939 11069 solver.cpp:242] Iteration 28720, loss = 0.972086
I1018 11:52:45.495965 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.316006 (* 1 = 0.316006 loss)
I1018 11:52:45.495970 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.65608 (* 1 = 0.65608 loss)
I1018 11:52:45.495973 11069 solver.cpp:571] Iteration 28720, lr = 0.001
I1018 11:52:53.201385 11069 solver.cpp:242] Iteration 28740, loss = 1.40719
I1018 11:52:53.201411 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.538826 (* 1 = 0.538826 loss)
I1018 11:52:53.201416 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.868366 (* 1 = 0.868366 loss)
I1018 11:52:53.201419 11069 solver.cpp:571] Iteration 28740, lr = 0.001
I1018 11:53:00.843720 11069 solver.cpp:242] Iteration 28760, loss = 0.272086
I1018 11:53:00.843747 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.072204 (* 1 = 0.072204 loss)
I1018 11:53:00.843752 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.199882 (* 1 = 0.199882 loss)
I1018 11:53:00.843756 11069 solver.cpp:571] Iteration 28760, lr = 0.001
I1018 11:53:08.460574 11069 solver.cpp:242] Iteration 28780, loss = 0.386388
I1018 11:53:08.460600 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0956234 (* 1 = 0.0956234 loss)
I1018 11:53:08.460605 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.290765 (* 1 = 0.290765 loss)
I1018 11:53:08.460609 11069 solver.cpp:571] Iteration 28780, lr = 0.001
speed: 0.378s / iter
I1018 11:53:16.106861 11069 solver.cpp:242] Iteration 28800, loss = 0.23436
I1018 11:53:16.106887 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0461466 (* 1 = 0.0461466 loss)
I1018 11:53:16.106894 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.188214 (* 1 = 0.188214 loss)
I1018 11:53:16.106897 11069 solver.cpp:571] Iteration 28800, lr = 0.001
I1018 11:53:23.687376 11069 solver.cpp:242] Iteration 28820, loss = 0.274123
I1018 11:53:23.687402 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0564594 (* 1 = 0.0564594 loss)
I1018 11:53:23.687407 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.217663 (* 1 = 0.217663 loss)
I1018 11:53:23.687412 11069 solver.cpp:571] Iteration 28820, lr = 0.001
I1018 11:53:31.289367 11069 solver.cpp:242] Iteration 28840, loss = 0.18806
I1018 11:53:31.289393 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0471345 (* 1 = 0.0471345 loss)
I1018 11:53:31.289398 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140925 (* 1 = 0.140925 loss)
I1018 11:53:31.289402 11069 solver.cpp:571] Iteration 28840, lr = 0.001
I1018 11:53:38.977026 11069 solver.cpp:242] Iteration 28860, loss = 1.13004
I1018 11:53:38.977051 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.306543 (* 1 = 0.306543 loss)
I1018 11:53:38.977056 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.823497 (* 1 = 0.823497 loss)
I1018 11:53:38.977061 11069 solver.cpp:571] Iteration 28860, lr = 0.001
I1018 11:53:46.594156 11069 solver.cpp:242] Iteration 28880, loss = 0.759448
I1018 11:53:46.594182 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.269447 (* 1 = 0.269447 loss)
I1018 11:53:46.594187 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.490002 (* 1 = 0.490002 loss)
I1018 11:53:46.594192 11069 solver.cpp:571] Iteration 28880, lr = 0.001
I1018 11:53:54.301090 11069 solver.cpp:242] Iteration 28900, loss = 0.392142
I1018 11:53:54.301115 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0882943 (* 1 = 0.0882943 loss)
I1018 11:53:54.301120 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.303847 (* 1 = 0.303847 loss)
I1018 11:53:54.301125 11069 solver.cpp:571] Iteration 28900, lr = 0.001
I1018 11:54:01.859683 11069 solver.cpp:242] Iteration 28920, loss = 0.644927
I1018 11:54:01.859707 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171758 (* 1 = 0.171758 loss)
I1018 11:54:01.859712 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.473169 (* 1 = 0.473169 loss)
I1018 11:54:01.859716 11069 solver.cpp:571] Iteration 28920, lr = 0.001
I1018 11:54:09.456115 11069 solver.cpp:242] Iteration 28940, loss = 0.202829
I1018 11:54:09.456140 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0362708 (* 1 = 0.0362708 loss)
I1018 11:54:09.456146 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166558 (* 1 = 0.166558 loss)
I1018 11:54:09.456151 11069 solver.cpp:571] Iteration 28940, lr = 0.001
I1018 11:54:16.969805 11069 solver.cpp:242] Iteration 28960, loss = 0.202149
I1018 11:54:16.969831 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0510883 (* 1 = 0.0510883 loss)
I1018 11:54:16.969836 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.15106 (* 1 = 0.15106 loss)
I1018 11:54:16.969841 11069 solver.cpp:571] Iteration 28960, lr = 0.001
I1018 11:54:24.586932 11069 solver.cpp:242] Iteration 28980, loss = 0.80767
I1018 11:54:24.586958 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.24771 (* 1 = 0.24771 loss)
I1018 11:54:24.586963 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.55996 (* 1 = 0.55996 loss)
I1018 11:54:24.586968 11069 solver.cpp:571] Iteration 28980, lr = 0.001
speed: 0.378s / iter
I1018 11:54:32.191896 11069 solver.cpp:242] Iteration 29000, loss = 0.259458
I1018 11:54:32.191923 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0460227 (* 1 = 0.0460227 loss)
I1018 11:54:32.191928 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.213435 (* 1 = 0.213435 loss)
I1018 11:54:32.191932 11069 solver.cpp:571] Iteration 29000, lr = 0.001
I1018 11:54:39.888527 11069 solver.cpp:242] Iteration 29020, loss = 0.648754
I1018 11:54:39.888553 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.132499 (* 1 = 0.132499 loss)
I1018 11:54:39.888559 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.516256 (* 1 = 0.516256 loss)
I1018 11:54:39.888563 11069 solver.cpp:571] Iteration 29020, lr = 0.001
I1018 11:54:47.462100 11069 solver.cpp:242] Iteration 29040, loss = 0.43463
I1018 11:54:47.462126 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103807 (* 1 = 0.103807 loss)
I1018 11:54:47.462131 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.330822 (* 1 = 0.330822 loss)
I1018 11:54:47.462136 11069 solver.cpp:571] Iteration 29040, lr = 0.001
I1018 11:54:55.128650 11069 solver.cpp:242] Iteration 29060, loss = 0.213974
I1018 11:54:55.128676 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0722972 (* 1 = 0.0722972 loss)
I1018 11:54:55.128681 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.141676 (* 1 = 0.141676 loss)
I1018 11:54:55.128686 11069 solver.cpp:571] Iteration 29060, lr = 0.001
I1018 11:55:02.708492 11069 solver.cpp:242] Iteration 29080, loss = 0.877094
I1018 11:55:02.708518 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212398 (* 1 = 0.212398 loss)
I1018 11:55:02.708523 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664697 (* 1 = 0.664697 loss)
I1018 11:55:02.708526 11069 solver.cpp:571] Iteration 29080, lr = 0.001
I1018 11:55:10.375864 11069 solver.cpp:242] Iteration 29100, loss = 0.283433
I1018 11:55:10.375888 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0784507 (* 1 = 0.0784507 loss)
I1018 11:55:10.375892 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204982 (* 1 = 0.204982 loss)
I1018 11:55:10.375897 11069 solver.cpp:571] Iteration 29100, lr = 0.001
I1018 11:55:18.071224 11069 solver.cpp:242] Iteration 29120, loss = 0.206179
I1018 11:55:18.071251 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0674426 (* 1 = 0.0674426 loss)
I1018 11:55:18.071255 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.138736 (* 1 = 0.138736 loss)
I1018 11:55:18.071260 11069 solver.cpp:571] Iteration 29120, lr = 0.001
I1018 11:55:25.663866 11069 solver.cpp:242] Iteration 29140, loss = 0.39464
I1018 11:55:25.663892 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0864529 (* 1 = 0.0864529 loss)
I1018 11:55:25.663897 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.308187 (* 1 = 0.308187 loss)
I1018 11:55:25.663902 11069 solver.cpp:571] Iteration 29140, lr = 0.001
I1018 11:55:33.325992 11069 solver.cpp:242] Iteration 29160, loss = 0.186976
I1018 11:55:33.326019 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0679504 (* 1 = 0.0679504 loss)
I1018 11:55:33.326023 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.119026 (* 1 = 0.119026 loss)
I1018 11:55:33.326027 11069 solver.cpp:571] Iteration 29160, lr = 0.001
I1018 11:55:40.958468 11069 solver.cpp:242] Iteration 29180, loss = 0.38443
I1018 11:55:40.958493 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114781 (* 1 = 0.114781 loss)
I1018 11:55:40.958498 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.269649 (* 1 = 0.269649 loss)
I1018 11:55:40.958503 11069 solver.cpp:571] Iteration 29180, lr = 0.001
speed: 0.378s / iter
I1018 11:55:48.614442 11069 solver.cpp:242] Iteration 29200, loss = 0.959218
I1018 11:55:48.614469 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.357422 (* 1 = 0.357422 loss)
I1018 11:55:48.614473 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.601796 (* 1 = 0.601796 loss)
I1018 11:55:48.614477 11069 solver.cpp:571] Iteration 29200, lr = 0.001
I1018 11:55:56.158366 11069 solver.cpp:242] Iteration 29220, loss = 1.02032
I1018 11:55:56.158391 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.424258 (* 1 = 0.424258 loss)
I1018 11:55:56.158396 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.596066 (* 1 = 0.596066 loss)
I1018 11:55:56.158401 11069 solver.cpp:571] Iteration 29220, lr = 0.001
I1018 11:56:03.790503 11069 solver.cpp:242] Iteration 29240, loss = 0.35638
I1018 11:56:03.790530 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0654923 (* 1 = 0.0654923 loss)
I1018 11:56:03.790535 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.290888 (* 1 = 0.290888 loss)
I1018 11:56:03.790539 11069 solver.cpp:571] Iteration 29240, lr = 0.001
I1018 11:56:11.435633 11069 solver.cpp:242] Iteration 29260, loss = 0.498175
I1018 11:56:11.435659 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1175 (* 1 = 0.1175 loss)
I1018 11:56:11.435664 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.380675 (* 1 = 0.380675 loss)
I1018 11:56:11.435668 11069 solver.cpp:571] Iteration 29260, lr = 0.001
I1018 11:56:19.066541 11069 solver.cpp:242] Iteration 29280, loss = 0.171743
I1018 11:56:19.066568 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.047759 (* 1 = 0.047759 loss)
I1018 11:56:19.066573 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123984 (* 1 = 0.123984 loss)
I1018 11:56:19.066577 11069 solver.cpp:571] Iteration 29280, lr = 0.001
I1018 11:56:26.675024 11069 solver.cpp:242] Iteration 29300, loss = 0.220593
I1018 11:56:26.675050 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0426687 (* 1 = 0.0426687 loss)
I1018 11:56:26.675055 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.177924 (* 1 = 0.177924 loss)
I1018 11:56:26.675058 11069 solver.cpp:571] Iteration 29300, lr = 0.001
I1018 11:56:34.287742 11069 solver.cpp:242] Iteration 29320, loss = 0.476121
I1018 11:56:34.287767 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.188098 (* 1 = 0.188098 loss)
I1018 11:56:34.287772 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.288022 (* 1 = 0.288022 loss)
I1018 11:56:34.287776 11069 solver.cpp:571] Iteration 29320, lr = 0.001
I1018 11:56:41.785779 11069 solver.cpp:242] Iteration 29340, loss = 0.249362
I1018 11:56:41.785805 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.04488 (* 1 = 0.04488 loss)
I1018 11:56:41.785810 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204482 (* 1 = 0.204482 loss)
I1018 11:56:41.785815 11069 solver.cpp:571] Iteration 29340, lr = 0.001
I1018 11:56:49.475831 11069 solver.cpp:242] Iteration 29360, loss = 0.259275
I1018 11:56:49.475857 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0482701 (* 1 = 0.0482701 loss)
I1018 11:56:49.475862 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.211005 (* 1 = 0.211005 loss)
I1018 11:56:49.475867 11069 solver.cpp:571] Iteration 29360, lr = 0.001
I1018 11:56:57.102155 11069 solver.cpp:242] Iteration 29380, loss = 0.305223
I1018 11:56:57.102181 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0777981 (* 1 = 0.0777981 loss)
I1018 11:56:57.102186 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.227425 (* 1 = 0.227425 loss)
I1018 11:56:57.102190 11069 solver.cpp:571] Iteration 29380, lr = 0.001
speed: 0.378s / iter
I1018 11:57:04.727802 11069 solver.cpp:242] Iteration 29400, loss = 0.302781
I1018 11:57:04.727828 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0810999 (* 1 = 0.0810999 loss)
I1018 11:57:04.727833 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.221681 (* 1 = 0.221681 loss)
I1018 11:57:04.727836 11069 solver.cpp:571] Iteration 29400, lr = 0.001
I1018 11:57:12.355854 11069 solver.cpp:242] Iteration 29420, loss = 1.00089
I1018 11:57:12.355881 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.376625 (* 1 = 0.376625 loss)
I1018 11:57:12.355886 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.624263 (* 1 = 0.624263 loss)
I1018 11:57:12.355890 11069 solver.cpp:571] Iteration 29420, lr = 0.001
I1018 11:57:20.085090 11069 solver.cpp:242] Iteration 29440, loss = 0.227893
I1018 11:57:20.085115 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0449414 (* 1 = 0.0449414 loss)
I1018 11:57:20.085120 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182952 (* 1 = 0.182952 loss)
I1018 11:57:20.085124 11069 solver.cpp:571] Iteration 29440, lr = 0.001
I1018 11:57:27.680940 11069 solver.cpp:242] Iteration 29460, loss = 0.1032
I1018 11:57:27.680966 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0409931 (* 1 = 0.0409931 loss)
I1018 11:57:27.680971 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0622073 (* 1 = 0.0622073 loss)
I1018 11:57:27.680976 11069 solver.cpp:571] Iteration 29460, lr = 0.001
I1018 11:57:35.413386 11069 solver.cpp:242] Iteration 29480, loss = 0.170829
I1018 11:57:35.413413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0473641 (* 1 = 0.0473641 loss)
I1018 11:57:35.413417 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123464 (* 1 = 0.123464 loss)
I1018 11:57:35.413421 11069 solver.cpp:571] Iteration 29480, lr = 0.001
I1018 11:57:43.053653 11069 solver.cpp:242] Iteration 29500, loss = 0.405935
I1018 11:57:43.053678 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1655 (* 1 = 0.1655 loss)
I1018 11:57:43.053683 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.240435 (* 1 = 0.240435 loss)
I1018 11:57:43.053689 11069 solver.cpp:571] Iteration 29500, lr = 0.001
I1018 11:57:50.656349 11069 solver.cpp:242] Iteration 29520, loss = 0.220533
I1018 11:57:50.656375 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.091531 (* 1 = 0.091531 loss)
I1018 11:57:50.656380 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.129002 (* 1 = 0.129002 loss)
I1018 11:57:50.656384 11069 solver.cpp:571] Iteration 29520, lr = 0.001
I1018 11:57:58.295584 11069 solver.cpp:242] Iteration 29540, loss = 0.552334
I1018 11:57:58.295610 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13602 (* 1 = 0.13602 loss)
I1018 11:57:58.295615 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.416314 (* 1 = 0.416314 loss)
I1018 11:57:58.295619 11069 solver.cpp:571] Iteration 29540, lr = 0.001
I1018 11:58:05.905191 11069 solver.cpp:242] Iteration 29560, loss = 0.345598
I1018 11:58:05.905217 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.126336 (* 1 = 0.126336 loss)
I1018 11:58:05.905222 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.219262 (* 1 = 0.219262 loss)
I1018 11:58:05.905226 11069 solver.cpp:571] Iteration 29560, lr = 0.001
I1018 11:58:13.515242 11069 solver.cpp:242] Iteration 29580, loss = 0.432809
I1018 11:58:13.515269 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.201273 (* 1 = 0.201273 loss)
I1018 11:58:13.515274 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231536 (* 1 = 0.231536 loss)
I1018 11:58:13.515277 11069 solver.cpp:571] Iteration 29580, lr = 0.001
speed: 0.378s / iter
I1018 11:58:21.096112 11069 solver.cpp:242] Iteration 29600, loss = 0.900801
I1018 11:58:21.096137 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.293189 (* 1 = 0.293189 loss)
I1018 11:58:21.096141 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.607612 (* 1 = 0.607612 loss)
I1018 11:58:21.096146 11069 solver.cpp:571] Iteration 29600, lr = 0.001
I1018 11:58:28.768436 11069 solver.cpp:242] Iteration 29620, loss = 0.548631
I1018 11:58:28.768462 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.192372 (* 1 = 0.192372 loss)
I1018 11:58:28.768467 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35626 (* 1 = 0.35626 loss)
I1018 11:58:28.768471 11069 solver.cpp:571] Iteration 29620, lr = 0.001
I1018 11:58:36.432816 11069 solver.cpp:242] Iteration 29640, loss = 0.938022
I1018 11:58:36.432843 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.314671 (* 1 = 0.314671 loss)
I1018 11:58:36.432848 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.623351 (* 1 = 0.623351 loss)
I1018 11:58:36.432852 11069 solver.cpp:571] Iteration 29640, lr = 0.001
I1018 11:58:44.082398 11069 solver.cpp:242] Iteration 29660, loss = 0.161203
I1018 11:58:44.082424 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0310744 (* 1 = 0.0310744 loss)
I1018 11:58:44.082429 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.130129 (* 1 = 0.130129 loss)
I1018 11:58:44.082434 11069 solver.cpp:571] Iteration 29660, lr = 0.001
I1018 11:58:51.733561 11069 solver.cpp:242] Iteration 29680, loss = 0.311395
I1018 11:58:51.733587 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0853855 (* 1 = 0.0853855 loss)
I1018 11:58:51.733592 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22601 (* 1 = 0.22601 loss)
I1018 11:58:51.733597 11069 solver.cpp:571] Iteration 29680, lr = 0.001
I1018 11:58:59.394356 11069 solver.cpp:242] Iteration 29700, loss = 0.490569
I1018 11:58:59.394381 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.149419 (* 1 = 0.149419 loss)
I1018 11:58:59.394387 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.341151 (* 1 = 0.341151 loss)
I1018 11:58:59.394390 11069 solver.cpp:571] Iteration 29700, lr = 0.001
I1018 11:59:07.048756 11069 solver.cpp:242] Iteration 29720, loss = 0.992799
I1018 11:59:07.048781 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.267065 (* 1 = 0.267065 loss)
I1018 11:59:07.048786 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.725734 (* 1 = 0.725734 loss)
I1018 11:59:07.048790 11069 solver.cpp:571] Iteration 29720, lr = 0.001
I1018 11:59:14.726910 11069 solver.cpp:242] Iteration 29740, loss = 0.301492
I1018 11:59:14.726935 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704086 (* 1 = 0.0704086 loss)
I1018 11:59:14.726940 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231083 (* 1 = 0.231083 loss)
I1018 11:59:14.726944 11069 solver.cpp:571] Iteration 29740, lr = 0.001
I1018 11:59:22.430297 11069 solver.cpp:242] Iteration 29760, loss = 1.39098
I1018 11:59:22.430323 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.619393 (* 1 = 0.619393 loss)
I1018 11:59:22.430328 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.771591 (* 1 = 0.771591 loss)
I1018 11:59:22.430332 11069 solver.cpp:571] Iteration 29760, lr = 0.001
I1018 11:59:30.120966 11069 solver.cpp:242] Iteration 29780, loss = 0.224807
I1018 11:59:30.120991 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0655716 (* 1 = 0.0655716 loss)
I1018 11:59:30.120996 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.159236 (* 1 = 0.159236 loss)
I1018 11:59:30.121001 11069 solver.cpp:571] Iteration 29780, lr = 0.001
speed: 0.378s / iter
I1018 11:59:37.606601 11069 solver.cpp:242] Iteration 29800, loss = 1.18933
I1018 11:59:37.606628 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.453612 (* 1 = 0.453612 loss)
I1018 11:59:37.606632 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.735718 (* 1 = 0.735718 loss)
I1018 11:59:37.606637 11069 solver.cpp:571] Iteration 29800, lr = 0.001
I1018 11:59:45.270635 11069 solver.cpp:242] Iteration 29820, loss = 0.35104
I1018 11:59:45.270659 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0963458 (* 1 = 0.0963458 loss)
I1018 11:59:45.270664 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254694 (* 1 = 0.254694 loss)
I1018 11:59:45.270668 11069 solver.cpp:571] Iteration 29820, lr = 0.001
I1018 11:59:52.928436 11069 solver.cpp:242] Iteration 29840, loss = 0.583063
I1018 11:59:52.928462 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.1604 (* 1 = 0.1604 loss)
I1018 11:59:52.928467 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.422663 (* 1 = 0.422663 loss)
I1018 11:59:52.928472 11069 solver.cpp:571] Iteration 29840, lr = 0.001
I1018 12:00:00.640971 11069 solver.cpp:242] Iteration 29860, loss = 0.365251
I1018 12:00:00.640997 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123082 (* 1 = 0.123082 loss)
I1018 12:00:00.641002 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242169 (* 1 = 0.242169 loss)
I1018 12:00:00.641007 11069 solver.cpp:571] Iteration 29860, lr = 0.001
I1018 12:00:08.342324 11069 solver.cpp:242] Iteration 29880, loss = 0.362454
I1018 12:00:08.342350 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0965088 (* 1 = 0.0965088 loss)
I1018 12:00:08.342355 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265946 (* 1 = 0.265946 loss)
I1018 12:00:08.342360 11069 solver.cpp:571] Iteration 29880, lr = 0.001
I1018 12:00:16.003558 11069 solver.cpp:242] Iteration 29900, loss = 0.442747
I1018 12:00:16.003585 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158089 (* 1 = 0.158089 loss)
I1018 12:00:16.003589 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.284657 (* 1 = 0.284657 loss)
I1018 12:00:16.003594 11069 solver.cpp:571] Iteration 29900, lr = 0.001
I1018 12:00:23.755741 11069 solver.cpp:242] Iteration 29920, loss = 0.184389
I1018 12:00:23.755767 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0477613 (* 1 = 0.0477613 loss)
I1018 12:00:23.755772 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.136627 (* 1 = 0.136627 loss)
I1018 12:00:23.755777 11069 solver.cpp:571] Iteration 29920, lr = 0.001
I1018 12:00:31.433322 11069 solver.cpp:242] Iteration 29940, loss = 0.209461
I1018 12:00:31.433348 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0719789 (* 1 = 0.0719789 loss)
I1018 12:00:31.433353 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137482 (* 1 = 0.137482 loss)
I1018 12:00:31.433357 11069 solver.cpp:571] Iteration 29940, lr = 0.001
I1018 12:00:39.021354 11069 solver.cpp:242] Iteration 29960, loss = 0.152205
I1018 12:00:39.021379 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0228039 (* 1 = 0.0228039 loss)
I1018 12:00:39.021384 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.129401 (* 1 = 0.129401 loss)
I1018 12:00:39.021389 11069 solver.cpp:571] Iteration 29960, lr = 0.001
I1018 12:00:46.640477 11069 solver.cpp:242] Iteration 29980, loss = 0.23388
I1018 12:00:46.640504 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0398598 (* 1 = 0.0398598 loss)
I1018 12:00:46.640511 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.19402 (* 1 = 0.19402 loss)
I1018 12:00:46.640514 11069 solver.cpp:571] Iteration 29980, lr = 0.001
speed: 0.378s / iter
Wrote snapshot to: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_fast_rcnn_stage2_iter_30000.caffemodel
I1018 12:00:55.563441 11069 solver.cpp:242] Iteration 30000, loss = 0.2432
I1018 12:00:55.563465 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.057948 (* 1 = 0.057948 loss)
I1018 12:00:55.563470 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.185252 (* 1 = 0.185252 loss)
I1018 12:00:55.563474 11069 solver.cpp:571] Iteration 30000, lr = 0.0001
I1018 12:01:02.905714 11069 solver.cpp:242] Iteration 30020, loss = 0.683567
I1018 12:01:02.905740 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.196928 (* 1 = 0.196928 loss)
I1018 12:01:02.905745 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.486639 (* 1 = 0.486639 loss)
I1018 12:01:02.905748 11069 solver.cpp:571] Iteration 30020, lr = 0.0001
I1018 12:01:10.562695 11069 solver.cpp:242] Iteration 30040, loss = 0.251025
I1018 12:01:10.562721 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0568919 (* 1 = 0.0568919 loss)
I1018 12:01:10.562726 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194133 (* 1 = 0.194133 loss)
I1018 12:01:10.562729 11069 solver.cpp:571] Iteration 30040, lr = 0.0001
I1018 12:01:18.216161 11069 solver.cpp:242] Iteration 30060, loss = 0.22343
I1018 12:01:18.216187 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704462 (* 1 = 0.0704462 loss)
I1018 12:01:18.216192 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.152983 (* 1 = 0.152983 loss)
I1018 12:01:18.216197 11069 solver.cpp:571] Iteration 30060, lr = 0.0001
I1018 12:01:25.812305 11069 solver.cpp:242] Iteration 30080, loss = 0.987904
I1018 12:01:25.812331 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.35028 (* 1 = 0.35028 loss)
I1018 12:01:25.812336 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.637624 (* 1 = 0.637624 loss)
I1018 12:01:25.812340 11069 solver.cpp:571] Iteration 30080, lr = 0.0001
I1018 12:01:33.548492 11069 solver.cpp:242] Iteration 30100, loss = 0.773456
I1018 12:01:33.548517 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.190714 (* 1 = 0.190714 loss)
I1018 12:01:33.548523 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.582741 (* 1 = 0.582741 loss)
I1018 12:01:33.548527 11069 solver.cpp:571] Iteration 30100, lr = 0.0001
I1018 12:01:41.114358 11069 solver.cpp:242] Iteration 30120, loss = 1.01392
I1018 12:01:41.114382 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.420964 (* 1 = 0.420964 loss)
I1018 12:01:41.114387 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.592959 (* 1 = 0.592959 loss)
I1018 12:01:41.114392 11069 solver.cpp:571] Iteration 30120, lr = 0.0001
I1018 12:01:48.700143 11069 solver.cpp:242] Iteration 30140, loss = 0.159155
I1018 12:01:48.700170 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0190047 (* 1 = 0.0190047 loss)
I1018 12:01:48.700175 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140151 (* 1 = 0.140151 loss)
I1018 12:01:48.700178 11069 solver.cpp:571] Iteration 30140, lr = 0.0001
I1018 12:01:56.366899 11069 solver.cpp:242] Iteration 30160, loss = 1.07242
I1018 12:01:56.366925 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.406489 (* 1 = 0.406489 loss)
I1018 12:01:56.366930 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.665928 (* 1 = 0.665928 loss)
I1018 12:01:56.366935 11069 solver.cpp:571] Iteration 30160, lr = 0.0001
I1018 12:02:04.052755 11069 solver.cpp:242] Iteration 30180, loss = 0.283978
I1018 12:02:04.052781 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0821319 (* 1 = 0.0821319 loss)
I1018 12:02:04.052786 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.201846 (* 1 = 0.201846 loss)
I1018 12:02:04.052791 11069 solver.cpp:571] Iteration 30180, lr = 0.0001
speed: 0.378s / iter
I1018 12:02:11.703521 11069 solver.cpp:242] Iteration 30200, loss = 0.220988
I1018 12:02:11.703547 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0555446 (* 1 = 0.0555446 loss)
I1018 12:02:11.703552 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165443 (* 1 = 0.165443 loss)
I1018 12:02:11.703557 11069 solver.cpp:571] Iteration 30200, lr = 0.0001
I1018 12:02:19.296541 11069 solver.cpp:242] Iteration 30220, loss = 0.427524
I1018 12:02:19.296567 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.102797 (* 1 = 0.102797 loss)
I1018 12:02:19.296572 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.324727 (* 1 = 0.324727 loss)
I1018 12:02:19.296576 11069 solver.cpp:571] Iteration 30220, lr = 0.0001
I1018 12:02:26.880492 11069 solver.cpp:242] Iteration 30240, loss = 0.227556
I1018 12:02:26.880519 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.09036 (* 1 = 0.09036 loss)
I1018 12:02:26.880524 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.137196 (* 1 = 0.137196 loss)
I1018 12:02:26.880528 11069 solver.cpp:571] Iteration 30240, lr = 0.0001
I1018 12:02:34.570127 11069 solver.cpp:242] Iteration 30260, loss = 0.185646
I1018 12:02:34.570152 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0586702 (* 1 = 0.0586702 loss)
I1018 12:02:34.570158 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126976 (* 1 = 0.126976 loss)
I1018 12:02:34.570161 11069 solver.cpp:571] Iteration 30260, lr = 0.0001
I1018 12:02:42.279947 11069 solver.cpp:242] Iteration 30280, loss = 0.240999
I1018 12:02:42.279973 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.046441 (* 1 = 0.046441 loss)
I1018 12:02:42.279978 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194558 (* 1 = 0.194558 loss)
I1018 12:02:42.279981 11069 solver.cpp:571] Iteration 30280, lr = 0.0001
I1018 12:02:49.848987 11069 solver.cpp:242] Iteration 30300, loss = 0.171007
I1018 12:02:49.849014 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0299773 (* 1 = 0.0299773 loss)
I1018 12:02:49.849020 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.14103 (* 1 = 0.14103 loss)
I1018 12:02:49.849023 11069 solver.cpp:571] Iteration 30300, lr = 0.0001
I1018 12:02:57.507889 11069 solver.cpp:242] Iteration 30320, loss = 0.169708
I1018 12:02:57.507915 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.052896 (* 1 = 0.052896 loss)
I1018 12:02:57.507920 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116812 (* 1 = 0.116812 loss)
I1018 12:02:57.507925 11069 solver.cpp:571] Iteration 30320, lr = 0.0001
I1018 12:03:05.116070 11069 solver.cpp:242] Iteration 30340, loss = 0.636676
I1018 12:03:05.116096 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.214573 (* 1 = 0.214573 loss)
I1018 12:03:05.116101 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.422103 (* 1 = 0.422103 loss)
I1018 12:03:05.116104 11069 solver.cpp:571] Iteration 30340, lr = 0.0001
I1018 12:03:12.719030 11069 solver.cpp:242] Iteration 30360, loss = 0.20189
I1018 12:03:12.719058 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.033132 (* 1 = 0.033132 loss)
I1018 12:03:12.719063 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.168758 (* 1 = 0.168758 loss)
I1018 12:03:12.719066 11069 solver.cpp:571] Iteration 30360, lr = 0.0001
I1018 12:03:20.374909 11069 solver.cpp:242] Iteration 30380, loss = 0.240003
I1018 12:03:20.374933 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0276693 (* 1 = 0.0276693 loss)
I1018 12:03:20.374938 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212334 (* 1 = 0.212334 loss)
I1018 12:03:20.374943 11069 solver.cpp:571] Iteration 30380, lr = 0.0001
speed: 0.378s / iter
I1018 12:03:28.031527 11069 solver.cpp:242] Iteration 30400, loss = 1.47181
I1018 12:03:28.031553 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.615605 (* 1 = 0.615605 loss)
I1018 12:03:28.031558 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.856209 (* 1 = 0.856209 loss)
I1018 12:03:28.031563 11069 solver.cpp:571] Iteration 30400, lr = 0.0001
I1018 12:03:35.667003 11069 solver.cpp:242] Iteration 30420, loss = 0.866618
I1018 12:03:35.667029 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.36113 (* 1 = 0.36113 loss)
I1018 12:03:35.667034 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.505488 (* 1 = 0.505488 loss)
I1018 12:03:35.667038 11069 solver.cpp:571] Iteration 30420, lr = 0.0001
I1018 12:03:43.334408 11069 solver.cpp:242] Iteration 30440, loss = 0.413504
I1018 12:03:43.334432 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.107111 (* 1 = 0.107111 loss)
I1018 12:03:43.334436 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.306393 (* 1 = 0.306393 loss)
I1018 12:03:43.334440 11069 solver.cpp:571] Iteration 30440, lr = 0.0001
I1018 12:03:50.798987 11069 solver.cpp:242] Iteration 30460, loss = 0.528025
I1018 12:03:50.799012 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.125893 (* 1 = 0.125893 loss)
I1018 12:03:50.799017 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.402132 (* 1 = 0.402132 loss)
I1018 12:03:50.799021 11069 solver.cpp:571] Iteration 30460, lr = 0.0001
I1018 12:03:58.387523 11069 solver.cpp:242] Iteration 30480, loss = 0.390403
I1018 12:03:58.387549 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0803995 (* 1 = 0.0803995 loss)
I1018 12:03:58.387553 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.310004 (* 1 = 0.310004 loss)
I1018 12:03:58.387557 11069 solver.cpp:571] Iteration 30480, lr = 0.0001
I1018 12:04:05.978338 11069 solver.cpp:242] Iteration 30500, loss = 0.829612
I1018 12:04:05.978361 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.2665 (* 1 = 0.2665 loss)
I1018 12:04:05.978365 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.563112 (* 1 = 0.563112 loss)
I1018 12:04:05.978369 11069 solver.cpp:571] Iteration 30500, lr = 0.0001
I1018 12:04:13.694005 11069 solver.cpp:242] Iteration 30520, loss = 0.222799
I1018 12:04:13.694031 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0836169 (* 1 = 0.0836169 loss)
I1018 12:04:13.694036 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.139182 (* 1 = 0.139182 loss)
I1018 12:04:13.694038 11069 solver.cpp:571] Iteration 30520, lr = 0.0001
I1018 12:04:21.330013 11069 solver.cpp:242] Iteration 30540, loss = 0.259455
I1018 12:04:21.330039 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0791116 (* 1 = 0.0791116 loss)
I1018 12:04:21.330044 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.180344 (* 1 = 0.180344 loss)
I1018 12:04:21.330047 11069 solver.cpp:571] Iteration 30540, lr = 0.0001
I1018 12:04:29.017218 11069 solver.cpp:242] Iteration 30560, loss = 1.26553
I1018 12:04:29.017244 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.292884 (* 1 = 0.292884 loss)
I1018 12:04:29.017248 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.972645 (* 1 = 0.972645 loss)
I1018 12:04:29.017253 11069 solver.cpp:571] Iteration 30560, lr = 0.0001
I1018 12:04:36.736194 11069 solver.cpp:242] Iteration 30580, loss = 0.136765
I1018 12:04:36.736220 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0286854 (* 1 = 0.0286854 loss)
I1018 12:04:36.736225 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.108079 (* 1 = 0.108079 loss)
I1018 12:04:36.736229 11069 solver.cpp:571] Iteration 30580, lr = 0.0001
speed: 0.378s / iter
I1018 12:04:44.315968 11069 solver.cpp:242] Iteration 30600, loss = 0.352974
I1018 12:04:44.315994 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0678842 (* 1 = 0.0678842 loss)
I1018 12:04:44.315999 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.285089 (* 1 = 0.285089 loss)
I1018 12:04:44.316004 11069 solver.cpp:571] Iteration 30600, lr = 0.0001
I1018 12:04:51.926204 11069 solver.cpp:242] Iteration 30620, loss = 0.61128
I1018 12:04:51.926230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.243261 (* 1 = 0.243261 loss)
I1018 12:04:51.926235 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.368019 (* 1 = 0.368019 loss)
I1018 12:04:51.926240 11069 solver.cpp:571] Iteration 30620, lr = 0.0001
I1018 12:04:59.550201 11069 solver.cpp:242] Iteration 30640, loss = 0.263482
I1018 12:04:59.550227 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0449719 (* 1 = 0.0449719 loss)
I1018 12:04:59.550232 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21851 (* 1 = 0.21851 loss)
I1018 12:04:59.550236 11069 solver.cpp:571] Iteration 30640, lr = 0.0001
I1018 12:05:07.172179 11069 solver.cpp:242] Iteration 30660, loss = 0.850812
I1018 12:05:07.172205 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.332387 (* 1 = 0.332387 loss)
I1018 12:05:07.172209 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.518426 (* 1 = 0.518426 loss)
I1018 12:05:07.172214 11069 solver.cpp:571] Iteration 30660, lr = 0.0001
I1018 12:05:14.764305 11069 solver.cpp:242] Iteration 30680, loss = 0.634592
I1018 12:05:14.764331 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.242696 (* 1 = 0.242696 loss)
I1018 12:05:14.764336 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.391896 (* 1 = 0.391896 loss)
I1018 12:05:14.764340 11069 solver.cpp:571] Iteration 30680, lr = 0.0001
I1018 12:05:22.358315 11069 solver.cpp:242] Iteration 30700, loss = 0.187813
I1018 12:05:22.358342 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0607657 (* 1 = 0.0607657 loss)
I1018 12:05:22.358347 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.127047 (* 1 = 0.127047 loss)
I1018 12:05:22.358351 11069 solver.cpp:571] Iteration 30700, lr = 0.0001
I1018 12:05:30.108430 11069 solver.cpp:242] Iteration 30720, loss = 0.621453
I1018 12:05:30.108454 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.162682 (* 1 = 0.162682 loss)
I1018 12:05:30.108459 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.458771 (* 1 = 0.458771 loss)
I1018 12:05:30.108464 11069 solver.cpp:571] Iteration 30720, lr = 0.0001
I1018 12:05:37.774391 11069 solver.cpp:242] Iteration 30740, loss = 1.54303
I1018 12:05:37.774417 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.735776 (* 1 = 0.735776 loss)
I1018 12:05:37.774422 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.807257 (* 1 = 0.807257 loss)
I1018 12:05:37.774426 11069 solver.cpp:571] Iteration 30740, lr = 0.0001
I1018 12:05:45.454440 11069 solver.cpp:242] Iteration 30760, loss = 0.123451
I1018 12:05:45.454466 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.034045 (* 1 = 0.034045 loss)
I1018 12:05:45.454471 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0894062 (* 1 = 0.0894062 loss)
I1018 12:05:45.454474 11069 solver.cpp:571] Iteration 30760, lr = 0.0001
I1018 12:05:53.046746 11069 solver.cpp:242] Iteration 30780, loss = 0.35577
I1018 12:05:53.046772 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139055 (* 1 = 0.139055 loss)
I1018 12:05:53.046777 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216714 (* 1 = 0.216714 loss)
I1018 12:05:53.046780 11069 solver.cpp:571] Iteration 30780, lr = 0.0001
speed: 0.378s / iter
I1018 12:06:00.601771 11069 solver.cpp:242] Iteration 30800, loss = 0.500425
I1018 12:06:00.601796 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168993 (* 1 = 0.168993 loss)
I1018 12:06:00.601800 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.331432 (* 1 = 0.331432 loss)
I1018 12:06:00.601804 11069 solver.cpp:571] Iteration 30800, lr = 0.0001
I1018 12:06:08.211470 11069 solver.cpp:242] Iteration 30820, loss = 0.16974
I1018 12:06:08.211495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0525927 (* 1 = 0.0525927 loss)
I1018 12:06:08.211500 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.117147 (* 1 = 0.117147 loss)
I1018 12:06:08.211504 11069 solver.cpp:571] Iteration 30820, lr = 0.0001
I1018 12:06:15.877552 11069 solver.cpp:242] Iteration 30840, loss = 0.223798
I1018 12:06:15.877578 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0578165 (* 1 = 0.0578165 loss)
I1018 12:06:15.877583 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165982 (* 1 = 0.165982 loss)
I1018 12:06:15.877586 11069 solver.cpp:571] Iteration 30840, lr = 0.0001
I1018 12:06:23.591922 11069 solver.cpp:242] Iteration 30860, loss = 0.684324
I1018 12:06:23.591949 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.278318 (* 1 = 0.278318 loss)
I1018 12:06:23.591954 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.406007 (* 1 = 0.406007 loss)
I1018 12:06:23.591958 11069 solver.cpp:571] Iteration 30860, lr = 0.0001
I1018 12:06:31.230471 11069 solver.cpp:242] Iteration 30880, loss = 0.308787
I1018 12:06:31.230497 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0612667 (* 1 = 0.0612667 loss)
I1018 12:06:31.230502 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.247521 (* 1 = 0.247521 loss)
I1018 12:06:31.230506 11069 solver.cpp:571] Iteration 30880, lr = 0.0001
I1018 12:06:38.889827 11069 solver.cpp:242] Iteration 30900, loss = 1.12388
I1018 12:06:38.889853 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.463626 (* 1 = 0.463626 loss)
I1018 12:06:38.889858 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.660253 (* 1 = 0.660253 loss)
I1018 12:06:38.889863 11069 solver.cpp:571] Iteration 30900, lr = 0.0001
I1018 12:06:46.562094 11069 solver.cpp:242] Iteration 30920, loss = 0.482611
I1018 12:06:46.562120 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0958704 (* 1 = 0.0958704 loss)
I1018 12:06:46.562126 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.38674 (* 1 = 0.38674 loss)
I1018 12:06:46.562130 11069 solver.cpp:571] Iteration 30920, lr = 0.0001
I1018 12:06:54.216241 11069 solver.cpp:242] Iteration 30940, loss = 0.627906
I1018 12:06:54.216267 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.19053 (* 1 = 0.19053 loss)
I1018 12:06:54.216272 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.437377 (* 1 = 0.437377 loss)
I1018 12:06:54.216276 11069 solver.cpp:571] Iteration 30940, lr = 0.0001
I1018 12:07:01.819583 11069 solver.cpp:242] Iteration 30960, loss = 0.623977
I1018 12:07:01.819607 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.241296 (* 1 = 0.241296 loss)
I1018 12:07:01.819612 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.382681 (* 1 = 0.382681 loss)
I1018 12:07:01.819617 11069 solver.cpp:571] Iteration 30960, lr = 0.0001
I1018 12:07:09.424543 11069 solver.cpp:242] Iteration 30980, loss = 0.569616
I1018 12:07:09.424569 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161105 (* 1 = 0.161105 loss)
I1018 12:07:09.424574 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.408512 (* 1 = 0.408512 loss)
I1018 12:07:09.424578 11069 solver.cpp:571] Iteration 30980, lr = 0.0001
speed: 0.378s / iter
I1018 12:07:17.007761 11069 solver.cpp:242] Iteration 31000, loss = 0.181832
I1018 12:07:17.007786 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0414546 (* 1 = 0.0414546 loss)
I1018 12:07:17.007791 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140377 (* 1 = 0.140377 loss)
I1018 12:07:17.007796 11069 solver.cpp:571] Iteration 31000, lr = 0.0001
I1018 12:07:24.684679 11069 solver.cpp:242] Iteration 31020, loss = 0.472997
I1018 12:07:24.684703 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.16087 (* 1 = 0.16087 loss)
I1018 12:07:24.684708 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.312127 (* 1 = 0.312127 loss)
I1018 12:07:24.684712 11069 solver.cpp:571] Iteration 31020, lr = 0.0001
I1018 12:07:32.243515 11069 solver.cpp:242] Iteration 31040, loss = 0.296402
I1018 12:07:32.243541 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0911069 (* 1 = 0.0911069 loss)
I1018 12:07:32.243546 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205295 (* 1 = 0.205295 loss)
I1018 12:07:32.243551 11069 solver.cpp:571] Iteration 31040, lr = 0.0001
I1018 12:07:39.821203 11069 solver.cpp:242] Iteration 31060, loss = 0.276949
I1018 12:07:39.821229 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0687467 (* 1 = 0.0687467 loss)
I1018 12:07:39.821234 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208202 (* 1 = 0.208202 loss)
I1018 12:07:39.821238 11069 solver.cpp:571] Iteration 31060, lr = 0.0001
I1018 12:07:47.534359 11069 solver.cpp:242] Iteration 31080, loss = 0.895717
I1018 12:07:47.534385 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.402958 (* 1 = 0.402958 loss)
I1018 12:07:47.534390 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.492759 (* 1 = 0.492759 loss)
I1018 12:07:47.534395 11069 solver.cpp:571] Iteration 31080, lr = 0.0001
I1018 12:07:55.108655 11069 solver.cpp:242] Iteration 31100, loss = 0.269929
I1018 12:07:55.108680 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0617318 (* 1 = 0.0617318 loss)
I1018 12:07:55.108686 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.208197 (* 1 = 0.208197 loss)
I1018 12:07:55.108690 11069 solver.cpp:571] Iteration 31100, lr = 0.0001
I1018 12:08:02.685348 11069 solver.cpp:242] Iteration 31120, loss = 0.306922
I1018 12:08:02.685374 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.077817 (* 1 = 0.077817 loss)
I1018 12:08:02.685379 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.229105 (* 1 = 0.229105 loss)
I1018 12:08:02.685384 11069 solver.cpp:571] Iteration 31120, lr = 0.0001
I1018 12:08:10.351480 11069 solver.cpp:242] Iteration 31140, loss = 0.675319
I1018 12:08:10.351505 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.254094 (* 1 = 0.254094 loss)
I1018 12:08:10.351510 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.421225 (* 1 = 0.421225 loss)
I1018 12:08:10.351513 11069 solver.cpp:571] Iteration 31140, lr = 0.0001
I1018 12:08:17.952579 11069 solver.cpp:242] Iteration 31160, loss = 0.5491
I1018 12:08:17.952605 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153254 (* 1 = 0.153254 loss)
I1018 12:08:17.952610 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.395846 (* 1 = 0.395846 loss)
I1018 12:08:17.952613 11069 solver.cpp:571] Iteration 31160, lr = 0.0001
I1018 12:08:25.628705 11069 solver.cpp:242] Iteration 31180, loss = 0.752609
I1018 12:08:25.628731 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.258857 (* 1 = 0.258857 loss)
I1018 12:08:25.628734 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.493752 (* 1 = 0.493752 loss)
I1018 12:08:25.628738 11069 solver.cpp:571] Iteration 31180, lr = 0.0001
speed: 0.378s / iter
I1018 12:08:33.252588 11069 solver.cpp:242] Iteration 31200, loss = 0.196611
I1018 12:08:33.252612 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0459122 (* 1 = 0.0459122 loss)
I1018 12:08:33.252616 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.150699 (* 1 = 0.150699 loss)
I1018 12:08:33.252620 11069 solver.cpp:571] Iteration 31200, lr = 0.0001
I1018 12:08:40.928724 11069 solver.cpp:242] Iteration 31220, loss = 0.19578
I1018 12:08:40.928747 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.073457 (* 1 = 0.073457 loss)
I1018 12:08:40.928752 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.122323 (* 1 = 0.122323 loss)
I1018 12:08:40.928756 11069 solver.cpp:571] Iteration 31220, lr = 0.0001
I1018 12:08:48.485319 11069 solver.cpp:242] Iteration 31240, loss = 0.131026
I1018 12:08:48.485345 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0263353 (* 1 = 0.0263353 loss)
I1018 12:08:48.485349 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.104691 (* 1 = 0.104691 loss)
I1018 12:08:48.485353 11069 solver.cpp:571] Iteration 31240, lr = 0.0001
I1018 12:08:56.157964 11069 solver.cpp:242] Iteration 31260, loss = 0.991306
I1018 12:08:56.157989 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.348137 (* 1 = 0.348137 loss)
I1018 12:08:56.157994 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.643169 (* 1 = 0.643169 loss)
I1018 12:08:56.157997 11069 solver.cpp:571] Iteration 31260, lr = 0.0001
I1018 12:09:03.787191 11069 solver.cpp:242] Iteration 31280, loss = 0.667151
I1018 12:09:03.787217 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.175888 (* 1 = 0.175888 loss)
I1018 12:09:03.787221 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.491262 (* 1 = 0.491262 loss)
I1018 12:09:03.787225 11069 solver.cpp:571] Iteration 31280, lr = 0.0001
I1018 12:09:11.317961 11069 solver.cpp:242] Iteration 31300, loss = 0.531127
I1018 12:09:11.317986 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.177629 (* 1 = 0.177629 loss)
I1018 12:09:11.317991 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.353498 (* 1 = 0.353498 loss)
I1018 12:09:11.317996 11069 solver.cpp:571] Iteration 31300, lr = 0.0001
I1018 12:09:18.985165 11069 solver.cpp:242] Iteration 31320, loss = 0.689219
I1018 12:09:18.985190 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.224533 (* 1 = 0.224533 loss)
I1018 12:09:18.985195 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.464686 (* 1 = 0.464686 loss)
I1018 12:09:18.985199 11069 solver.cpp:571] Iteration 31320, lr = 0.0001
I1018 12:09:26.676646 11069 solver.cpp:242] Iteration 31340, loss = 0.235703
I1018 12:09:26.676671 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0694405 (* 1 = 0.0694405 loss)
I1018 12:09:26.676676 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166262 (* 1 = 0.166262 loss)
I1018 12:09:26.676679 11069 solver.cpp:571] Iteration 31340, lr = 0.0001
I1018 12:09:34.252148 11069 solver.cpp:242] Iteration 31360, loss = 0.444129
I1018 12:09:34.252173 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.134053 (* 1 = 0.134053 loss)
I1018 12:09:34.252177 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.310077 (* 1 = 0.310077 loss)
I1018 12:09:34.252182 11069 solver.cpp:571] Iteration 31360, lr = 0.0001
I1018 12:09:41.809386 11069 solver.cpp:242] Iteration 31380, loss = 0.206507
I1018 12:09:41.809419 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0278539 (* 1 = 0.0278539 loss)
I1018 12:09:41.809424 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178653 (* 1 = 0.178653 loss)
I1018 12:09:41.809428 11069 solver.cpp:571] Iteration 31380, lr = 0.0001
speed: 0.378s / iter
I1018 12:09:49.462206 11069 solver.cpp:242] Iteration 31400, loss = 0.88752
I1018 12:09:49.462231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.281549 (* 1 = 0.281549 loss)
I1018 12:09:49.462236 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.605971 (* 1 = 0.605971 loss)
I1018 12:09:49.462240 11069 solver.cpp:571] Iteration 31400, lr = 0.0001
I1018 12:09:57.060684 11069 solver.cpp:242] Iteration 31420, loss = 0.190694
I1018 12:09:57.060711 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306441 (* 1 = 0.0306441 loss)
I1018 12:09:57.060716 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.16005 (* 1 = 0.16005 loss)
I1018 12:09:57.060720 11069 solver.cpp:571] Iteration 31420, lr = 0.0001
I1018 12:10:04.714931 11069 solver.cpp:242] Iteration 31440, loss = 0.302413
I1018 12:10:04.714957 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0844312 (* 1 = 0.0844312 loss)
I1018 12:10:04.714962 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.217982 (* 1 = 0.217982 loss)
I1018 12:10:04.714967 11069 solver.cpp:571] Iteration 31440, lr = 0.0001
I1018 12:10:12.349005 11069 solver.cpp:242] Iteration 31460, loss = 1.04064
I1018 12:10:12.349031 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.496234 (* 1 = 0.496234 loss)
I1018 12:10:12.349036 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.544406 (* 1 = 0.544406 loss)
I1018 12:10:12.349040 11069 solver.cpp:571] Iteration 31460, lr = 0.0001
I1018 12:10:19.886042 11069 solver.cpp:242] Iteration 31480, loss = 0.285314
I1018 12:10:19.886067 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0781045 (* 1 = 0.0781045 loss)
I1018 12:10:19.886072 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.20721 (* 1 = 0.20721 loss)
I1018 12:10:19.886075 11069 solver.cpp:571] Iteration 31480, lr = 0.0001
I1018 12:10:27.523936 11069 solver.cpp:242] Iteration 31500, loss = 0.355979
I1018 12:10:27.523962 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114332 (* 1 = 0.114332 loss)
I1018 12:10:27.523967 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.241647 (* 1 = 0.241647 loss)
I1018 12:10:27.523970 11069 solver.cpp:571] Iteration 31500, lr = 0.0001
I1018 12:10:35.074972 11069 solver.cpp:242] Iteration 31520, loss = 0.161291
I1018 12:10:35.074998 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0287126 (* 1 = 0.0287126 loss)
I1018 12:10:35.075003 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.132579 (* 1 = 0.132579 loss)
I1018 12:10:35.075007 11069 solver.cpp:571] Iteration 31520, lr = 0.0001
I1018 12:10:42.572540 11069 solver.cpp:242] Iteration 31540, loss = 0.274831
I1018 12:10:42.572566 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.102282 (* 1 = 0.102282 loss)
I1018 12:10:42.572571 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.172549 (* 1 = 0.172549 loss)
I1018 12:10:42.572573 11069 solver.cpp:571] Iteration 31540, lr = 0.0001
I1018 12:10:50.226030 11069 solver.cpp:242] Iteration 31560, loss = 1.16355
I1018 12:10:50.226054 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.402898 (* 1 = 0.402898 loss)
I1018 12:10:50.226058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.760653 (* 1 = 0.760653 loss)
I1018 12:10:50.226063 11069 solver.cpp:571] Iteration 31560, lr = 0.0001
I1018 12:10:57.815932 11069 solver.cpp:242] Iteration 31580, loss = 0.532918
I1018 12:10:57.815955 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.190477 (* 1 = 0.190477 loss)
I1018 12:10:57.815960 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.342441 (* 1 = 0.342441 loss)
I1018 12:10:57.815964 11069 solver.cpp:571] Iteration 31580, lr = 0.0001
speed: 0.378s / iter
I1018 12:11:05.371615 11069 solver.cpp:242] Iteration 31600, loss = 0.268503
I1018 12:11:05.371641 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0787656 (* 1 = 0.0787656 loss)
I1018 12:11:05.371645 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.189737 (* 1 = 0.189737 loss)
I1018 12:11:05.371649 11069 solver.cpp:571] Iteration 31600, lr = 0.0001
I1018 12:11:13.090041 11069 solver.cpp:242] Iteration 31620, loss = 0.407735
I1018 12:11:13.090066 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0758411 (* 1 = 0.0758411 loss)
I1018 12:11:13.090071 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.331894 (* 1 = 0.331894 loss)
I1018 12:11:13.090075 11069 solver.cpp:571] Iteration 31620, lr = 0.0001
I1018 12:11:20.726621 11069 solver.cpp:242] Iteration 31640, loss = 1.19225
I1018 12:11:20.726647 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.563834 (* 1 = 0.563834 loss)
I1018 12:11:20.726652 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.628416 (* 1 = 0.628416 loss)
I1018 12:11:20.726656 11069 solver.cpp:571] Iteration 31640, lr = 0.0001
I1018 12:11:28.339062 11069 solver.cpp:242] Iteration 31660, loss = 0.86366
I1018 12:11:28.339087 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.361828 (* 1 = 0.361828 loss)
I1018 12:11:28.339092 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.501832 (* 1 = 0.501832 loss)
I1018 12:11:28.339095 11069 solver.cpp:571] Iteration 31660, lr = 0.0001
I1018 12:11:36.004226 11069 solver.cpp:242] Iteration 31680, loss = 1.36918
I1018 12:11:36.004251 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.613756 (* 1 = 0.613756 loss)
I1018 12:11:36.004256 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.755423 (* 1 = 0.755423 loss)
I1018 12:11:36.004259 11069 solver.cpp:571] Iteration 31680, lr = 0.0001
I1018 12:11:43.482484 11069 solver.cpp:242] Iteration 31700, loss = 0.383559
I1018 12:11:43.482511 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.103599 (* 1 = 0.103599 loss)
I1018 12:11:43.482516 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.27996 (* 1 = 0.27996 loss)
I1018 12:11:43.482519 11069 solver.cpp:571] Iteration 31700, lr = 0.0001
I1018 12:11:51.091439 11069 solver.cpp:242] Iteration 31720, loss = 0.756717
I1018 12:11:51.091464 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.218187 (* 1 = 0.218187 loss)
I1018 12:11:51.091470 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.53853 (* 1 = 0.53853 loss)
I1018 12:11:51.091473 11069 solver.cpp:571] Iteration 31720, lr = 0.0001
I1018 12:11:58.705773 11069 solver.cpp:242] Iteration 31740, loss = 0.10464
I1018 12:11:58.705799 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.031714 (* 1 = 0.031714 loss)
I1018 12:11:58.705804 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0729255 (* 1 = 0.0729255 loss)
I1018 12:11:58.705808 11069 solver.cpp:571] Iteration 31740, lr = 0.0001
I1018 12:12:06.342432 11069 solver.cpp:242] Iteration 31760, loss = 0.713901
I1018 12:12:06.342458 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.36264 (* 1 = 0.36264 loss)
I1018 12:12:06.342463 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.351261 (* 1 = 0.351261 loss)
I1018 12:12:06.342466 11069 solver.cpp:571] Iteration 31760, lr = 0.0001
I1018 12:12:13.960659 11069 solver.cpp:242] Iteration 31780, loss = 0.348831
I1018 12:12:13.960685 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0942382 (* 1 = 0.0942382 loss)
I1018 12:12:13.960690 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254593 (* 1 = 0.254593 loss)
I1018 12:12:13.960695 11069 solver.cpp:571] Iteration 31780, lr = 0.0001
speed: 0.378s / iter
I1018 12:12:21.487880 11069 solver.cpp:242] Iteration 31800, loss = 0.120176
I1018 12:12:21.487906 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306859 (* 1 = 0.0306859 loss)
I1018 12:12:21.487911 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0894904 (* 1 = 0.0894904 loss)
I1018 12:12:21.487915 11069 solver.cpp:571] Iteration 31800, lr = 0.0001
I1018 12:12:29.146144 11069 solver.cpp:242] Iteration 31820, loss = 0.290487
I1018 12:12:29.146170 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.111923 (* 1 = 0.111923 loss)
I1018 12:12:29.146176 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178565 (* 1 = 0.178565 loss)
I1018 12:12:29.146179 11069 solver.cpp:571] Iteration 31820, lr = 0.0001
I1018 12:12:36.769520 11069 solver.cpp:242] Iteration 31840, loss = 0.362277
I1018 12:12:36.769546 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0835379 (* 1 = 0.0835379 loss)
I1018 12:12:36.769551 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.278739 (* 1 = 0.278739 loss)
I1018 12:12:36.769556 11069 solver.cpp:571] Iteration 31840, lr = 0.0001
I1018 12:12:44.515254 11069 solver.cpp:242] Iteration 31860, loss = 2.1875
I1018 12:12:44.515280 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.186 (* 1 = 1.186 loss)
I1018 12:12:44.515283 11069 solver.cpp:258]     Train net output #1: loss_cls = 1.0015 (* 1 = 1.0015 loss)
I1018 12:12:44.515287 11069 solver.cpp:571] Iteration 31860, lr = 0.0001
I1018 12:12:52.151784 11069 solver.cpp:242] Iteration 31880, loss = 0.0806821
I1018 12:12:52.151810 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0230901 (* 1 = 0.0230901 loss)
I1018 12:12:52.151814 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.057592 (* 1 = 0.057592 loss)
I1018 12:12:52.151819 11069 solver.cpp:571] Iteration 31880, lr = 0.0001
I1018 12:12:59.926496 11069 solver.cpp:242] Iteration 31900, loss = 0.145784
I1018 12:12:59.926522 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.050329 (* 1 = 0.050329 loss)
I1018 12:12:59.926527 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0954549 (* 1 = 0.0954549 loss)
I1018 12:12:59.926532 11069 solver.cpp:571] Iteration 31900, lr = 0.0001
I1018 12:13:07.503929 11069 solver.cpp:242] Iteration 31920, loss = 0.207143
I1018 12:13:07.503955 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0527431 (* 1 = 0.0527431 loss)
I1018 12:13:07.503962 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.1544 (* 1 = 0.1544 loss)
I1018 12:13:07.503965 11069 solver.cpp:571] Iteration 31920, lr = 0.0001
I1018 12:13:15.183969 11069 solver.cpp:242] Iteration 31940, loss = 0.799308
I1018 12:13:15.183993 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.216055 (* 1 = 0.216055 loss)
I1018 12:13:15.183998 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.583253 (* 1 = 0.583253 loss)
I1018 12:13:15.184003 11069 solver.cpp:571] Iteration 31940, lr = 0.0001
I1018 12:13:22.843987 11069 solver.cpp:242] Iteration 31960, loss = 0.311064
I1018 12:13:22.844013 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.086507 (* 1 = 0.086507 loss)
I1018 12:13:22.844018 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224557 (* 1 = 0.224557 loss)
I1018 12:13:22.844022 11069 solver.cpp:571] Iteration 31960, lr = 0.0001
I1018 12:13:30.528280 11069 solver.cpp:242] Iteration 31980, loss = 1.4819
I1018 12:13:30.528306 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.568899 (* 1 = 0.568899 loss)
I1018 12:13:30.528311 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.913003 (* 1 = 0.913003 loss)
I1018 12:13:30.528316 11069 solver.cpp:571] Iteration 31980, lr = 0.0001
speed: 0.378s / iter
I1018 12:13:38.063854 11069 solver.cpp:242] Iteration 32000, loss = 0.229785
I1018 12:13:38.063880 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0512295 (* 1 = 0.0512295 loss)
I1018 12:13:38.063885 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178555 (* 1 = 0.178555 loss)
I1018 12:13:38.063889 11069 solver.cpp:571] Iteration 32000, lr = 0.0001
I1018 12:13:45.770297 11069 solver.cpp:242] Iteration 32020, loss = 0.73057
I1018 12:13:45.770321 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.24167 (* 1 = 0.24167 loss)
I1018 12:13:45.770326 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.488901 (* 1 = 0.488901 loss)
I1018 12:13:45.770331 11069 solver.cpp:571] Iteration 32020, lr = 0.0001
I1018 12:13:53.354737 11069 solver.cpp:242] Iteration 32040, loss = 0.346133
I1018 12:13:53.354763 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159858 (* 1 = 0.159858 loss)
I1018 12:13:53.354768 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.186275 (* 1 = 0.186275 loss)
I1018 12:13:53.354773 11069 solver.cpp:571] Iteration 32040, lr = 0.0001
I1018 12:14:00.934526 11069 solver.cpp:242] Iteration 32060, loss = 0.118933
I1018 12:14:00.934552 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0216843 (* 1 = 0.0216843 loss)
I1018 12:14:00.934557 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0972484 (* 1 = 0.0972484 loss)
I1018 12:14:00.934561 11069 solver.cpp:571] Iteration 32060, lr = 0.0001
I1018 12:14:08.569494 11069 solver.cpp:242] Iteration 32080, loss = 0.19836
I1018 12:14:08.569519 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0577484 (* 1 = 0.0577484 loss)
I1018 12:14:08.569525 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.140612 (* 1 = 0.140612 loss)
I1018 12:14:08.569528 11069 solver.cpp:571] Iteration 32080, lr = 0.0001
I1018 12:14:16.220234 11069 solver.cpp:242] Iteration 32100, loss = 0.467736
I1018 12:14:16.220260 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151368 (* 1 = 0.151368 loss)
I1018 12:14:16.220264 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.316368 (* 1 = 0.316368 loss)
I1018 12:14:16.220268 11069 solver.cpp:571] Iteration 32100, lr = 0.0001
I1018 12:14:23.861861 11069 solver.cpp:242] Iteration 32120, loss = 0.557306
I1018 12:14:23.861886 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135788 (* 1 = 0.135788 loss)
I1018 12:14:23.861891 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.421518 (* 1 = 0.421518 loss)
I1018 12:14:23.861896 11069 solver.cpp:571] Iteration 32120, lr = 0.0001
I1018 12:14:31.553441 11069 solver.cpp:242] Iteration 32140, loss = 0.610742
I1018 12:14:31.553465 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170852 (* 1 = 0.170852 loss)
I1018 12:14:31.553470 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.439891 (* 1 = 0.439891 loss)
I1018 12:14:31.553474 11069 solver.cpp:571] Iteration 32140, lr = 0.0001
I1018 12:14:39.204109 11069 solver.cpp:242] Iteration 32160, loss = 0.399865
I1018 12:14:39.204135 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0905168 (* 1 = 0.0905168 loss)
I1018 12:14:39.204140 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.309348 (* 1 = 0.309348 loss)
I1018 12:14:39.204144 11069 solver.cpp:571] Iteration 32160, lr = 0.0001
I1018 12:14:46.817672 11069 solver.cpp:242] Iteration 32180, loss = 0.234813
I1018 12:14:46.817698 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0597991 (* 1 = 0.0597991 loss)
I1018 12:14:46.817703 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.175014 (* 1 = 0.175014 loss)
I1018 12:14:46.817708 11069 solver.cpp:571] Iteration 32180, lr = 0.0001
speed: 0.378s / iter
I1018 12:14:54.388615 11069 solver.cpp:242] Iteration 32200, loss = 0.800941
I1018 12:14:54.388640 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.296485 (* 1 = 0.296485 loss)
I1018 12:14:54.388646 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.504456 (* 1 = 0.504456 loss)
I1018 12:14:54.388650 11069 solver.cpp:571] Iteration 32200, lr = 0.0001
I1018 12:15:02.030637 11069 solver.cpp:242] Iteration 32220, loss = 1.47661
I1018 12:15:02.030664 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.5404 (* 1 = 0.5404 loss)
I1018 12:15:02.030669 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.936208 (* 1 = 0.936208 loss)
I1018 12:15:02.030674 11069 solver.cpp:571] Iteration 32220, lr = 0.0001
I1018 12:15:09.649497 11069 solver.cpp:242] Iteration 32240, loss = 0.198848
I1018 12:15:09.649523 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0671882 (* 1 = 0.0671882 loss)
I1018 12:15:09.649528 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13166 (* 1 = 0.13166 loss)
I1018 12:15:09.649531 11069 solver.cpp:571] Iteration 32240, lr = 0.0001
I1018 12:15:17.251389 11069 solver.cpp:242] Iteration 32260, loss = 0.751362
I1018 12:15:17.251413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.244952 (* 1 = 0.244952 loss)
I1018 12:15:17.251420 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.50641 (* 1 = 0.50641 loss)
I1018 12:15:17.251423 11069 solver.cpp:571] Iteration 32260, lr = 0.0001
I1018 12:15:24.930910 11069 solver.cpp:242] Iteration 32280, loss = 0.148591
I1018 12:15:24.930935 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0598218 (* 1 = 0.0598218 loss)
I1018 12:15:24.930941 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0887688 (* 1 = 0.0887688 loss)
I1018 12:15:24.930945 11069 solver.cpp:571] Iteration 32280, lr = 0.0001
I1018 12:15:32.560396 11069 solver.cpp:242] Iteration 32300, loss = 0.177825
I1018 12:15:32.560422 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479443 (* 1 = 0.0479443 loss)
I1018 12:15:32.560427 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.129881 (* 1 = 0.129881 loss)
I1018 12:15:32.560431 11069 solver.cpp:571] Iteration 32300, lr = 0.0001
I1018 12:15:40.058573 11069 solver.cpp:242] Iteration 32320, loss = 0.327353
I1018 12:15:40.058598 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0482458 (* 1 = 0.0482458 loss)
I1018 12:15:40.058603 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.279107 (* 1 = 0.279107 loss)
I1018 12:15:40.058606 11069 solver.cpp:571] Iteration 32320, lr = 0.0001
I1018 12:15:47.737229 11069 solver.cpp:242] Iteration 32340, loss = 0.302218
I1018 12:15:47.737256 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0902222 (* 1 = 0.0902222 loss)
I1018 12:15:47.737260 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.211996 (* 1 = 0.211996 loss)
I1018 12:15:47.737264 11069 solver.cpp:571] Iteration 32340, lr = 0.0001
I1018 12:15:55.429443 11069 solver.cpp:242] Iteration 32360, loss = 0.190642
I1018 12:15:55.429469 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557827 (* 1 = 0.0557827 loss)
I1018 12:15:55.429474 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.134859 (* 1 = 0.134859 loss)
I1018 12:15:55.429479 11069 solver.cpp:571] Iteration 32360, lr = 0.0001
I1018 12:16:03.020437 11069 solver.cpp:242] Iteration 32380, loss = 0.420073
I1018 12:16:03.020463 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.142076 (* 1 = 0.142076 loss)
I1018 12:16:03.020468 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.277997 (* 1 = 0.277997 loss)
I1018 12:16:03.020473 11069 solver.cpp:571] Iteration 32380, lr = 0.0001
speed: 0.378s / iter
I1018 12:16:10.578411 11069 solver.cpp:242] Iteration 32400, loss = 1.05442
I1018 12:16:10.578438 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.326649 (* 1 = 0.326649 loss)
I1018 12:16:10.578443 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.727766 (* 1 = 0.727766 loss)
I1018 12:16:10.578446 11069 solver.cpp:571] Iteration 32400, lr = 0.0001
I1018 12:16:18.067068 11069 solver.cpp:242] Iteration 32420, loss = 0.154123
I1018 12:16:18.067095 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0470993 (* 1 = 0.0470993 loss)
I1018 12:16:18.067101 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.107024 (* 1 = 0.107024 loss)
I1018 12:16:18.067104 11069 solver.cpp:571] Iteration 32420, lr = 0.0001
I1018 12:16:25.716040 11069 solver.cpp:242] Iteration 32440, loss = 0.554161
I1018 12:16:25.716066 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114812 (* 1 = 0.114812 loss)
I1018 12:16:25.716071 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.439349 (* 1 = 0.439349 loss)
I1018 12:16:25.716076 11069 solver.cpp:571] Iteration 32440, lr = 0.0001
I1018 12:16:33.315951 11069 solver.cpp:242] Iteration 32460, loss = 0.444709
I1018 12:16:33.315976 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.127945 (* 1 = 0.127945 loss)
I1018 12:16:33.315981 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.316764 (* 1 = 0.316764 loss)
I1018 12:16:33.315985 11069 solver.cpp:571] Iteration 32460, lr = 0.0001
I1018 12:16:40.900022 11069 solver.cpp:242] Iteration 32480, loss = 0.905425
I1018 12:16:40.900044 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.336213 (* 1 = 0.336213 loss)
I1018 12:16:40.900050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.569212 (* 1 = 0.569212 loss)
I1018 12:16:40.900054 11069 solver.cpp:571] Iteration 32480, lr = 0.0001
I1018 12:16:48.481370 11069 solver.cpp:242] Iteration 32500, loss = 0.220201
I1018 12:16:48.481396 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0853693 (* 1 = 0.0853693 loss)
I1018 12:16:48.481401 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.134832 (* 1 = 0.134832 loss)
I1018 12:16:48.481405 11069 solver.cpp:571] Iteration 32500, lr = 0.0001
I1018 12:16:56.212582 11069 solver.cpp:242] Iteration 32520, loss = 1.19699
I1018 12:16:56.212608 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.48472 (* 1 = 0.48472 loss)
I1018 12:16:56.212613 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.712269 (* 1 = 0.712269 loss)
I1018 12:16:56.212617 11069 solver.cpp:571] Iteration 32520, lr = 0.0001
I1018 12:17:03.772989 11069 solver.cpp:242] Iteration 32540, loss = 1.15009
I1018 12:17:03.773015 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.413346 (* 1 = 0.413346 loss)
I1018 12:17:03.773020 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.736747 (* 1 = 0.736747 loss)
I1018 12:17:03.773025 11069 solver.cpp:571] Iteration 32540, lr = 0.0001
I1018 12:17:11.472959 11069 solver.cpp:242] Iteration 32560, loss = 0.237106
I1018 12:17:11.472985 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0384142 (* 1 = 0.0384142 loss)
I1018 12:17:11.472990 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.198692 (* 1 = 0.198692 loss)
I1018 12:17:11.472995 11069 solver.cpp:571] Iteration 32560, lr = 0.0001
I1018 12:17:19.050700 11069 solver.cpp:242] Iteration 32580, loss = 1.1944
I1018 12:17:19.050729 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.430929 (* 1 = 0.430929 loss)
I1018 12:17:19.050734 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.763468 (* 1 = 0.763468 loss)
I1018 12:17:19.050737 11069 solver.cpp:571] Iteration 32580, lr = 0.0001
speed: 0.379s / iter
I1018 12:17:26.724534 11069 solver.cpp:242] Iteration 32600, loss = 0.137609
I1018 12:17:26.724560 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0431356 (* 1 = 0.0431356 loss)
I1018 12:17:26.724565 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0944738 (* 1 = 0.0944738 loss)
I1018 12:17:26.724570 11069 solver.cpp:571] Iteration 32600, lr = 0.0001
I1018 12:17:34.316304 11069 solver.cpp:242] Iteration 32620, loss = 0.374753
I1018 12:17:34.316329 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11516 (* 1 = 0.11516 loss)
I1018 12:17:34.316334 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259593 (* 1 = 0.259593 loss)
I1018 12:17:34.316339 11069 solver.cpp:571] Iteration 32620, lr = 0.0001
I1018 12:17:41.951061 11069 solver.cpp:242] Iteration 32640, loss = 0.0984527
I1018 12:17:41.951086 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.032087 (* 1 = 0.032087 loss)
I1018 12:17:41.951092 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0663657 (* 1 = 0.0663657 loss)
I1018 12:17:41.951095 11069 solver.cpp:571] Iteration 32640, lr = 0.0001
I1018 12:17:49.578086 11069 solver.cpp:242] Iteration 32660, loss = 0.282408
I1018 12:17:49.578111 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704874 (* 1 = 0.0704874 loss)
I1018 12:17:49.578117 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.21192 (* 1 = 0.21192 loss)
I1018 12:17:49.578121 11069 solver.cpp:571] Iteration 32660, lr = 0.0001
I1018 12:17:57.187654 11069 solver.cpp:242] Iteration 32680, loss = 0.513145
I1018 12:17:57.187680 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.160456 (* 1 = 0.160456 loss)
I1018 12:17:57.187685 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.352689 (* 1 = 0.352689 loss)
I1018 12:17:57.187688 11069 solver.cpp:571] Iteration 32680, lr = 0.0001
I1018 12:18:04.821553 11069 solver.cpp:242] Iteration 32700, loss = 0.179074
I1018 12:18:04.821580 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0445634 (* 1 = 0.0445634 loss)
I1018 12:18:04.821585 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.134511 (* 1 = 0.134511 loss)
I1018 12:18:04.821590 11069 solver.cpp:571] Iteration 32700, lr = 0.0001
I1018 12:18:12.416885 11069 solver.cpp:242] Iteration 32720, loss = 0.342272
I1018 12:18:12.416913 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108696 (* 1 = 0.108696 loss)
I1018 12:18:12.416918 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.233576 (* 1 = 0.233576 loss)
I1018 12:18:12.416923 11069 solver.cpp:571] Iteration 32720, lr = 0.0001
I1018 12:18:20.016270 11069 solver.cpp:242] Iteration 32740, loss = 0.161623
I1018 12:18:20.016295 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0364738 (* 1 = 0.0364738 loss)
I1018 12:18:20.016300 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.125149 (* 1 = 0.125149 loss)
I1018 12:18:20.016305 11069 solver.cpp:571] Iteration 32740, lr = 0.0001
I1018 12:18:27.738888 11069 solver.cpp:242] Iteration 32760, loss = 0.159627
I1018 12:18:27.738914 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0443894 (* 1 = 0.0443894 loss)
I1018 12:18:27.738919 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.115237 (* 1 = 0.115237 loss)
I1018 12:18:27.738922 11069 solver.cpp:571] Iteration 32760, lr = 0.0001
I1018 12:18:35.395474 11069 solver.cpp:242] Iteration 32780, loss = 0.232847
I1018 12:18:35.395500 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0582542 (* 1 = 0.0582542 loss)
I1018 12:18:35.395505 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.174592 (* 1 = 0.174592 loss)
I1018 12:18:35.395509 11069 solver.cpp:571] Iteration 32780, lr = 0.0001
speed: 0.379s / iter
I1018 12:18:43.080734 11069 solver.cpp:242] Iteration 32800, loss = 0.1687
I1018 12:18:43.080761 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0424275 (* 1 = 0.0424275 loss)
I1018 12:18:43.080766 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126272 (* 1 = 0.126272 loss)
I1018 12:18:43.080770 11069 solver.cpp:571] Iteration 32800, lr = 0.0001
I1018 12:18:50.673146 11069 solver.cpp:242] Iteration 32820, loss = 0.697225
I1018 12:18:50.673172 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.200005 (* 1 = 0.200005 loss)
I1018 12:18:50.673177 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.49722 (* 1 = 0.49722 loss)
I1018 12:18:50.673182 11069 solver.cpp:571] Iteration 32820, lr = 0.0001
I1018 12:18:58.289145 11069 solver.cpp:242] Iteration 32840, loss = 0.693856
I1018 12:18:58.289171 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164228 (* 1 = 0.164228 loss)
I1018 12:18:58.289176 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.529627 (* 1 = 0.529627 loss)
I1018 12:18:58.289180 11069 solver.cpp:571] Iteration 32840, lr = 0.0001
I1018 12:19:05.936008 11069 solver.cpp:242] Iteration 32860, loss = 1.08994
I1018 12:19:05.936034 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.339474 (* 1 = 0.339474 loss)
I1018 12:19:05.936040 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.750463 (* 1 = 0.750463 loss)
I1018 12:19:05.936044 11069 solver.cpp:571] Iteration 32860, lr = 0.0001
I1018 12:19:13.626670 11069 solver.cpp:242] Iteration 32880, loss = 0.214073
I1018 12:19:13.626696 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0609389 (* 1 = 0.0609389 loss)
I1018 12:19:13.626701 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.153134 (* 1 = 0.153134 loss)
I1018 12:19:13.626705 11069 solver.cpp:571] Iteration 32880, lr = 0.0001
I1018 12:19:21.260264 11069 solver.cpp:242] Iteration 32900, loss = 1.66712
I1018 12:19:21.260289 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.67759 (* 1 = 0.67759 loss)
I1018 12:19:21.260294 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.989532 (* 1 = 0.989532 loss)
I1018 12:19:21.260298 11069 solver.cpp:571] Iteration 32900, lr = 0.0001
I1018 12:19:28.874851 11069 solver.cpp:242] Iteration 32920, loss = 0.463537
I1018 12:19:28.874877 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.118952 (* 1 = 0.118952 loss)
I1018 12:19:28.874883 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.344584 (* 1 = 0.344584 loss)
I1018 12:19:28.874887 11069 solver.cpp:571] Iteration 32920, lr = 0.0001
I1018 12:19:36.496582 11069 solver.cpp:242] Iteration 32940, loss = 0.727888
I1018 12:19:36.496608 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.203023 (* 1 = 0.203023 loss)
I1018 12:19:36.496613 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.524865 (* 1 = 0.524865 loss)
I1018 12:19:36.496618 11069 solver.cpp:571] Iteration 32940, lr = 0.0001
I1018 12:19:44.026315 11069 solver.cpp:242] Iteration 32960, loss = 0.605918
I1018 12:19:44.026341 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.220125 (* 1 = 0.220125 loss)
I1018 12:19:44.026346 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.385793 (* 1 = 0.385793 loss)
I1018 12:19:44.026351 11069 solver.cpp:571] Iteration 32960, lr = 0.0001
I1018 12:19:51.741019 11069 solver.cpp:242] Iteration 32980, loss = 0.10964
I1018 12:19:51.741045 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.029496 (* 1 = 0.029496 loss)
I1018 12:19:51.741050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.080144 (* 1 = 0.080144 loss)
I1018 12:19:51.741055 11069 solver.cpp:571] Iteration 32980, lr = 0.0001
speed: 0.379s / iter
I1018 12:19:59.335619 11069 solver.cpp:242] Iteration 33000, loss = 0.125931
I1018 12:19:59.335645 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0471419 (* 1 = 0.0471419 loss)
I1018 12:19:59.335650 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0787892 (* 1 = 0.0787892 loss)
I1018 12:19:59.335654 11069 solver.cpp:571] Iteration 33000, lr = 0.0001
I1018 12:20:06.965351 11069 solver.cpp:242] Iteration 33020, loss = 0.236148
I1018 12:20:06.965376 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0525227 (* 1 = 0.0525227 loss)
I1018 12:20:06.965381 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.183625 (* 1 = 0.183625 loss)
I1018 12:20:06.965385 11069 solver.cpp:571] Iteration 33020, lr = 0.0001
I1018 12:20:14.650956 11069 solver.cpp:242] Iteration 33040, loss = 0.163331
I1018 12:20:14.650982 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0254809 (* 1 = 0.0254809 loss)
I1018 12:20:14.650987 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13785 (* 1 = 0.13785 loss)
I1018 12:20:14.650992 11069 solver.cpp:571] Iteration 33040, lr = 0.0001
I1018 12:20:22.282315 11069 solver.cpp:242] Iteration 33060, loss = 0.390474
I1018 12:20:22.282341 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0651169 (* 1 = 0.0651169 loss)
I1018 12:20:22.282344 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.325357 (* 1 = 0.325357 loss)
I1018 12:20:22.282348 11069 solver.cpp:571] Iteration 33060, lr = 0.0001
I1018 12:20:29.944860 11069 solver.cpp:242] Iteration 33080, loss = 0.805696
I1018 12:20:29.944885 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.254774 (* 1 = 0.254774 loss)
I1018 12:20:29.944890 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.550922 (* 1 = 0.550922 loss)
I1018 12:20:29.944893 11069 solver.cpp:571] Iteration 33080, lr = 0.0001
I1018 12:20:37.534337 11069 solver.cpp:242] Iteration 33100, loss = 0.162532
I1018 12:20:37.534361 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.041655 (* 1 = 0.041655 loss)
I1018 12:20:37.534366 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.120877 (* 1 = 0.120877 loss)
I1018 12:20:37.534370 11069 solver.cpp:571] Iteration 33100, lr = 0.0001
I1018 12:20:45.099527 11069 solver.cpp:242] Iteration 33120, loss = 0.502499
I1018 12:20:45.099553 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205787 (* 1 = 0.205787 loss)
I1018 12:20:45.099558 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296712 (* 1 = 0.296712 loss)
I1018 12:20:45.099562 11069 solver.cpp:571] Iteration 33120, lr = 0.0001
I1018 12:20:52.775388 11069 solver.cpp:242] Iteration 33140, loss = 0.111641
I1018 12:20:52.775413 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0347439 (* 1 = 0.0347439 loss)
I1018 12:20:52.775418 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.076897 (* 1 = 0.076897 loss)
I1018 12:20:52.775421 11069 solver.cpp:571] Iteration 33140, lr = 0.0001
I1018 12:21:00.377590 11069 solver.cpp:242] Iteration 33160, loss = 0.673791
I1018 12:21:00.377614 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.227699 (* 1 = 0.227699 loss)
I1018 12:21:00.377619 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.446092 (* 1 = 0.446092 loss)
I1018 12:21:00.377624 11069 solver.cpp:571] Iteration 33160, lr = 0.0001
I1018 12:21:08.080783 11069 solver.cpp:242] Iteration 33180, loss = 0.183806
I1018 12:21:08.080808 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0595004 (* 1 = 0.0595004 loss)
I1018 12:21:08.080813 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.124306 (* 1 = 0.124306 loss)
I1018 12:21:08.080817 11069 solver.cpp:571] Iteration 33180, lr = 0.0001
speed: 0.379s / iter
I1018 12:21:15.743892 11069 solver.cpp:242] Iteration 33200, loss = 0.355968
I1018 12:21:15.743917 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0903615 (* 1 = 0.0903615 loss)
I1018 12:21:15.743922 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.265606 (* 1 = 0.265606 loss)
I1018 12:21:15.743927 11069 solver.cpp:571] Iteration 33200, lr = 0.0001
I1018 12:21:23.275697 11069 solver.cpp:242] Iteration 33220, loss = 1.06638
I1018 12:21:23.275722 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.393813 (* 1 = 0.393813 loss)
I1018 12:21:23.275727 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.672572 (* 1 = 0.672572 loss)
I1018 12:21:23.275732 11069 solver.cpp:571] Iteration 33220, lr = 0.0001
I1018 12:21:30.855093 11069 solver.cpp:242] Iteration 33240, loss = 0.11396
I1018 12:21:30.855118 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0358046 (* 1 = 0.0358046 loss)
I1018 12:21:30.855123 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0781557 (* 1 = 0.0781557 loss)
I1018 12:21:30.855128 11069 solver.cpp:571] Iteration 33240, lr = 0.0001
I1018 12:21:38.492221 11069 solver.cpp:242] Iteration 33260, loss = 0.258749
I1018 12:21:38.492246 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0954272 (* 1 = 0.0954272 loss)
I1018 12:21:38.492250 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.163322 (* 1 = 0.163322 loss)
I1018 12:21:38.492254 11069 solver.cpp:571] Iteration 33260, lr = 0.0001
I1018 12:21:46.096235 11069 solver.cpp:242] Iteration 33280, loss = 0.114566
I1018 12:21:46.096261 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0502098 (* 1 = 0.0502098 loss)
I1018 12:21:46.096264 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0643563 (* 1 = 0.0643563 loss)
I1018 12:21:46.096268 11069 solver.cpp:571] Iteration 33280, lr = 0.0001
I1018 12:21:53.699164 11069 solver.cpp:242] Iteration 33300, loss = 0.678925
I1018 12:21:53.699189 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205244 (* 1 = 0.205244 loss)
I1018 12:21:53.699193 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.47368 (* 1 = 0.47368 loss)
I1018 12:21:53.699198 11069 solver.cpp:571] Iteration 33300, lr = 0.0001
I1018 12:22:01.343291 11069 solver.cpp:242] Iteration 33320, loss = 0.243645
I1018 12:22:01.343318 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0525776 (* 1 = 0.0525776 loss)
I1018 12:22:01.343323 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.191067 (* 1 = 0.191067 loss)
I1018 12:22:01.343328 11069 solver.cpp:571] Iteration 33320, lr = 0.0001
I1018 12:22:08.977118 11069 solver.cpp:242] Iteration 33340, loss = 0.886329
I1018 12:22:08.977143 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.250784 (* 1 = 0.250784 loss)
I1018 12:22:08.977147 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.635545 (* 1 = 0.635545 loss)
I1018 12:22:08.977151 11069 solver.cpp:571] Iteration 33340, lr = 0.0001
I1018 12:22:16.628476 11069 solver.cpp:242] Iteration 33360, loss = 1.12671
I1018 12:22:16.628501 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.40569 (* 1 = 0.40569 loss)
I1018 12:22:16.628505 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.721022 (* 1 = 0.721022 loss)
I1018 12:22:16.628509 11069 solver.cpp:571] Iteration 33360, lr = 0.0001
I1018 12:22:24.326699 11069 solver.cpp:242] Iteration 33380, loss = 0.219546
I1018 12:22:24.326723 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0310674 (* 1 = 0.0310674 loss)
I1018 12:22:24.326728 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.188479 (* 1 = 0.188479 loss)
I1018 12:22:24.326732 11069 solver.cpp:571] Iteration 33380, lr = 0.0001
speed: 0.379s / iter
I1018 12:22:31.920052 11069 solver.cpp:242] Iteration 33400, loss = 1.07438
I1018 12:22:31.920076 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.409675 (* 1 = 0.409675 loss)
I1018 12:22:31.920081 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664702 (* 1 = 0.664702 loss)
I1018 12:22:31.920085 11069 solver.cpp:571] Iteration 33400, lr = 0.0001
I1018 12:22:39.593299 11069 solver.cpp:242] Iteration 33420, loss = 0.634274
I1018 12:22:39.593324 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.182324 (* 1 = 0.182324 loss)
I1018 12:22:39.593328 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.45195 (* 1 = 0.45195 loss)
I1018 12:22:39.593333 11069 solver.cpp:571] Iteration 33420, lr = 0.0001
I1018 12:22:47.214709 11069 solver.cpp:242] Iteration 33440, loss = 0.534219
I1018 12:22:47.214735 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.171689 (* 1 = 0.171689 loss)
I1018 12:22:47.214738 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.362529 (* 1 = 0.362529 loss)
I1018 12:22:47.214742 11069 solver.cpp:571] Iteration 33440, lr = 0.0001
I1018 12:22:54.838021 11069 solver.cpp:242] Iteration 33460, loss = 0.969652
I1018 12:22:54.838047 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.338794 (* 1 = 0.338794 loss)
I1018 12:22:54.838050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.630858 (* 1 = 0.630858 loss)
I1018 12:22:54.838054 11069 solver.cpp:571] Iteration 33460, lr = 0.0001
I1018 12:23:02.534482 11069 solver.cpp:242] Iteration 33480, loss = 0.324303
I1018 12:23:02.534507 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0779326 (* 1 = 0.0779326 loss)
I1018 12:23:02.534512 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.24637 (* 1 = 0.24637 loss)
I1018 12:23:02.534515 11069 solver.cpp:571] Iteration 33480, lr = 0.0001
I1018 12:23:10.208027 11069 solver.cpp:242] Iteration 33500, loss = 1.26969
I1018 12:23:10.208055 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.447878 (* 1 = 0.447878 loss)
I1018 12:23:10.208058 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.82181 (* 1 = 0.82181 loss)
I1018 12:23:10.208062 11069 solver.cpp:571] Iteration 33500, lr = 0.0001
I1018 12:23:17.855952 11069 solver.cpp:242] Iteration 33520, loss = 0.34051
I1018 12:23:17.855978 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.133519 (* 1 = 0.133519 loss)
I1018 12:23:17.855983 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.206991 (* 1 = 0.206991 loss)
I1018 12:23:17.855988 11069 solver.cpp:571] Iteration 33520, lr = 0.0001
I1018 12:23:25.564852 11069 solver.cpp:242] Iteration 33540, loss = 0.654507
I1018 12:23:25.564879 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.122344 (* 1 = 0.122344 loss)
I1018 12:23:25.564884 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.532162 (* 1 = 0.532162 loss)
I1018 12:23:25.564888 11069 solver.cpp:571] Iteration 33540, lr = 0.0001
I1018 12:23:33.285904 11069 solver.cpp:242] Iteration 33560, loss = 0.121126
I1018 12:23:33.285929 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0629068 (* 1 = 0.0629068 loss)
I1018 12:23:33.285934 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0582191 (* 1 = 0.0582191 loss)
I1018 12:23:33.285939 11069 solver.cpp:571] Iteration 33560, lr = 0.0001
I1018 12:23:40.958109 11069 solver.cpp:242] Iteration 33580, loss = 0.210369
I1018 12:23:40.958134 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0636696 (* 1 = 0.0636696 loss)
I1018 12:23:40.958139 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.1467 (* 1 = 0.1467 loss)
I1018 12:23:40.958143 11069 solver.cpp:571] Iteration 33580, lr = 0.0001
speed: 0.379s / iter
I1018 12:23:48.530118 11069 solver.cpp:242] Iteration 33600, loss = 1.05487
I1018 12:23:48.530144 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.442909 (* 1 = 0.442909 loss)
I1018 12:23:48.530149 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.611963 (* 1 = 0.611963 loss)
I1018 12:23:48.530153 11069 solver.cpp:571] Iteration 33600, lr = 0.0001
I1018 12:23:56.221874 11069 solver.cpp:242] Iteration 33620, loss = 0.369859
I1018 12:23:56.221900 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.146019 (* 1 = 0.146019 loss)
I1018 12:23:56.221905 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22384 (* 1 = 0.22384 loss)
I1018 12:23:56.221909 11069 solver.cpp:571] Iteration 33620, lr = 0.0001
I1018 12:24:03.839972 11069 solver.cpp:242] Iteration 33640, loss = 0.762914
I1018 12:24:03.839998 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.212596 (* 1 = 0.212596 loss)
I1018 12:24:03.840001 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.550318 (* 1 = 0.550318 loss)
I1018 12:24:03.840006 11069 solver.cpp:571] Iteration 33640, lr = 0.0001
I1018 12:24:11.547504 11069 solver.cpp:242] Iteration 33660, loss = 0.538416
I1018 12:24:11.547531 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0979179 (* 1 = 0.0979179 loss)
I1018 12:24:11.547536 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.440498 (* 1 = 0.440498 loss)
I1018 12:24:11.547540 11069 solver.cpp:571] Iteration 33660, lr = 0.0001
I1018 12:24:19.167753 11069 solver.cpp:242] Iteration 33680, loss = 0.742661
I1018 12:24:19.167779 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.284799 (* 1 = 0.284799 loss)
I1018 12:24:19.167784 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.457861 (* 1 = 0.457861 loss)
I1018 12:24:19.167788 11069 solver.cpp:571] Iteration 33680, lr = 0.0001
I1018 12:24:26.756104 11069 solver.cpp:242] Iteration 33700, loss = 0.1032
I1018 12:24:26.756131 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0149012 (* 1 = 0.0149012 loss)
I1018 12:24:26.756136 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0882992 (* 1 = 0.0882992 loss)
I1018 12:24:26.756140 11069 solver.cpp:571] Iteration 33700, lr = 0.0001
I1018 12:24:34.382354 11069 solver.cpp:242] Iteration 33720, loss = 0.316904
I1018 12:24:34.382380 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0767075 (* 1 = 0.0767075 loss)
I1018 12:24:34.382385 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.240196 (* 1 = 0.240196 loss)
I1018 12:24:34.382390 11069 solver.cpp:571] Iteration 33720, lr = 0.0001
I1018 12:24:42.021574 11069 solver.cpp:242] Iteration 33740, loss = 0.38836
I1018 12:24:42.021601 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0845796 (* 1 = 0.0845796 loss)
I1018 12:24:42.021606 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.30378 (* 1 = 0.30378 loss)
I1018 12:24:42.021610 11069 solver.cpp:571] Iteration 33740, lr = 0.0001
I1018 12:24:49.637120 11069 solver.cpp:242] Iteration 33760, loss = 0.325755
I1018 12:24:49.637145 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.109021 (* 1 = 0.109021 loss)
I1018 12:24:49.637150 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.216733 (* 1 = 0.216733 loss)
I1018 12:24:49.637154 11069 solver.cpp:571] Iteration 33760, lr = 0.0001
I1018 12:24:57.294287 11069 solver.cpp:242] Iteration 33780, loss = 0.722999
I1018 12:24:57.294313 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.271377 (* 1 = 0.271377 loss)
I1018 12:24:57.294318 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.451621 (* 1 = 0.451621 loss)
I1018 12:24:57.294322 11069 solver.cpp:571] Iteration 33780, lr = 0.0001
speed: 0.379s / iter
I1018 12:25:04.814980 11069 solver.cpp:242] Iteration 33800, loss = 0.230708
I1018 12:25:04.815006 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0701618 (* 1 = 0.0701618 loss)
I1018 12:25:04.815011 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.160546 (* 1 = 0.160546 loss)
I1018 12:25:04.815016 11069 solver.cpp:571] Iteration 33800, lr = 0.0001
I1018 12:25:12.502485 11069 solver.cpp:242] Iteration 33820, loss = 0.736116
I1018 12:25:12.502511 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170888 (* 1 = 0.170888 loss)
I1018 12:25:12.502516 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.565228 (* 1 = 0.565228 loss)
I1018 12:25:12.502521 11069 solver.cpp:571] Iteration 33820, lr = 0.0001
I1018 12:25:20.059165 11069 solver.cpp:242] Iteration 33840, loss = 0.330743
I1018 12:25:20.059188 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152623 (* 1 = 0.152623 loss)
I1018 12:25:20.059193 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178119 (* 1 = 0.178119 loss)
I1018 12:25:20.059197 11069 solver.cpp:571] Iteration 33840, lr = 0.0001
I1018 12:25:27.803428 11069 solver.cpp:242] Iteration 33860, loss = 0.497345
I1018 12:25:27.803453 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.162904 (* 1 = 0.162904 loss)
I1018 12:25:27.803458 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.334441 (* 1 = 0.334441 loss)
I1018 12:25:27.803462 11069 solver.cpp:571] Iteration 33860, lr = 0.0001
I1018 12:25:35.488117 11069 solver.cpp:242] Iteration 33880, loss = 0.51761
I1018 12:25:35.488142 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.134769 (* 1 = 0.134769 loss)
I1018 12:25:35.488147 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.382841 (* 1 = 0.382841 loss)
I1018 12:25:35.488152 11069 solver.cpp:571] Iteration 33880, lr = 0.0001
I1018 12:25:43.120363 11069 solver.cpp:242] Iteration 33900, loss = 0.353359
I1018 12:25:43.120389 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0657007 (* 1 = 0.0657007 loss)
I1018 12:25:43.120394 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.287659 (* 1 = 0.287659 loss)
I1018 12:25:43.120399 11069 solver.cpp:571] Iteration 33900, lr = 0.0001
I1018 12:25:50.819763 11069 solver.cpp:242] Iteration 33920, loss = 0.108707
I1018 12:25:50.819789 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0267947 (* 1 = 0.0267947 loss)
I1018 12:25:50.819794 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0819124 (* 1 = 0.0819124 loss)
I1018 12:25:50.819798 11069 solver.cpp:571] Iteration 33920, lr = 0.0001
I1018 12:25:58.448398 11069 solver.cpp:242] Iteration 33940, loss = 0.259811
I1018 12:25:58.448423 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.071505 (* 1 = 0.071505 loss)
I1018 12:25:58.448427 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.188306 (* 1 = 0.188306 loss)
I1018 12:25:58.448431 11069 solver.cpp:571] Iteration 33940, lr = 0.0001
I1018 12:26:06.005525 11069 solver.cpp:242] Iteration 33960, loss = 0.348421
I1018 12:26:06.005551 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152223 (* 1 = 0.152223 loss)
I1018 12:26:06.005556 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.196197 (* 1 = 0.196197 loss)
I1018 12:26:06.005560 11069 solver.cpp:571] Iteration 33960, lr = 0.0001
I1018 12:26:13.728554 11069 solver.cpp:242] Iteration 33980, loss = 0.317166
I1018 12:26:13.728581 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.112939 (* 1 = 0.112939 loss)
I1018 12:26:13.728586 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204228 (* 1 = 0.204228 loss)
I1018 12:26:13.728591 11069 solver.cpp:571] Iteration 33980, lr = 0.0001
speed: 0.379s / iter
I1018 12:26:21.327839 11069 solver.cpp:242] Iteration 34000, loss = 0.171969
I1018 12:26:21.327865 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0636856 (* 1 = 0.0636856 loss)
I1018 12:26:21.327870 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.108283 (* 1 = 0.108283 loss)
I1018 12:26:21.327875 11069 solver.cpp:571] Iteration 34000, lr = 0.0001
I1018 12:26:28.994776 11069 solver.cpp:242] Iteration 34020, loss = 0.452003
I1018 12:26:28.994801 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.119391 (* 1 = 0.119391 loss)
I1018 12:26:28.994807 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.332612 (* 1 = 0.332612 loss)
I1018 12:26:28.994812 11069 solver.cpp:571] Iteration 34020, lr = 0.0001
I1018 12:26:36.726132 11069 solver.cpp:242] Iteration 34040, loss = 0.243838
I1018 12:26:36.726158 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0788111 (* 1 = 0.0788111 loss)
I1018 12:26:36.726163 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165027 (* 1 = 0.165027 loss)
I1018 12:26:36.726167 11069 solver.cpp:571] Iteration 34040, lr = 0.0001
I1018 12:26:44.362018 11069 solver.cpp:242] Iteration 34060, loss = 0.213175
I1018 12:26:44.362045 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0427367 (* 1 = 0.0427367 loss)
I1018 12:26:44.362049 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.170438 (* 1 = 0.170438 loss)
I1018 12:26:44.362053 11069 solver.cpp:571] Iteration 34060, lr = 0.0001
I1018 12:26:52.001955 11069 solver.cpp:242] Iteration 34080, loss = 0.193965
I1018 12:26:52.001983 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.050151 (* 1 = 0.050151 loss)
I1018 12:26:52.001988 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.143814 (* 1 = 0.143814 loss)
I1018 12:26:52.001992 11069 solver.cpp:571] Iteration 34080, lr = 0.0001
I1018 12:26:59.665194 11069 solver.cpp:242] Iteration 34100, loss = 0.161348
I1018 12:26:59.665218 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0680523 (* 1 = 0.0680523 loss)
I1018 12:26:59.665223 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0932954 (* 1 = 0.0932954 loss)
I1018 12:26:59.665227 11069 solver.cpp:571] Iteration 34100, lr = 0.0001
I1018 12:27:07.311305 11069 solver.cpp:242] Iteration 34120, loss = 0.38461
I1018 12:27:07.311334 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.198287 (* 1 = 0.198287 loss)
I1018 12:27:07.311339 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.186323 (* 1 = 0.186323 loss)
I1018 12:27:07.311343 11069 solver.cpp:571] Iteration 34120, lr = 0.0001
I1018 12:27:15.012503 11069 solver.cpp:242] Iteration 34140, loss = 1.11011
I1018 12:27:15.012529 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.413943 (* 1 = 0.413943 loss)
I1018 12:27:15.012534 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.696168 (* 1 = 0.696168 loss)
I1018 12:27:15.012538 11069 solver.cpp:571] Iteration 34140, lr = 0.0001
I1018 12:27:22.670806 11069 solver.cpp:242] Iteration 34160, loss = 0.136171
I1018 12:27:22.670832 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.034526 (* 1 = 0.034526 loss)
I1018 12:27:22.670837 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.101645 (* 1 = 0.101645 loss)
I1018 12:27:22.670841 11069 solver.cpp:571] Iteration 34160, lr = 0.0001
I1018 12:27:30.277021 11069 solver.cpp:242] Iteration 34180, loss = 0.198034
I1018 12:27:30.277046 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0489579 (* 1 = 0.0489579 loss)
I1018 12:27:30.277050 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149076 (* 1 = 0.149076 loss)
I1018 12:27:30.277055 11069 solver.cpp:571] Iteration 34180, lr = 0.0001
speed: 0.379s / iter
I1018 12:27:37.972501 11069 solver.cpp:242] Iteration 34200, loss = 0.22054
I1018 12:27:37.972527 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834901 (* 1 = 0.0834901 loss)
I1018 12:27:37.972532 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13705 (* 1 = 0.13705 loss)
I1018 12:27:37.972535 11069 solver.cpp:571] Iteration 34200, lr = 0.0001
I1018 12:27:45.712024 11069 solver.cpp:242] Iteration 34220, loss = 0.240929
I1018 12:27:45.712050 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0934833 (* 1 = 0.0934833 loss)
I1018 12:27:45.712055 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.147446 (* 1 = 0.147446 loss)
I1018 12:27:45.712060 11069 solver.cpp:571] Iteration 34220, lr = 0.0001
I1018 12:27:53.381834 11069 solver.cpp:242] Iteration 34240, loss = 0.923358
I1018 12:27:53.381858 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.363006 (* 1 = 0.363006 loss)
I1018 12:27:53.381865 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.560352 (* 1 = 0.560352 loss)
I1018 12:27:53.381868 11069 solver.cpp:571] Iteration 34240, lr = 0.0001
I1018 12:28:01.001066 11069 solver.cpp:242] Iteration 34260, loss = 0.134987
I1018 12:28:01.001093 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0375453 (* 1 = 0.0375453 loss)
I1018 12:28:01.001098 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0974415 (* 1 = 0.0974415 loss)
I1018 12:28:01.001102 11069 solver.cpp:571] Iteration 34260, lr = 0.0001
I1018 12:28:08.649752 11069 solver.cpp:242] Iteration 34280, loss = 0.48535
I1018 12:28:08.649778 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.105775 (* 1 = 0.105775 loss)
I1018 12:28:08.649783 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.379575 (* 1 = 0.379575 loss)
I1018 12:28:08.649787 11069 solver.cpp:571] Iteration 34280, lr = 0.0001
I1018 12:28:16.279698 11069 solver.cpp:242] Iteration 34300, loss = 0.327451
I1018 12:28:16.279724 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0730247 (* 1 = 0.0730247 loss)
I1018 12:28:16.279729 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.254426 (* 1 = 0.254426 loss)
I1018 12:28:16.279734 11069 solver.cpp:571] Iteration 34300, lr = 0.0001
I1018 12:28:23.995350 11069 solver.cpp:242] Iteration 34320, loss = 0.208453
I1018 12:28:23.995376 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0559482 (* 1 = 0.0559482 loss)
I1018 12:28:23.995381 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.152505 (* 1 = 0.152505 loss)
I1018 12:28:23.995386 11069 solver.cpp:571] Iteration 34320, lr = 0.0001
I1018 12:28:31.551735 11069 solver.cpp:242] Iteration 34340, loss = 0.262713
I1018 12:28:31.551761 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0434553 (* 1 = 0.0434553 loss)
I1018 12:28:31.551766 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.219258 (* 1 = 0.219258 loss)
I1018 12:28:31.551770 11069 solver.cpp:571] Iteration 34340, lr = 0.0001
I1018 12:28:39.163163 11069 solver.cpp:242] Iteration 34360, loss = 0.605054
I1018 12:28:39.163189 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.288536 (* 1 = 0.288536 loss)
I1018 12:28:39.163194 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.316517 (* 1 = 0.316517 loss)
I1018 12:28:39.163198 11069 solver.cpp:571] Iteration 34360, lr = 0.0001
I1018 12:28:46.800189 11069 solver.cpp:242] Iteration 34380, loss = 0.213411
I1018 12:28:46.800215 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0595098 (* 1 = 0.0595098 loss)
I1018 12:28:46.800220 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.153901 (* 1 = 0.153901 loss)
I1018 12:28:46.800225 11069 solver.cpp:571] Iteration 34380, lr = 0.0001
speed: 0.379s / iter
I1018 12:28:54.359226 11069 solver.cpp:242] Iteration 34400, loss = 0.759147
I1018 12:28:54.359252 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.236445 (* 1 = 0.236445 loss)
I1018 12:28:54.359257 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.522702 (* 1 = 0.522702 loss)
I1018 12:28:54.359261 11069 solver.cpp:571] Iteration 34400, lr = 0.0001
I1018 12:29:01.928174 11069 solver.cpp:242] Iteration 34420, loss = 0.581462
I1018 12:29:01.928197 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.126589 (* 1 = 0.126589 loss)
I1018 12:29:01.928201 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.454874 (* 1 = 0.454874 loss)
I1018 12:29:01.928206 11069 solver.cpp:571] Iteration 34420, lr = 0.0001
I1018 12:29:09.581941 11069 solver.cpp:242] Iteration 34440, loss = 0.171343
I1018 12:29:09.581966 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.047881 (* 1 = 0.047881 loss)
I1018 12:29:09.581972 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123462 (* 1 = 0.123462 loss)
I1018 12:29:09.581976 11069 solver.cpp:571] Iteration 34440, lr = 0.0001
I1018 12:29:17.176095 11069 solver.cpp:242] Iteration 34460, loss = 0.285027
I1018 12:29:17.176120 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0992766 (* 1 = 0.0992766 loss)
I1018 12:29:17.176126 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.18575 (* 1 = 0.18575 loss)
I1018 12:29:17.176131 11069 solver.cpp:571] Iteration 34460, lr = 0.0001
I1018 12:29:24.754362 11069 solver.cpp:242] Iteration 34480, loss = 0.981443
I1018 12:29:24.754389 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.207086 (* 1 = 0.207086 loss)
I1018 12:29:24.754393 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.774357 (* 1 = 0.774357 loss)
I1018 12:29:24.754397 11069 solver.cpp:571] Iteration 34480, lr = 0.0001
I1018 12:29:32.332447 11069 solver.cpp:242] Iteration 34500, loss = 0.237073
I1018 12:29:32.332473 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0685039 (* 1 = 0.0685039 loss)
I1018 12:29:32.332478 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.168569 (* 1 = 0.168569 loss)
I1018 12:29:32.332482 11069 solver.cpp:571] Iteration 34500, lr = 0.0001
I1018 12:29:39.750286 11069 solver.cpp:242] Iteration 34520, loss = 0.28749
I1018 12:29:39.750313 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0840963 (* 1 = 0.0840963 loss)
I1018 12:29:39.750316 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.203394 (* 1 = 0.203394 loss)
I1018 12:29:39.750321 11069 solver.cpp:571] Iteration 34520, lr = 0.0001
I1018 12:29:46.510546 11069 solver.cpp:242] Iteration 34540, loss = 0.535939
I1018 12:29:46.510573 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.183495 (* 1 = 0.183495 loss)
I1018 12:29:46.510578 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.352445 (* 1 = 0.352445 loss)
I1018 12:29:46.510582 11069 solver.cpp:571] Iteration 34540, lr = 0.0001
I1018 12:29:53.919553 11069 solver.cpp:242] Iteration 34560, loss = 0.290583
I1018 12:29:53.919579 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0927078 (* 1 = 0.0927078 loss)
I1018 12:29:53.919584 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197876 (* 1 = 0.197876 loss)
I1018 12:29:53.919587 11069 solver.cpp:571] Iteration 34560, lr = 0.0001
I1018 12:30:01.467458 11069 solver.cpp:242] Iteration 34580, loss = 0.116276
I1018 12:30:01.467483 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0447882 (* 1 = 0.0447882 loss)
I1018 12:30:01.467488 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0714882 (* 1 = 0.0714882 loss)
I1018 12:30:01.467491 11069 solver.cpp:571] Iteration 34580, lr = 0.0001
speed: 0.379s / iter
I1018 12:30:09.009073 11069 solver.cpp:242] Iteration 34600, loss = 0.720239
I1018 12:30:09.009099 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.240079 (* 1 = 0.240079 loss)
I1018 12:30:09.009104 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.48016 (* 1 = 0.48016 loss)
I1018 12:30:09.009109 11069 solver.cpp:571] Iteration 34600, lr = 0.0001
I1018 12:30:16.728569 11069 solver.cpp:242] Iteration 34620, loss = 0.247046
I1018 12:30:16.728595 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0640581 (* 1 = 0.0640581 loss)
I1018 12:30:16.728600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182988 (* 1 = 0.182988 loss)
I1018 12:30:16.728605 11069 solver.cpp:571] Iteration 34620, lr = 0.0001
I1018 12:30:24.292141 11069 solver.cpp:242] Iteration 34640, loss = 0.151553
I1018 12:30:24.292166 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0422195 (* 1 = 0.0422195 loss)
I1018 12:30:24.292171 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.109334 (* 1 = 0.109334 loss)
I1018 12:30:24.292176 11069 solver.cpp:571] Iteration 34640, lr = 0.0001
I1018 12:30:31.870895 11069 solver.cpp:242] Iteration 34660, loss = 0.532658
I1018 12:30:31.870920 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170547 (* 1 = 0.170547 loss)
I1018 12:30:31.870924 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.362112 (* 1 = 0.362112 loss)
I1018 12:30:31.870929 11069 solver.cpp:571] Iteration 34660, lr = 0.0001
I1018 12:30:39.516655 11069 solver.cpp:242] Iteration 34680, loss = 0.290006
I1018 12:30:39.516680 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0761615 (* 1 = 0.0761615 loss)
I1018 12:30:39.516685 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.213845 (* 1 = 0.213845 loss)
I1018 12:30:39.516688 11069 solver.cpp:571] Iteration 34680, lr = 0.0001
I1018 12:30:47.148306 11069 solver.cpp:242] Iteration 34700, loss = 0.676188
I1018 12:30:47.148331 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.180238 (* 1 = 0.180238 loss)
I1018 12:30:47.148336 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495949 (* 1 = 0.495949 loss)
I1018 12:30:47.148340 11069 solver.cpp:571] Iteration 34700, lr = 0.0001
I1018 12:30:54.732662 11069 solver.cpp:242] Iteration 34720, loss = 0.0871556
I1018 12:30:54.732687 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0163996 (* 1 = 0.0163996 loss)
I1018 12:30:54.732692 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.070756 (* 1 = 0.070756 loss)
I1018 12:30:54.732697 11069 solver.cpp:571] Iteration 34720, lr = 0.0001
I1018 12:31:02.292775 11069 solver.cpp:242] Iteration 34740, loss = 0.159125
I1018 12:31:02.292801 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0396467 (* 1 = 0.0396467 loss)
I1018 12:31:02.292806 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.119478 (* 1 = 0.119478 loss)
I1018 12:31:02.292810 11069 solver.cpp:571] Iteration 34740, lr = 0.0001
I1018 12:31:09.977182 11069 solver.cpp:242] Iteration 34760, loss = 0.517332
I1018 12:31:09.977207 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.169534 (* 1 = 0.169534 loss)
I1018 12:31:09.977212 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.347799 (* 1 = 0.347799 loss)
I1018 12:31:09.977216 11069 solver.cpp:571] Iteration 34760, lr = 0.0001
I1018 12:31:17.527865 11069 solver.cpp:242] Iteration 34780, loss = 0.611435
I1018 12:31:17.527890 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168214 (* 1 = 0.168214 loss)
I1018 12:31:17.527895 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.443222 (* 1 = 0.443222 loss)
I1018 12:31:17.527899 11069 solver.cpp:571] Iteration 34780, lr = 0.0001
speed: 0.379s / iter
I1018 12:31:25.113351 11069 solver.cpp:242] Iteration 34800, loss = 0.152156
I1018 12:31:25.113378 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0443894 (* 1 = 0.0443894 loss)
I1018 12:31:25.113382 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.107767 (* 1 = 0.107767 loss)
I1018 12:31:25.113386 11069 solver.cpp:571] Iteration 34800, lr = 0.0001
I1018 12:31:32.749267 11069 solver.cpp:242] Iteration 34820, loss = 1.21924
I1018 12:31:32.749292 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.457705 (* 1 = 0.457705 loss)
I1018 12:31:32.749297 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.761535 (* 1 = 0.761535 loss)
I1018 12:31:32.749301 11069 solver.cpp:571] Iteration 34820, lr = 0.0001
I1018 12:31:40.290724 11069 solver.cpp:242] Iteration 34840, loss = 0.186589
I1018 12:31:40.290747 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0426463 (* 1 = 0.0426463 loss)
I1018 12:31:40.290752 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.143943 (* 1 = 0.143943 loss)
I1018 12:31:40.290756 11069 solver.cpp:571] Iteration 34840, lr = 0.0001
I1018 12:31:47.857826 11069 solver.cpp:242] Iteration 34860, loss = 1.71828
I1018 12:31:47.857851 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.820678 (* 1 = 0.820678 loss)
I1018 12:31:47.857857 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.897599 (* 1 = 0.897599 loss)
I1018 12:31:47.857861 11069 solver.cpp:571] Iteration 34860, lr = 0.0001
I1018 12:31:55.437938 11069 solver.cpp:242] Iteration 34880, loss = 0.591374
I1018 12:31:55.437964 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.202581 (* 1 = 0.202581 loss)
I1018 12:31:55.437969 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.388794 (* 1 = 0.388794 loss)
I1018 12:31:55.437973 11069 solver.cpp:571] Iteration 34880, lr = 0.0001
I1018 12:32:03.165127 11069 solver.cpp:242] Iteration 34900, loss = 0.384396
I1018 12:32:03.165153 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.120295 (* 1 = 0.120295 loss)
I1018 12:32:03.165158 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.264101 (* 1 = 0.264101 loss)
I1018 12:32:03.165163 11069 solver.cpp:571] Iteration 34900, lr = 0.0001
I1018 12:32:10.821867 11069 solver.cpp:242] Iteration 34920, loss = 0.204906
I1018 12:32:10.821892 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0733227 (* 1 = 0.0733227 loss)
I1018 12:32:10.821897 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131584 (* 1 = 0.131584 loss)
I1018 12:32:10.821902 11069 solver.cpp:571] Iteration 34920, lr = 0.0001
I1018 12:32:18.435832 11069 solver.cpp:242] Iteration 34940, loss = 0.253318
I1018 12:32:18.435858 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.117778 (* 1 = 0.117778 loss)
I1018 12:32:18.435863 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13554 (* 1 = 0.13554 loss)
I1018 12:32:18.435868 11069 solver.cpp:571] Iteration 34940, lr = 0.0001
I1018 12:32:25.946796 11069 solver.cpp:242] Iteration 34960, loss = 0.341217
I1018 12:32:25.946820 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.108851 (* 1 = 0.108851 loss)
I1018 12:32:25.946825 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.232365 (* 1 = 0.232365 loss)
I1018 12:32:25.946830 11069 solver.cpp:571] Iteration 34960, lr = 0.0001
I1018 12:32:33.574364 11069 solver.cpp:242] Iteration 34980, loss = 0.263588
I1018 12:32:33.574390 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0884266 (* 1 = 0.0884266 loss)
I1018 12:32:33.574395 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.175161 (* 1 = 0.175161 loss)
I1018 12:32:33.574399 11069 solver.cpp:571] Iteration 34980, lr = 0.0001
speed: 0.379s / iter
I1018 12:32:41.315757 11069 solver.cpp:242] Iteration 35000, loss = 0.523722
I1018 12:32:41.315783 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128112 (* 1 = 0.128112 loss)
I1018 12:32:41.315788 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.39561 (* 1 = 0.39561 loss)
I1018 12:32:41.315793 11069 solver.cpp:571] Iteration 35000, lr = 0.0001
I1018 12:32:48.951268 11069 solver.cpp:242] Iteration 35020, loss = 0.145445
I1018 12:32:48.951293 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0319593 (* 1 = 0.0319593 loss)
I1018 12:32:48.951298 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.113486 (* 1 = 0.113486 loss)
I1018 12:32:48.951303 11069 solver.cpp:571] Iteration 35020, lr = 0.0001
I1018 12:32:56.539537 11069 solver.cpp:242] Iteration 35040, loss = 0.148855
I1018 12:32:56.539562 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0626377 (* 1 = 0.0626377 loss)
I1018 12:32:56.539567 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0862177 (* 1 = 0.0862177 loss)
I1018 12:32:56.539572 11069 solver.cpp:571] Iteration 35040, lr = 0.0001
I1018 12:33:03.994035 11069 solver.cpp:242] Iteration 35060, loss = 0.160982
I1018 12:33:03.994061 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529475 (* 1 = 0.0529475 loss)
I1018 12:33:03.994067 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.108034 (* 1 = 0.108034 loss)
I1018 12:33:03.994071 11069 solver.cpp:571] Iteration 35060, lr = 0.0001
I1018 12:33:11.510360 11069 solver.cpp:242] Iteration 35080, loss = 0.0811419
I1018 12:33:11.510386 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0225539 (* 1 = 0.0225539 loss)
I1018 12:33:11.510391 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.058588 (* 1 = 0.058588 loss)
I1018 12:33:11.510396 11069 solver.cpp:571] Iteration 35080, lr = 0.0001
I1018 12:33:19.010383 11069 solver.cpp:242] Iteration 35100, loss = 0.73568
I1018 12:33:19.010409 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.256095 (* 1 = 0.256095 loss)
I1018 12:33:19.010414 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.479585 (* 1 = 0.479585 loss)
I1018 12:33:19.010418 11069 solver.cpp:571] Iteration 35100, lr = 0.0001
I1018 12:33:26.320752 11069 solver.cpp:242] Iteration 35120, loss = 0.520623
I1018 12:33:26.320787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.131466 (* 1 = 0.131466 loss)
I1018 12:33:26.320792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.389157 (* 1 = 0.389157 loss)
I1018 12:33:26.320797 11069 solver.cpp:571] Iteration 35120, lr = 0.0001
I1018 12:33:33.254541 11069 solver.cpp:242] Iteration 35140, loss = 0.161383
I1018 12:33:33.254567 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.03668 (* 1 = 0.03668 loss)
I1018 12:33:33.254571 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.124703 (* 1 = 0.124703 loss)
I1018 12:33:33.254575 11069 solver.cpp:571] Iteration 35140, lr = 0.0001
I1018 12:33:40.570221 11069 solver.cpp:242] Iteration 35160, loss = 0.678463
I1018 12:33:40.570246 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.31104 (* 1 = 0.31104 loss)
I1018 12:33:40.570251 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.367422 (* 1 = 0.367422 loss)
I1018 12:33:40.570255 11069 solver.cpp:571] Iteration 35160, lr = 0.0001
I1018 12:33:48.162252 11069 solver.cpp:242] Iteration 35180, loss = 1.19749
I1018 12:33:48.162278 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.423358 (* 1 = 0.423358 loss)
I1018 12:33:48.162284 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.774132 (* 1 = 0.774132 loss)
I1018 12:33:48.162288 11069 solver.cpp:571] Iteration 35180, lr = 0.0001
speed: 0.379s / iter
I1018 12:33:55.498358 11069 solver.cpp:242] Iteration 35200, loss = 0.715777
I1018 12:33:55.498384 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.228044 (* 1 = 0.228044 loss)
I1018 12:33:55.498389 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.487733 (* 1 = 0.487733 loss)
I1018 12:33:55.498392 11069 solver.cpp:571] Iteration 35200, lr = 0.0001
I1018 12:34:02.566085 11069 solver.cpp:242] Iteration 35220, loss = 0.201645
I1018 12:34:02.566108 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0538167 (* 1 = 0.0538167 loss)
I1018 12:34:02.566113 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.147828 (* 1 = 0.147828 loss)
I1018 12:34:02.566118 11069 solver.cpp:571] Iteration 35220, lr = 0.0001
I1018 12:34:10.188144 11069 solver.cpp:242] Iteration 35240, loss = 0.256607
I1018 12:34:10.188169 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0520282 (* 1 = 0.0520282 loss)
I1018 12:34:10.188174 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.204579 (* 1 = 0.204579 loss)
I1018 12:34:10.188179 11069 solver.cpp:571] Iteration 35240, lr = 0.0001
I1018 12:34:17.981298 11069 solver.cpp:242] Iteration 35260, loss = 0.307385
I1018 12:34:17.981325 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0991753 (* 1 = 0.0991753 loss)
I1018 12:34:17.981330 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.20821 (* 1 = 0.20821 loss)
I1018 12:34:17.981335 11069 solver.cpp:571] Iteration 35260, lr = 0.0001
I1018 12:34:25.480134 11069 solver.cpp:242] Iteration 35280, loss = 0.558348
I1018 12:34:25.480159 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.15929 (* 1 = 0.15929 loss)
I1018 12:34:25.480165 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.399058 (* 1 = 0.399058 loss)
I1018 12:34:25.480168 11069 solver.cpp:571] Iteration 35280, lr = 0.0001
I1018 12:34:32.915036 11069 solver.cpp:242] Iteration 35300, loss = 0.344421
I1018 12:34:32.915063 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.110424 (* 1 = 0.110424 loss)
I1018 12:34:32.915068 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.233997 (* 1 = 0.233997 loss)
I1018 12:34:32.915073 11069 solver.cpp:571] Iteration 35300, lr = 0.0001
I1018 12:34:40.474438 11069 solver.cpp:242] Iteration 35320, loss = 0.362864
I1018 12:34:40.474465 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.155201 (* 1 = 0.155201 loss)
I1018 12:34:40.474470 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.207663 (* 1 = 0.207663 loss)
I1018 12:34:40.474474 11069 solver.cpp:571] Iteration 35320, lr = 0.0001
I1018 12:34:47.778955 11069 solver.cpp:242] Iteration 35340, loss = 0.570566
I1018 12:34:47.778981 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.168355 (* 1 = 0.168355 loss)
I1018 12:34:47.778986 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.402211 (* 1 = 0.402211 loss)
I1018 12:34:47.778991 11069 solver.cpp:571] Iteration 35340, lr = 0.0001
I1018 12:34:54.980877 11069 solver.cpp:242] Iteration 35360, loss = 0.183058
I1018 12:34:54.980903 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0531299 (* 1 = 0.0531299 loss)
I1018 12:34:54.980908 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.129928 (* 1 = 0.129928 loss)
I1018 12:34:54.980913 11069 solver.cpp:571] Iteration 35360, lr = 0.0001
I1018 12:35:02.418781 11069 solver.cpp:242] Iteration 35380, loss = 0.291169
I1018 12:35:02.418805 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0899419 (* 1 = 0.0899419 loss)
I1018 12:35:02.418809 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.201227 (* 1 = 0.201227 loss)
I1018 12:35:02.418813 11069 solver.cpp:571] Iteration 35380, lr = 0.0001
speed: 0.379s / iter
I1018 12:35:09.892629 11069 solver.cpp:242] Iteration 35400, loss = 0.872904
I1018 12:35:09.892654 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.281671 (* 1 = 0.281671 loss)
I1018 12:35:09.892658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.591233 (* 1 = 0.591233 loss)
I1018 12:35:09.892663 11069 solver.cpp:571] Iteration 35400, lr = 0.0001
I1018 12:35:17.501886 11069 solver.cpp:242] Iteration 35420, loss = 0.891223
I1018 12:35:17.501912 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.348135 (* 1 = 0.348135 loss)
I1018 12:35:17.501917 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.543088 (* 1 = 0.543088 loss)
I1018 12:35:17.501921 11069 solver.cpp:571] Iteration 35420, lr = 0.0001
I1018 12:35:25.143283 11069 solver.cpp:242] Iteration 35440, loss = 0.226652
I1018 12:35:25.143309 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0686611 (* 1 = 0.0686611 loss)
I1018 12:35:25.143316 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.157991 (* 1 = 0.157991 loss)
I1018 12:35:25.143321 11069 solver.cpp:571] Iteration 35440, lr = 0.0001
I1018 12:35:32.223217 11069 solver.cpp:242] Iteration 35460, loss = 0.845987
I1018 12:35:32.223243 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.262901 (* 1 = 0.262901 loss)
I1018 12:35:32.223248 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.583087 (* 1 = 0.583087 loss)
I1018 12:35:32.223253 11069 solver.cpp:571] Iteration 35460, lr = 0.0001
I1018 12:35:39.402575 11069 solver.cpp:242] Iteration 35480, loss = 0.435193
I1018 12:35:39.402601 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.152829 (* 1 = 0.152829 loss)
I1018 12:35:39.402606 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.282364 (* 1 = 0.282364 loss)
I1018 12:35:39.402611 11069 solver.cpp:571] Iteration 35480, lr = 0.0001
I1018 12:35:46.883533 11069 solver.cpp:242] Iteration 35500, loss = 0.383014
I1018 12:35:46.883559 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104417 (* 1 = 0.104417 loss)
I1018 12:35:46.883564 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.278597 (* 1 = 0.278597 loss)
I1018 12:35:46.883569 11069 solver.cpp:571] Iteration 35500, lr = 0.0001
I1018 12:35:54.435626 11069 solver.cpp:242] Iteration 35520, loss = 0.406421
I1018 12:35:54.435650 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.144545 (* 1 = 0.144545 loss)
I1018 12:35:54.435655 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.261875 (* 1 = 0.261875 loss)
I1018 12:35:54.435659 11069 solver.cpp:571] Iteration 35520, lr = 0.0001
I1018 12:36:01.863440 11069 solver.cpp:242] Iteration 35540, loss = 2.23641
I1018 12:36:01.863464 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.26233 (* 1 = 1.26233 loss)
I1018 12:36:01.863468 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.974082 (* 1 = 0.974082 loss)
I1018 12:36:01.863472 11069 solver.cpp:571] Iteration 35540, lr = 0.0001
I1018 12:36:09.032310 11069 solver.cpp:242] Iteration 35560, loss = 0.513256
I1018 12:36:09.032337 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.202556 (* 1 = 0.202556 loss)
I1018 12:36:09.032342 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3107 (* 1 = 0.3107 loss)
I1018 12:36:09.032346 11069 solver.cpp:571] Iteration 35560, lr = 0.0001
I1018 12:36:16.204852 11069 solver.cpp:242] Iteration 35580, loss = 0.252065
I1018 12:36:16.204879 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.046651 (* 1 = 0.046651 loss)
I1018 12:36:16.204884 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205414 (* 1 = 0.205414 loss)
I1018 12:36:16.204887 11069 solver.cpp:571] Iteration 35580, lr = 0.0001
speed: 0.379s / iter
I1018 12:36:23.297091 11069 solver.cpp:242] Iteration 35600, loss = 0.224681
I1018 12:36:23.297117 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0761584 (* 1 = 0.0761584 loss)
I1018 12:36:23.297123 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.148522 (* 1 = 0.148522 loss)
I1018 12:36:23.297127 11069 solver.cpp:571] Iteration 35600, lr = 0.0001
I1018 12:36:30.676590 11069 solver.cpp:242] Iteration 35620, loss = 0.423806
I1018 12:36:30.676614 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.132092 (* 1 = 0.132092 loss)
I1018 12:36:30.676620 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.291714 (* 1 = 0.291714 loss)
I1018 12:36:30.676623 11069 solver.cpp:571] Iteration 35620, lr = 0.0001
I1018 12:36:37.684257 11069 solver.cpp:242] Iteration 35640, loss = 0.251603
I1018 12:36:37.684283 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0502562 (* 1 = 0.0502562 loss)
I1018 12:36:37.684288 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.201347 (* 1 = 0.201347 loss)
I1018 12:36:37.684291 11069 solver.cpp:571] Iteration 35640, lr = 0.0001
I1018 12:36:45.102648 11069 solver.cpp:242] Iteration 35660, loss = 0.175585
I1018 12:36:45.102672 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0435409 (* 1 = 0.0435409 loss)
I1018 12:36:45.102677 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.132044 (* 1 = 0.132044 loss)
I1018 12:36:45.102680 11069 solver.cpp:571] Iteration 35660, lr = 0.0001
I1018 12:36:52.969517 11069 solver.cpp:242] Iteration 35680, loss = 0.196567
I1018 12:36:52.969542 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0842291 (* 1 = 0.0842291 loss)
I1018 12:36:52.969547 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.112338 (* 1 = 0.112338 loss)
I1018 12:36:52.969550 11069 solver.cpp:571] Iteration 35680, lr = 0.0001
I1018 12:37:00.484660 11069 solver.cpp:242] Iteration 35700, loss = 0.438951
I1018 12:37:00.484684 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.136272 (* 1 = 0.136272 loss)
I1018 12:37:00.484689 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.302678 (* 1 = 0.302678 loss)
I1018 12:37:00.484693 11069 solver.cpp:571] Iteration 35700, lr = 0.0001
I1018 12:37:08.233343 11069 solver.cpp:242] Iteration 35720, loss = 0.218914
I1018 12:37:08.233371 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0768904 (* 1 = 0.0768904 loss)
I1018 12:37:08.233376 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.142024 (* 1 = 0.142024 loss)
I1018 12:37:08.233379 11069 solver.cpp:571] Iteration 35720, lr = 0.0001
I1018 12:37:15.925225 11069 solver.cpp:242] Iteration 35740, loss = 0.745875
I1018 12:37:15.925249 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.292793 (* 1 = 0.292793 loss)
I1018 12:37:15.925254 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.453082 (* 1 = 0.453082 loss)
I1018 12:37:15.925258 11069 solver.cpp:571] Iteration 35740, lr = 0.0001
I1018 12:37:22.872529 11069 solver.cpp:242] Iteration 35760, loss = 1.05224
I1018 12:37:22.872553 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.341127 (* 1 = 0.341127 loss)
I1018 12:37:22.872558 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.711109 (* 1 = 0.711109 loss)
I1018 12:37:22.872562 11069 solver.cpp:571] Iteration 35760, lr = 0.0001
I1018 12:37:30.204933 11069 solver.cpp:242] Iteration 35780, loss = 0.444599
I1018 12:37:30.204958 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0768876 (* 1 = 0.0768876 loss)
I1018 12:37:30.204963 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.367711 (* 1 = 0.367711 loss)
I1018 12:37:30.204967 11069 solver.cpp:571] Iteration 35780, lr = 0.0001
speed: 0.378s / iter
I1018 12:37:37.364718 11069 solver.cpp:242] Iteration 35800, loss = 0.244264
I1018 12:37:37.364743 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0831904 (* 1 = 0.0831904 loss)
I1018 12:37:37.364748 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.161073 (* 1 = 0.161073 loss)
I1018 12:37:37.364753 11069 solver.cpp:571] Iteration 35800, lr = 0.0001
I1018 12:37:44.365702 11069 solver.cpp:242] Iteration 35820, loss = 0.336284
I1018 12:37:44.365730 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0963056 (* 1 = 0.0963056 loss)
I1018 12:37:44.365734 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.239979 (* 1 = 0.239979 loss)
I1018 12:37:44.365738 11069 solver.cpp:571] Iteration 35820, lr = 0.0001
I1018 12:37:51.284728 11069 solver.cpp:242] Iteration 35840, loss = 0.252707
I1018 12:37:51.284754 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0582135 (* 1 = 0.0582135 loss)
I1018 12:37:51.284760 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194494 (* 1 = 0.194494 loss)
I1018 12:37:51.284765 11069 solver.cpp:571] Iteration 35840, lr = 0.0001
I1018 12:37:58.316975 11069 solver.cpp:242] Iteration 35860, loss = 0.556973
I1018 12:37:58.317000 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.228337 (* 1 = 0.228337 loss)
I1018 12:37:58.317005 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.328635 (* 1 = 0.328635 loss)
I1018 12:37:58.317009 11069 solver.cpp:571] Iteration 35860, lr = 0.0001
I1018 12:38:05.695024 11069 solver.cpp:242] Iteration 35880, loss = 0.17219
I1018 12:38:05.695050 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0411663 (* 1 = 0.0411663 loss)
I1018 12:38:05.695055 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131024 (* 1 = 0.131024 loss)
I1018 12:38:05.695058 11069 solver.cpp:571] Iteration 35880, lr = 0.0001
I1018 12:38:13.193802 11069 solver.cpp:242] Iteration 35900, loss = 0.198315
I1018 12:38:13.193828 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0478596 (* 1 = 0.0478596 loss)
I1018 12:38:13.193835 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.150455 (* 1 = 0.150455 loss)
I1018 12:38:13.193837 11069 solver.cpp:571] Iteration 35900, lr = 0.0001
I1018 12:38:20.514577 11069 solver.cpp:242] Iteration 35920, loss = 0.578425
I1018 12:38:20.514602 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.170611 (* 1 = 0.170611 loss)
I1018 12:38:20.514606 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.407814 (* 1 = 0.407814 loss)
I1018 12:38:20.514611 11069 solver.cpp:571] Iteration 35920, lr = 0.0001
I1018 12:38:27.660547 11069 solver.cpp:242] Iteration 35940, loss = 0.223844
I1018 12:38:27.660573 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.102692 (* 1 = 0.102692 loss)
I1018 12:38:27.660578 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.121152 (* 1 = 0.121152 loss)
I1018 12:38:27.660581 11069 solver.cpp:571] Iteration 35940, lr = 0.0001
I1018 12:38:34.974398 11069 solver.cpp:242] Iteration 35960, loss = 0.128482
I1018 12:38:34.974424 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.034936 (* 1 = 0.034936 loss)
I1018 12:38:34.974429 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0935461 (* 1 = 0.0935461 loss)
I1018 12:38:34.974433 11069 solver.cpp:571] Iteration 35960, lr = 0.0001
I1018 12:38:42.412762 11069 solver.cpp:242] Iteration 35980, loss = 0.482678
I1018 12:38:42.412787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13347 (* 1 = 0.13347 loss)
I1018 12:38:42.412792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.349208 (* 1 = 0.349208 loss)
I1018 12:38:42.412796 11069 solver.cpp:571] Iteration 35980, lr = 0.0001
speed: 0.378s / iter
I1018 12:38:49.250452 11069 solver.cpp:242] Iteration 36000, loss = 0.215742
I1018 12:38:49.250478 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0516028 (* 1 = 0.0516028 loss)
I1018 12:38:49.250481 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.16414 (* 1 = 0.16414 loss)
I1018 12:38:49.250485 11069 solver.cpp:571] Iteration 36000, lr = 0.0001
I1018 12:38:56.100391 11069 solver.cpp:242] Iteration 36020, loss = 0.322599
I1018 12:38:56.100416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.110355 (* 1 = 0.110355 loss)
I1018 12:38:56.100421 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.212245 (* 1 = 0.212245 loss)
I1018 12:38:56.100425 11069 solver.cpp:571] Iteration 36020, lr = 0.0001
I1018 12:39:03.542260 11069 solver.cpp:242] Iteration 36040, loss = 0.252938
I1018 12:39:03.542286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529446 (* 1 = 0.0529446 loss)
I1018 12:39:03.542291 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.199994 (* 1 = 0.199994 loss)
I1018 12:39:03.542295 11069 solver.cpp:571] Iteration 36040, lr = 0.0001
I1018 12:39:11.371791 11069 solver.cpp:242] Iteration 36060, loss = 0.878631
I1018 12:39:11.371817 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.382655 (* 1 = 0.382655 loss)
I1018 12:39:11.371821 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495976 (* 1 = 0.495976 loss)
I1018 12:39:11.371826 11069 solver.cpp:571] Iteration 36060, lr = 0.0001
I1018 12:39:19.112197 11069 solver.cpp:242] Iteration 36080, loss = 0.427554
I1018 12:39:19.112223 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143153 (* 1 = 0.143153 loss)
I1018 12:39:19.112228 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.284401 (* 1 = 0.284401 loss)
I1018 12:39:19.112232 11069 solver.cpp:571] Iteration 36080, lr = 0.0001
I1018 12:39:26.778406 11069 solver.cpp:242] Iteration 36100, loss = 0.792427
I1018 12:39:26.778435 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.272767 (* 1 = 0.272767 loss)
I1018 12:39:26.778439 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.51966 (* 1 = 0.51966 loss)
I1018 12:39:26.778444 11069 solver.cpp:571] Iteration 36100, lr = 0.0001
I1018 12:39:34.070636 11069 solver.cpp:242] Iteration 36120, loss = 0.294478
I1018 12:39:34.070662 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0886821 (* 1 = 0.0886821 loss)
I1018 12:39:34.070667 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.205796 (* 1 = 0.205796 loss)
I1018 12:39:34.070672 11069 solver.cpp:571] Iteration 36120, lr = 0.0001
I1018 12:39:41.758698 11069 solver.cpp:242] Iteration 36140, loss = 0.138335
I1018 12:39:41.758726 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.033399 (* 1 = 0.033399 loss)
I1018 12:39:41.758731 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.104936 (* 1 = 0.104936 loss)
I1018 12:39:41.758736 11069 solver.cpp:571] Iteration 36140, lr = 0.0001
I1018 12:39:49.121678 11069 solver.cpp:242] Iteration 36160, loss = 0.151132
I1018 12:39:49.121703 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0453093 (* 1 = 0.0453093 loss)
I1018 12:39:49.121709 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.105823 (* 1 = 0.105823 loss)
I1018 12:39:49.121713 11069 solver.cpp:571] Iteration 36160, lr = 0.0001
I1018 12:39:56.717281 11069 solver.cpp:242] Iteration 36180, loss = 0.175135
I1018 12:39:56.717308 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0669617 (* 1 = 0.0669617 loss)
I1018 12:39:56.717314 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.108173 (* 1 = 0.108173 loss)
I1018 12:39:56.717317 11069 solver.cpp:571] Iteration 36180, lr = 0.0001
speed: 0.378s / iter
I1018 12:40:03.992856 11069 solver.cpp:242] Iteration 36200, loss = 0.604303
I1018 12:40:03.992882 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.215298 (* 1 = 0.215298 loss)
I1018 12:40:03.992887 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.389005 (* 1 = 0.389005 loss)
I1018 12:40:03.992890 11069 solver.cpp:571] Iteration 36200, lr = 0.0001
I1018 12:40:11.638761 11069 solver.cpp:242] Iteration 36220, loss = 0.207275
I1018 12:40:11.638787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0524302 (* 1 = 0.0524302 loss)
I1018 12:40:11.638792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.154845 (* 1 = 0.154845 loss)
I1018 12:40:11.638794 11069 solver.cpp:571] Iteration 36220, lr = 0.0001
I1018 12:40:18.980573 11069 solver.cpp:242] Iteration 36240, loss = 1.44598
I1018 12:40:18.980598 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.650029 (* 1 = 0.650029 loss)
I1018 12:40:18.980603 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.795952 (* 1 = 0.795952 loss)
I1018 12:40:18.980607 11069 solver.cpp:571] Iteration 36240, lr = 0.0001
I1018 12:40:26.697382 11069 solver.cpp:242] Iteration 36260, loss = 0.563279
I1018 12:40:26.697408 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.178463 (* 1 = 0.178463 loss)
I1018 12:40:26.697413 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.384816 (* 1 = 0.384816 loss)
I1018 12:40:26.697417 11069 solver.cpp:571] Iteration 36260, lr = 0.0001
I1018 12:40:34.388625 11069 solver.cpp:242] Iteration 36280, loss = 0.469432
I1018 12:40:34.388653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.101943 (* 1 = 0.101943 loss)
I1018 12:40:34.388658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.367489 (* 1 = 0.367489 loss)
I1018 12:40:34.388661 11069 solver.cpp:571] Iteration 36280, lr = 0.0001
I1018 12:40:42.125751 11069 solver.cpp:242] Iteration 36300, loss = 1.45513
I1018 12:40:42.125777 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.620361 (* 1 = 0.620361 loss)
I1018 12:40:42.125782 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.834766 (* 1 = 0.834766 loss)
I1018 12:40:42.125787 11069 solver.cpp:571] Iteration 36300, lr = 0.0001
I1018 12:40:49.668015 11069 solver.cpp:242] Iteration 36320, loss = 0.312544
I1018 12:40:49.668041 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.10875 (* 1 = 0.10875 loss)
I1018 12:40:49.668047 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.203794 (* 1 = 0.203794 loss)
I1018 12:40:49.668051 11069 solver.cpp:571] Iteration 36320, lr = 0.0001
I1018 12:40:57.292057 11069 solver.cpp:242] Iteration 36340, loss = 0.177923
I1018 12:40:57.292080 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0550649 (* 1 = 0.0550649 loss)
I1018 12:40:57.292085 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.122858 (* 1 = 0.122858 loss)
I1018 12:40:57.292089 11069 solver.cpp:571] Iteration 36340, lr = 0.0001
I1018 12:41:04.810700 11069 solver.cpp:242] Iteration 36360, loss = 0.189918
I1018 12:41:04.810726 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0540068 (* 1 = 0.0540068 loss)
I1018 12:41:04.810731 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.135911 (* 1 = 0.135911 loss)
I1018 12:41:04.810735 11069 solver.cpp:571] Iteration 36360, lr = 0.0001
I1018 12:41:12.281126 11069 solver.cpp:242] Iteration 36380, loss = 0.284509
I1018 12:41:12.281152 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.056649 (* 1 = 0.056649 loss)
I1018 12:41:12.281157 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.22786 (* 1 = 0.22786 loss)
I1018 12:41:12.281160 11069 solver.cpp:571] Iteration 36380, lr = 0.0001
speed: 0.378s / iter
I1018 12:41:19.831653 11069 solver.cpp:242] Iteration 36400, loss = 1.37612
I1018 12:41:19.831689 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.579299 (* 1 = 0.579299 loss)
I1018 12:41:19.831694 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.79682 (* 1 = 0.79682 loss)
I1018 12:41:19.831698 11069 solver.cpp:571] Iteration 36400, lr = 0.0001
I1018 12:41:27.294769 11069 solver.cpp:242] Iteration 36420, loss = 0.828007
I1018 12:41:27.294793 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.271345 (* 1 = 0.271345 loss)
I1018 12:41:27.294800 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.556662 (* 1 = 0.556662 loss)
I1018 12:41:27.294803 11069 solver.cpp:571] Iteration 36420, lr = 0.0001
I1018 12:41:34.763851 11069 solver.cpp:242] Iteration 36440, loss = 0.167273
I1018 12:41:34.763876 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0344659 (* 1 = 0.0344659 loss)
I1018 12:41:34.763881 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.132807 (* 1 = 0.132807 loss)
I1018 12:41:34.763885 11069 solver.cpp:571] Iteration 36440, lr = 0.0001
I1018 12:41:42.207772 11069 solver.cpp:242] Iteration 36460, loss = 0.329077
I1018 12:41:42.207799 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0994134 (* 1 = 0.0994134 loss)
I1018 12:41:42.207805 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.229663 (* 1 = 0.229663 loss)
I1018 12:41:42.207809 11069 solver.cpp:571] Iteration 36460, lr = 0.0001
I1018 12:41:49.727388 11069 solver.cpp:242] Iteration 36480, loss = 0.0962102
I1018 12:41:49.727416 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0433909 (* 1 = 0.0433909 loss)
I1018 12:41:49.727421 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0528193 (* 1 = 0.0528193 loss)
I1018 12:41:49.727424 11069 solver.cpp:571] Iteration 36480, lr = 0.0001
I1018 12:41:57.429000 11069 solver.cpp:242] Iteration 36500, loss = 1.48489
I1018 12:41:57.429026 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.638138 (* 1 = 0.638138 loss)
I1018 12:41:57.429031 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.846754 (* 1 = 0.846754 loss)
I1018 12:41:57.429035 11069 solver.cpp:571] Iteration 36500, lr = 0.0001
I1018 12:42:05.078877 11069 solver.cpp:242] Iteration 36520, loss = 0.241967
I1018 12:42:05.078904 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0529979 (* 1 = 0.0529979 loss)
I1018 12:42:05.078909 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.188969 (* 1 = 0.188969 loss)
I1018 12:42:05.078913 11069 solver.cpp:571] Iteration 36520, lr = 0.0001
I1018 12:42:12.565129 11069 solver.cpp:242] Iteration 36540, loss = 0.616128
I1018 12:42:12.565155 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.164128 (* 1 = 0.164128 loss)
I1018 12:42:12.565160 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.452 (* 1 = 0.452 loss)
I1018 12:42:12.565165 11069 solver.cpp:571] Iteration 36540, lr = 0.0001
I1018 12:42:19.999476 11069 solver.cpp:242] Iteration 36560, loss = 0.240309
I1018 12:42:19.999501 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0594465 (* 1 = 0.0594465 loss)
I1018 12:42:19.999506 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.180863 (* 1 = 0.180863 loss)
I1018 12:42:19.999511 11069 solver.cpp:571] Iteration 36560, lr = 0.0001
I1018 12:42:27.820899 11069 solver.cpp:242] Iteration 36580, loss = 1.08227
I1018 12:42:27.820925 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.43356 (* 1 = 0.43356 loss)
I1018 12:42:27.820930 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.648709 (* 1 = 0.648709 loss)
I1018 12:42:27.820935 11069 solver.cpp:571] Iteration 36580, lr = 0.0001
speed: 0.378s / iter
I1018 12:42:35.481626 11069 solver.cpp:242] Iteration 36600, loss = 0.455499
I1018 12:42:35.481653 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.153777 (* 1 = 0.153777 loss)
I1018 12:42:35.481658 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.301721 (* 1 = 0.301721 loss)
I1018 12:42:35.481662 11069 solver.cpp:571] Iteration 36600, lr = 0.0001
I1018 12:42:43.092810 11069 solver.cpp:242] Iteration 36620, loss = 0.88403
I1018 12:42:43.092833 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.275318 (* 1 = 0.275318 loss)
I1018 12:42:43.092839 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.608713 (* 1 = 0.608713 loss)
I1018 12:42:43.092842 11069 solver.cpp:571] Iteration 36620, lr = 0.0001
I1018 12:42:50.660831 11069 solver.cpp:242] Iteration 36640, loss = 0.242926
I1018 12:42:50.660856 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0517482 (* 1 = 0.0517482 loss)
I1018 12:42:50.660861 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.191178 (* 1 = 0.191178 loss)
I1018 12:42:50.660864 11069 solver.cpp:571] Iteration 36640, lr = 0.0001
I1018 12:42:58.349141 11069 solver.cpp:242] Iteration 36660, loss = 1.45737
I1018 12:42:58.349166 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.568767 (* 1 = 0.568767 loss)
I1018 12:42:58.349171 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.888599 (* 1 = 0.888599 loss)
I1018 12:42:58.349175 11069 solver.cpp:571] Iteration 36660, lr = 0.0001
I1018 12:43:05.627391 11069 solver.cpp:242] Iteration 36680, loss = 0.263351
I1018 12:43:05.627418 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0776197 (* 1 = 0.0776197 loss)
I1018 12:43:05.627421 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.185731 (* 1 = 0.185731 loss)
I1018 12:43:05.627425 11069 solver.cpp:571] Iteration 36680, lr = 0.0001
I1018 12:43:13.160135 11069 solver.cpp:242] Iteration 36700, loss = 0.190812
I1018 12:43:13.160159 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0571952 (* 1 = 0.0571952 loss)
I1018 12:43:13.160164 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133617 (* 1 = 0.133617 loss)
I1018 12:43:13.160168 11069 solver.cpp:571] Iteration 36700, lr = 0.0001
I1018 12:43:20.446024 11069 solver.cpp:242] Iteration 36720, loss = 0.170432
I1018 12:43:20.446049 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0523726 (* 1 = 0.0523726 loss)
I1018 12:43:20.446054 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.118059 (* 1 = 0.118059 loss)
I1018 12:43:20.446058 11069 solver.cpp:571] Iteration 36720, lr = 0.0001
I1018 12:43:28.096911 11069 solver.cpp:242] Iteration 36740, loss = 0.265636
I1018 12:43:28.096936 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0836592 (* 1 = 0.0836592 loss)
I1018 12:43:28.096941 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.181976 (* 1 = 0.181976 loss)
I1018 12:43:28.096946 11069 solver.cpp:571] Iteration 36740, lr = 0.0001
I1018 12:43:35.443126 11069 solver.cpp:242] Iteration 36760, loss = 0.85721
I1018 12:43:35.443151 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.326354 (* 1 = 0.326354 loss)
I1018 12:43:35.443156 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.530856 (* 1 = 0.530856 loss)
I1018 12:43:35.443161 11069 solver.cpp:571] Iteration 36760, lr = 0.0001
I1018 12:43:42.840898 11069 solver.cpp:242] Iteration 36780, loss = 0.133154
I1018 12:43:42.840922 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0355397 (* 1 = 0.0355397 loss)
I1018 12:43:42.840926 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0976146 (* 1 = 0.0976146 loss)
I1018 12:43:42.840931 11069 solver.cpp:571] Iteration 36780, lr = 0.0001
speed: 0.378s / iter
I1018 12:43:50.238898 11069 solver.cpp:242] Iteration 36800, loss = 0.484206
I1018 12:43:50.238924 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.11761 (* 1 = 0.11761 loss)
I1018 12:43:50.238929 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.366596 (* 1 = 0.366596 loss)
I1018 12:43:50.238932 11069 solver.cpp:571] Iteration 36800, lr = 0.0001
I1018 12:43:57.518659 11069 solver.cpp:242] Iteration 36820, loss = 0.461873
I1018 12:43:57.518685 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.110313 (* 1 = 0.110313 loss)
I1018 12:43:57.518690 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.35156 (* 1 = 0.35156 loss)
I1018 12:43:57.518695 11069 solver.cpp:571] Iteration 36820, lr = 0.0001
I1018 12:44:04.902953 11069 solver.cpp:242] Iteration 36840, loss = 1.3883
I1018 12:44:04.902979 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.660964 (* 1 = 0.660964 loss)
I1018 12:44:04.902986 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.727332 (* 1 = 0.727332 loss)
I1018 12:44:04.902989 11069 solver.cpp:571] Iteration 36840, lr = 0.0001
I1018 12:44:12.667317 11069 solver.cpp:242] Iteration 36860, loss = 0.204414
I1018 12:44:12.667343 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0600694 (* 1 = 0.0600694 loss)
I1018 12:44:12.667348 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.144345 (* 1 = 0.144345 loss)
I1018 12:44:12.667351 11069 solver.cpp:571] Iteration 36860, lr = 0.0001
I1018 12:44:20.383215 11069 solver.cpp:242] Iteration 36880, loss = 0.458293
I1018 12:44:20.383239 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.116987 (* 1 = 0.116987 loss)
I1018 12:44:20.383244 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.341306 (* 1 = 0.341306 loss)
I1018 12:44:20.383249 11069 solver.cpp:571] Iteration 36880, lr = 0.0001
I1018 12:44:28.111423 11069 solver.cpp:242] Iteration 36900, loss = 0.242553
I1018 12:44:28.111449 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.072989 (* 1 = 0.072989 loss)
I1018 12:44:28.111452 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.169564 (* 1 = 0.169564 loss)
I1018 12:44:28.111456 11069 solver.cpp:571] Iteration 36900, lr = 0.0001
I1018 12:44:35.599969 11069 solver.cpp:242] Iteration 36920, loss = 0.113679
I1018 12:44:35.599994 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0271532 (* 1 = 0.0271532 loss)
I1018 12:44:35.599999 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.086526 (* 1 = 0.086526 loss)
I1018 12:44:35.600003 11069 solver.cpp:571] Iteration 36920, lr = 0.0001
I1018 12:44:43.185672 11069 solver.cpp:242] Iteration 36940, loss = 0.482246
I1018 12:44:43.185695 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.185857 (* 1 = 0.185857 loss)
I1018 12:44:43.185700 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296389 (* 1 = 0.296389 loss)
I1018 12:44:43.185704 11069 solver.cpp:571] Iteration 36940, lr = 0.0001
I1018 12:44:50.995652 11069 solver.cpp:242] Iteration 36960, loss = 0.439637
I1018 12:44:50.995678 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.119522 (* 1 = 0.119522 loss)
I1018 12:44:50.995683 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.320115 (* 1 = 0.320115 loss)
I1018 12:44:50.995687 11069 solver.cpp:571] Iteration 36960, lr = 0.0001
I1018 12:44:58.294569 11069 solver.cpp:242] Iteration 36980, loss = 0.646232
I1018 12:44:58.294594 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159194 (* 1 = 0.159194 loss)
I1018 12:44:58.294598 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.487038 (* 1 = 0.487038 loss)
I1018 12:44:58.294601 11069 solver.cpp:571] Iteration 36980, lr = 0.0001
speed: 0.378s / iter
I1018 12:45:05.704094 11069 solver.cpp:242] Iteration 37000, loss = 0.854062
I1018 12:45:05.704120 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.296204 (* 1 = 0.296204 loss)
I1018 12:45:05.704124 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.557858 (* 1 = 0.557858 loss)
I1018 12:45:05.704128 11069 solver.cpp:571] Iteration 37000, lr = 0.0001
I1018 12:45:12.831667 11069 solver.cpp:242] Iteration 37020, loss = 0.200687
I1018 12:45:12.831693 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0513835 (* 1 = 0.0513835 loss)
I1018 12:45:12.831697 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.149303 (* 1 = 0.149303 loss)
I1018 12:45:12.831701 11069 solver.cpp:571] Iteration 37020, lr = 0.0001
I1018 12:45:20.340257 11069 solver.cpp:242] Iteration 37040, loss = 1.13841
I1018 12:45:20.340281 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.403799 (* 1 = 0.403799 loss)
I1018 12:45:20.340286 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.734606 (* 1 = 0.734606 loss)
I1018 12:45:20.340291 11069 solver.cpp:571] Iteration 37040, lr = 0.0001
I1018 12:45:27.511373 11069 solver.cpp:242] Iteration 37060, loss = 1.49158
I1018 12:45:27.511397 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.798357 (* 1 = 0.798357 loss)
I1018 12:45:27.511402 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.693228 (* 1 = 0.693228 loss)
I1018 12:45:27.511407 11069 solver.cpp:571] Iteration 37060, lr = 0.0001
I1018 12:45:34.708417 11069 solver.cpp:242] Iteration 37080, loss = 0.7292
I1018 12:45:34.708442 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.205795 (* 1 = 0.205795 loss)
I1018 12:45:34.708447 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.523404 (* 1 = 0.523404 loss)
I1018 12:45:34.708451 11069 solver.cpp:571] Iteration 37080, lr = 0.0001
I1018 12:45:42.265346 11069 solver.cpp:242] Iteration 37100, loss = 1.03216
I1018 12:45:42.265372 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.399156 (* 1 = 0.399156 loss)
I1018 12:45:42.265377 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.633 (* 1 = 0.633 loss)
I1018 12:45:42.265382 11069 solver.cpp:571] Iteration 37100, lr = 0.0001
I1018 12:45:49.766726 11069 solver.cpp:242] Iteration 37120, loss = 0.379773
I1018 12:45:49.766751 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.128708 (* 1 = 0.128708 loss)
I1018 12:45:49.766755 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.251065 (* 1 = 0.251065 loss)
I1018 12:45:49.766759 11069 solver.cpp:571] Iteration 37120, lr = 0.0001
I1018 12:45:57.433595 11069 solver.cpp:242] Iteration 37140, loss = 0.773839
I1018 12:45:57.433619 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.237157 (* 1 = 0.237157 loss)
I1018 12:45:57.433624 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.536682 (* 1 = 0.536682 loss)
I1018 12:45:57.433627 11069 solver.cpp:571] Iteration 37140, lr = 0.0001
I1018 12:46:04.871367 11069 solver.cpp:242] Iteration 37160, loss = 0.208117
I1018 12:46:04.871393 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104403 (* 1 = 0.104403 loss)
I1018 12:46:04.871397 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.103714 (* 1 = 0.103714 loss)
I1018 12:46:04.871402 11069 solver.cpp:571] Iteration 37160, lr = 0.0001
I1018 12:46:12.506325 11069 solver.cpp:242] Iteration 37180, loss = 1.2579
I1018 12:46:12.506350 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.446456 (* 1 = 0.446456 loss)
I1018 12:46:12.506355 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.811443 (* 1 = 0.811443 loss)
I1018 12:46:12.506358 11069 solver.cpp:571] Iteration 37180, lr = 0.0001
speed: 0.378s / iter
I1018 12:46:20.204996 11069 solver.cpp:242] Iteration 37200, loss = 0.177446
I1018 12:46:20.205021 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0388487 (* 1 = 0.0388487 loss)
I1018 12:46:20.205025 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.138597 (* 1 = 0.138597 loss)
I1018 12:46:20.205029 11069 solver.cpp:571] Iteration 37200, lr = 0.0001
I1018 12:46:27.882730 11069 solver.cpp:242] Iteration 37220, loss = 0.0876045
I1018 12:46:27.882755 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0212127 (* 1 = 0.0212127 loss)
I1018 12:46:27.882760 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0663918 (* 1 = 0.0663918 loss)
I1018 12:46:27.882763 11069 solver.cpp:571] Iteration 37220, lr = 0.0001
I1018 12:46:35.232872 11069 solver.cpp:242] Iteration 37240, loss = 1.16759
I1018 12:46:35.232898 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.440717 (* 1 = 0.440717 loss)
I1018 12:46:35.232903 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.726878 (* 1 = 0.726878 loss)
I1018 12:46:35.232908 11069 solver.cpp:571] Iteration 37240, lr = 0.0001
I1018 12:46:42.638568 11069 solver.cpp:242] Iteration 37260, loss = 0.319953
I1018 12:46:42.638593 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13788 (* 1 = 0.13788 loss)
I1018 12:46:42.638597 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.182073 (* 1 = 0.182073 loss)
I1018 12:46:42.638602 11069 solver.cpp:571] Iteration 37260, lr = 0.0001
I1018 12:46:49.942194 11069 solver.cpp:242] Iteration 37280, loss = 0.256353
I1018 12:46:49.942219 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0606947 (* 1 = 0.0606947 loss)
I1018 12:46:49.942224 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.195658 (* 1 = 0.195658 loss)
I1018 12:46:49.942229 11069 solver.cpp:571] Iteration 37280, lr = 0.0001
I1018 12:46:57.330497 11069 solver.cpp:242] Iteration 37300, loss = 0.571258
I1018 12:46:57.330523 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.175206 (* 1 = 0.175206 loss)
I1018 12:46:57.330528 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.396051 (* 1 = 0.396051 loss)
I1018 12:46:57.330533 11069 solver.cpp:571] Iteration 37300, lr = 0.0001
I1018 12:47:04.751633 11069 solver.cpp:242] Iteration 37320, loss = 0.693677
I1018 12:47:04.751658 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.239171 (* 1 = 0.239171 loss)
I1018 12:47:04.751662 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.454507 (* 1 = 0.454507 loss)
I1018 12:47:04.751667 11069 solver.cpp:571] Iteration 37320, lr = 0.0001
I1018 12:47:12.098718 11069 solver.cpp:242] Iteration 37340, loss = 0.502073
I1018 12:47:12.098743 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.175104 (* 1 = 0.175104 loss)
I1018 12:47:12.098748 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.326969 (* 1 = 0.326969 loss)
I1018 12:47:12.098752 11069 solver.cpp:571] Iteration 37340, lr = 0.0001
I1018 12:47:19.752529 11069 solver.cpp:242] Iteration 37360, loss = 0.817391
I1018 12:47:19.752555 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.249645 (* 1 = 0.249645 loss)
I1018 12:47:19.752560 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.567746 (* 1 = 0.567746 loss)
I1018 12:47:19.752564 11069 solver.cpp:571] Iteration 37360, lr = 0.0001
I1018 12:47:27.118203 11069 solver.cpp:242] Iteration 37380, loss = 0.226548
I1018 12:47:27.118230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0540204 (* 1 = 0.0540204 loss)
I1018 12:47:27.118235 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.172528 (* 1 = 0.172528 loss)
I1018 12:47:27.118239 11069 solver.cpp:571] Iteration 37380, lr = 0.0001
speed: 0.378s / iter
I1018 12:47:34.608772 11069 solver.cpp:242] Iteration 37400, loss = 0.350114
I1018 12:47:34.608798 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0539887 (* 1 = 0.0539887 loss)
I1018 12:47:34.608803 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.296126 (* 1 = 0.296126 loss)
I1018 12:47:34.608808 11069 solver.cpp:571] Iteration 37400, lr = 0.0001
I1018 12:47:42.085142 11069 solver.cpp:242] Iteration 37420, loss = 0.443857
I1018 12:47:42.085167 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.141261 (* 1 = 0.141261 loss)
I1018 12:47:42.085172 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.302596 (* 1 = 0.302596 loss)
I1018 12:47:42.085176 11069 solver.cpp:571] Iteration 37420, lr = 0.0001
I1018 12:47:49.557986 11069 solver.cpp:242] Iteration 37440, loss = 0.197334
I1018 12:47:49.558012 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0536028 (* 1 = 0.0536028 loss)
I1018 12:47:49.558017 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.143731 (* 1 = 0.143731 loss)
I1018 12:47:49.558022 11069 solver.cpp:571] Iteration 37440, lr = 0.0001
I1018 12:47:57.133864 11069 solver.cpp:242] Iteration 37460, loss = 1.35961
I1018 12:47:57.133889 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.574283 (* 1 = 0.574283 loss)
I1018 12:47:57.133894 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.785324 (* 1 = 0.785324 loss)
I1018 12:47:57.133898 11069 solver.cpp:571] Iteration 37460, lr = 0.0001
I1018 12:48:04.656205 11069 solver.cpp:242] Iteration 37480, loss = 0.162961
I1018 12:48:04.656231 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0394688 (* 1 = 0.0394688 loss)
I1018 12:48:04.656236 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123493 (* 1 = 0.123493 loss)
I1018 12:48:04.656240 11069 solver.cpp:571] Iteration 37480, lr = 0.0001
I1018 12:48:12.209985 11069 solver.cpp:242] Iteration 37500, loss = 1.19405
I1018 12:48:12.210011 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.513575 (* 1 = 0.513575 loss)
I1018 12:48:12.210016 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.680473 (* 1 = 0.680473 loss)
I1018 12:48:12.210019 11069 solver.cpp:571] Iteration 37500, lr = 0.0001
I1018 12:48:19.708282 11069 solver.cpp:242] Iteration 37520, loss = 0.187174
I1018 12:48:19.708308 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0678239 (* 1 = 0.0678239 loss)
I1018 12:48:19.708324 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.11935 (* 1 = 0.11935 loss)
I1018 12:48:19.708328 11069 solver.cpp:571] Iteration 37520, lr = 0.0001
I1018 12:48:27.026898 11069 solver.cpp:242] Iteration 37540, loss = 0.173508
I1018 12:48:27.026926 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0372381 (* 1 = 0.0372381 loss)
I1018 12:48:27.026931 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.13627 (* 1 = 0.13627 loss)
I1018 12:48:27.026935 11069 solver.cpp:571] Iteration 37540, lr = 0.0001
I1018 12:48:34.588704 11069 solver.cpp:242] Iteration 37560, loss = 0.430896
I1018 12:48:34.588729 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.158409 (* 1 = 0.158409 loss)
I1018 12:48:34.588734 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.272487 (* 1 = 0.272487 loss)
I1018 12:48:34.588738 11069 solver.cpp:571] Iteration 37560, lr = 0.0001
I1018 12:48:42.020720 11069 solver.cpp:242] Iteration 37580, loss = 0.958415
I1018 12:48:42.020746 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.352921 (* 1 = 0.352921 loss)
I1018 12:48:42.020751 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.605494 (* 1 = 0.605494 loss)
I1018 12:48:42.020756 11069 solver.cpp:571] Iteration 37580, lr = 0.0001
speed: 0.378s / iter
I1018 12:48:49.689493 11069 solver.cpp:242] Iteration 37600, loss = 0.350257
I1018 12:48:49.689520 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0938008 (* 1 = 0.0938008 loss)
I1018 12:48:49.689525 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.256456 (* 1 = 0.256456 loss)
I1018 12:48:49.689529 11069 solver.cpp:571] Iteration 37600, lr = 0.0001
I1018 12:48:57.378744 11069 solver.cpp:242] Iteration 37620, loss = 0.866069
I1018 12:48:57.378770 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.285364 (* 1 = 0.285364 loss)
I1018 12:48:57.378775 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.580705 (* 1 = 0.580705 loss)
I1018 12:48:57.378780 11069 solver.cpp:571] Iteration 37620, lr = 0.0001
I1018 12:49:05.159840 11069 solver.cpp:242] Iteration 37640, loss = 0.101326
I1018 12:49:05.159867 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0323705 (* 1 = 0.0323705 loss)
I1018 12:49:05.159873 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.068955 (* 1 = 0.068955 loss)
I1018 12:49:05.159876 11069 solver.cpp:571] Iteration 37640, lr = 0.0001
I1018 12:49:12.753373 11069 solver.cpp:242] Iteration 37660, loss = 0.292455
I1018 12:49:12.753399 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0647176 (* 1 = 0.0647176 loss)
I1018 12:49:12.753406 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.227738 (* 1 = 0.227738 loss)
I1018 12:49:12.753409 11069 solver.cpp:571] Iteration 37660, lr = 0.0001
I1018 12:49:20.446027 11069 solver.cpp:242] Iteration 37680, loss = 0.760969
I1018 12:49:20.446054 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.26539 (* 1 = 0.26539 loss)
I1018 12:49:20.446059 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.495579 (* 1 = 0.495579 loss)
I1018 12:49:20.446063 11069 solver.cpp:571] Iteration 37680, lr = 0.0001
I1018 12:49:28.253151 11069 solver.cpp:242] Iteration 37700, loss = 0.856241
I1018 12:49:28.253175 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.291577 (* 1 = 0.291577 loss)
I1018 12:49:28.253180 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.564664 (* 1 = 0.564664 loss)
I1018 12:49:28.253185 11069 solver.cpp:571] Iteration 37700, lr = 0.0001
I1018 12:49:36.000802 11069 solver.cpp:242] Iteration 37720, loss = 0.177627
I1018 12:49:36.000829 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0581837 (* 1 = 0.0581837 loss)
I1018 12:49:36.000834 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.119443 (* 1 = 0.119443 loss)
I1018 12:49:36.000838 11069 solver.cpp:571] Iteration 37720, lr = 0.0001
I1018 12:49:43.812247 11069 solver.cpp:242] Iteration 37740, loss = 0.198837
I1018 12:49:43.812275 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0726444 (* 1 = 0.0726444 loss)
I1018 12:49:43.812280 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.126193 (* 1 = 0.126193 loss)
I1018 12:49:43.812284 11069 solver.cpp:571] Iteration 37740, lr = 0.0001
I1018 12:49:51.412248 11069 solver.cpp:242] Iteration 37760, loss = 0.159464
I1018 12:49:51.412276 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0456134 (* 1 = 0.0456134 loss)
I1018 12:49:51.412281 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.113851 (* 1 = 0.113851 loss)
I1018 12:49:51.412283 11069 solver.cpp:571] Iteration 37760, lr = 0.0001
I1018 12:49:59.241014 11069 solver.cpp:242] Iteration 37780, loss = 0.563536
I1018 12:49:59.241039 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.148375 (* 1 = 0.148375 loss)
I1018 12:49:59.241042 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.415161 (* 1 = 0.415161 loss)
I1018 12:49:59.241046 11069 solver.cpp:571] Iteration 37780, lr = 0.0001
speed: 0.378s / iter
I1018 12:50:06.971328 11069 solver.cpp:242] Iteration 37800, loss = 0.224065
I1018 12:50:06.971354 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479072 (* 1 = 0.0479072 loss)
I1018 12:50:06.971357 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.176158 (* 1 = 0.176158 loss)
I1018 12:50:06.971361 11069 solver.cpp:571] Iteration 37800, lr = 0.0001
I1018 12:50:14.752578 11069 solver.cpp:242] Iteration 37820, loss = 0.449556
I1018 12:50:14.752604 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159839 (* 1 = 0.159839 loss)
I1018 12:50:14.752607 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.289717 (* 1 = 0.289717 loss)
I1018 12:50:14.752611 11069 solver.cpp:571] Iteration 37820, lr = 0.0001
I1018 12:50:22.446504 11069 solver.cpp:242] Iteration 37840, loss = 0.160543
I1018 12:50:22.446532 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0675507 (* 1 = 0.0675507 loss)
I1018 12:50:22.446537 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0929918 (* 1 = 0.0929918 loss)
I1018 12:50:22.446540 11069 solver.cpp:571] Iteration 37840, lr = 0.0001
I1018 12:50:30.184774 11069 solver.cpp:242] Iteration 37860, loss = 0.225857
I1018 12:50:30.184799 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0522191 (* 1 = 0.0522191 loss)
I1018 12:50:30.184804 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.173638 (* 1 = 0.173638 loss)
I1018 12:50:30.184808 11069 solver.cpp:571] Iteration 37860, lr = 0.0001
I1018 12:50:37.991487 11069 solver.cpp:242] Iteration 37880, loss = 0.512131
I1018 12:50:37.991511 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.197875 (* 1 = 0.197875 loss)
I1018 12:50:37.991516 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.314256 (* 1 = 0.314256 loss)
I1018 12:50:37.991520 11069 solver.cpp:571] Iteration 37880, lr = 0.0001
I1018 12:50:45.788775 11069 solver.cpp:242] Iteration 37900, loss = 0.592804
I1018 12:50:45.788800 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.187389 (* 1 = 0.187389 loss)
I1018 12:50:45.788805 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.405416 (* 1 = 0.405416 loss)
I1018 12:50:45.788810 11069 solver.cpp:571] Iteration 37900, lr = 0.0001
I1018 12:50:53.506469 11069 solver.cpp:242] Iteration 37920, loss = 0.347736
I1018 12:50:53.506495 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0985836 (* 1 = 0.0985836 loss)
I1018 12:50:53.506500 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.249153 (* 1 = 0.249153 loss)
I1018 12:50:53.506505 11069 solver.cpp:571] Iteration 37920, lr = 0.0001
I1018 12:51:01.310773 11069 solver.cpp:242] Iteration 37940, loss = 0.368789
I1018 12:51:01.310799 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.081335 (* 1 = 0.081335 loss)
I1018 12:51:01.310804 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.287454 (* 1 = 0.287454 loss)
I1018 12:51:01.310808 11069 solver.cpp:571] Iteration 37940, lr = 0.0001
I1018 12:51:09.099083 11069 solver.cpp:242] Iteration 37960, loss = 0.141435
I1018 12:51:09.099112 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0453591 (* 1 = 0.0453591 loss)
I1018 12:51:09.099117 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0960758 (* 1 = 0.0960758 loss)
I1018 12:51:09.099120 11069 solver.cpp:571] Iteration 37960, lr = 0.0001
I1018 12:51:16.859365 11069 solver.cpp:242] Iteration 37980, loss = 0.135038
I1018 12:51:16.859393 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0299772 (* 1 = 0.0299772 loss)
I1018 12:51:16.859398 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.105061 (* 1 = 0.105061 loss)
I1018 12:51:16.859403 11069 solver.cpp:571] Iteration 37980, lr = 0.0001
speed: 0.378s / iter
I1018 12:51:24.561450 11069 solver.cpp:242] Iteration 38000, loss = 0.457829
I1018 12:51:24.561476 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.143387 (* 1 = 0.143387 loss)
I1018 12:51:24.561481 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.314442 (* 1 = 0.314442 loss)
I1018 12:51:24.561486 11069 solver.cpp:571] Iteration 38000, lr = 0.0001
I1018 12:51:32.419663 11069 solver.cpp:242] Iteration 38020, loss = 0.174286
I1018 12:51:32.419692 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0411603 (* 1 = 0.0411603 loss)
I1018 12:51:32.419697 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.133126 (* 1 = 0.133126 loss)
I1018 12:51:32.419701 11069 solver.cpp:571] Iteration 38020, lr = 0.0001
I1018 12:51:40.150897 11069 solver.cpp:242] Iteration 38040, loss = 0.525391
I1018 12:51:40.150923 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.151191 (* 1 = 0.151191 loss)
I1018 12:51:40.150928 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.3742 (* 1 = 0.3742 loss)
I1018 12:51:40.150933 11069 solver.cpp:571] Iteration 38040, lr = 0.0001
I1018 12:51:47.897409 11069 solver.cpp:242] Iteration 38060, loss = 0.449246
I1018 12:51:47.897436 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.190227 (* 1 = 0.190227 loss)
I1018 12:51:47.897441 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.259019 (* 1 = 0.259019 loss)
I1018 12:51:47.897446 11069 solver.cpp:571] Iteration 38060, lr = 0.0001
I1018 12:51:55.596563 11069 solver.cpp:242] Iteration 38080, loss = 0.331303
I1018 12:51:55.596590 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0739206 (* 1 = 0.0739206 loss)
I1018 12:51:55.596595 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.257383 (* 1 = 0.257383 loss)
I1018 12:51:55.596598 11069 solver.cpp:571] Iteration 38080, lr = 0.0001
I1018 12:52:03.345893 11069 solver.cpp:242] Iteration 38100, loss = 0.148493
I1018 12:52:03.345919 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0453327 (* 1 = 0.0453327 loss)
I1018 12:52:03.345924 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.103161 (* 1 = 0.103161 loss)
I1018 12:52:03.345928 11069 solver.cpp:571] Iteration 38100, lr = 0.0001
I1018 12:52:11.144896 11069 solver.cpp:242] Iteration 38120, loss = 0.206058
I1018 12:52:11.144922 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.053145 (* 1 = 0.053145 loss)
I1018 12:52:11.144927 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.152913 (* 1 = 0.152913 loss)
I1018 12:52:11.144930 11069 solver.cpp:571] Iteration 38120, lr = 0.0001
I1018 12:52:18.991068 11069 solver.cpp:242] Iteration 38140, loss = 0.273266
I1018 12:52:18.991094 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0657871 (* 1 = 0.0657871 loss)
I1018 12:52:18.991099 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.207478 (* 1 = 0.207478 loss)
I1018 12:52:18.991102 11069 solver.cpp:571] Iteration 38140, lr = 0.0001
I1018 12:52:26.745332 11069 solver.cpp:242] Iteration 38160, loss = 0.641487
I1018 12:52:26.745357 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.190972 (* 1 = 0.190972 loss)
I1018 12:52:26.745362 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.450515 (* 1 = 0.450515 loss)
I1018 12:52:26.745365 11069 solver.cpp:571] Iteration 38160, lr = 0.0001
I1018 12:52:34.479109 11069 solver.cpp:242] Iteration 38180, loss = 0.283518
I1018 12:52:34.479133 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.114307 (* 1 = 0.114307 loss)
I1018 12:52:34.479138 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.169211 (* 1 = 0.169211 loss)
I1018 12:52:34.479142 11069 solver.cpp:571] Iteration 38180, lr = 0.0001
speed: 0.378s / iter
I1018 12:52:42.286171 11069 solver.cpp:242] Iteration 38200, loss = 0.447268
I1018 12:52:42.286198 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.172034 (* 1 = 0.172034 loss)
I1018 12:52:42.286202 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.275234 (* 1 = 0.275234 loss)
I1018 12:52:42.286206 11069 solver.cpp:571] Iteration 38200, lr = 0.0001
I1018 12:52:49.967664 11069 solver.cpp:242] Iteration 38220, loss = 0.291988
I1018 12:52:49.967690 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0658377 (* 1 = 0.0658377 loss)
I1018 12:52:49.967695 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.226151 (* 1 = 0.226151 loss)
I1018 12:52:49.967700 11069 solver.cpp:571] Iteration 38220, lr = 0.0001
I1018 12:52:57.725652 11069 solver.cpp:242] Iteration 38240, loss = 0.329573
I1018 12:52:57.725678 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.115707 (* 1 = 0.115707 loss)
I1018 12:52:57.725683 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.213866 (* 1 = 0.213866 loss)
I1018 12:52:57.725687 11069 solver.cpp:571] Iteration 38240, lr = 0.0001
I1018 12:53:05.549206 11069 solver.cpp:242] Iteration 38260, loss = 1.35008
I1018 12:53:05.549230 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.500958 (* 1 = 0.500958 loss)
I1018 12:53:05.549234 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.849122 (* 1 = 0.849122 loss)
I1018 12:53:05.549238 11069 solver.cpp:571] Iteration 38260, lr = 0.0001
I1018 12:53:13.307282 11069 solver.cpp:242] Iteration 38280, loss = 0.200736
I1018 12:53:13.307307 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0577269 (* 1 = 0.0577269 loss)
I1018 12:53:13.307315 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.143009 (* 1 = 0.143009 loss)
I1018 12:53:13.307319 11069 solver.cpp:571] Iteration 38280, lr = 0.0001
I1018 12:53:21.021869 11069 solver.cpp:242] Iteration 38300, loss = 0.7184
I1018 12:53:21.021895 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.13 (* 1 = 0.13 loss)
I1018 12:53:21.021900 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.5884 (* 1 = 0.5884 loss)
I1018 12:53:21.021904 11069 solver.cpp:571] Iteration 38300, lr = 0.0001
I1018 12:53:28.738983 11069 solver.cpp:242] Iteration 38320, loss = 0.60282
I1018 12:53:28.739009 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.150724 (* 1 = 0.150724 loss)
I1018 12:53:28.739014 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.452097 (* 1 = 0.452097 loss)
I1018 12:53:28.739018 11069 solver.cpp:571] Iteration 38320, lr = 0.0001
I1018 12:53:36.499168 11069 solver.cpp:242] Iteration 38340, loss = 1.0503
I1018 12:53:36.499192 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.324926 (* 1 = 0.324926 loss)
I1018 12:53:36.499197 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.725373 (* 1 = 0.725373 loss)
I1018 12:53:36.499202 11069 solver.cpp:571] Iteration 38340, lr = 0.0001
I1018 12:53:44.286626 11069 solver.cpp:242] Iteration 38360, loss = 0.104644
I1018 12:53:44.286648 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0308086 (* 1 = 0.0308086 loss)
I1018 12:53:44.286653 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0738357 (* 1 = 0.0738357 loss)
I1018 12:53:44.286656 11069 solver.cpp:571] Iteration 38360, lr = 0.0001
I1018 12:53:51.964025 11069 solver.cpp:242] Iteration 38380, loss = 0.51497
I1018 12:53:51.964049 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.159245 (* 1 = 0.159245 loss)
I1018 12:53:51.964053 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.355725 (* 1 = 0.355725 loss)
I1018 12:53:51.964058 11069 solver.cpp:571] Iteration 38380, lr = 0.0001
speed: 0.378s / iter
I1018 12:53:59.752267 11069 solver.cpp:242] Iteration 38400, loss = 0.44209
I1018 12:53:59.752293 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.135739 (* 1 = 0.135739 loss)
I1018 12:53:59.752297 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.306351 (* 1 = 0.306351 loss)
I1018 12:53:59.752302 11069 solver.cpp:571] Iteration 38400, lr = 0.0001
I1018 12:54:07.479933 11069 solver.cpp:242] Iteration 38420, loss = 0.125534
I1018 12:54:07.479960 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0266654 (* 1 = 0.0266654 loss)
I1018 12:54:07.479965 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0988687 (* 1 = 0.0988687 loss)
I1018 12:54:07.479969 11069 solver.cpp:571] Iteration 38420, lr = 0.0001
I1018 12:54:15.268735 11069 solver.cpp:242] Iteration 38440, loss = 0.0793099
I1018 12:54:15.268761 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0273732 (* 1 = 0.0273732 loss)
I1018 12:54:15.268766 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0519367 (* 1 = 0.0519367 loss)
I1018 12:54:15.268770 11069 solver.cpp:571] Iteration 38440, lr = 0.0001
I1018 12:54:23.035393 11069 solver.cpp:242] Iteration 38460, loss = 0.961015
I1018 12:54:23.035418 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.297867 (* 1 = 0.297867 loss)
I1018 12:54:23.035423 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.663148 (* 1 = 0.663148 loss)
I1018 12:54:23.035428 11069 solver.cpp:571] Iteration 38460, lr = 0.0001
I1018 12:54:30.792862 11069 solver.cpp:242] Iteration 38480, loss = 0.503626
I1018 12:54:30.792888 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.172845 (* 1 = 0.172845 loss)
I1018 12:54:30.792893 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.330781 (* 1 = 0.330781 loss)
I1018 12:54:30.792896 11069 solver.cpp:571] Iteration 38480, lr = 0.0001
I1018 12:54:38.528825 11069 solver.cpp:242] Iteration 38500, loss = 0.469024
I1018 12:54:38.528853 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.161833 (* 1 = 0.161833 loss)
I1018 12:54:38.528858 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.307191 (* 1 = 0.307191 loss)
I1018 12:54:38.528863 11069 solver.cpp:571] Iteration 38500, lr = 0.0001
I1018 12:54:46.240494 11069 solver.cpp:242] Iteration 38520, loss = 0.867147
I1018 12:54:46.240521 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.374512 (* 1 = 0.374512 loss)
I1018 12:54:46.240526 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.492634 (* 1 = 0.492634 loss)
I1018 12:54:46.240530 11069 solver.cpp:571] Iteration 38520, lr = 0.0001
I1018 12:54:54.081967 11069 solver.cpp:242] Iteration 38540, loss = 0.229671
I1018 12:54:54.081995 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0640394 (* 1 = 0.0640394 loss)
I1018 12:54:54.082000 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.165632 (* 1 = 0.165632 loss)
I1018 12:54:54.082005 11069 solver.cpp:571] Iteration 38540, lr = 0.0001
I1018 12:55:01.891999 11069 solver.cpp:242] Iteration 38560, loss = 0.467333
I1018 12:55:01.892022 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.146407 (* 1 = 0.146407 loss)
I1018 12:55:01.892027 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.320926 (* 1 = 0.320926 loss)
I1018 12:55:01.892031 11069 solver.cpp:571] Iteration 38560, lr = 0.0001
I1018 12:55:09.674790 11069 solver.cpp:242] Iteration 38580, loss = 0.130133
I1018 12:55:09.674818 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0282345 (* 1 = 0.0282345 loss)
I1018 12:55:09.674823 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.101899 (* 1 = 0.101899 loss)
I1018 12:55:09.674827 11069 solver.cpp:571] Iteration 38580, lr = 0.0001
speed: 0.378s / iter
I1018 12:55:17.482147 11069 solver.cpp:242] Iteration 38600, loss = 0.159831
I1018 12:55:17.482175 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0392934 (* 1 = 0.0392934 loss)
I1018 12:55:17.482180 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.120538 (* 1 = 0.120538 loss)
I1018 12:55:17.482185 11069 solver.cpp:571] Iteration 38600, lr = 0.0001
I1018 12:55:25.239634 11069 solver.cpp:242] Iteration 38620, loss = 0.170554
I1018 12:55:25.239660 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0627249 (* 1 = 0.0627249 loss)
I1018 12:55:25.239665 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.107829 (* 1 = 0.107829 loss)
I1018 12:55:25.239668 11069 solver.cpp:571] Iteration 38620, lr = 0.0001
I1018 12:55:33.042881 11069 solver.cpp:242] Iteration 38640, loss = 0.135202
I1018 12:55:33.042906 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0317854 (* 1 = 0.0317854 loss)
I1018 12:55:33.042912 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.103417 (* 1 = 0.103417 loss)
I1018 12:55:33.042915 11069 solver.cpp:571] Iteration 38640, lr = 0.0001
I1018 12:55:40.857270 11069 solver.cpp:242] Iteration 38660, loss = 0.240831
I1018 12:55:40.857296 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0748301 (* 1 = 0.0748301 loss)
I1018 12:55:40.857301 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.166001 (* 1 = 0.166001 loss)
I1018 12:55:40.857306 11069 solver.cpp:571] Iteration 38660, lr = 0.0001
I1018 12:55:48.558697 11069 solver.cpp:242] Iteration 38680, loss = 0.238464
I1018 12:55:48.558723 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.12197 (* 1 = 0.12197 loss)
I1018 12:55:48.558728 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.116494 (* 1 = 0.116494 loss)
I1018 12:55:48.558732 11069 solver.cpp:571] Iteration 38680, lr = 0.0001
I1018 12:55:56.355670 11069 solver.cpp:242] Iteration 38700, loss = 0.161777
I1018 12:55:56.355697 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0386527 (* 1 = 0.0386527 loss)
I1018 12:55:56.355702 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123124 (* 1 = 0.123124 loss)
I1018 12:55:56.355706 11069 solver.cpp:571] Iteration 38700, lr = 0.0001
I1018 12:56:04.169482 11069 solver.cpp:242] Iteration 38720, loss = 0.361558
I1018 12:56:04.169507 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.136842 (* 1 = 0.136842 loss)
I1018 12:56:04.169512 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224716 (* 1 = 0.224716 loss)
I1018 12:56:04.169515 11069 solver.cpp:571] Iteration 38720, lr = 0.0001
I1018 12:56:11.890837 11069 solver.cpp:242] Iteration 38740, loss = 1.25472
I1018 12:56:11.890864 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.479118 (* 1 = 0.479118 loss)
I1018 12:56:11.890868 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.775604 (* 1 = 0.775604 loss)
I1018 12:56:11.890872 11069 solver.cpp:571] Iteration 38740, lr = 0.0001
I1018 12:56:19.543936 11069 solver.cpp:242] Iteration 38760, loss = 0.467362
I1018 12:56:19.543962 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.210198 (* 1 = 0.210198 loss)
I1018 12:56:19.543965 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.257164 (* 1 = 0.257164 loss)
I1018 12:56:19.543969 11069 solver.cpp:571] Iteration 38760, lr = 0.0001
I1018 12:56:27.269317 11069 solver.cpp:242] Iteration 38780, loss = 1.24319
I1018 12:56:27.269343 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.533772 (* 1 = 0.533772 loss)
I1018 12:56:27.269347 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.709415 (* 1 = 0.709415 loss)
I1018 12:56:27.269351 11069 solver.cpp:571] Iteration 38780, lr = 0.0001
speed: 0.379s / iter
I1018 12:56:35.032454 11069 solver.cpp:242] Iteration 38800, loss = 0.30872
I1018 12:56:35.032481 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0530433 (* 1 = 0.0530433 loss)
I1018 12:56:35.032486 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.255677 (* 1 = 0.255677 loss)
I1018 12:56:35.032490 11069 solver.cpp:571] Iteration 38800, lr = 0.0001
I1018 12:56:42.846134 11069 solver.cpp:242] Iteration 38820, loss = 0.555675
I1018 12:56:42.846161 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.147556 (* 1 = 0.147556 loss)
I1018 12:56:42.846166 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.408119 (* 1 = 0.408119 loss)
I1018 12:56:42.846170 11069 solver.cpp:571] Iteration 38820, lr = 0.0001
I1018 12:56:50.618929 11069 solver.cpp:242] Iteration 38840, loss = 0.275662
I1018 12:56:50.618955 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0815196 (* 1 = 0.0815196 loss)
I1018 12:56:50.618960 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.194142 (* 1 = 0.194142 loss)
I1018 12:56:50.618964 11069 solver.cpp:571] Iteration 38840, lr = 0.0001
I1018 12:56:58.339761 11069 solver.cpp:242] Iteration 38860, loss = 0.242137
I1018 12:56:58.339787 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0668913 (* 1 = 0.0668913 loss)
I1018 12:56:58.339792 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.175245 (* 1 = 0.175245 loss)
I1018 12:56:58.339795 11069 solver.cpp:571] Iteration 38860, lr = 0.0001
I1018 12:57:06.156260 11069 solver.cpp:242] Iteration 38880, loss = 0.854493
I1018 12:57:06.156286 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.25663 (* 1 = 0.25663 loss)
I1018 12:57:06.156291 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.597863 (* 1 = 0.597863 loss)
I1018 12:57:06.156294 11069 solver.cpp:571] Iteration 38880, lr = 0.0001
I1018 12:57:13.915007 11069 solver.cpp:242] Iteration 38900, loss = 0.766403
I1018 12:57:13.915032 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.248334 (* 1 = 0.248334 loss)
I1018 12:57:13.915037 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.518069 (* 1 = 0.518069 loss)
I1018 12:57:13.915041 11069 solver.cpp:571] Iteration 38900, lr = 0.0001
I1018 12:57:21.617102 11069 solver.cpp:242] Iteration 38920, loss = 0.333874
I1018 12:57:21.617128 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0649071 (* 1 = 0.0649071 loss)
I1018 12:57:21.617133 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.268967 (* 1 = 0.268967 loss)
I1018 12:57:21.617137 11069 solver.cpp:571] Iteration 38920, lr = 0.0001
I1018 12:57:29.335448 11069 solver.cpp:242] Iteration 38940, loss = 1.40399
I1018 12:57:29.335474 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.549845 (* 1 = 0.549845 loss)
I1018 12:57:29.335479 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.854145 (* 1 = 0.854145 loss)
I1018 12:57:29.335482 11069 solver.cpp:571] Iteration 38940, lr = 0.0001
I1018 12:57:37.085999 11069 solver.cpp:242] Iteration 38960, loss = 1.00937
I1018 12:57:37.086024 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.283646 (* 1 = 0.283646 loss)
I1018 12:57:37.086030 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.72572 (* 1 = 0.72572 loss)
I1018 12:57:37.086033 11069 solver.cpp:571] Iteration 38960, lr = 0.0001
I1018 12:57:44.894345 11069 solver.cpp:242] Iteration 38980, loss = 0.84
I1018 12:57:44.894371 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.252569 (* 1 = 0.252569 loss)
I1018 12:57:44.894376 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.58743 (* 1 = 0.58743 loss)
I1018 12:57:44.894379 11069 solver.cpp:571] Iteration 38980, lr = 0.0001
speed: 0.379s / iter
I1018 12:57:52.675362 11069 solver.cpp:242] Iteration 39000, loss = 0.44053
I1018 12:57:52.675389 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139194 (* 1 = 0.139194 loss)
I1018 12:57:52.675393 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.301336 (* 1 = 0.301336 loss)
I1018 12:57:52.675397 11069 solver.cpp:571] Iteration 39000, lr = 0.0001
I1018 12:58:00.393571 11069 solver.cpp:242] Iteration 39020, loss = 0.549514
I1018 12:58:00.393596 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.181266 (* 1 = 0.181266 loss)
I1018 12:58:00.393600 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.368248 (* 1 = 0.368248 loss)
I1018 12:58:00.393604 11069 solver.cpp:571] Iteration 39020, lr = 0.0001
I1018 12:58:08.158730 11069 solver.cpp:242] Iteration 39040, loss = 0.181429
I1018 12:58:08.158756 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0497481 (* 1 = 0.0497481 loss)
I1018 12:58:08.158761 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.131681 (* 1 = 0.131681 loss)
I1018 12:58:08.158766 11069 solver.cpp:571] Iteration 39040, lr = 0.0001
I1018 12:58:15.896420 11069 solver.cpp:242] Iteration 39060, loss = 0.275465
I1018 12:58:15.896446 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0964595 (* 1 = 0.0964595 loss)
I1018 12:58:15.896451 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.179006 (* 1 = 0.179006 loss)
I1018 12:58:15.896455 11069 solver.cpp:571] Iteration 39060, lr = 0.0001
I1018 12:58:23.539005 11069 solver.cpp:242] Iteration 39080, loss = 0.231793
I1018 12:58:23.539031 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.053568 (* 1 = 0.053568 loss)
I1018 12:58:23.539036 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.178225 (* 1 = 0.178225 loss)
I1018 12:58:23.539041 11069 solver.cpp:571] Iteration 39080, lr = 0.0001
I1018 12:58:31.350284 11069 solver.cpp:242] Iteration 39100, loss = 0.341195
I1018 12:58:31.350311 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123857 (* 1 = 0.123857 loss)
I1018 12:58:31.350316 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.217339 (* 1 = 0.217339 loss)
I1018 12:58:31.350319 11069 solver.cpp:571] Iteration 39100, lr = 0.0001
I1018 12:58:39.091475 11069 solver.cpp:242] Iteration 39120, loss = 0.587369
I1018 12:58:39.091500 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.192373 (* 1 = 0.192373 loss)
I1018 12:58:39.091506 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.394997 (* 1 = 0.394997 loss)
I1018 12:58:39.091509 11069 solver.cpp:571] Iteration 39120, lr = 0.0001
I1018 12:58:46.851567 11069 solver.cpp:242] Iteration 39140, loss = 0.21131
I1018 12:58:46.851593 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0490829 (* 1 = 0.0490829 loss)
I1018 12:58:46.851599 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.162227 (* 1 = 0.162227 loss)
I1018 12:58:46.851603 11069 solver.cpp:571] Iteration 39140, lr = 0.0001
I1018 12:58:54.658607 11069 solver.cpp:242] Iteration 39160, loss = 0.128745
I1018 12:58:54.658633 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0304441 (* 1 = 0.0304441 loss)
I1018 12:58:54.658639 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0983012 (* 1 = 0.0983012 loss)
I1018 12:58:54.658644 11069 solver.cpp:571] Iteration 39160, lr = 0.0001
I1018 12:59:02.486033 11069 solver.cpp:242] Iteration 39180, loss = 0.170499
I1018 12:59:02.486059 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0475338 (* 1 = 0.0475338 loss)
I1018 12:59:02.486064 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.122965 (* 1 = 0.122965 loss)
I1018 12:59:02.486068 11069 solver.cpp:571] Iteration 39180, lr = 0.0001
speed: 0.379s / iter
I1018 12:59:10.365118 11069 solver.cpp:242] Iteration 39200, loss = 0.302154
I1018 12:59:10.365144 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.104678 (* 1 = 0.104678 loss)
I1018 12:59:10.365149 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.197476 (* 1 = 0.197476 loss)
I1018 12:59:10.365154 11069 solver.cpp:571] Iteration 39200, lr = 0.0001
I1018 12:59:18.172817 11069 solver.cpp:242] Iteration 39220, loss = 0.105828
I1018 12:59:18.172843 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0219633 (* 1 = 0.0219633 loss)
I1018 12:59:18.172849 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0838649 (* 1 = 0.0838649 loss)
I1018 12:59:18.172853 11069 solver.cpp:571] Iteration 39220, lr = 0.0001
I1018 12:59:25.937779 11069 solver.cpp:242] Iteration 39240, loss = 0.163434
I1018 12:59:25.937806 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0400957 (* 1 = 0.0400957 loss)
I1018 12:59:25.937811 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.123338 (* 1 = 0.123338 loss)
I1018 12:59:25.937815 11069 solver.cpp:571] Iteration 39240, lr = 0.0001
I1018 12:59:33.710456 11069 solver.cpp:242] Iteration 39260, loss = 0.864197
I1018 12:59:33.710484 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.250272 (* 1 = 0.250272 loss)
I1018 12:59:33.710489 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.613924 (* 1 = 0.613924 loss)
I1018 12:59:33.710494 11069 solver.cpp:571] Iteration 39260, lr = 0.0001
I1018 12:59:41.497303 11069 solver.cpp:242] Iteration 39280, loss = 0.102153
I1018 12:59:41.497329 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0354318 (* 1 = 0.0354318 loss)
I1018 12:59:41.497334 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0667216 (* 1 = 0.0667216 loss)
I1018 12:59:41.497339 11069 solver.cpp:571] Iteration 39280, lr = 0.0001
I1018 12:59:49.415962 11069 solver.cpp:242] Iteration 39300, loss = 0.642371
I1018 12:59:49.415988 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.136733 (* 1 = 0.136733 loss)
I1018 12:59:49.415993 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.505637 (* 1 = 0.505637 loss)
I1018 12:59:49.415998 11069 solver.cpp:571] Iteration 39300, lr = 0.0001
I1018 12:59:57.199941 11069 solver.cpp:242] Iteration 39320, loss = 0.190726
I1018 12:59:57.199968 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.061536 (* 1 = 0.061536 loss)
I1018 12:59:57.199973 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.12919 (* 1 = 0.12919 loss)
I1018 12:59:57.199977 11069 solver.cpp:571] Iteration 39320, lr = 0.0001
I1018 13:00:04.978405 11069 solver.cpp:242] Iteration 39340, loss = 0.186354
I1018 13:00:04.978431 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0647124 (* 1 = 0.0647124 loss)
I1018 13:00:04.978436 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.121642 (* 1 = 0.121642 loss)
I1018 13:00:04.978440 11069 solver.cpp:571] Iteration 39340, lr = 0.0001
I1018 13:00:12.840766 11069 solver.cpp:242] Iteration 39360, loss = 1.53166
I1018 13:00:12.840795 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.750606 (* 1 = 0.750606 loss)
I1018 13:00:12.840800 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.781053 (* 1 = 0.781053 loss)
I1018 13:00:12.840803 11069 solver.cpp:571] Iteration 39360, lr = 0.0001
I1018 13:00:20.584336 11069 solver.cpp:242] Iteration 39380, loss = 0.337917
I1018 13:00:20.584362 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.106012 (* 1 = 0.106012 loss)
I1018 13:00:20.584367 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231904 (* 1 = 0.231904 loss)
I1018 13:00:20.584372 11069 solver.cpp:571] Iteration 39380, lr = 0.0001
speed: 0.379s / iter
I1018 13:00:28.345417 11069 solver.cpp:242] Iteration 39400, loss = 0.611142
I1018 13:00:28.345443 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.202259 (* 1 = 0.202259 loss)
I1018 13:00:28.345448 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.408883 (* 1 = 0.408883 loss)
I1018 13:00:28.345453 11069 solver.cpp:571] Iteration 39400, lr = 0.0001
I1018 13:00:36.122560 11069 solver.cpp:242] Iteration 39420, loss = 0.26977
I1018 13:00:36.122587 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0384877 (* 1 = 0.0384877 loss)
I1018 13:00:36.122593 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.231282 (* 1 = 0.231282 loss)
I1018 13:00:36.122598 11069 solver.cpp:571] Iteration 39420, lr = 0.0001
I1018 13:00:43.877650 11069 solver.cpp:242] Iteration 39440, loss = 0.531819
I1018 13:00:43.877676 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.194405 (* 1 = 0.194405 loss)
I1018 13:00:43.877681 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.337414 (* 1 = 0.337414 loss)
I1018 13:00:43.877686 11069 solver.cpp:571] Iteration 39440, lr = 0.0001
I1018 13:00:51.736502 11069 solver.cpp:242] Iteration 39460, loss = 0.926791
I1018 13:00:51.736529 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.26278 (* 1 = 0.26278 loss)
I1018 13:00:51.736534 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.664011 (* 1 = 0.664011 loss)
I1018 13:00:51.736538 11069 solver.cpp:571] Iteration 39460, lr = 0.0001
I1018 13:00:59.466279 11069 solver.cpp:242] Iteration 39480, loss = 1.67844
I1018 13:00:59.466305 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.71912 (* 1 = 0.71912 loss)
I1018 13:00:59.466310 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.959318 (* 1 = 0.959318 loss)
I1018 13:00:59.466315 11069 solver.cpp:571] Iteration 39480, lr = 0.0001
I1018 13:01:07.325721 11069 solver.cpp:242] Iteration 39500, loss = 0.116062
I1018 13:01:07.325748 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306455 (* 1 = 0.0306455 loss)
I1018 13:01:07.325753 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.085417 (* 1 = 0.085417 loss)
I1018 13:01:07.325758 11069 solver.cpp:571] Iteration 39500, lr = 0.0001
I1018 13:01:15.017464 11069 solver.cpp:242] Iteration 39520, loss = 0.832002
I1018 13:01:15.017493 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.270042 (* 1 = 0.270042 loss)
I1018 13:01:15.017498 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.56196 (* 1 = 0.56196 loss)
I1018 13:01:15.017503 11069 solver.cpp:571] Iteration 39520, lr = 0.0001
I1018 13:01:22.754863 11069 solver.cpp:242] Iteration 39540, loss = 0.0847425
I1018 13:01:22.754890 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0211448 (* 1 = 0.0211448 loss)
I1018 13:01:22.754895 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0635977 (* 1 = 0.0635977 loss)
I1018 13:01:22.754899 11069 solver.cpp:571] Iteration 39540, lr = 0.0001
I1018 13:01:30.616518 11069 solver.cpp:242] Iteration 39560, loss = 0.302033
I1018 13:01:30.616544 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.073768 (* 1 = 0.073768 loss)
I1018 13:01:30.616549 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.228265 (* 1 = 0.228265 loss)
I1018 13:01:30.616554 11069 solver.cpp:571] Iteration 39560, lr = 0.0001
I1018 13:01:38.411958 11069 solver.cpp:242] Iteration 39580, loss = 0.241175
I1018 13:01:38.411983 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0551898 (* 1 = 0.0551898 loss)
I1018 13:01:38.411988 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.185985 (* 1 = 0.185985 loss)
I1018 13:01:38.411993 11069 solver.cpp:571] Iteration 39580, lr = 0.0001
speed: 0.379s / iter
I1018 13:01:46.242823 11069 solver.cpp:242] Iteration 39600, loss = 0.0975084
I1018 13:01:46.242851 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.023393 (* 1 = 0.023393 loss)
I1018 13:01:46.242856 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0741154 (* 1 = 0.0741154 loss)
I1018 13:01:46.242861 11069 solver.cpp:571] Iteration 39600, lr = 0.0001
I1018 13:01:54.032869 11069 solver.cpp:242] Iteration 39620, loss = 0.246791
I1018 13:01:54.032896 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479445 (* 1 = 0.0479445 loss)
I1018 13:01:54.032902 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.198847 (* 1 = 0.198847 loss)
I1018 13:01:54.032905 11069 solver.cpp:571] Iteration 39620, lr = 0.0001
I1018 13:02:01.727181 11069 solver.cpp:242] Iteration 39640, loss = 0.145753
I1018 13:02:01.727205 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.053585 (* 1 = 0.053585 loss)
I1018 13:02:01.727211 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0921683 (* 1 = 0.0921683 loss)
I1018 13:02:01.727216 11069 solver.cpp:571] Iteration 39640, lr = 0.0001
I1018 13:02:09.523651 11069 solver.cpp:242] Iteration 39660, loss = 0.389678
I1018 13:02:09.523679 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.139633 (* 1 = 0.139633 loss)
I1018 13:02:09.523684 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.250045 (* 1 = 0.250045 loss)
I1018 13:02:09.523689 11069 solver.cpp:571] Iteration 39660, lr = 0.0001
I1018 13:02:17.396419 11069 solver.cpp:242] Iteration 39680, loss = 0.153798
I1018 13:02:17.396445 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0570256 (* 1 = 0.0570256 loss)
I1018 13:02:17.396450 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.0967721 (* 1 = 0.0967721 loss)
I1018 13:02:17.396455 11069 solver.cpp:571] Iteration 39680, lr = 0.0001
I1018 13:02:25.050832 11069 solver.cpp:242] Iteration 39700, loss = 0.410678
I1018 13:02:25.050859 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.093201 (* 1 = 0.093201 loss)
I1018 13:02:25.050864 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.317477 (* 1 = 0.317477 loss)
I1018 13:02:25.050869 11069 solver.cpp:571] Iteration 39700, lr = 0.0001
I1018 13:02:32.841279 11069 solver.cpp:242] Iteration 39720, loss = 0.233982
I1018 13:02:32.841306 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0332798 (* 1 = 0.0332798 loss)
I1018 13:02:32.841311 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.200702 (* 1 = 0.200702 loss)
I1018 13:02:32.841315 11069 solver.cpp:571] Iteration 39720, lr = 0.0001
I1018 13:02:40.546929 11069 solver.cpp:242] Iteration 39740, loss = 2.07934
I1018 13:02:40.546957 11069 solver.cpp:258]     Train net output #0: loss_bbox = 1.21575 (* 1 = 1.21575 loss)
I1018 13:02:40.546962 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.863586 (* 1 = 0.863586 loss)
I1018 13:02:40.546967 11069 solver.cpp:571] Iteration 39740, lr = 0.0001
I1018 13:02:48.354339 11069 solver.cpp:242] Iteration 39760, loss = 0.347299
I1018 13:02:48.354367 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.123006 (* 1 = 0.123006 loss)
I1018 13:02:48.354372 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.224293 (* 1 = 0.224293 loss)
I1018 13:02:48.354377 11069 solver.cpp:571] Iteration 39760, lr = 0.0001
I1018 13:02:56.128478 11069 solver.cpp:242] Iteration 39780, loss = 0.385664
I1018 13:02:56.128504 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0864167 (* 1 = 0.0864167 loss)
I1018 13:02:56.128510 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.299247 (* 1 = 0.299247 loss)
I1018 13:02:56.128515 11069 solver.cpp:571] Iteration 39780, lr = 0.0001
speed: 0.379s / iter
I1018 13:03:03.846529 11069 solver.cpp:242] Iteration 39800, loss = 0.774004
I1018 13:03:03.846554 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.273721 (* 1 = 0.273721 loss)
I1018 13:03:03.846559 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.500283 (* 1 = 0.500283 loss)
I1018 13:03:03.846562 11069 solver.cpp:571] Iteration 39800, lr = 0.0001
I1018 13:03:11.680835 11069 solver.cpp:242] Iteration 39820, loss = 0.319473
I1018 13:03:11.680861 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0769872 (* 1 = 0.0769872 loss)
I1018 13:03:11.680866 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.242485 (* 1 = 0.242485 loss)
I1018 13:03:11.680871 11069 solver.cpp:571] Iteration 39820, lr = 0.0001
I1018 13:03:19.481442 11069 solver.cpp:242] Iteration 39840, loss = 0.204199
I1018 13:03:19.481467 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.056345 (* 1 = 0.056345 loss)
I1018 13:03:19.481472 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.147854 (* 1 = 0.147854 loss)
I1018 13:03:19.481477 11069 solver.cpp:571] Iteration 39840, lr = 0.0001
I1018 13:03:27.221283 11069 solver.cpp:242] Iteration 39860, loss = 0.343421
I1018 13:03:27.221308 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.0628595 (* 1 = 0.0628595 loss)
I1018 13:03:27.221313 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.280562 (* 1 = 0.280562 loss)
I1018 13:03:27.221318 11069 solver.cpp:571] Iteration 39860, lr = 0.0001
I1018 13:03:34.941920 11069 solver.cpp:242] Iteration 39880, loss = 0.500841
I1018 13:03:34.941946 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.146486 (* 1 = 0.146486 loss)
I1018 13:03:34.941951 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.354355 (* 1 = 0.354355 loss)
I1018 13:03:34.941954 11069 solver.cpp:571] Iteration 39880, lr = 0.0001
I1018 13:03:42.722314 11069 solver.cpp:242] Iteration 39900, loss = 0.375767
I1018 13:03:42.722340 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.155722 (* 1 = 0.155722 loss)
I1018 13:03:42.722345 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.220046 (* 1 = 0.220046 loss)
I1018 13:03:42.722349 11069 solver.cpp:571] Iteration 39900, lr = 0.0001
I1018 13:03:50.494314 11069 solver.cpp:242] Iteration 39920, loss = 1.15376
I1018 13:03:50.494343 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.469885 (* 1 = 0.469885 loss)
I1018 13:03:50.494348 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.683875 (* 1 = 0.683875 loss)
I1018 13:03:50.494350 11069 solver.cpp:571] Iteration 39920, lr = 0.0001
I1018 13:03:58.317255 11069 solver.cpp:242] Iteration 39940, loss = 0.635277
I1018 13:03:58.317281 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.278468 (* 1 = 0.278468 loss)
I1018 13:03:58.317286 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.356809 (* 1 = 0.356809 loss)
I1018 13:03:58.317289 11069 solver.cpp:571] Iteration 39940, lr = 0.0001
I1018 13:04:06.062635 11069 solver.cpp:242] Iteration 39960, loss = 1.58219
I1018 13:04:06.062661 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.706102 (* 1 = 0.706102 loss)
I1018 13:04:06.062666 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.87609 (* 1 = 0.87609 loss)
I1018 13:04:06.062670 11069 solver.cpp:571] Iteration 39960, lr = 0.0001
I1018 13:04:13.860342 11069 solver.cpp:242] Iteration 39980, loss = 0.690585
I1018 13:04:13.860368 11069 solver.cpp:258]     Train net output #0: loss_bbox = 0.215233 (* 1 = 0.215233 loss)
I1018 13:04:13.860373 11069 solver.cpp:258]     Train net output #1: loss_cls = 0.475352 (* 1 = 0.475352 loss)
I1018 13:04:13.860378 11069 solver.cpp:571] Iteration 39980, lr = 0.0001
speed: 0.379s / iter
Wrote snapshot to: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_fast_rcnn_stage2_iter_40000.caffemodel
done solving
cp /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/vgg16_fast_rcnn_stage2_iter_40000.caffemodel -> /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/VGG16_faster_rcnn_final.caffemodel
Final model: /home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_trainval/VGG16_faster_rcnn_final.caffemodel

/usr/bin/python2.7 /home/bsl/py-faster-rcnn-master/tools/test_net_debug.py
Called with args:
Namespace(caffemodel='/home/bsl/py-faster-rcnn-master/data/faster_rcnn_models/VGG16_faster_rcnn_final.caffemodel', cfg_file='/home/bsl/py-faster-rcnn-master/experiments/cfgs/faster_rcnn_alt_opt.yml', comp_mode=False, gpu_id=0, imdb_name='voc_2007_test', prototxt='/home/bsl/py-faster-rcnn-master/models/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt', set_cfgs=None, wait=False)
Using config:
{'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_alt_opt',
 'GPU_ID': 0,
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/bsl/py-faster-rcnn-master',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'selective_search',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1018 13:21:49.102931 12584 net.cpp:50] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
input: "data"
input: "im_info"
state {
  phase: TEST
}
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}
input_shape {
  dim: 1
  dim: 3
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  inner_product_param {
    num_output: 21
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  inner_product_param {
    num_output: 84
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
I1018 13:21:49.103029 12584 net.cpp:435] Input 0 -> data
I1018 13:21:49.103039 12584 net.cpp:435] Input 1 -> im_info
I1018 13:21:49.103049 12584 layer_factory.hpp:76] Creating layer conv1_1
I1018 13:21:49.103056 12584 net.cpp:110] Creating Layer conv1_1
I1018 13:21:49.103060 12584 net.cpp:477] conv1_1 <- data
I1018 13:21:49.103062 12584 net.cpp:433] conv1_1 -> conv1_1
I1018 13:21:49.107458 12584 net.cpp:155] Setting up conv1_1
I1018 13:21:49.107475 12584 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 13:21:49.107483 12584 layer_factory.hpp:76] Creating layer relu1_1
I1018 13:21:49.107491 12584 net.cpp:110] Creating Layer relu1_1
I1018 13:21:49.107492 12584 net.cpp:477] relu1_1 <- conv1_1
I1018 13:21:49.107496 12584 net.cpp:419] relu1_1 -> conv1_1 (in-place)
I1018 13:21:49.107504 12584 net.cpp:155] Setting up relu1_1
I1018 13:21:49.107507 12584 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 13:21:49.107509 12584 layer_factory.hpp:76] Creating layer conv1_2
I1018 13:21:49.107513 12584 net.cpp:110] Creating Layer conv1_2
I1018 13:21:49.107514 12584 net.cpp:477] conv1_2 <- conv1_1
I1018 13:21:49.107517 12584 net.cpp:433] conv1_2 -> conv1_2
I1018 13:21:49.107574 12584 net.cpp:155] Setting up conv1_2
I1018 13:21:49.107578 12584 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 13:21:49.107583 12584 layer_factory.hpp:76] Creating layer relu1_2
I1018 13:21:49.107587 12584 net.cpp:110] Creating Layer relu1_2
I1018 13:21:49.107589 12584 net.cpp:477] relu1_2 <- conv1_2
I1018 13:21:49.107592 12584 net.cpp:419] relu1_2 -> conv1_2 (in-place)
I1018 13:21:49.107595 12584 net.cpp:155] Setting up relu1_2
I1018 13:21:49.107597 12584 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1018 13:21:49.107599 12584 layer_factory.hpp:76] Creating layer pool1
I1018 13:21:49.107604 12584 net.cpp:110] Creating Layer pool1
I1018 13:21:49.107605 12584 net.cpp:477] pool1 <- conv1_2
I1018 13:21:49.107607 12584 net.cpp:433] pool1 -> pool1
I1018 13:21:49.107614 12584 net.cpp:155] Setting up pool1
I1018 13:21:49.107615 12584 net.cpp:163] Top shape: 1 64 112 112 (802816)
I1018 13:21:49.107619 12584 layer_factory.hpp:76] Creating layer conv2_1
I1018 13:21:49.107621 12584 net.cpp:110] Creating Layer conv2_1
I1018 13:21:49.107623 12584 net.cpp:477] conv2_1 <- pool1
I1018 13:21:49.107625 12584 net.cpp:433] conv2_1 -> conv2_1
I1018 13:21:49.108150 12584 net.cpp:155] Setting up conv2_1
I1018 13:21:49.108157 12584 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 13:21:49.108163 12584 layer_factory.hpp:76] Creating layer relu2_1
I1018 13:21:49.108167 12584 net.cpp:110] Creating Layer relu2_1
I1018 13:21:49.108170 12584 net.cpp:477] relu2_1 <- conv2_1
I1018 13:21:49.108172 12584 net.cpp:419] relu2_1 -> conv2_1 (in-place)
I1018 13:21:49.108175 12584 net.cpp:155] Setting up relu2_1
I1018 13:21:49.108178 12584 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 13:21:49.108180 12584 layer_factory.hpp:76] Creating layer conv2_2
I1018 13:21:49.108183 12584 net.cpp:110] Creating Layer conv2_2
I1018 13:21:49.108186 12584 net.cpp:477] conv2_2 <- conv2_1
I1018 13:21:49.108188 12584 net.cpp:433] conv2_2 -> conv2_2
I1018 13:21:49.108273 12584 net.cpp:155] Setting up conv2_2
I1018 13:21:49.108276 12584 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 13:21:49.108280 12584 layer_factory.hpp:76] Creating layer relu2_2
I1018 13:21:49.108283 12584 net.cpp:110] Creating Layer relu2_2
I1018 13:21:49.108286 12584 net.cpp:477] relu2_2 <- conv2_2
I1018 13:21:49.108289 12584 net.cpp:419] relu2_2 -> conv2_2 (in-place)
I1018 13:21:49.108291 12584 net.cpp:155] Setting up relu2_2
I1018 13:21:49.108294 12584 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1018 13:21:49.108295 12584 layer_factory.hpp:76] Creating layer pool2
I1018 13:21:49.108299 12584 net.cpp:110] Creating Layer pool2
I1018 13:21:49.108300 12584 net.cpp:477] pool2 <- conv2_2
I1018 13:21:49.108304 12584 net.cpp:433] pool2 -> pool2
I1018 13:21:49.108311 12584 net.cpp:155] Setting up pool2
I1018 13:21:49.108314 12584 net.cpp:163] Top shape: 1 128 56 56 (401408)
I1018 13:21:49.108316 12584 layer_factory.hpp:76] Creating layer conv3_1
I1018 13:21:49.108319 12584 net.cpp:110] Creating Layer conv3_1
I1018 13:21:49.108321 12584 net.cpp:477] conv3_1 <- pool2
I1018 13:21:49.108324 12584 net.cpp:433] conv3_1 -> conv3_1
I1018 13:21:49.108800 12584 net.cpp:155] Setting up conv3_1
I1018 13:21:49.108808 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.108814 12584 layer_factory.hpp:76] Creating layer relu3_1
I1018 13:21:49.108817 12584 net.cpp:110] Creating Layer relu3_1
I1018 13:21:49.108819 12584 net.cpp:477] relu3_1 <- conv3_1
I1018 13:21:49.108822 12584 net.cpp:419] relu3_1 -> conv3_1 (in-place)
I1018 13:21:49.108825 12584 net.cpp:155] Setting up relu3_1
I1018 13:21:49.108829 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.108830 12584 layer_factory.hpp:76] Creating layer conv3_2
I1018 13:21:49.108834 12584 net.cpp:110] Creating Layer conv3_2
I1018 13:21:49.108835 12584 net.cpp:477] conv3_2 <- conv3_1
I1018 13:21:49.108840 12584 net.cpp:433] conv3_2 -> conv3_2
I1018 13:21:49.109501 12584 net.cpp:155] Setting up conv3_2
I1018 13:21:49.109508 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.109513 12584 layer_factory.hpp:76] Creating layer relu3_2
I1018 13:21:49.109516 12584 net.cpp:110] Creating Layer relu3_2
I1018 13:21:49.109519 12584 net.cpp:477] relu3_2 <- conv3_2
I1018 13:21:49.109520 12584 net.cpp:419] relu3_2 -> conv3_2 (in-place)
I1018 13:21:49.109524 12584 net.cpp:155] Setting up relu3_2
I1018 13:21:49.109526 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.109529 12584 layer_factory.hpp:76] Creating layer conv3_3
I1018 13:21:49.109532 12584 net.cpp:110] Creating Layer conv3_3
I1018 13:21:49.109534 12584 net.cpp:477] conv3_3 <- conv3_2
I1018 13:21:49.109537 12584 net.cpp:433] conv3_3 -> conv3_3
I1018 13:21:49.110240 12584 net.cpp:155] Setting up conv3_3
I1018 13:21:49.110246 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.110251 12584 layer_factory.hpp:76] Creating layer relu3_3
I1018 13:21:49.110255 12584 net.cpp:110] Creating Layer relu3_3
I1018 13:21:49.110256 12584 net.cpp:477] relu3_3 <- conv3_3
I1018 13:21:49.110260 12584 net.cpp:419] relu3_3 -> conv3_3 (in-place)
I1018 13:21:49.110263 12584 net.cpp:155] Setting up relu3_3
I1018 13:21:49.110266 12584 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1018 13:21:49.110268 12584 layer_factory.hpp:76] Creating layer pool3
I1018 13:21:49.110273 12584 net.cpp:110] Creating Layer pool3
I1018 13:21:49.110275 12584 net.cpp:477] pool3 <- conv3_3
I1018 13:21:49.110277 12584 net.cpp:433] pool3 -> pool3
I1018 13:21:49.110282 12584 net.cpp:155] Setting up pool3
I1018 13:21:49.110285 12584 net.cpp:163] Top shape: 1 256 28 28 (200704)
I1018 13:21:49.110286 12584 layer_factory.hpp:76] Creating layer conv4_1
I1018 13:21:49.110290 12584 net.cpp:110] Creating Layer conv4_1
I1018 13:21:49.110291 12584 net.cpp:477] conv4_1 <- pool3
I1018 13:21:49.110294 12584 net.cpp:433] conv4_1 -> conv4_1
I1018 13:21:49.111826 12584 net.cpp:155] Setting up conv4_1
I1018 13:21:49.111843 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.111850 12584 layer_factory.hpp:76] Creating layer relu4_1
I1018 13:21:49.111855 12584 net.cpp:110] Creating Layer relu4_1
I1018 13:21:49.111858 12584 net.cpp:477] relu4_1 <- conv4_1
I1018 13:21:49.111862 12584 net.cpp:419] relu4_1 -> conv4_1 (in-place)
I1018 13:21:49.111866 12584 net.cpp:155] Setting up relu4_1
I1018 13:21:49.111870 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.111871 12584 layer_factory.hpp:76] Creating layer conv4_2
I1018 13:21:49.111876 12584 net.cpp:110] Creating Layer conv4_2
I1018 13:21:49.111878 12584 net.cpp:477] conv4_2 <- conv4_1
I1018 13:21:49.111881 12584 net.cpp:433] conv4_2 -> conv4_2
I1018 13:21:49.114917 12584 net.cpp:155] Setting up conv4_2
I1018 13:21:49.114940 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.114953 12584 layer_factory.hpp:76] Creating layer relu4_2
I1018 13:21:49.114959 12584 net.cpp:110] Creating Layer relu4_2
I1018 13:21:49.114962 12584 net.cpp:477] relu4_2 <- conv4_2
I1018 13:21:49.114966 12584 net.cpp:419] relu4_2 -> conv4_2 (in-place)
I1018 13:21:49.114971 12584 net.cpp:155] Setting up relu4_2
I1018 13:21:49.114974 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.114976 12584 layer_factory.hpp:76] Creating layer conv4_3
I1018 13:21:49.114980 12584 net.cpp:110] Creating Layer conv4_3
I1018 13:21:49.114981 12584 net.cpp:477] conv4_3 <- conv4_2
I1018 13:21:49.114984 12584 net.cpp:433] conv4_3 -> conv4_3
I1018 13:21:49.118141 12584 net.cpp:155] Setting up conv4_3
I1018 13:21:49.118165 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.118172 12584 layer_factory.hpp:76] Creating layer relu4_3
I1018 13:21:49.118180 12584 net.cpp:110] Creating Layer relu4_3
I1018 13:21:49.118182 12584 net.cpp:477] relu4_3 <- conv4_3
I1018 13:21:49.118187 12584 net.cpp:419] relu4_3 -> conv4_3 (in-place)
I1018 13:21:49.118192 12584 net.cpp:155] Setting up relu4_3
I1018 13:21:49.118196 12584 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1018 13:21:49.118196 12584 layer_factory.hpp:76] Creating layer pool4
I1018 13:21:49.118201 12584 net.cpp:110] Creating Layer pool4
I1018 13:21:49.118202 12584 net.cpp:477] pool4 <- conv4_3
I1018 13:21:49.118206 12584 net.cpp:433] pool4 -> pool4
I1018 13:21:49.118212 12584 net.cpp:155] Setting up pool4
I1018 13:21:49.118216 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.118217 12584 layer_factory.hpp:76] Creating layer conv5_1
I1018 13:21:49.118221 12584 net.cpp:110] Creating Layer conv5_1
I1018 13:21:49.118223 12584 net.cpp:477] conv5_1 <- pool4
I1018 13:21:49.118227 12584 net.cpp:433] conv5_1 -> conv5_1
I1018 13:21:49.121393 12584 net.cpp:155] Setting up conv5_1
I1018 13:21:49.121417 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.121424 12584 layer_factory.hpp:76] Creating layer relu5_1
I1018 13:21:49.121431 12584 net.cpp:110] Creating Layer relu5_1
I1018 13:21:49.121434 12584 net.cpp:477] relu5_1 <- conv5_1
I1018 13:21:49.121438 12584 net.cpp:419] relu5_1 -> conv5_1 (in-place)
I1018 13:21:49.121444 12584 net.cpp:155] Setting up relu5_1
I1018 13:21:49.121446 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.121448 12584 layer_factory.hpp:76] Creating layer conv5_2
I1018 13:21:49.121453 12584 net.cpp:110] Creating Layer conv5_2
I1018 13:21:49.121454 12584 net.cpp:477] conv5_2 <- conv5_1
I1018 13:21:49.121457 12584 net.cpp:433] conv5_2 -> conv5_2
I1018 13:21:49.124474 12584 net.cpp:155] Setting up conv5_2
I1018 13:21:49.124496 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.124505 12584 layer_factory.hpp:76] Creating layer relu5_2
I1018 13:21:49.124511 12584 net.cpp:110] Creating Layer relu5_2
I1018 13:21:49.124513 12584 net.cpp:477] relu5_2 <- conv5_2
I1018 13:21:49.124517 12584 net.cpp:419] relu5_2 -> conv5_2 (in-place)
I1018 13:21:49.124522 12584 net.cpp:155] Setting up relu5_2
I1018 13:21:49.124524 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.124526 12584 layer_factory.hpp:76] Creating layer conv5_3
I1018 13:21:49.124531 12584 net.cpp:110] Creating Layer conv5_3
I1018 13:21:49.124532 12584 net.cpp:477] conv5_3 <- conv5_2
I1018 13:21:49.124536 12584 net.cpp:433] conv5_3 -> conv5_3
I1018 13:21:49.127670 12584 net.cpp:155] Setting up conv5_3
I1018 13:21:49.127692 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.127701 12584 layer_factory.hpp:76] Creating layer relu5_3
I1018 13:21:49.127708 12584 net.cpp:110] Creating Layer relu5_3
I1018 13:21:49.127712 12584 net.cpp:477] relu5_3 <- conv5_3
I1018 13:21:49.127715 12584 net.cpp:419] relu5_3 -> conv5_3 (in-place)
I1018 13:21:49.127720 12584 net.cpp:155] Setting up relu5_3
I1018 13:21:49.127723 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.127725 12584 layer_factory.hpp:76] Creating layer conv5_3_relu5_3_0_split
I1018 13:21:49.127734 12584 net.cpp:110] Creating Layer conv5_3_relu5_3_0_split
I1018 13:21:49.127737 12584 net.cpp:477] conv5_3_relu5_3_0_split <- conv5_3
I1018 13:21:49.127739 12584 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I1018 13:21:49.127743 12584 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I1018 13:21:49.127748 12584 net.cpp:155] Setting up conv5_3_relu5_3_0_split
I1018 13:21:49.127749 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.127753 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.127754 12584 layer_factory.hpp:76] Creating layer rpn_conv/3x3
I1018 13:21:49.127758 12584 net.cpp:110] Creating Layer rpn_conv/3x3
I1018 13:21:49.127760 12584 net.cpp:477] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I1018 13:21:49.127763 12584 net.cpp:433] rpn_conv/3x3 -> rpn/output
I1018 13:21:49.130872 12584 net.cpp:155] Setting up rpn_conv/3x3
I1018 13:21:49.130895 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.130903 12584 layer_factory.hpp:76] Creating layer rpn_relu/3x3
I1018 13:21:49.130913 12584 net.cpp:110] Creating Layer rpn_relu/3x3
I1018 13:21:49.130918 12584 net.cpp:477] rpn_relu/3x3 <- rpn/output
I1018 13:21:49.130921 12584 net.cpp:419] rpn_relu/3x3 -> rpn/output (in-place)
I1018 13:21:49.130928 12584 net.cpp:155] Setting up rpn_relu/3x3
I1018 13:21:49.130929 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.130931 12584 layer_factory.hpp:76] Creating layer rpn/output_rpn_relu/3x3_0_split
I1018 13:21:49.130936 12584 net.cpp:110] Creating Layer rpn/output_rpn_relu/3x3_0_split
I1018 13:21:49.130939 12584 net.cpp:477] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I1018 13:21:49.130941 12584 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I1018 13:21:49.130945 12584 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I1018 13:21:49.130949 12584 net.cpp:155] Setting up rpn/output_rpn_relu/3x3_0_split
I1018 13:21:49.130951 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.130954 12584 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1018 13:21:49.130955 12584 layer_factory.hpp:76] Creating layer rpn_cls_score
I1018 13:21:49.130960 12584 net.cpp:110] Creating Layer rpn_cls_score
I1018 13:21:49.130962 12584 net.cpp:477] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I1018 13:21:49.130965 12584 net.cpp:433] rpn_cls_score -> rpn_cls_score
I1018 13:21:49.131006 12584 net.cpp:155] Setting up rpn_cls_score
I1018 13:21:49.131011 12584 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1018 13:21:49.131013 12584 layer_factory.hpp:76] Creating layer rpn_bbox_pred
I1018 13:21:49.131017 12584 net.cpp:110] Creating Layer rpn_bbox_pred
I1018 13:21:49.131019 12584 net.cpp:477] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I1018 13:21:49.131021 12584 net.cpp:433] rpn_bbox_pred -> rpn_bbox_pred
I1018 13:21:49.131062 12584 net.cpp:155] Setting up rpn_bbox_pred
I1018 13:21:49.131067 12584 net.cpp:163] Top shape: 1 36 14 14 (7056)
I1018 13:21:49.131069 12584 layer_factory.hpp:76] Creating layer rpn_cls_score_reshape
I1018 13:21:49.131074 12584 net.cpp:110] Creating Layer rpn_cls_score_reshape
I1018 13:21:49.131078 12584 net.cpp:477] rpn_cls_score_reshape <- rpn_cls_score
I1018 13:21:49.131079 12584 net.cpp:433] rpn_cls_score_reshape -> rpn_cls_score_reshape
I1018 13:21:49.131085 12584 net.cpp:155] Setting up rpn_cls_score_reshape
I1018 13:21:49.131088 12584 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1018 13:21:49.131090 12584 layer_factory.hpp:76] Creating layer rpn_cls_prob
I1018 13:21:49.131093 12584 net.cpp:110] Creating Layer rpn_cls_prob
I1018 13:21:49.131095 12584 net.cpp:477] rpn_cls_prob <- rpn_cls_score_reshape
I1018 13:21:49.131098 12584 net.cpp:433] rpn_cls_prob -> rpn_cls_prob
I1018 13:21:49.131113 12584 net.cpp:155] Setting up rpn_cls_prob
I1018 13:21:49.131115 12584 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1018 13:21:49.131117 12584 layer_factory.hpp:76] Creating layer rpn_cls_prob_reshape
I1018 13:21:49.131121 12584 net.cpp:110] Creating Layer rpn_cls_prob_reshape
I1018 13:21:49.131124 12584 net.cpp:477] rpn_cls_prob_reshape <- rpn_cls_prob
I1018 13:21:49.131126 12584 net.cpp:433] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I1018 13:21:49.131130 12584 net.cpp:155] Setting up rpn_cls_prob_reshape
I1018 13:21:49.131132 12584 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1018 13:21:49.131134 12584 layer_factory.hpp:76] Creating layer proposal
I1018 13:21:49.131431 12584 net.cpp:110] Creating Layer proposal
I1018 13:21:49.131438 12584 net.cpp:477] proposal <- rpn_cls_prob_reshape
I1018 13:21:49.131443 12584 net.cpp:477] proposal <- rpn_bbox_pred
I1018 13:21:49.131444 12584 net.cpp:477] proposal <- im_info
I1018 13:21:49.131448 12584 net.cpp:433] proposal -> rois
I1018 13:21:49.131855 12584 net.cpp:155] Setting up proposal
I1018 13:21:49.131863 12584 net.cpp:163] Top shape: 1 5 (5)
I1018 13:21:49.131866 12584 layer_factory.hpp:76] Creating layer roi_pool5
I1018 13:21:49.131875 12584 net.cpp:110] Creating Layer roi_pool5
I1018 13:21:49.131877 12584 net.cpp:477] roi_pool5 <- conv5_3_relu5_3_0_split_1
I1018 13:21:49.131880 12584 net.cpp:477] roi_pool5 <- rois
I1018 13:21:49.131883 12584 net.cpp:433] roi_pool5 -> pool5
I1018 13:21:49.131888 12584 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1018 13:21:49.131897 12584 net.cpp:155] Setting up roi_pool5
I1018 13:21:49.131901 12584 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1018 13:21:49.131902 12584 layer_factory.hpp:76] Creating layer fc6
I1018 13:21:49.131906 12584 net.cpp:110] Creating Layer fc6
I1018 13:21:49.131908 12584 net.cpp:477] fc6 <- pool5
I1018 13:21:49.131911 12584 net.cpp:433] fc6 -> fc6
I1018 13:21:49.288488 12584 net.cpp:155] Setting up fc6
I1018 13:21:49.288514 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.288528 12584 layer_factory.hpp:76] Creating layer relu6
I1018 13:21:49.288537 12584 net.cpp:110] Creating Layer relu6
I1018 13:21:49.288540 12584 net.cpp:477] relu6 <- fc6
I1018 13:21:49.288550 12584 net.cpp:419] relu6 -> fc6 (in-place)
I1018 13:21:49.288558 12584 net.cpp:155] Setting up relu6
I1018 13:21:49.288561 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.288564 12584 layer_factory.hpp:76] Creating layer fc7
I1018 13:21:49.288568 12584 net.cpp:110] Creating Layer fc7
I1018 13:21:49.288570 12584 net.cpp:477] fc7 <- fc6
I1018 13:21:49.288573 12584 net.cpp:433] fc7 -> fc7
I1018 13:21:49.312454 12584 net.cpp:155] Setting up fc7
I1018 13:21:49.312479 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.312489 12584 layer_factory.hpp:76] Creating layer relu7
I1018 13:21:49.312497 12584 net.cpp:110] Creating Layer relu7
I1018 13:21:49.312500 12584 net.cpp:477] relu7 <- fc7
I1018 13:21:49.312505 12584 net.cpp:419] relu7 -> fc7 (in-place)
I1018 13:21:49.312511 12584 net.cpp:155] Setting up relu7
I1018 13:21:49.312515 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.312516 12584 layer_factory.hpp:76] Creating layer fc7_relu7_0_split
I1018 13:21:49.312520 12584 net.cpp:110] Creating Layer fc7_relu7_0_split
I1018 13:21:49.312523 12584 net.cpp:477] fc7_relu7_0_split <- fc7
I1018 13:21:49.312526 12584 net.cpp:433] fc7_relu7_0_split -> fc7_relu7_0_split_0
I1018 13:21:49.312530 12584 net.cpp:433] fc7_relu7_0_split -> fc7_relu7_0_split_1
I1018 13:21:49.312535 12584 net.cpp:155] Setting up fc7_relu7_0_split
I1018 13:21:49.312537 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.312539 12584 net.cpp:163] Top shape: 1 4096 (4096)
I1018 13:21:49.312541 12584 layer_factory.hpp:76] Creating layer cls_score
I1018 13:21:49.312546 12584 net.cpp:110] Creating Layer cls_score
I1018 13:21:49.312548 12584 net.cpp:477] cls_score <- fc7_relu7_0_split_0
I1018 13:21:49.312552 12584 net.cpp:433] cls_score -> cls_score
I1018 13:21:49.312978 12584 net.cpp:155] Setting up cls_score
I1018 13:21:49.312984 12584 net.cpp:163] Top shape: 1 21 (21)
I1018 13:21:49.312989 12584 layer_factory.hpp:76] Creating layer bbox_pred
I1018 13:21:49.312994 12584 net.cpp:110] Creating Layer bbox_pred
I1018 13:21:49.312996 12584 net.cpp:477] bbox_pred <- fc7_relu7_0_split_1
I1018 13:21:49.313000 12584 net.cpp:433] bbox_pred -> bbox_pred
I1018 13:21:49.313573 12584 net.cpp:155] Setting up bbox_pred
I1018 13:21:49.313580 12584 net.cpp:163] Top shape: 1 84 (84)
I1018 13:21:49.313586 12584 layer_factory.hpp:76] Creating layer cls_prob
I1018 13:21:49.313591 12584 net.cpp:110] Creating Layer cls_prob
I1018 13:21:49.313593 12584 net.cpp:477] cls_prob <- cls_score
I1018 13:21:49.313597 12584 net.cpp:433] cls_prob -> cls_prob
I1018 13:21:49.313613 12584 net.cpp:155] Setting up cls_prob
I1018 13:21:49.313616 12584 net.cpp:163] Top shape: 1 21 (21)
I1018 13:21:49.313618 12584 net.cpp:240] cls_prob does not need backward computation.
I1018 13:21:49.313621 12584 net.cpp:240] bbox_pred does not need backward computation.
I1018 13:21:49.313622 12584 net.cpp:240] cls_score does not need backward computation.
I1018 13:21:49.313624 12584 net.cpp:240] fc7_relu7_0_split does not need backward computation.
I1018 13:21:49.313627 12584 net.cpp:240] relu7 does not need backward computation.
I1018 13:21:49.313628 12584 net.cpp:240] fc7 does not need backward computation.
I1018 13:21:49.313630 12584 net.cpp:240] relu6 does not need backward computation.
I1018 13:21:49.313632 12584 net.cpp:240] fc6 does not need backward computation.
I1018 13:21:49.313634 12584 net.cpp:240] roi_pool5 does not need backward computation.
I1018 13:21:49.313637 12584 net.cpp:240] proposal does not need backward computation.
I1018 13:21:49.313640 12584 net.cpp:240] rpn_cls_prob_reshape does not need backward computation.
I1018 13:21:49.313642 12584 net.cpp:240] rpn_cls_prob does not need backward computation.
I1018 13:21:49.313645 12584 net.cpp:240] rpn_cls_score_reshape does not need backward computation.
I1018 13:21:49.313647 12584 net.cpp:240] rpn_bbox_pred does not need backward computation.
I1018 13:21:49.313649 12584 net.cpp:240] rpn_cls_score does not need backward computation.
I1018 13:21:49.313652 12584 net.cpp:240] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I1018 13:21:49.313654 12584 net.cpp:240] rpn_relu/3x3 does not need backward computation.
I1018 13:21:49.313657 12584 net.cpp:240] rpn_conv/3x3 does not need backward computation.
I1018 13:21:49.313658 12584 net.cpp:240] conv5_3_relu5_3_0_split does not need backward computation.
I1018 13:21:49.313660 12584 net.cpp:240] relu5_3 does not need backward computation.
I1018 13:21:49.313663 12584 net.cpp:240] conv5_3 does not need backward computation.
I1018 13:21:49.313665 12584 net.cpp:240] relu5_2 does not need backward computation.
I1018 13:21:49.313668 12584 net.cpp:240] conv5_2 does not need backward computation.
I1018 13:21:49.313669 12584 net.cpp:240] relu5_1 does not need backward computation.
I1018 13:21:49.313671 12584 net.cpp:240] conv5_1 does not need backward computation.
I1018 13:21:49.313673 12584 net.cpp:240] pool4 does not need backward computation.
I1018 13:21:49.313675 12584 net.cpp:240] relu4_3 does not need backward computation.
I1018 13:21:49.313678 12584 net.cpp:240] conv4_3 does not need backward computation.
I1018 13:21:49.313679 12584 net.cpp:240] relu4_2 does not need backward computation.
I1018 13:21:49.313681 12584 net.cpp:240] conv4_2 does not need backward computation.
I1018 13:21:49.313683 12584 net.cpp:240] relu4_1 does not need backward computation.
I1018 13:21:49.313685 12584 net.cpp:240] conv4_1 does not need backward computation.
I1018 13:21:49.313688 12584 net.cpp:240] pool3 does not need backward computation.
I1018 13:21:49.313690 12584 net.cpp:240] relu3_3 does not need backward computation.
I1018 13:21:49.313693 12584 net.cpp:240] conv3_3 does not need backward computation.
I1018 13:21:49.313694 12584 net.cpp:240] relu3_2 does not need backward computation.
I1018 13:21:49.313696 12584 net.cpp:240] conv3_2 does not need backward computation.
I1018 13:21:49.313699 12584 net.cpp:240] relu3_1 does not need backward computation.
I1018 13:21:49.313700 12584 net.cpp:240] conv3_1 does not need backward computation.
I1018 13:21:49.313702 12584 net.cpp:240] pool2 does not need backward computation.
I1018 13:21:49.313705 12584 net.cpp:240] relu2_2 does not need backward computation.
I1018 13:21:49.313707 12584 net.cpp:240] conv2_2 does not need backward computation.
I1018 13:21:49.313710 12584 net.cpp:240] relu2_1 does not need backward computation.
I1018 13:21:49.313711 12584 net.cpp:240] conv2_1 does not need backward computation.
I1018 13:21:49.313714 12584 net.cpp:240] pool1 does not need backward computation.
I1018 13:21:49.313716 12584 net.cpp:240] relu1_2 does not need backward computation.
I1018 13:21:49.313719 12584 net.cpp:240] conv1_2 does not need backward computation.
I1018 13:21:49.313720 12584 net.cpp:240] relu1_1 does not need backward computation.
I1018 13:21:49.313722 12584 net.cpp:240] conv1_1 does not need backward computation.
I1018 13:21:49.313724 12584 net.cpp:283] This network produces output bbox_pred
I1018 13:21:49.313726 12584 net.cpp:283] This network produces output cls_prob
I1018 13:21:49.313743 12584 net.cpp:297] Network initialization done.
I1018 13:21:49.313745 12584 net.cpp:298] Memory required for data: 117093580
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 1028223059
im_detect: 1/4952 0.208s 0.001s
im_detect: 2/4952 0.192s 0.001s
im_detect: 3/4952 0.175s 0.001s
im_detect: 4/4952 0.165s 0.001s
im_detect: 5/4952 0.160s 0.001s
im_detect: 6/4952 0.155s 0.001s
im_detect: 7/4952 0.153s 0.001s
im_detect: 8/4952 0.154s 0.001s
im_detect: 9/4952 0.154s 0.001s
im_detect: 10/4952 0.153s 0.001s
im_detect: 11/4952 0.153s 0.001s
im_detect: 12/4952 0.151s 0.001s
im_detect: 13/4952 0.152s 0.001s
im_detect: 14/4952 0.151s 0.001s
im_detect: 15/4952 0.149s 0.001s
im_detect: 16/4952 0.148s 0.001s
im_detect: 17/4952 0.148s 0.001s
im_detect: 18/4952 0.147s 0.001s
im_detect: 19/4952 0.146s 0.001s
im_detect: 20/4952 0.145s 0.001s
im_detect: 21/4952 0.145s 0.001s
im_detect: 22/4952 0.145s 0.001s
im_detect: 23/4952 0.144s 0.001s
im_detect: 24/4952 0.144s 0.001s
im_detect: 25/4952 0.143s 0.001s
im_detect: 26/4952 0.143s 0.001s
im_detect: 27/4952 0.143s 0.001s
im_detect: 28/4952 0.143s 0.001s
im_detect: 29/4952 0.143s 0.001s
im_detect: 30/4952 0.144s 0.001s
im_detect: 31/4952 0.144s 0.001s
im_detect: 32/4952 0.143s 0.001s
im_detect: 33/4952 0.144s 0.001s
im_detect: 34/4952 0.143s 0.001s
im_detect: 35/4952 0.143s 0.001s
im_detect: 36/4952 0.143s 0.001s
im_detect: 37/4952 0.143s 0.001s
im_detect: 38/4952 0.143s 0.001s
im_detect: 39/4952 0.142s 0.001s
im_detect: 40/4952 0.143s 0.001s
im_detect: 41/4952 0.142s 0.001s
im_detect: 42/4952 0.142s 0.001s
im_detect: 43/4952 0.142s 0.001s
im_detect: 44/4952 0.142s 0.001s
im_detect: 45/4952 0.142s 0.001s
im_detect: 46/4952 0.143s 0.001s
im_detect: 47/4952 0.143s 0.001s
im_detect: 48/4952 0.143s 0.001s
im_detect: 49/4952 0.143s 0.001s
im_detect: 50/4952 0.142s 0.001s
im_detect: 51/4952 0.142s 0.001s
im_detect: 52/4952 0.142s 0.001s
im_detect: 53/4952 0.142s 0.001s
im_detect: 54/4952 0.142s 0.001s
im_detect: 55/4952 0.143s 0.001s
im_detect: 56/4952 0.143s 0.001s
im_detect: 57/4952 0.143s 0.001s
im_detect: 58/4952 0.143s 0.001s
im_detect: 59/4952 0.142s 0.001s
im_detect: 60/4952 0.142s 0.001s
im_detect: 61/4952 0.142s 0.001s
im_detect: 62/4952 0.142s 0.001s
im_detect: 63/4952 0.142s 0.001s
im_detect: 64/4952 0.142s 0.001s
im_detect: 65/4952 0.142s 0.001s
im_detect: 66/4952 0.141s 0.001s
im_detect: 67/4952 0.141s 0.001s
im_detect: 68/4952 0.141s 0.001s
im_detect: 69/4952 0.142s 0.001s
im_detect: 70/4952 0.142s 0.001s
im_detect: 71/4952 0.142s 0.001s
im_detect: 72/4952 0.141s 0.001s
im_detect: 73/4952 0.142s 0.001s
im_detect: 74/4952 0.142s 0.001s
im_detect: 75/4952 0.141s 0.001s
im_detect: 76/4952 0.141s 0.001s
im_detect: 77/4952 0.141s 0.001s
im_detect: 78/4952 0.142s 0.001s
im_detect: 79/4952 0.141s 0.001s
im_detect: 80/4952 0.141s 0.001s
im_detect: 81/4952 0.141s 0.001s
im_detect: 82/4952 0.141s 0.001s
im_detect: 83/4952 0.141s 0.001s
im_detect: 84/4952 0.141s 0.001s
im_detect: 85/4952 0.141s 0.001s
im_detect: 86/4952 0.141s 0.001s
im_detect: 87/4952 0.141s 0.001s
im_detect: 88/4952 0.141s 0.001s
im_detect: 89/4952 0.141s 0.001s
im_detect: 90/4952 0.141s 0.001s
im_detect: 91/4952 0.141s 0.001s
im_detect: 92/4952 0.141s 0.001s
im_detect: 93/4952 0.141s 0.001s
im_detect: 94/4952 0.141s 0.001s
im_detect: 95/4952 0.141s 0.001s
im_detect: 96/4952 0.141s 0.001s
im_detect: 97/4952 0.141s 0.001s
im_detect: 98/4952 0.141s 0.001s
im_detect: 99/4952 0.141s 0.001s
im_detect: 100/4952 0.141s 0.001s
im_detect: 101/4952 0.141s 0.001s
im_detect: 102/4952 0.141s 0.001s
im_detect: 103/4952 0.141s 0.001s
im_detect: 104/4952 0.141s 0.001s
im_detect: 105/4952 0.141s 0.001s
im_detect: 106/4952 0.141s 0.001s
im_detect: 107/4952 0.141s 0.001s
im_detect: 108/4952 0.141s 0.001s
im_detect: 109/4952 0.141s 0.001s
im_detect: 110/4952 0.141s 0.001s
im_detect: 111/4952 0.141s 0.001s
im_detect: 112/4952 0.141s 0.001s
im_detect: 113/4952 0.141s 0.001s
im_detect: 114/4952 0.141s 0.001s
im_detect: 115/4952 0.141s 0.001s
im_detect: 116/4952 0.141s 0.001s
im_detect: 117/4952 0.141s 0.001s
im_detect: 118/4952 0.141s 0.001s
im_detect: 119/4952 0.141s 0.001s
im_detect: 120/4952 0.141s 0.001s
im_detect: 121/4952 0.142s 0.001s
im_detect: 122/4952 0.142s 0.001s
im_detect: 123/4952 0.142s 0.001s
im_detect: 124/4952 0.142s 0.001s
im_detect: 125/4952 0.142s 0.001s
im_detect: 126/4952 0.142s 0.001s
im_detect: 127/4952 0.142s 0.001s
im_detect: 128/4952 0.142s 0.001s
im_detect: 129/4952 0.142s 0.001s
im_detect: 130/4952 0.142s 0.001s
im_detect: 131/4952 0.142s 0.001s
im_detect: 132/4952 0.142s 0.001s
im_detect: 133/4952 0.142s 0.001s
im_detect: 134/4952 0.142s 0.001s
im_detect: 135/4952 0.142s 0.001s
im_detect: 136/4952 0.142s 0.001s
im_detect: 137/4952 0.142s 0.001s
im_detect: 138/4952 0.142s 0.001s
im_detect: 139/4952 0.142s 0.001s
im_detect: 140/4952 0.142s 0.001s
im_detect: 141/4952 0.142s 0.001s
im_detect: 142/4952 0.142s 0.001s
im_detect: 143/4952 0.142s 0.001s
im_detect: 144/4952 0.142s 0.001s
im_detect: 145/4952 0.141s 0.001s
im_detect: 146/4952 0.141s 0.001s
im_detect: 147/4952 0.141s 0.001s
im_detect: 148/4952 0.141s 0.001s
im_detect: 149/4952 0.141s 0.001s
im_detect: 150/4952 0.141s 0.001s
im_detect: 151/4952 0.141s 0.001s
im_detect: 152/4952 0.141s 0.001s
im_detect: 153/4952 0.141s 0.001s
im_detect: 154/4952 0.141s 0.001s
im_detect: 155/4952 0.141s 0.001s
im_detect: 156/4952 0.141s 0.001s
im_detect: 157/4952 0.141s 0.001s
im_detect: 158/4952 0.141s 0.001s
im_detect: 159/4952 0.141s 0.001s
im_detect: 160/4952 0.141s 0.001s
im_detect: 161/4952 0.141s 0.001s
im_detect: 162/4952 0.141s 0.001s
im_detect: 163/4952 0.141s 0.001s
im_detect: 164/4952 0.141s 0.001s
im_detect: 165/4952 0.141s 0.001s
im_detect: 166/4952 0.141s 0.001s
im_detect: 167/4952 0.141s 0.001s
im_detect: 168/4952 0.141s 0.001s
im_detect: 169/4952 0.141s 0.001s
im_detect: 170/4952 0.141s 0.001s
im_detect: 171/4952 0.141s 0.001s
im_detect: 172/4952 0.142s 0.001s
im_detect: 173/4952 0.142s 0.001s
im_detect: 174/4952 0.142s 0.001s
im_detect: 175/4952 0.142s 0.001s
im_detect: 176/4952 0.142s 0.001s
im_detect: 177/4952 0.141s 0.001s
im_detect: 178/4952 0.141s 0.001s
im_detect: 179/4952 0.141s 0.001s
im_detect: 180/4952 0.141s 0.001s
im_detect: 181/4952 0.141s 0.001s
im_detect: 182/4952 0.141s 0.001s
im_detect: 183/4952 0.141s 0.001s
im_detect: 184/4952 0.141s 0.001s
im_detect: 185/4952 0.141s 0.001s
im_detect: 186/4952 0.141s 0.001s
im_detect: 187/4952 0.141s 0.001s
im_detect: 188/4952 0.141s 0.001s
im_detect: 189/4952 0.141s 0.001s
im_detect: 190/4952 0.141s 0.001s
im_detect: 191/4952 0.141s 0.001s
im_detect: 192/4952 0.141s 0.001s
im_detect: 193/4952 0.141s 0.001s
im_detect: 194/4952 0.141s 0.001s
im_detect: 195/4952 0.141s 0.001s
im_detect: 196/4952 0.141s 0.001s
im_detect: 197/4952 0.141s 0.001s
im_detect: 198/4952 0.141s 0.001s
im_detect: 199/4952 0.141s 0.001s
im_detect: 200/4952 0.141s 0.001s
im_detect: 201/4952 0.141s 0.001s
im_detect: 202/4952 0.141s 0.001s
im_detect: 203/4952 0.141s 0.001s
im_detect: 204/4952 0.141s 0.001s
im_detect: 205/4952 0.141s 0.001s
im_detect: 206/4952 0.141s 0.001s
im_detect: 207/4952 0.141s 0.001s
im_detect: 208/4952 0.141s 0.001s
im_detect: 209/4952 0.141s 0.001s
im_detect: 210/4952 0.141s 0.001s
im_detect: 211/4952 0.141s 0.001s
im_detect: 212/4952 0.141s 0.001s
im_detect: 213/4952 0.141s 0.001s
im_detect: 214/4952 0.141s 0.001s
im_detect: 215/4952 0.141s 0.001s
im_detect: 216/4952 0.141s 0.001s
im_detect: 217/4952 0.141s 0.001s
im_detect: 218/4952 0.141s 0.001s
im_detect: 219/4952 0.141s 0.001s
im_detect: 220/4952 0.141s 0.001s
im_detect: 221/4952 0.141s 0.001s
im_detect: 222/4952 0.141s 0.001s
im_detect: 223/4952 0.141s 0.001s
im_detect: 224/4952 0.141s 0.001s
im_detect: 225/4952 0.141s 0.001s
im_detect: 226/4952 0.141s 0.001s
im_detect: 227/4952 0.141s 0.001s
im_detect: 228/4952 0.141s 0.001s
im_detect: 229/4952 0.141s 0.001s
im_detect: 230/4952 0.141s 0.001s
im_detect: 231/4952 0.141s 0.001s
im_detect: 232/4952 0.141s 0.001s
im_detect: 233/4952 0.141s 0.001s
im_detect: 234/4952 0.141s 0.001s
im_detect: 235/4952 0.141s 0.001s
im_detect: 236/4952 0.141s 0.001s
im_detect: 237/4952 0.141s 0.001s
im_detect: 238/4952 0.141s 0.001s
im_detect: 239/4952 0.141s 0.001s
im_detect: 240/4952 0.141s 0.001s
im_detect: 241/4952 0.141s 0.001s
im_detect: 242/4952 0.141s 0.001s
im_detect: 243/4952 0.141s 0.001s
im_detect: 244/4952 0.141s 0.001s
im_detect: 245/4952 0.141s 0.001s
im_detect: 246/4952 0.141s 0.001s
im_detect: 247/4952 0.141s 0.001s
im_detect: 248/4952 0.141s 0.001s
im_detect: 249/4952 0.141s 0.001s
im_detect: 250/4952 0.141s 0.001s
im_detect: 251/4952 0.141s 0.001s
im_detect: 252/4952 0.141s 0.001s
im_detect: 253/4952 0.141s 0.001s
im_detect: 254/4952 0.141s 0.001s
im_detect: 255/4952 0.141s 0.001s
im_detect: 256/4952 0.141s 0.001s
im_detect: 257/4952 0.141s 0.001s
im_detect: 258/4952 0.141s 0.001s
im_detect: 259/4952 0.141s 0.001s
im_detect: 260/4952 0.141s 0.001s
im_detect: 261/4952 0.141s 0.001s
im_detect: 262/4952 0.141s 0.001s
im_detect: 263/4952 0.141s 0.001s
im_detect: 264/4952 0.141s 0.001s
im_detect: 265/4952 0.141s 0.001s
im_detect: 266/4952 0.141s 0.001s
im_detect: 267/4952 0.141s 0.001s
im_detect: 268/4952 0.141s 0.001s
im_detect: 269/4952 0.141s 0.001s
im_detect: 270/4952 0.141s 0.001s
im_detect: 271/4952 0.141s 0.001s
im_detect: 272/4952 0.141s 0.001s
im_detect: 273/4952 0.141s 0.001s
im_detect: 274/4952 0.141s 0.001s
im_detect: 275/4952 0.141s 0.001s
im_detect: 276/4952 0.141s 0.001s
im_detect: 277/4952 0.141s 0.001s
im_detect: 278/4952 0.141s 0.001s
im_detect: 279/4952 0.141s 0.001s
im_detect: 280/4952 0.141s 0.001s
im_detect: 281/4952 0.141s 0.001s
im_detect: 282/4952 0.141s 0.001s
im_detect: 283/4952 0.141s 0.001s
im_detect: 284/4952 0.141s 0.001s
im_detect: 285/4952 0.141s 0.001s
im_detect: 286/4952 0.141s 0.001s
im_detect: 287/4952 0.141s 0.001s
im_detect: 288/4952 0.141s 0.001s
im_detect: 289/4952 0.141s 0.001s
im_detect: 290/4952 0.141s 0.001s
im_detect: 291/4952 0.141s 0.001s
im_detect: 292/4952 0.141s 0.001s
im_detect: 293/4952 0.141s 0.001s
im_detect: 294/4952 0.141s 0.001s
im_detect: 295/4952 0.141s 0.001s
im_detect: 296/4952 0.141s 0.001s
im_detect: 297/4952 0.141s 0.001s
im_detect: 298/4952 0.141s 0.001s
im_detect: 299/4952 0.141s 0.001s
im_detect: 300/4952 0.141s 0.001s
im_detect: 301/4952 0.141s 0.001s
im_detect: 302/4952 0.141s 0.001s
im_detect: 303/4952 0.141s 0.001s
im_detect: 304/4952 0.141s 0.001s
im_detect: 305/4952 0.141s 0.001s
im_detect: 306/4952 0.141s 0.001s
im_detect: 307/4952 0.141s 0.001s
im_detect: 308/4952 0.141s 0.001s
im_detect: 309/4952 0.141s 0.001s
im_detect: 310/4952 0.141s 0.001s
im_detect: 311/4952 0.141s 0.001s
im_detect: 312/4952 0.141s 0.001s
im_detect: 313/4952 0.141s 0.001s
im_detect: 314/4952 0.141s 0.001s
im_detect: 315/4952 0.141s 0.001s
im_detect: 316/4952 0.141s 0.001s
im_detect: 317/4952 0.141s 0.001s
im_detect: 318/4952 0.141s 0.001s
im_detect: 319/4952 0.141s 0.001s
im_detect: 320/4952 0.141s 0.001s
im_detect: 321/4952 0.141s 0.001s
im_detect: 322/4952 0.141s 0.001s
im_detect: 323/4952 0.141s 0.001s
im_detect: 324/4952 0.141s 0.001s
im_detect: 325/4952 0.141s 0.001s
im_detect: 326/4952 0.141s 0.001s
im_detect: 327/4952 0.141s 0.001s
im_detect: 328/4952 0.141s 0.001s
im_detect: 329/4952 0.141s 0.001s
im_detect: 330/4952 0.141s 0.001s
im_detect: 331/4952 0.141s 0.001s
im_detect: 332/4952 0.141s 0.001s
im_detect: 333/4952 0.141s 0.001s
im_detect: 334/4952 0.141s 0.001s
im_detect: 335/4952 0.141s 0.001s
im_detect: 336/4952 0.141s 0.001s
im_detect: 337/4952 0.141s 0.001s
im_detect: 338/4952 0.141s 0.001s
im_detect: 339/4952 0.141s 0.001s
im_detect: 340/4952 0.141s 0.001s
im_detect: 341/4952 0.141s 0.001s
im_detect: 342/4952 0.141s 0.001s
im_detect: 343/4952 0.141s 0.001s
im_detect: 344/4952 0.141s 0.001s
im_detect: 345/4952 0.141s 0.001s
im_detect: 346/4952 0.141s 0.001s
im_detect: 347/4952 0.141s 0.001s
im_detect: 348/4952 0.141s 0.001s
im_detect: 349/4952 0.141s 0.001s
im_detect: 350/4952 0.141s 0.001s
im_detect: 351/4952 0.141s 0.001s
im_detect: 352/4952 0.141s 0.001s
im_detect: 353/4952 0.141s 0.001s
im_detect: 354/4952 0.141s 0.001s
im_detect: 355/4952 0.141s 0.001s
im_detect: 356/4952 0.141s 0.001s
im_detect: 357/4952 0.141s 0.001s
im_detect: 358/4952 0.141s 0.001s
im_detect: 359/4952 0.141s 0.001s
im_detect: 360/4952 0.141s 0.001s
im_detect: 361/4952 0.141s 0.001s
im_detect: 362/4952 0.141s 0.001s
im_detect: 363/4952 0.141s 0.001s
im_detect: 364/4952 0.141s 0.001s
im_detect: 365/4952 0.141s 0.001s
im_detect: 366/4952 0.141s 0.001s
im_detect: 367/4952 0.141s 0.001s
im_detect: 368/4952 0.141s 0.001s
im_detect: 369/4952 0.141s 0.001s
im_detect: 370/4952 0.141s 0.001s
im_detect: 371/4952 0.141s 0.001s
im_detect: 372/4952 0.141s 0.001s
im_detect: 373/4952 0.141s 0.001s
im_detect: 374/4952 0.141s 0.001s
im_detect: 375/4952 0.142s 0.001s
im_detect: 376/4952 0.142s 0.001s
im_detect: 377/4952 0.142s 0.001s
im_detect: 378/4952 0.142s 0.001s
im_detect: 379/4952 0.142s 0.001s
im_detect: 380/4952 0.142s 0.001s
im_detect: 381/4952 0.142s 0.001s
im_detect: 382/4952 0.142s 0.001s
im_detect: 383/4952 0.142s 0.001s
im_detect: 384/4952 0.142s 0.001s
im_detect: 385/4952 0.142s 0.001s
im_detect: 386/4952 0.142s 0.001s
im_detect: 387/4952 0.142s 0.001s
im_detect: 388/4952 0.142s 0.001s
im_detect: 389/4952 0.142s 0.001s
im_detect: 390/4952 0.142s 0.001s
im_detect: 391/4952 0.142s 0.001s
im_detect: 392/4952 0.142s 0.001s
im_detect: 393/4952 0.142s 0.001s
im_detect: 394/4952 0.142s 0.001s
im_detect: 395/4952 0.142s 0.001s
im_detect: 396/4952 0.142s 0.001s
im_detect: 397/4952 0.141s 0.001s
im_detect: 398/4952 0.141s 0.001s
im_detect: 399/4952 0.141s 0.001s
im_detect: 400/4952 0.141s 0.001s
im_detect: 401/4952 0.141s 0.001s
im_detect: 402/4952 0.141s 0.001s
im_detect: 403/4952 0.141s 0.001s
im_detect: 404/4952 0.141s 0.001s
im_detect: 405/4952 0.141s 0.001s
im_detect: 406/4952 0.141s 0.001s
im_detect: 407/4952 0.141s 0.001s
im_detect: 408/4952 0.141s 0.001s
im_detect: 409/4952 0.141s 0.001s
im_detect: 410/4952 0.141s 0.001s
im_detect: 411/4952 0.141s 0.001s
im_detect: 412/4952 0.141s 0.001s
im_detect: 413/4952 0.142s 0.001s
im_detect: 414/4952 0.142s 0.001s
im_detect: 415/4952 0.142s 0.001s
im_detect: 416/4952 0.142s 0.001s
im_detect: 417/4952 0.142s 0.001s
im_detect: 418/4952 0.142s 0.001s
im_detect: 419/4952 0.142s 0.001s
im_detect: 420/4952 0.142s 0.001s
im_detect: 421/4952 0.142s 0.001s
im_detect: 422/4952 0.142s 0.001s
im_detect: 423/4952 0.142s 0.001s
im_detect: 424/4952 0.142s 0.001s
im_detect: 425/4952 0.142s 0.001s
im_detect: 426/4952 0.142s 0.001s
im_detect: 427/4952 0.142s 0.001s
im_detect: 428/4952 0.142s 0.001s
im_detect: 429/4952 0.142s 0.001s
im_detect: 430/4952 0.142s 0.001s
im_detect: 431/4952 0.142s 0.001s
im_detect: 432/4952 0.142s 0.001s
im_detect: 433/4952 0.142s 0.001s
im_detect: 434/4952 0.142s 0.001s
im_detect: 435/4952 0.142s 0.001s
im_detect: 436/4952 0.142s 0.001s
im_detect: 437/4952 0.142s 0.001s
im_detect: 438/4952 0.142s 0.001s
im_detect: 439/4952 0.142s 0.001s
im_detect: 440/4952 0.142s 0.001s
im_detect: 441/4952 0.142s 0.001s
im_detect: 442/4952 0.142s 0.001s
im_detect: 443/4952 0.142s 0.001s
im_detect: 444/4952 0.142s 0.001s
im_detect: 445/4952 0.142s 0.001s
im_detect: 446/4952 0.142s 0.001s
im_detect: 447/4952 0.142s 0.001s
im_detect: 448/4952 0.142s 0.001s
im_detect: 449/4952 0.142s 0.001s
im_detect: 450/4952 0.142s 0.001s
im_detect: 451/4952 0.142s 0.001s
im_detect: 452/4952 0.142s 0.001s
im_detect: 453/4952 0.142s 0.001s
im_detect: 454/4952 0.142s 0.001s
im_detect: 455/4952 0.142s 0.001s
im_detect: 456/4952 0.142s 0.001s
im_detect: 457/4952 0.142s 0.001s
im_detect: 458/4952 0.142s 0.001s
im_detect: 459/4952 0.142s 0.001s
im_detect: 460/4952 0.142s 0.001s
im_detect: 461/4952 0.142s 0.001s
im_detect: 462/4952 0.142s 0.001s
im_detect: 463/4952 0.142s 0.001s
im_detect: 464/4952 0.142s 0.001s
im_detect: 465/4952 0.142s 0.001s
im_detect: 466/4952 0.142s 0.001s
im_detect: 467/4952 0.142s 0.001s
im_detect: 468/4952 0.142s 0.001s
im_detect: 469/4952 0.142s 0.001s
im_detect: 470/4952 0.141s 0.001s
im_detect: 471/4952 0.141s 0.001s
im_detect: 472/4952 0.141s 0.001s
im_detect: 473/4952 0.141s 0.001s
im_detect: 474/4952 0.141s 0.001s
im_detect: 475/4952 0.141s 0.001s
im_detect: 476/4952 0.141s 0.001s
im_detect: 477/4952 0.141s 0.001s
im_detect: 478/4952 0.141s 0.001s
im_detect: 479/4952 0.141s 0.001s
im_detect: 480/4952 0.141s 0.001s
im_detect: 481/4952 0.141s 0.001s
im_detect: 482/4952 0.141s 0.001s
im_detect: 483/4952 0.141s 0.001s
im_detect: 484/4952 0.141s 0.001s
im_detect: 485/4952 0.141s 0.001s
im_detect: 486/4952 0.142s 0.001s
im_detect: 487/4952 0.142s 0.001s
im_detect: 488/4952 0.141s 0.001s
im_detect: 489/4952 0.142s 0.001s
im_detect: 490/4952 0.142s 0.001s
im_detect: 491/4952 0.142s 0.001s
im_detect: 492/4952 0.142s 0.001s
im_detect: 493/4952 0.142s 0.001s
im_detect: 494/4952 0.142s 0.001s
im_detect: 495/4952 0.142s 0.001s
im_detect: 496/4952 0.142s 0.001s
im_detect: 497/4952 0.142s 0.001s
im_detect: 498/4952 0.142s 0.001s
im_detect: 499/4952 0.142s 0.001s
im_detect: 500/4952 0.142s 0.001s
im_detect: 501/4952 0.142s 0.001s
im_detect: 502/4952 0.142s 0.001s
im_detect: 503/4952 0.142s 0.001s
im_detect: 504/4952 0.142s 0.001s
im_detect: 505/4952 0.142s 0.001s
im_detect: 506/4952 0.142s 0.001s
im_detect: 507/4952 0.142s 0.001s
im_detect: 508/4952 0.142s 0.001s
im_detect: 509/4952 0.142s 0.001s
im_detect: 510/4952 0.142s 0.001s
im_detect: 511/4952 0.142s 0.001s
im_detect: 512/4952 0.142s 0.001s
im_detect: 513/4952 0.142s 0.001s
im_detect: 514/4952 0.142s 0.001s
im_detect: 515/4952 0.142s 0.001s
im_detect: 516/4952 0.142s 0.001s
im_detect: 517/4952 0.142s 0.001s
im_detect: 518/4952 0.142s 0.001s
im_detect: 519/4952 0.142s 0.001s
im_detect: 520/4952 0.142s 0.001s
im_detect: 521/4952 0.142s 0.001s
im_detect: 522/4952 0.142s 0.001s
im_detect: 523/4952 0.142s 0.001s
im_detect: 524/4952 0.142s 0.001s
im_detect: 525/4952 0.142s 0.001s
im_detect: 526/4952 0.142s 0.001s
im_detect: 527/4952 0.142s 0.001s
im_detect: 528/4952 0.142s 0.001s
im_detect: 529/4952 0.142s 0.001s
im_detect: 530/4952 0.142s 0.001s
im_detect: 531/4952 0.142s 0.001s
im_detect: 532/4952 0.142s 0.001s
im_detect: 533/4952 0.142s 0.001s
im_detect: 534/4952 0.142s 0.001s
im_detect: 535/4952 0.142s 0.001s
im_detect: 536/4952 0.142s 0.001s
im_detect: 537/4952 0.142s 0.001s
im_detect: 538/4952 0.142s 0.001s
im_detect: 539/4952 0.142s 0.001s
im_detect: 540/4952 0.142s 0.001s
im_detect: 541/4952 0.142s 0.001s
im_detect: 542/4952 0.142s 0.001s
im_detect: 543/4952 0.142s 0.001s
im_detect: 544/4952 0.143s 0.001s
im_detect: 545/4952 0.143s 0.001s
im_detect: 546/4952 0.143s 0.001s
im_detect: 547/4952 0.143s 0.001s
im_detect: 548/4952 0.143s 0.001s
im_detect: 549/4952 0.143s 0.001s
im_detect: 550/4952 0.143s 0.001s
im_detect: 551/4952 0.143s 0.001s
im_detect: 552/4952 0.143s 0.001s
im_detect: 553/4952 0.143s 0.001s
im_detect: 554/4952 0.143s 0.001s
im_detect: 555/4952 0.143s 0.001s
im_detect: 556/4952 0.143s 0.001s
im_detect: 557/4952 0.143s 0.001s
im_detect: 558/4952 0.143s 0.001s
im_detect: 559/4952 0.143s 0.001s
im_detect: 560/4952 0.143s 0.001s
im_detect: 561/4952 0.143s 0.001s
im_detect: 562/4952 0.143s 0.001s
im_detect: 563/4952 0.143s 0.001s
im_detect: 564/4952 0.143s 0.001s
im_detect: 565/4952 0.143s 0.001s
im_detect: 566/4952 0.143s 0.001s
im_detect: 567/4952 0.143s 0.001s
im_detect: 568/4952 0.143s 0.001s
im_detect: 569/4952 0.143s 0.001s
im_detect: 570/4952 0.143s 0.001s
im_detect: 571/4952 0.143s 0.001s
im_detect: 572/4952 0.143s 0.001s
im_detect: 573/4952 0.143s 0.001s
im_detect: 574/4952 0.143s 0.001s
im_detect: 575/4952 0.143s 0.001s
im_detect: 576/4952 0.143s 0.001s
im_detect: 577/4952 0.143s 0.001s
im_detect: 578/4952 0.143s 0.001s
im_detect: 579/4952 0.143s 0.001s
im_detect: 580/4952 0.143s 0.001s
im_detect: 581/4952 0.143s 0.001s
im_detect: 582/4952 0.143s 0.001s
im_detect: 583/4952 0.143s 0.001s
im_detect: 584/4952 0.143s 0.001s
im_detect: 585/4952 0.143s 0.001s
im_detect: 586/4952 0.143s 0.001s
im_detect: 587/4952 0.143s 0.001s
im_detect: 588/4952 0.143s 0.001s
im_detect: 589/4952 0.143s 0.001s
im_detect: 590/4952 0.143s 0.001s
im_detect: 591/4952 0.143s 0.001s
im_detect: 592/4952 0.143s 0.001s
im_detect: 593/4952 0.143s 0.001s
im_detect: 594/4952 0.143s 0.001s
im_detect: 595/4952 0.143s 0.001s
im_detect: 596/4952 0.143s 0.001s
im_detect: 597/4952 0.143s 0.001s
im_detect: 598/4952 0.143s 0.001s
im_detect: 599/4952 0.143s 0.001s
im_detect: 600/4952 0.143s 0.001s
im_detect: 601/4952 0.143s 0.001s
im_detect: 602/4952 0.143s 0.001s
im_detect: 603/4952 0.143s 0.001s
im_detect: 604/4952 0.143s 0.001s
im_detect: 605/4952 0.143s 0.001s
im_detect: 606/4952 0.143s 0.001s
im_detect: 607/4952 0.143s 0.001s
im_detect: 608/4952 0.143s 0.001s
im_detect: 609/4952 0.143s 0.001s
im_detect: 610/4952 0.143s 0.001s
im_detect: 611/4952 0.143s 0.001s
im_detect: 612/4952 0.143s 0.001s
im_detect: 613/4952 0.143s 0.001s
im_detect: 614/4952 0.143s 0.001s
im_detect: 615/4952 0.143s 0.001s
im_detect: 616/4952 0.143s 0.001s
im_detect: 617/4952 0.143s 0.001s
im_detect: 618/4952 0.143s 0.001s
im_detect: 619/4952 0.143s 0.001s
im_detect: 620/4952 0.143s 0.001s
im_detect: 621/4952 0.143s 0.001s
im_detect: 622/4952 0.143s 0.001s
im_detect: 623/4952 0.143s 0.001s
im_detect: 624/4952 0.143s 0.001s
im_detect: 625/4952 0.143s 0.001s
im_detect: 626/4952 0.143s 0.001s
im_detect: 627/4952 0.143s 0.001s
im_detect: 628/4952 0.143s 0.001s
im_detect: 629/4952 0.143s 0.001s
im_detect: 630/4952 0.143s 0.001s
im_detect: 631/4952 0.143s 0.001s
im_detect: 632/4952 0.144s 0.001s
im_detect: 633/4952 0.144s 0.001s
im_detect: 634/4952 0.143s 0.001s
im_detect: 635/4952 0.143s 0.001s
im_detect: 636/4952 0.143s 0.001s
im_detect: 637/4952 0.143s 0.001s
im_detect: 638/4952 0.143s 0.001s
im_detect: 639/4952 0.143s 0.001s
im_detect: 640/4952 0.144s 0.001s
im_detect: 641/4952 0.143s 0.001s
im_detect: 642/4952 0.143s 0.001s
im_detect: 643/4952 0.144s 0.001s
im_detect: 644/4952 0.144s 0.001s
im_detect: 645/4952 0.144s 0.001s
im_detect: 646/4952 0.144s 0.001s
im_detect: 647/4952 0.144s 0.001s
im_detect: 648/4952 0.144s 0.001s
im_detect: 649/4952 0.144s 0.001s
im_detect: 650/4952 0.144s 0.001s
im_detect: 651/4952 0.144s 0.001s
im_detect: 652/4952 0.144s 0.001s
im_detect: 653/4952 0.144s 0.001s
im_detect: 654/4952 0.144s 0.001s
im_detect: 655/4952 0.144s 0.001s
im_detect: 656/4952 0.144s 0.001s
im_detect: 657/4952 0.144s 0.001s
im_detect: 658/4952 0.144s 0.001s
im_detect: 659/4952 0.144s 0.001s
im_detect: 660/4952 0.144s 0.001s
im_detect: 661/4952 0.144s 0.001s
im_detect: 662/4952 0.144s 0.001s
im_detect: 663/4952 0.144s 0.001s
im_detect: 664/4952 0.144s 0.001s
im_detect: 665/4952 0.144s 0.001s
im_detect: 666/4952 0.144s 0.001s
im_detect: 667/4952 0.144s 0.001s
im_detect: 668/4952 0.144s 0.001s
im_detect: 669/4952 0.144s 0.001s
im_detect: 670/4952 0.144s 0.001s
im_detect: 671/4952 0.144s 0.001s
im_detect: 672/4952 0.144s 0.001s
im_detect: 673/4952 0.144s 0.001s
im_detect: 674/4952 0.144s 0.001s
im_detect: 675/4952 0.144s 0.001s
im_detect: 676/4952 0.144s 0.001s
im_detect: 677/4952 0.144s 0.001s
im_detect: 678/4952 0.144s 0.001s
im_detect: 679/4952 0.144s 0.001s
im_detect: 680/4952 0.144s 0.001s
im_detect: 681/4952 0.144s 0.001s
im_detect: 682/4952 0.144s 0.001s
im_detect: 683/4952 0.144s 0.001s
im_detect: 684/4952 0.144s 0.001s
im_detect: 685/4952 0.144s 0.001s
im_detect: 686/4952 0.144s 0.001s
im_detect: 687/4952 0.144s 0.001s
im_detect: 688/4952 0.144s 0.001s
im_detect: 689/4952 0.144s 0.001s
im_detect: 690/4952 0.144s 0.001s
im_detect: 691/4952 0.144s 0.001s
im_detect: 692/4952 0.144s 0.001s
im_detect: 693/4952 0.144s 0.001s
im_detect: 694/4952 0.144s 0.001s
im_detect: 695/4952 0.144s 0.001s
im_detect: 696/4952 0.144s 0.001s
im_detect: 697/4952 0.144s 0.001s
im_detect: 698/4952 0.144s 0.001s
im_detect: 699/4952 0.144s 0.001s
im_detect: 700/4952 0.144s 0.001s
im_detect: 701/4952 0.144s 0.001s
im_detect: 702/4952 0.144s 0.001s
im_detect: 703/4952 0.144s 0.001s
im_detect: 704/4952 0.144s 0.001s
im_detect: 705/4952 0.144s 0.001s
im_detect: 706/4952 0.144s 0.001s
im_detect: 707/4952 0.144s 0.001s
im_detect: 708/4952 0.144s 0.001s
im_detect: 709/4952 0.144s 0.001s
im_detect: 710/4952 0.144s 0.001s
im_detect: 711/4952 0.144s 0.001s
im_detect: 712/4952 0.144s 0.001s
im_detect: 713/4952 0.144s 0.001s
im_detect: 714/4952 0.144s 0.001s
im_detect: 715/4952 0.144s 0.001s
im_detect: 716/4952 0.144s 0.001s
im_detect: 717/4952 0.144s 0.001s
im_detect: 718/4952 0.144s 0.001s
im_detect: 719/4952 0.144s 0.001s
im_detect: 720/4952 0.144s 0.001s
im_detect: 721/4952 0.144s 0.001s
im_detect: 722/4952 0.144s 0.001s
im_detect: 723/4952 0.144s 0.001s
im_detect: 724/4952 0.144s 0.001s
im_detect: 725/4952 0.144s 0.001s
im_detect: 726/4952 0.144s 0.001s
im_detect: 727/4952 0.144s 0.001s
im_detect: 728/4952 0.144s 0.001s
im_detect: 729/4952 0.144s 0.001s
im_detect: 730/4952 0.144s 0.001s
im_detect: 731/4952 0.144s 0.001s
im_detect: 732/4952 0.144s 0.001s
im_detect: 733/4952 0.144s 0.001s
im_detect: 734/4952 0.144s 0.001s
im_detect: 735/4952 0.144s 0.001s
im_detect: 736/4952 0.144s 0.001s
im_detect: 737/4952 0.144s 0.001s
im_detect: 738/4952 0.144s 0.001s
im_detect: 739/4952 0.144s 0.001s
im_detect: 740/4952 0.144s 0.001s
im_detect: 741/4952 0.144s 0.001s
im_detect: 742/4952 0.144s 0.001s
im_detect: 743/4952 0.144s 0.001s
im_detect: 744/4952 0.144s 0.001s
im_detect: 745/4952 0.144s 0.001s
im_detect: 746/4952 0.144s 0.001s
im_detect: 747/4952 0.144s 0.001s
im_detect: 748/4952 0.144s 0.001s
im_detect: 749/4952 0.144s 0.001s
im_detect: 750/4952 0.144s 0.001s
im_detect: 751/4952 0.144s 0.001s
im_detect: 752/4952 0.144s 0.001s
im_detect: 753/4952 0.144s 0.001s
im_detect: 754/4952 0.144s 0.001s
im_detect: 755/4952 0.144s 0.001s
im_detect: 756/4952 0.144s 0.001s
im_detect: 757/4952 0.144s 0.001s
im_detect: 758/4952 0.144s 0.001s
im_detect: 759/4952 0.144s 0.001s
im_detect: 760/4952 0.144s 0.001s
im_detect: 761/4952 0.144s 0.001s
im_detect: 762/4952 0.144s 0.001s
im_detect: 763/4952 0.144s 0.001s
im_detect: 764/4952 0.144s 0.001s
im_detect: 765/4952 0.144s 0.001s
im_detect: 766/4952 0.144s 0.001s
im_detect: 767/4952 0.144s 0.001s
im_detect: 768/4952 0.144s 0.001s
im_detect: 769/4952 0.144s 0.001s
im_detect: 770/4952 0.144s 0.001s
im_detect: 771/4952 0.144s 0.001s
im_detect: 772/4952 0.144s 0.001s
im_detect: 773/4952 0.144s 0.001s
im_detect: 774/4952 0.144s 0.001s
im_detect: 775/4952 0.144s 0.001s
im_detect: 776/4952 0.144s 0.001s
im_detect: 777/4952 0.144s 0.001s
im_detect: 778/4952 0.144s 0.001s
im_detect: 779/4952 0.144s 0.001s
im_detect: 780/4952 0.144s 0.001s
im_detect: 781/4952 0.144s 0.001s
im_detect: 782/4952 0.144s 0.001s
im_detect: 783/4952 0.144s 0.001s
im_detect: 784/4952 0.144s 0.001s
im_detect: 785/4952 0.144s 0.001s
im_detect: 786/4952 0.144s 0.001s
im_detect: 787/4952 0.144s 0.001s
im_detect: 788/4952 0.144s 0.001s
im_detect: 789/4952 0.144s 0.001s
im_detect: 790/4952 0.144s 0.001s
im_detect: 791/4952 0.144s 0.001s
im_detect: 792/4952 0.144s 0.001s
im_detect: 793/4952 0.144s 0.001s
im_detect: 794/4952 0.144s 0.001s
im_detect: 795/4952 0.144s 0.001s
im_detect: 796/4952 0.144s 0.001s
im_detect: 797/4952 0.144s 0.001s
im_detect: 798/4952 0.144s 0.001s
im_detect: 799/4952 0.144s 0.001s
im_detect: 800/4952 0.144s 0.001s
im_detect: 801/4952 0.144s 0.001s
im_detect: 802/4952 0.144s 0.001s
im_detect: 803/4952 0.144s 0.001s
im_detect: 804/4952 0.144s 0.001s
im_detect: 805/4952 0.144s 0.001s
im_detect: 806/4952 0.144s 0.001s
im_detect: 807/4952 0.144s 0.001s
im_detect: 808/4952 0.144s 0.001s
im_detect: 809/4952 0.144s 0.001s
im_detect: 810/4952 0.144s 0.001s
im_detect: 811/4952 0.144s 0.001s
im_detect: 812/4952 0.144s 0.001s
im_detect: 813/4952 0.144s 0.001s
im_detect: 814/4952 0.144s 0.001s
im_detect: 815/4952 0.144s 0.001s
im_detect: 816/4952 0.144s 0.001s
im_detect: 817/4952 0.144s 0.001s
im_detect: 818/4952 0.145s 0.001s
im_detect: 819/4952 0.145s 0.001s
im_detect: 820/4952 0.145s 0.001s
im_detect: 821/4952 0.145s 0.001s
im_detect: 822/4952 0.145s 0.001s
im_detect: 823/4952 0.145s 0.001s
im_detect: 824/4952 0.145s 0.001s
im_detect: 825/4952 0.145s 0.001s
im_detect: 826/4952 0.145s 0.001s
im_detect: 827/4952 0.145s 0.001s
im_detect: 828/4952 0.145s 0.001s
im_detect: 829/4952 0.145s 0.001s
im_detect: 830/4952 0.145s 0.001s
im_detect: 831/4952 0.145s 0.001s
im_detect: 832/4952 0.145s 0.001s
im_detect: 833/4952 0.145s 0.001s
im_detect: 834/4952 0.145s 0.001s
im_detect: 835/4952 0.145s 0.001s
im_detect: 836/4952 0.145s 0.001s
im_detect: 837/4952 0.145s 0.001s
im_detect: 838/4952 0.145s 0.001s
im_detect: 839/4952 0.145s 0.001s
im_detect: 840/4952 0.145s 0.001s
im_detect: 841/4952 0.145s 0.001s
im_detect: 842/4952 0.145s 0.001s
im_detect: 843/4952 0.145s 0.001s
im_detect: 844/4952 0.145s 0.001s
im_detect: 845/4952 0.145s 0.001s
im_detect: 846/4952 0.145s 0.001s
im_detect: 847/4952 0.145s 0.001s
im_detect: 848/4952 0.145s 0.001s
im_detect: 849/4952 0.145s 0.001s
im_detect: 850/4952 0.145s 0.001s
im_detect: 851/4952 0.145s 0.001s
im_detect: 852/4952 0.145s 0.001s
im_detect: 853/4952 0.145s 0.001s
im_detect: 854/4952 0.145s 0.001s
im_detect: 855/4952 0.145s 0.001s
im_detect: 856/4952 0.145s 0.001s
im_detect: 857/4952 0.145s 0.001s
im_detect: 858/4952 0.145s 0.001s
im_detect: 859/4952 0.145s 0.001s
im_detect: 860/4952 0.145s 0.001s
im_detect: 861/4952 0.145s 0.001s
im_detect: 862/4952 0.145s 0.001s
im_detect: 863/4952 0.145s 0.001s
im_detect: 864/4952 0.145s 0.001s
im_detect: 865/4952 0.145s 0.001s
im_detect: 866/4952 0.145s 0.001s
im_detect: 867/4952 0.145s 0.001s
im_detect: 868/4952 0.145s 0.001s
im_detect: 869/4952 0.145s 0.001s
im_detect: 870/4952 0.145s 0.001s
im_detect: 871/4952 0.145s 0.001s
im_detect: 872/4952 0.145s 0.001s
im_detect: 873/4952 0.145s 0.001s
im_detect: 874/4952 0.145s 0.001s
im_detect: 875/4952 0.145s 0.001s
im_detect: 876/4952 0.145s 0.001s
im_detect: 877/4952 0.145s 0.001s
im_detect: 878/4952 0.145s 0.001s
im_detect: 879/4952 0.145s 0.001s
im_detect: 880/4952 0.145s 0.001s
im_detect: 881/4952 0.145s 0.001s
im_detect: 882/4952 0.145s 0.001s
im_detect: 883/4952 0.145s 0.001s
im_detect: 884/4952 0.145s 0.001s
im_detect: 885/4952 0.145s 0.001s
im_detect: 886/4952 0.145s 0.001s
im_detect: 887/4952 0.145s 0.001s
im_detect: 888/4952 0.145s 0.001s
im_detect: 889/4952 0.145s 0.001s
im_detect: 890/4952 0.145s 0.001s
im_detect: 891/4952 0.145s 0.001s
im_detect: 892/4952 0.145s 0.001s
im_detect: 893/4952 0.145s 0.001s
im_detect: 894/4952 0.145s 0.001s
im_detect: 895/4952 0.145s 0.001s
im_detect: 896/4952 0.145s 0.001s
im_detect: 897/4952 0.145s 0.001s
im_detect: 898/4952 0.145s 0.001s
im_detect: 899/4952 0.145s 0.001s
im_detect: 900/4952 0.145s 0.001s
im_detect: 901/4952 0.145s 0.001s
im_detect: 902/4952 0.145s 0.001s
im_detect: 903/4952 0.145s 0.001s
im_detect: 904/4952 0.145s 0.001s
im_detect: 905/4952 0.145s 0.001s
im_detect: 906/4952 0.145s 0.001s
im_detect: 907/4952 0.145s 0.001s
im_detect: 908/4952 0.145s 0.001s
im_detect: 909/4952 0.145s 0.001s
im_detect: 910/4952 0.145s 0.001s
im_detect: 911/4952 0.145s 0.001s
im_detect: 912/4952 0.145s 0.001s
im_detect: 913/4952 0.145s 0.001s
im_detect: 914/4952 0.145s 0.001s
im_detect: 915/4952 0.145s 0.001s
im_detect: 916/4952 0.145s 0.001s
im_detect: 917/4952 0.145s 0.001s
im_detect: 918/4952 0.145s 0.001s
im_detect: 919/4952 0.145s 0.001s
im_detect: 920/4952 0.145s 0.001s
im_detect: 921/4952 0.145s 0.001s
im_detect: 922/4952 0.145s 0.001s
im_detect: 923/4952 0.145s 0.001s
im_detect: 924/4952 0.145s 0.001s
im_detect: 925/4952 0.145s 0.001s
im_detect: 926/4952 0.145s 0.001s
im_detect: 927/4952 0.145s 0.001s
im_detect: 928/4952 0.145s 0.001s
im_detect: 929/4952 0.145s 0.001s
im_detect: 930/4952 0.145s 0.001s
im_detect: 931/4952 0.145s 0.001s
im_detect: 932/4952 0.145s 0.001s
im_detect: 933/4952 0.145s 0.001s
im_detect: 934/4952 0.145s 0.001s
im_detect: 935/4952 0.145s 0.001s
im_detect: 936/4952 0.145s 0.001s
im_detect: 937/4952 0.145s 0.001s
im_detect: 938/4952 0.145s 0.001s
im_detect: 939/4952 0.145s 0.001s
im_detect: 940/4952 0.145s 0.001s
im_detect: 941/4952 0.145s 0.001s
im_detect: 942/4952 0.145s 0.001s
im_detect: 943/4952 0.145s 0.001s
im_detect: 944/4952 0.145s 0.001s
im_detect: 945/4952 0.145s 0.001s
im_detect: 946/4952 0.145s 0.001s
im_detect: 947/4952 0.145s 0.001s
im_detect: 948/4952 0.145s 0.001s
im_detect: 949/4952 0.145s 0.001s
im_detect: 950/4952 0.145s 0.001s
im_detect: 951/4952 0.145s 0.001s
im_detect: 952/4952 0.145s 0.001s
im_detect: 953/4952 0.145s 0.001s
im_detect: 954/4952 0.145s 0.001s
im_detect: 955/4952 0.145s 0.001s
im_detect: 956/4952 0.145s 0.001s
im_detect: 957/4952 0.145s 0.001s
im_detect: 958/4952 0.145s 0.001s
im_detect: 959/4952 0.145s 0.001s
im_detect: 960/4952 0.145s 0.001s
im_detect: 961/4952 0.145s 0.001s
im_detect: 962/4952 0.145s 0.001s
im_detect: 963/4952 0.145s 0.001s
im_detect: 964/4952 0.145s 0.001s
im_detect: 965/4952 0.145s 0.001s
im_detect: 966/4952 0.145s 0.001s
im_detect: 967/4952 0.145s 0.001s
im_detect: 968/4952 0.145s 0.001s
im_detect: 969/4952 0.145s 0.001s
im_detect: 970/4952 0.145s 0.001s
im_detect: 971/4952 0.145s 0.001s
im_detect: 972/4952 0.145s 0.001s
im_detect: 973/4952 0.145s 0.001s
im_detect: 974/4952 0.145s 0.001s
im_detect: 975/4952 0.145s 0.001s
im_detect: 976/4952 0.145s 0.001s
im_detect: 977/4952 0.145s 0.001s
im_detect: 978/4952 0.145s 0.001s
im_detect: 979/4952 0.145s 0.001s
im_detect: 980/4952 0.145s 0.001s
im_detect: 981/4952 0.145s 0.001s
im_detect: 982/4952 0.145s 0.001s
im_detect: 983/4952 0.145s 0.001s
im_detect: 984/4952 0.145s 0.001s
im_detect: 985/4952 0.145s 0.001s
im_detect: 986/4952 0.145s 0.001s
im_detect: 987/4952 0.145s 0.001s
im_detect: 988/4952 0.145s 0.001s
im_detect: 989/4952 0.145s 0.001s
im_detect: 990/4952 0.145s 0.001s
im_detect: 991/4952 0.145s 0.001s
im_detect: 992/4952 0.145s 0.001s
im_detect: 993/4952 0.145s 0.001s
im_detect: 994/4952 0.145s 0.001s
im_detect: 995/4952 0.145s 0.001s
im_detect: 996/4952 0.145s 0.001s
im_detect: 997/4952 0.145s 0.001s
im_detect: 998/4952 0.145s 0.001s
im_detect: 999/4952 0.145s 0.001s
im_detect: 1000/4952 0.145s 0.001s
im_detect: 1001/4952 0.145s 0.001s
im_detect: 1002/4952 0.145s 0.001s
im_detect: 1003/4952 0.145s 0.001s
im_detect: 1004/4952 0.145s 0.001s
im_detect: 1005/4952 0.145s 0.001s
im_detect: 1006/4952 0.145s 0.001s
im_detect: 1007/4952 0.145s 0.001s
im_detect: 1008/4952 0.145s 0.001s
im_detect: 1009/4952 0.145s 0.001s
im_detect: 1010/4952 0.145s 0.001s
im_detect: 1011/4952 0.146s 0.001s
im_detect: 1012/4952 0.145s 0.001s
im_detect: 1013/4952 0.145s 0.001s
im_detect: 1014/4952 0.145s 0.001s
im_detect: 1015/4952 0.146s 0.001s
im_detect: 1016/4952 0.145s 0.001s
im_detect: 1017/4952 0.145s 0.001s
im_detect: 1018/4952 0.146s 0.001s
im_detect: 1019/4952 0.146s 0.001s
im_detect: 1020/4952 0.146s 0.001s
im_detect: 1021/4952 0.146s 0.001s
im_detect: 1022/4952 0.145s 0.001s
im_detect: 1023/4952 0.145s 0.001s
im_detect: 1024/4952 0.145s 0.001s
im_detect: 1025/4952 0.145s 0.001s
im_detect: 1026/4952 0.145s 0.001s
im_detect: 1027/4952 0.145s 0.001s
im_detect: 1028/4952 0.146s 0.001s
im_detect: 1029/4952 0.145s 0.001s
im_detect: 1030/4952 0.145s 0.001s
im_detect: 1031/4952 0.145s 0.001s
im_detect: 1032/4952 0.145s 0.001s
im_detect: 1033/4952 0.146s 0.001s
im_detect: 1034/4952 0.146s 0.001s
im_detect: 1035/4952 0.146s 0.001s
im_detect: 1036/4952 0.146s 0.001s
im_detect: 1037/4952 0.146s 0.001s
im_detect: 1038/4952 0.146s 0.001s
im_detect: 1039/4952 0.146s 0.001s
im_detect: 1040/4952 0.146s 0.001s
im_detect: 1041/4952 0.146s 0.001s
im_detect: 1042/4952 0.146s 0.001s
im_detect: 1043/4952 0.146s 0.001s
im_detect: 1044/4952 0.146s 0.001s
im_detect: 1045/4952 0.146s 0.001s
im_detect: 1046/4952 0.146s 0.001s
im_detect: 1047/4952 0.146s 0.001s
im_detect: 1048/4952 0.146s 0.001s
im_detect: 1049/4952 0.146s 0.001s
im_detect: 1050/4952 0.146s 0.001s
im_detect: 1051/4952 0.146s 0.001s
im_detect: 1052/4952 0.146s 0.001s
im_detect: 1053/4952 0.146s 0.001s
im_detect: 1054/4952 0.146s 0.001s
im_detect: 1055/4952 0.146s 0.001s
im_detect: 1056/4952 0.146s 0.001s
im_detect: 1057/4952 0.146s 0.001s
im_detect: 1058/4952 0.146s 0.001s
im_detect: 1059/4952 0.146s 0.001s
im_detect: 1060/4952 0.146s 0.001s
im_detect: 1061/4952 0.146s 0.001s
im_detect: 1062/4952 0.146s 0.001s
im_detect: 1063/4952 0.146s 0.001s
im_detect: 1064/4952 0.146s 0.001s
im_detect: 1065/4952 0.146s 0.001s
im_detect: 1066/4952 0.146s 0.001s
im_detect: 1067/4952 0.146s 0.001s
im_detect: 1068/4952 0.146s 0.001s
im_detect: 1069/4952 0.146s 0.001s
im_detect: 1070/4952 0.146s 0.001s
im_detect: 1071/4952 0.146s 0.001s
im_detect: 1072/4952 0.146s 0.001s
im_detect: 1073/4952 0.146s 0.001s
im_detect: 1074/4952 0.146s 0.001s
im_detect: 1075/4952 0.146s 0.001s
im_detect: 1076/4952 0.146s 0.001s
im_detect: 1077/4952 0.146s 0.001s
im_detect: 1078/4952 0.146s 0.001s
im_detect: 1079/4952 0.146s 0.001s
im_detect: 1080/4952 0.146s 0.001s
im_detect: 1081/4952 0.146s 0.001s
im_detect: 1082/4952 0.146s 0.001s
im_detect: 1083/4952 0.146s 0.001s
im_detect: 1084/4952 0.146s 0.001s
im_detect: 1085/4952 0.146s 0.001s
im_detect: 1086/4952 0.146s 0.001s
im_detect: 1087/4952 0.146s 0.001s
im_detect: 1088/4952 0.146s 0.001s
im_detect: 1089/4952 0.146s 0.001s
im_detect: 1090/4952 0.146s 0.001s
im_detect: 1091/4952 0.146s 0.001s
im_detect: 1092/4952 0.146s 0.001s
im_detect: 1093/4952 0.146s 0.001s
im_detect: 1094/4952 0.146s 0.001s
im_detect: 1095/4952 0.146s 0.001s
im_detect: 1096/4952 0.146s 0.001s
im_detect: 1097/4952 0.146s 0.001s
im_detect: 1098/4952 0.146s 0.001s
im_detect: 1099/4952 0.146s 0.001s
im_detect: 1100/4952 0.146s 0.001s
im_detect: 1101/4952 0.146s 0.001s
im_detect: 1102/4952 0.146s 0.001s
im_detect: 1103/4952 0.146s 0.001s
im_detect: 1104/4952 0.146s 0.001s
im_detect: 1105/4952 0.146s 0.001s
im_detect: 1106/4952 0.146s 0.001s
im_detect: 1107/4952 0.146s 0.001s
im_detect: 1108/4952 0.146s 0.001s
im_detect: 1109/4952 0.146s 0.001s
im_detect: 1110/4952 0.146s 0.001s
im_detect: 1111/4952 0.146s 0.001s
im_detect: 1112/4952 0.146s 0.001s
im_detect: 1113/4952 0.146s 0.001s
im_detect: 1114/4952 0.146s 0.001s
im_detect: 1115/4952 0.146s 0.001s
im_detect: 1116/4952 0.146s 0.001s
im_detect: 1117/4952 0.146s 0.001s
im_detect: 1118/4952 0.146s 0.001s
im_detect: 1119/4952 0.146s 0.001s
im_detect: 1120/4952 0.146s 0.001s
im_detect: 1121/4952 0.146s 0.001s
im_detect: 1122/4952 0.146s 0.001s
im_detect: 1123/4952 0.146s 0.001s
im_detect: 1124/4952 0.146s 0.001s
im_detect: 1125/4952 0.146s 0.001s
im_detect: 1126/4952 0.146s 0.001s
im_detect: 1127/4952 0.146s 0.001s
im_detect: 1128/4952 0.146s 0.001s
im_detect: 1129/4952 0.146s 0.001s
im_detect: 1130/4952 0.146s 0.001s
im_detect: 1131/4952 0.146s 0.001s
im_detect: 1132/4952 0.146s 0.001s
im_detect: 1133/4952 0.146s 0.001s
im_detect: 1134/4952 0.146s 0.001s
im_detect: 1135/4952 0.146s 0.001s
im_detect: 1136/4952 0.146s 0.001s
im_detect: 1137/4952 0.146s 0.001s
im_detect: 1138/4952 0.146s 0.001s
im_detect: 1139/4952 0.146s 0.001s
im_detect: 1140/4952 0.146s 0.001s
im_detect: 1141/4952 0.146s 0.001s
im_detect: 1142/4952 0.146s 0.001s
im_detect: 1143/4952 0.146s 0.001s
im_detect: 1144/4952 0.146s 0.001s
im_detect: 1145/4952 0.146s 0.001s
im_detect: 1146/4952 0.146s 0.001s
im_detect: 1147/4952 0.146s 0.001s
im_detect: 1148/4952 0.146s 0.001s
im_detect: 1149/4952 0.146s 0.001s
im_detect: 1150/4952 0.146s 0.001s
im_detect: 1151/4952 0.146s 0.001s
im_detect: 1152/4952 0.146s 0.001s
im_detect: 1153/4952 0.146s 0.001s
im_detect: 1154/4952 0.146s 0.001s
im_detect: 1155/4952 0.146s 0.001s
im_detect: 1156/4952 0.146s 0.001s
im_detect: 1157/4952 0.146s 0.001s
im_detect: 1158/4952 0.146s 0.001s
im_detect: 1159/4952 0.146s 0.001s
im_detect: 1160/4952 0.146s 0.001s
im_detect: 1161/4952 0.146s 0.001s
im_detect: 1162/4952 0.146s 0.001s
im_detect: 1163/4952 0.146s 0.001s
im_detect: 1164/4952 0.146s 0.001s
im_detect: 1165/4952 0.146s 0.001s
im_detect: 1166/4952 0.146s 0.001s
im_detect: 1167/4952 0.146s 0.001s
im_detect: 1168/4952 0.146s 0.001s
im_detect: 1169/4952 0.146s 0.001s
im_detect: 1170/4952 0.146s 0.001s
im_detect: 1171/4952 0.146s 0.001s
im_detect: 1172/4952 0.146s 0.001s
im_detect: 1173/4952 0.146s 0.001s
im_detect: 1174/4952 0.146s 0.001s
im_detect: 1175/4952 0.146s 0.001s
im_detect: 1176/4952 0.146s 0.001s
im_detect: 1177/4952 0.146s 0.001s
im_detect: 1178/4952 0.146s 0.001s
im_detect: 1179/4952 0.146s 0.001s
im_detect: 1180/4952 0.146s 0.001s
im_detect: 1181/4952 0.146s 0.001s
im_detect: 1182/4952 0.146s 0.001s
im_detect: 1183/4952 0.146s 0.001s
im_detect: 1184/4952 0.146s 0.001s
im_detect: 1185/4952 0.146s 0.001s
im_detect: 1186/4952 0.146s 0.001s
im_detect: 1187/4952 0.146s 0.001s
im_detect: 1188/4952 0.146s 0.001s
im_detect: 1189/4952 0.146s 0.001s
im_detect: 1190/4952 0.146s 0.001s
im_detect: 1191/4952 0.146s 0.001s
im_detect: 1192/4952 0.146s 0.001s
im_detect: 1193/4952 0.146s 0.001s
im_detect: 1194/4952 0.146s 0.001s
im_detect: 1195/4952 0.146s 0.001s
im_detect: 1196/4952 0.146s 0.001s
im_detect: 1197/4952 0.146s 0.001s
im_detect: 1198/4952 0.146s 0.001s
im_detect: 1199/4952 0.146s 0.001s
im_detect: 1200/4952 0.146s 0.001s
im_detect: 1201/4952 0.146s 0.001s
im_detect: 1202/4952 0.146s 0.001s
im_detect: 1203/4952 0.146s 0.001s
im_detect: 1204/4952 0.146s 0.001s
im_detect: 1205/4952 0.146s 0.001s
im_detect: 1206/4952 0.146s 0.001s
im_detect: 1207/4952 0.146s 0.001s
im_detect: 1208/4952 0.146s 0.001s
im_detect: 1209/4952 0.146s 0.001s
im_detect: 1210/4952 0.146s 0.001s
im_detect: 1211/4952 0.146s 0.001s
im_detect: 1212/4952 0.146s 0.001s
im_detect: 1213/4952 0.146s 0.001s
im_detect: 1214/4952 0.146s 0.001s
im_detect: 1215/4952 0.146s 0.001s
im_detect: 1216/4952 0.146s 0.001s
im_detect: 1217/4952 0.146s 0.001s
im_detect: 1218/4952 0.146s 0.001s
im_detect: 1219/4952 0.146s 0.001s
im_detect: 1220/4952 0.146s 0.001s
im_detect: 1221/4952 0.146s 0.001s
im_detect: 1222/4952 0.146s 0.001s
im_detect: 1223/4952 0.146s 0.001s
im_detect: 1224/4952 0.146s 0.001s
im_detect: 1225/4952 0.146s 0.001s
im_detect: 1226/4952 0.146s 0.001s
im_detect: 1227/4952 0.146s 0.001s
im_detect: 1228/4952 0.146s 0.001s
im_detect: 1229/4952 0.146s 0.001s
im_detect: 1230/4952 0.146s 0.001s
im_detect: 1231/4952 0.146s 0.001s
im_detect: 1232/4952 0.146s 0.001s
im_detect: 1233/4952 0.146s 0.001s
im_detect: 1234/4952 0.146s 0.001s
im_detect: 1235/4952 0.146s 0.001s
im_detect: 1236/4952 0.146s 0.001s
im_detect: 1237/4952 0.146s 0.001s
im_detect: 1238/4952 0.146s 0.001s
im_detect: 1239/4952 0.146s 0.001s
im_detect: 1240/4952 0.146s 0.001s
im_detect: 1241/4952 0.146s 0.001s
im_detect: 1242/4952 0.146s 0.001s
im_detect: 1243/4952 0.146s 0.001s
im_detect: 1244/4952 0.146s 0.001s
im_detect: 1245/4952 0.146s 0.001s
im_detect: 1246/4952 0.146s 0.001s
im_detect: 1247/4952 0.146s 0.001s
im_detect: 1248/4952 0.146s 0.001s
im_detect: 1249/4952 0.146s 0.001s
im_detect: 1250/4952 0.146s 0.001s
im_detect: 1251/4952 0.146s 0.001s
im_detect: 1252/4952 0.146s 0.001s
im_detect: 1253/4952 0.146s 0.001s
im_detect: 1254/4952 0.146s 0.001s
im_detect: 1255/4952 0.146s 0.001s
im_detect: 1256/4952 0.146s 0.001s
im_detect: 1257/4952 0.146s 0.001s
im_detect: 1258/4952 0.146s 0.001s
im_detect: 1259/4952 0.146s 0.001s
im_detect: 1260/4952 0.146s 0.001s
im_detect: 1261/4952 0.146s 0.001s
im_detect: 1262/4952 0.146s 0.001s
im_detect: 1263/4952 0.146s 0.001s
im_detect: 1264/4952 0.146s 0.001s
im_detect: 1265/4952 0.146s 0.001s
im_detect: 1266/4952 0.146s 0.001s
im_detect: 1267/4952 0.146s 0.001s
im_detect: 1268/4952 0.146s 0.001s
im_detect: 1269/4952 0.146s 0.001s
im_detect: 1270/4952 0.146s 0.001s
im_detect: 1271/4952 0.146s 0.001s
im_detect: 1272/4952 0.146s 0.001s
im_detect: 1273/4952 0.146s 0.001s
im_detect: 1274/4952 0.146s 0.001s
im_detect: 1275/4952 0.146s 0.001s
im_detect: 1276/4952 0.146s 0.001s
im_detect: 1277/4952 0.146s 0.001s
im_detect: 1278/4952 0.146s 0.001s
im_detect: 1279/4952 0.146s 0.001s
im_detect: 1280/4952 0.146s 0.001s
im_detect: 1281/4952 0.146s 0.001s
im_detect: 1282/4952 0.146s 0.001s
im_detect: 1283/4952 0.146s 0.001s
im_detect: 1284/4952 0.146s 0.001s
im_detect: 1285/4952 0.146s 0.001s
im_detect: 1286/4952 0.146s 0.001s
im_detect: 1287/4952 0.146s 0.001s
im_detect: 1288/4952 0.146s 0.001s
im_detect: 1289/4952 0.146s 0.001s
im_detect: 1290/4952 0.146s 0.001s
im_detect: 1291/4952 0.146s 0.001s
im_detect: 1292/4952 0.146s 0.001s
im_detect: 1293/4952 0.146s 0.001s
im_detect: 1294/4952 0.146s 0.001s
im_detect: 1295/4952 0.146s 0.001s
im_detect: 1296/4952 0.146s 0.001s
im_detect: 1297/4952 0.146s 0.001s
im_detect: 1298/4952 0.146s 0.001s
im_detect: 1299/4952 0.146s 0.001s
im_detect: 1300/4952 0.146s 0.001s
im_detect: 1301/4952 0.146s 0.001s
im_detect: 1302/4952 0.146s 0.001s
im_detect: 1303/4952 0.146s 0.001s
im_detect: 1304/4952 0.146s 0.001s
im_detect: 1305/4952 0.146s 0.001s
im_detect: 1306/4952 0.147s 0.001s
im_detect: 1307/4952 0.147s 0.001s
im_detect: 1308/4952 0.147s 0.001s
im_detect: 1309/4952 0.147s 0.001s
im_detect: 1310/4952 0.147s 0.001s
im_detect: 1311/4952 0.147s 0.001s
im_detect: 1312/4952 0.147s 0.001s
im_detect: 1313/4952 0.147s 0.001s
im_detect: 1314/4952 0.147s 0.001s
im_detect: 1315/4952 0.147s 0.001s
im_detect: 1316/4952 0.147s 0.001s
im_detect: 1317/4952 0.147s 0.001s
im_detect: 1318/4952 0.147s 0.001s
im_detect: 1319/4952 0.147s 0.001s
im_detect: 1320/4952 0.147s 0.001s
im_detect: 1321/4952 0.147s 0.001s
im_detect: 1322/4952 0.147s 0.001s
im_detect: 1323/4952 0.147s 0.001s
im_detect: 1324/4952 0.147s 0.001s
im_detect: 1325/4952 0.147s 0.001s
im_detect: 1326/4952 0.147s 0.001s
im_detect: 1327/4952 0.147s 0.001s
im_detect: 1328/4952 0.147s 0.001s
im_detect: 1329/4952 0.147s 0.001s
im_detect: 1330/4952 0.147s 0.001s
im_detect: 1331/4952 0.147s 0.001s
im_detect: 1332/4952 0.147s 0.001s
im_detect: 1333/4952 0.147s 0.001s
im_detect: 1334/4952 0.147s 0.001s
im_detect: 1335/4952 0.147s 0.001s
im_detect: 1336/4952 0.147s 0.001s
im_detect: 1337/4952 0.147s 0.001s
im_detect: 1338/4952 0.147s 0.001s
im_detect: 1339/4952 0.147s 0.001s
im_detect: 1340/4952 0.147s 0.001s
im_detect: 1341/4952 0.147s 0.001s
im_detect: 1342/4952 0.147s 0.001s
im_detect: 1343/4952 0.147s 0.001s
im_detect: 1344/4952 0.147s 0.001s
im_detect: 1345/4952 0.147s 0.001s
im_detect: 1346/4952 0.147s 0.001s
im_detect: 1347/4952 0.147s 0.001s
im_detect: 1348/4952 0.147s 0.001s
im_detect: 1349/4952 0.147s 0.001s
im_detect: 1350/4952 0.147s 0.001s
im_detect: 1351/4952 0.147s 0.001s
im_detect: 1352/4952 0.147s 0.001s
im_detect: 1353/4952 0.147s 0.001s
im_detect: 1354/4952 0.147s 0.001s
im_detect: 1355/4952 0.147s 0.001s
im_detect: 1356/4952 0.147s 0.001s
im_detect: 1357/4952 0.147s 0.001s
im_detect: 1358/4952 0.147s 0.001s
im_detect: 1359/4952 0.147s 0.001s
im_detect: 1360/4952 0.147s 0.001s
im_detect: 1361/4952 0.147s 0.001s
im_detect: 1362/4952 0.147s 0.001s
im_detect: 1363/4952 0.147s 0.001s
im_detect: 1364/4952 0.147s 0.001s
im_detect: 1365/4952 0.147s 0.001s
im_detect: 1366/4952 0.147s 0.001s
im_detect: 1367/4952 0.147s 0.001s
im_detect: 1368/4952 0.147s 0.001s
im_detect: 1369/4952 0.147s 0.001s
im_detect: 1370/4952 0.147s 0.001s
im_detect: 1371/4952 0.147s 0.001s
im_detect: 1372/4952 0.147s 0.001s
im_detect: 1373/4952 0.147s 0.001s
im_detect: 1374/4952 0.147s 0.001s
im_detect: 1375/4952 0.147s 0.001s
im_detect: 1376/4952 0.147s 0.001s
im_detect: 1377/4952 0.147s 0.001s
im_detect: 1378/4952 0.147s 0.001s
im_detect: 1379/4952 0.147s 0.001s
im_detect: 1380/4952 0.147s 0.001s
im_detect: 1381/4952 0.147s 0.001s
im_detect: 1382/4952 0.147s 0.001s
im_detect: 1383/4952 0.147s 0.001s
im_detect: 1384/4952 0.147s 0.001s
im_detect: 1385/4952 0.147s 0.001s
im_detect: 1386/4952 0.147s 0.001s
im_detect: 1387/4952 0.147s 0.001s
im_detect: 1388/4952 0.147s 0.001s
im_detect: 1389/4952 0.147s 0.001s
im_detect: 1390/4952 0.147s 0.001s
im_detect: 1391/4952 0.147s 0.001s
im_detect: 1392/4952 0.147s 0.001s
im_detect: 1393/4952 0.147s 0.001s
im_detect: 1394/4952 0.147s 0.001s
im_detect: 1395/4952 0.147s 0.001s
im_detect: 1396/4952 0.147s 0.001s
im_detect: 1397/4952 0.147s 0.001s
im_detect: 1398/4952 0.147s 0.001s
im_detect: 1399/4952 0.147s 0.001s
im_detect: 1400/4952 0.147s 0.001s
im_detect: 1401/4952 0.147s 0.001s
im_detect: 1402/4952 0.147s 0.001s
im_detect: 1403/4952 0.147s 0.001s
im_detect: 1404/4952 0.147s 0.001s
im_detect: 1405/4952 0.147s 0.001s
im_detect: 1406/4952 0.147s 0.001s
im_detect: 1407/4952 0.147s 0.001s
im_detect: 1408/4952 0.147s 0.001s
im_detect: 1409/4952 0.147s 0.001s
im_detect: 1410/4952 0.147s 0.001s
im_detect: 1411/4952 0.147s 0.001s
im_detect: 1412/4952 0.147s 0.001s
im_detect: 1413/4952 0.147s 0.001s
im_detect: 1414/4952 0.147s 0.001s
im_detect: 1415/4952 0.147s 0.001s
im_detect: 1416/4952 0.147s 0.001s
im_detect: 1417/4952 0.147s 0.001s
im_detect: 1418/4952 0.147s 0.001s
im_detect: 1419/4952 0.147s 0.001s
im_detect: 1420/4952 0.147s 0.001s
im_detect: 1421/4952 0.147s 0.001s
im_detect: 1422/4952 0.147s 0.001s
im_detect: 1423/4952 0.147s 0.001s
im_detect: 1424/4952 0.147s 0.001s
im_detect: 1425/4952 0.147s 0.001s
im_detect: 1426/4952 0.147s 0.001s
im_detect: 1427/4952 0.147s 0.001s
im_detect: 1428/4952 0.147s 0.001s
im_detect: 1429/4952 0.147s 0.001s
im_detect: 1430/4952 0.147s 0.001s
im_detect: 1431/4952 0.147s 0.001s
im_detect: 1432/4952 0.147s 0.001s
im_detect: 1433/4952 0.147s 0.001s
im_detect: 1434/4952 0.147s 0.001s
im_detect: 1435/4952 0.147s 0.001s
im_detect: 1436/4952 0.147s 0.001s
im_detect: 1437/4952 0.147s 0.001s
im_detect: 1438/4952 0.147s 0.001s
im_detect: 1439/4952 0.147s 0.001s
im_detect: 1440/4952 0.147s 0.001s
im_detect: 1441/4952 0.147s 0.001s
im_detect: 1442/4952 0.147s 0.001s
im_detect: 1443/4952 0.147s 0.001s
im_detect: 1444/4952 0.147s 0.001s
im_detect: 1445/4952 0.147s 0.001s
im_detect: 1446/4952 0.147s 0.001s
im_detect: 1447/4952 0.147s 0.001s
im_detect: 1448/4952 0.147s 0.001s
im_detect: 1449/4952 0.147s 0.001s
im_detect: 1450/4952 0.147s 0.001s
im_detect: 1451/4952 0.147s 0.001s
im_detect: 1452/4952 0.147s 0.001s
im_detect: 1453/4952 0.147s 0.001s
im_detect: 1454/4952 0.147s 0.001s
im_detect: 1455/4952 0.147s 0.001s
im_detect: 1456/4952 0.147s 0.001s
im_detect: 1457/4952 0.147s 0.001s
im_detect: 1458/4952 0.147s 0.001s
im_detect: 1459/4952 0.147s 0.001s
im_detect: 1460/4952 0.147s 0.001s
im_detect: 1461/4952 0.147s 0.001s
im_detect: 1462/4952 0.147s 0.001s
im_detect: 1463/4952 0.147s 0.001s
im_detect: 1464/4952 0.147s 0.001s
im_detect: 1465/4952 0.147s 0.001s
im_detect: 1466/4952 0.147s 0.001s
im_detect: 1467/4952 0.147s 0.001s
im_detect: 1468/4952 0.147s 0.001s
im_detect: 1469/4952 0.147s 0.001s
im_detect: 1470/4952 0.147s 0.001s
im_detect: 1471/4952 0.147s 0.001s
im_detect: 1472/4952 0.147s 0.001s
im_detect: 1473/4952 0.147s 0.001s
im_detect: 1474/4952 0.147s 0.001s
im_detect: 1475/4952 0.147s 0.001s
im_detect: 1476/4952 0.147s 0.001s
im_detect: 1477/4952 0.147s 0.001s
im_detect: 1478/4952 0.147s 0.001s
im_detect: 1479/4952 0.147s 0.001s
im_detect: 1480/4952 0.147s 0.001s
im_detect: 1481/4952 0.147s 0.001s
im_detect: 1482/4952 0.147s 0.001s
im_detect: 1483/4952 0.147s 0.001s
im_detect: 1484/4952 0.147s 0.001s
im_detect: 1485/4952 0.147s 0.001s
im_detect: 1486/4952 0.147s 0.001s
im_detect: 1487/4952 0.147s 0.001s
im_detect: 1488/4952 0.147s 0.001s
im_detect: 1489/4952 0.147s 0.001s
im_detect: 1490/4952 0.147s 0.001s
im_detect: 1491/4952 0.147s 0.001s
im_detect: 1492/4952 0.147s 0.001s
im_detect: 1493/4952 0.147s 0.001s
im_detect: 1494/4952 0.147s 0.001s
im_detect: 1495/4952 0.147s 0.001s
im_detect: 1496/4952 0.147s 0.001s
im_detect: 1497/4952 0.147s 0.001s
im_detect: 1498/4952 0.147s 0.001s
im_detect: 1499/4952 0.147s 0.001s
im_detect: 1500/4952 0.147s 0.001s
im_detect: 1501/4952 0.147s 0.001s
im_detect: 1502/4952 0.147s 0.001s
im_detect: 1503/4952 0.147s 0.001s
im_detect: 1504/4952 0.147s 0.001s
im_detect: 1505/4952 0.147s 0.001s
im_detect: 1506/4952 0.147s 0.001s
im_detect: 1507/4952 0.147s 0.001s
im_detect: 1508/4952 0.147s 0.001s
im_detect: 1509/4952 0.147s 0.001s
im_detect: 1510/4952 0.147s 0.001s
im_detect: 1511/4952 0.147s 0.001s
im_detect: 1512/4952 0.147s 0.001s
im_detect: 1513/4952 0.147s 0.001s
im_detect: 1514/4952 0.147s 0.001s
im_detect: 1515/4952 0.147s 0.001s
im_detect: 1516/4952 0.147s 0.001s
im_detect: 1517/4952 0.147s 0.001s
im_detect: 1518/4952 0.147s 0.001s
im_detect: 1519/4952 0.147s 0.001s
im_detect: 1520/4952 0.147s 0.001s
im_detect: 1521/4952 0.147s 0.001s
im_detect: 1522/4952 0.147s 0.001s
im_detect: 1523/4952 0.147s 0.001s
im_detect: 1524/4952 0.147s 0.001s
im_detect: 1525/4952 0.147s 0.001s
im_detect: 1526/4952 0.147s 0.001s
im_detect: 1527/4952 0.147s 0.001s
im_detect: 1528/4952 0.147s 0.001s
im_detect: 1529/4952 0.147s 0.001s
im_detect: 1530/4952 0.147s 0.001s
im_detect: 1531/4952 0.147s 0.001s
im_detect: 1532/4952 0.147s 0.001s
im_detect: 1533/4952 0.147s 0.001s
im_detect: 1534/4952 0.147s 0.001s
im_detect: 1535/4952 0.147s 0.001s
im_detect: 1536/4952 0.147s 0.001s
im_detect: 1537/4952 0.147s 0.001s
im_detect: 1538/4952 0.147s 0.001s
im_detect: 1539/4952 0.147s 0.001s
im_detect: 1540/4952 0.147s 0.001s
im_detect: 1541/4952 0.147s 0.001s
im_detect: 1542/4952 0.147s 0.001s
im_detect: 1543/4952 0.147s 0.001s
im_detect: 1544/4952 0.147s 0.001s
im_detect: 1545/4952 0.147s 0.001s
im_detect: 1546/4952 0.147s 0.001s
im_detect: 1547/4952 0.147s 0.001s
im_detect: 1548/4952 0.147s 0.001s
im_detect: 1549/4952 0.147s 0.001s
im_detect: 1550/4952 0.147s 0.001s
im_detect: 1551/4952 0.147s 0.001s
im_detect: 1552/4952 0.147s 0.001s
im_detect: 1553/4952 0.147s 0.001s
im_detect: 1554/4952 0.147s 0.001s
im_detect: 1555/4952 0.147s 0.001s
im_detect: 1556/4952 0.147s 0.001s
im_detect: 1557/4952 0.147s 0.001s
im_detect: 1558/4952 0.147s 0.001s
im_detect: 1559/4952 0.147s 0.001s
im_detect: 1560/4952 0.147s 0.001s
im_detect: 1561/4952 0.147s 0.001s
im_detect: 1562/4952 0.147s 0.001s
im_detect: 1563/4952 0.147s 0.001s
im_detect: 1564/4952 0.147s 0.001s
im_detect: 1565/4952 0.147s 0.001s
im_detect: 1566/4952 0.147s 0.001s
im_detect: 1567/4952 0.147s 0.001s
im_detect: 1568/4952 0.147s 0.001s
im_detect: 1569/4952 0.147s 0.001s
im_detect: 1570/4952 0.147s 0.001s
im_detect: 1571/4952 0.147s 0.001s
im_detect: 1572/4952 0.147s 0.001s
im_detect: 1573/4952 0.147s 0.001s
im_detect: 1574/4952 0.147s 0.001s
im_detect: 1575/4952 0.147s 0.001s
im_detect: 1576/4952 0.147s 0.001s
im_detect: 1577/4952 0.147s 0.001s
im_detect: 1578/4952 0.147s 0.001s
im_detect: 1579/4952 0.147s 0.001s
im_detect: 1580/4952 0.147s 0.001s
im_detect: 1581/4952 0.147s 0.001s
im_detect: 1582/4952 0.147s 0.001s
im_detect: 1583/4952 0.147s 0.001s
im_detect: 1584/4952 0.147s 0.001s
im_detect: 1585/4952 0.147s 0.001s
im_detect: 1586/4952 0.147s 0.001s
im_detect: 1587/4952 0.147s 0.001s
im_detect: 1588/4952 0.147s 0.001s
im_detect: 1589/4952 0.147s 0.001s
im_detect: 1590/4952 0.147s 0.001s
im_detect: 1591/4952 0.147s 0.001s
im_detect: 1592/4952 0.147s 0.001s
im_detect: 1593/4952 0.147s 0.001s
im_detect: 1594/4952 0.147s 0.001s
im_detect: 1595/4952 0.147s 0.001s
im_detect: 1596/4952 0.147s 0.001s
im_detect: 1597/4952 0.147s 0.001s
im_detect: 1598/4952 0.147s 0.001s
im_detect: 1599/4952 0.147s 0.001s
im_detect: 1600/4952 0.147s 0.001s
im_detect: 1601/4952 0.147s 0.001s
im_detect: 1602/4952 0.147s 0.001s
im_detect: 1603/4952 0.147s 0.001s
im_detect: 1604/4952 0.147s 0.001s
im_detect: 1605/4952 0.147s 0.001s
im_detect: 1606/4952 0.147s 0.001s
im_detect: 1607/4952 0.147s 0.001s
im_detect: 1608/4952 0.147s 0.001s
im_detect: 1609/4952 0.148s 0.001s
im_detect: 1610/4952 0.148s 0.001s
im_detect: 1611/4952 0.148s 0.001s
im_detect: 1612/4952 0.148s 0.001s
im_detect: 1613/4952 0.148s 0.001s
im_detect: 1614/4952 0.148s 0.001s
im_detect: 1615/4952 0.148s 0.001s
im_detect: 1616/4952 0.148s 0.001s
im_detect: 1617/4952 0.147s 0.001s
im_detect: 1618/4952 0.147s 0.001s
im_detect: 1619/4952 0.147s 0.001s
im_detect: 1620/4952 0.147s 0.001s
im_detect: 1621/4952 0.147s 0.001s
im_detect: 1622/4952 0.147s 0.001s
im_detect: 1623/4952 0.147s 0.001s
im_detect: 1624/4952 0.147s 0.001s
im_detect: 1625/4952 0.147s 0.001s
im_detect: 1626/4952 0.147s 0.001s
im_detect: 1627/4952 0.147s 0.001s
im_detect: 1628/4952 0.147s 0.001s
im_detect: 1629/4952 0.147s 0.001s
im_detect: 1630/4952 0.147s 0.001s
im_detect: 1631/4952 0.147s 0.001s
im_detect: 1632/4952 0.147s 0.001s
im_detect: 1633/4952 0.147s 0.001s
im_detect: 1634/4952 0.147s 0.001s
im_detect: 1635/4952 0.147s 0.001s
im_detect: 1636/4952 0.147s 0.001s
im_detect: 1637/4952 0.148s 0.001s
im_detect: 1638/4952 0.148s 0.001s
im_detect: 1639/4952 0.148s 0.001s
im_detect: 1640/4952 0.148s 0.001s
im_detect: 1641/4952 0.148s 0.001s
im_detect: 1642/4952 0.148s 0.001s
im_detect: 1643/4952 0.148s 0.001s
im_detect: 1644/4952 0.148s 0.001s
im_detect: 1645/4952 0.148s 0.001s
im_detect: 1646/4952 0.148s 0.001s
im_detect: 1647/4952 0.148s 0.001s
im_detect: 1648/4952 0.148s 0.001s
im_detect: 1649/4952 0.148s 0.001s
im_detect: 1650/4952 0.148s 0.001s
im_detect: 1651/4952 0.148s 0.001s
im_detect: 1652/4952 0.148s 0.001s
im_detect: 1653/4952 0.148s 0.001s
im_detect: 1654/4952 0.148s 0.001s
im_detect: 1655/4952 0.148s 0.001s
im_detect: 1656/4952 0.148s 0.001s
im_detect: 1657/4952 0.148s 0.001s
im_detect: 1658/4952 0.148s 0.001s
im_detect: 1659/4952 0.148s 0.001s
im_detect: 1660/4952 0.148s 0.001s
im_detect: 1661/4952 0.148s 0.001s
im_detect: 1662/4952 0.148s 0.001s
im_detect: 1663/4952 0.148s 0.001s
im_detect: 1664/4952 0.148s 0.001s
im_detect: 1665/4952 0.148s 0.001s
im_detect: 1666/4952 0.148s 0.001s
im_detect: 1667/4952 0.148s 0.001s
im_detect: 1668/4952 0.148s 0.001s
im_detect: 1669/4952 0.148s 0.001s
im_detect: 1670/4952 0.148s 0.001s
im_detect: 1671/4952 0.148s 0.001s
im_detect: 1672/4952 0.148s 0.001s
im_detect: 1673/4952 0.148s 0.001s
im_detect: 1674/4952 0.148s 0.001s
im_detect: 1675/4952 0.148s 0.001s
im_detect: 1676/4952 0.148s 0.001s
im_detect: 1677/4952 0.148s 0.001s
im_detect: 1678/4952 0.148s 0.001s
im_detect: 1679/4952 0.148s 0.001s
im_detect: 1680/4952 0.148s 0.001s
im_detect: 1681/4952 0.148s 0.001s
im_detect: 1682/4952 0.148s 0.001s
im_detect: 1683/4952 0.148s 0.001s
im_detect: 1684/4952 0.148s 0.001s
im_detect: 1685/4952 0.148s 0.001s
im_detect: 1686/4952 0.148s 0.001s
im_detect: 1687/4952 0.148s 0.001s
im_detect: 1688/4952 0.148s 0.001s
im_detect: 1689/4952 0.148s 0.001s
im_detect: 1690/4952 0.148s 0.001s
im_detect: 1691/4952 0.148s 0.001s
im_detect: 1692/4952 0.148s 0.001s
im_detect: 1693/4952 0.148s 0.001s
im_detect: 1694/4952 0.148s 0.001s
im_detect: 1695/4952 0.148s 0.001s
im_detect: 1696/4952 0.148s 0.001s
im_detect: 1697/4952 0.148s 0.001s
im_detect: 1698/4952 0.148s 0.001s
im_detect: 1699/4952 0.148s 0.001s
im_detect: 1700/4952 0.148s 0.001s
im_detect: 1701/4952 0.148s 0.001s
im_detect: 1702/4952 0.148s 0.001s
im_detect: 1703/4952 0.148s 0.001s
im_detect: 1704/4952 0.148s 0.001s
im_detect: 1705/4952 0.148s 0.001s
im_detect: 1706/4952 0.148s 0.001s
im_detect: 1707/4952 0.148s 0.001s
im_detect: 1708/4952 0.148s 0.001s
im_detect: 1709/4952 0.148s 0.001s
im_detect: 1710/4952 0.148s 0.001s
im_detect: 1711/4952 0.148s 0.001s
im_detect: 1712/4952 0.148s 0.001s
im_detect: 1713/4952 0.148s 0.001s
im_detect: 1714/4952 0.148s 0.001s
im_detect: 1715/4952 0.148s 0.001s
im_detect: 1716/4952 0.148s 0.001s
im_detect: 1717/4952 0.148s 0.001s
im_detect: 1718/4952 0.148s 0.001s
im_detect: 1719/4952 0.148s 0.001s
im_detect: 1720/4952 0.148s 0.001s
im_detect: 1721/4952 0.148s 0.001s
im_detect: 1722/4952 0.148s 0.001s
im_detect: 1723/4952 0.148s 0.001s
im_detect: 1724/4952 0.148s 0.001s
im_detect: 1725/4952 0.148s 0.001s
im_detect: 1726/4952 0.148s 0.001s
im_detect: 1727/4952 0.148s 0.001s
im_detect: 1728/4952 0.148s 0.001s
im_detect: 1729/4952 0.148s 0.001s
im_detect: 1730/4952 0.148s 0.001s
im_detect: 1731/4952 0.148s 0.001s
im_detect: 1732/4952 0.148s 0.001s
im_detect: 1733/4952 0.148s 0.001s
im_detect: 1734/4952 0.148s 0.001s
im_detect: 1735/4952 0.148s 0.001s
im_detect: 1736/4952 0.148s 0.001s
im_detect: 1737/4952 0.148s 0.001s
im_detect: 1738/4952 0.148s 0.001s
im_detect: 1739/4952 0.148s 0.001s
im_detect: 1740/4952 0.148s 0.001s
im_detect: 1741/4952 0.148s 0.001s
im_detect: 1742/4952 0.148s 0.001s
im_detect: 1743/4952 0.148s 0.001s
im_detect: 1744/4952 0.148s 0.001s
im_detect: 1745/4952 0.148s 0.001s
im_detect: 1746/4952 0.148s 0.001s
im_detect: 1747/4952 0.148s 0.001s
im_detect: 1748/4952 0.148s 0.001s
im_detect: 1749/4952 0.148s 0.001s
im_detect: 1750/4952 0.148s 0.001s
im_detect: 1751/4952 0.148s 0.001s
im_detect: 1752/4952 0.148s 0.001s
im_detect: 1753/4952 0.148s 0.001s
im_detect: 1754/4952 0.148s 0.001s
im_detect: 1755/4952 0.148s 0.001s
im_detect: 1756/4952 0.148s 0.001s
im_detect: 1757/4952 0.148s 0.001s
im_detect: 1758/4952 0.148s 0.001s
im_detect: 1759/4952 0.148s 0.001s
im_detect: 1760/4952 0.148s 0.001s
im_detect: 1761/4952 0.148s 0.001s
im_detect: 1762/4952 0.148s 0.001s
im_detect: 1763/4952 0.148s 0.001s
im_detect: 1764/4952 0.148s 0.001s
im_detect: 1765/4952 0.148s 0.001s
im_detect: 1766/4952 0.148s 0.001s
im_detect: 1767/4952 0.148s 0.001s
im_detect: 1768/4952 0.148s 0.001s
im_detect: 1769/4952 0.148s 0.001s
im_detect: 1770/4952 0.148s 0.001s
im_detect: 1771/4952 0.148s 0.001s
im_detect: 1772/4952 0.148s 0.001s
im_detect: 1773/4952 0.148s 0.001s
im_detect: 1774/4952 0.148s 0.001s
im_detect: 1775/4952 0.148s 0.001s
im_detect: 1776/4952 0.148s 0.001s
im_detect: 1777/4952 0.148s 0.001s
im_detect: 1778/4952 0.148s 0.001s
im_detect: 1779/4952 0.148s 0.001s
im_detect: 1780/4952 0.148s 0.001s
im_detect: 1781/4952 0.148s 0.001s
im_detect: 1782/4952 0.148s 0.001s
im_detect: 1783/4952 0.148s 0.001s
im_detect: 1784/4952 0.148s 0.001s
im_detect: 1785/4952 0.148s 0.001s
im_detect: 1786/4952 0.148s 0.001s
im_detect: 1787/4952 0.148s 0.001s
im_detect: 1788/4952 0.148s 0.001s
im_detect: 1789/4952 0.148s 0.001s
im_detect: 1790/4952 0.148s 0.001s
im_detect: 1791/4952 0.148s 0.001s
im_detect: 1792/4952 0.148s 0.001s
im_detect: 1793/4952 0.148s 0.001s
im_detect: 1794/4952 0.148s 0.001s
im_detect: 1795/4952 0.148s 0.001s
im_detect: 1796/4952 0.148s 0.001s
im_detect: 1797/4952 0.148s 0.001s
im_detect: 1798/4952 0.148s 0.001s
im_detect: 1799/4952 0.148s 0.001s
im_detect: 1800/4952 0.148s 0.001s
im_detect: 1801/4952 0.148s 0.001s
im_detect: 1802/4952 0.148s 0.001s
im_detect: 1803/4952 0.148s 0.001s
im_detect: 1804/4952 0.148s 0.001s
im_detect: 1805/4952 0.148s 0.001s
im_detect: 1806/4952 0.148s 0.001s
im_detect: 1807/4952 0.148s 0.001s
im_detect: 1808/4952 0.148s 0.001s
im_detect: 1809/4952 0.148s 0.001s
im_detect: 1810/4952 0.148s 0.001s
im_detect: 1811/4952 0.148s 0.001s
im_detect: 1812/4952 0.148s 0.001s
im_detect: 1813/4952 0.148s 0.001s
im_detect: 1814/4952 0.148s 0.001s
im_detect: 1815/4952 0.148s 0.001s
im_detect: 1816/4952 0.148s 0.001s
im_detect: 1817/4952 0.148s 0.001s
im_detect: 1818/4952 0.148s 0.001s
im_detect: 1819/4952 0.148s 0.001s
im_detect: 1820/4952 0.148s 0.001s
im_detect: 1821/4952 0.148s 0.001s
im_detect: 1822/4952 0.148s 0.001s
im_detect: 1823/4952 0.148s 0.001s
im_detect: 1824/4952 0.148s 0.001s
im_detect: 1825/4952 0.148s 0.001s
im_detect: 1826/4952 0.148s 0.001s
im_detect: 1827/4952 0.148s 0.001s
im_detect: 1828/4952 0.148s 0.001s
im_detect: 1829/4952 0.148s 0.001s
im_detect: 1830/4952 0.148s 0.001s
im_detect: 1831/4952 0.148s 0.001s
im_detect: 1832/4952 0.148s 0.001s
im_detect: 1833/4952 0.148s 0.001s
im_detect: 1834/4952 0.148s 0.001s
im_detect: 1835/4952 0.148s 0.001s
im_detect: 1836/4952 0.148s 0.001s
im_detect: 1837/4952 0.148s 0.001s
im_detect: 1838/4952 0.148s 0.001s
im_detect: 1839/4952 0.148s 0.001s
im_detect: 1840/4952 0.148s 0.001s
im_detect: 1841/4952 0.148s 0.001s
im_detect: 1842/4952 0.148s 0.001s
im_detect: 1843/4952 0.148s 0.001s
im_detect: 1844/4952 0.148s 0.001s
im_detect: 1845/4952 0.148s 0.001s
im_detect: 1846/4952 0.148s 0.001s
im_detect: 1847/4952 0.148s 0.001s
im_detect: 1848/4952 0.148s 0.001s
im_detect: 1849/4952 0.148s 0.001s
im_detect: 1850/4952 0.148s 0.001s
im_detect: 1851/4952 0.148s 0.001s
im_detect: 1852/4952 0.148s 0.001s
im_detect: 1853/4952 0.148s 0.001s
im_detect: 1854/4952 0.148s 0.001s
im_detect: 1855/4952 0.148s 0.001s
im_detect: 1856/4952 0.148s 0.001s
im_detect: 1857/4952 0.148s 0.001s
im_detect: 1858/4952 0.148s 0.001s
im_detect: 1859/4952 0.148s 0.001s
im_detect: 1860/4952 0.148s 0.001s
im_detect: 1861/4952 0.148s 0.001s
im_detect: 1862/4952 0.148s 0.001s
im_detect: 1863/4952 0.148s 0.001s
im_detect: 1864/4952 0.148s 0.001s
im_detect: 1865/4952 0.148s 0.001s
im_detect: 1866/4952 0.148s 0.001s
im_detect: 1867/4952 0.148s 0.001s
im_detect: 1868/4952 0.148s 0.001s
im_detect: 1869/4952 0.148s 0.001s
im_detect: 1870/4952 0.148s 0.001s
im_detect: 1871/4952 0.148s 0.001s
im_detect: 1872/4952 0.148s 0.001s
im_detect: 1873/4952 0.148s 0.001s
im_detect: 1874/4952 0.148s 0.001s
im_detect: 1875/4952 0.148s 0.001s
im_detect: 1876/4952 0.148s 0.001s
im_detect: 1877/4952 0.148s 0.001s
im_detect: 1878/4952 0.148s 0.001s
im_detect: 1879/4952 0.148s 0.001s
im_detect: 1880/4952 0.148s 0.001s
im_detect: 1881/4952 0.148s 0.001s
im_detect: 1882/4952 0.148s 0.001s
im_detect: 1883/4952 0.148s 0.001s
im_detect: 1884/4952 0.148s 0.001s
im_detect: 1885/4952 0.148s 0.001s
im_detect: 1886/4952 0.148s 0.001s
im_detect: 1887/4952 0.148s 0.001s
im_detect: 1888/4952 0.148s 0.001s
im_detect: 1889/4952 0.148s 0.001s
im_detect: 1890/4952 0.148s 0.001s
im_detect: 1891/4952 0.148s 0.001s
im_detect: 1892/4952 0.148s 0.001s
im_detect: 1893/4952 0.148s 0.001s
im_detect: 1894/4952 0.148s 0.001s
im_detect: 1895/4952 0.148s 0.001s
im_detect: 1896/4952 0.148s 0.001s
im_detect: 1897/4952 0.148s 0.001s
im_detect: 1898/4952 0.148s 0.001s
im_detect: 1899/4952 0.148s 0.001s
im_detect: 1900/4952 0.148s 0.001s
im_detect: 1901/4952 0.148s 0.001s
im_detect: 1902/4952 0.148s 0.001s
im_detect: 1903/4952 0.148s 0.001s
im_detect: 1904/4952 0.148s 0.001s
im_detect: 1905/4952 0.148s 0.001s
im_detect: 1906/4952 0.148s 0.001s
im_detect: 1907/4952 0.148s 0.001s
im_detect: 1908/4952 0.148s 0.001s
im_detect: 1909/4952 0.148s 0.001s
im_detect: 1910/4952 0.148s 0.001s
im_detect: 1911/4952 0.148s 0.001s
im_detect: 1912/4952 0.148s 0.001s
im_detect: 1913/4952 0.148s 0.001s
im_detect: 1914/4952 0.148s 0.001s
im_detect: 1915/4952 0.148s 0.001s
im_detect: 1916/4952 0.148s 0.001s
im_detect: 1917/4952 0.148s 0.001s
im_detect: 1918/4952 0.148s 0.001s
im_detect: 1919/4952 0.148s 0.001s
im_detect: 1920/4952 0.148s 0.001s
im_detect: 1921/4952 0.148s 0.001s
im_detect: 1922/4952 0.148s 0.001s
im_detect: 1923/4952 0.148s 0.001s
im_detect: 1924/4952 0.148s 0.001s
im_detect: 1925/4952 0.148s 0.001s
im_detect: 1926/4952 0.148s 0.001s
im_detect: 1927/4952 0.148s 0.001s
im_detect: 1928/4952 0.148s 0.001s
im_detect: 1929/4952 0.148s 0.001s
im_detect: 1930/4952 0.148s 0.001s
im_detect: 1931/4952 0.148s 0.001s
im_detect: 1932/4952 0.148s 0.001s
im_detect: 1933/4952 0.148s 0.001s
im_detect: 1934/4952 0.148s 0.001s
im_detect: 1935/4952 0.148s 0.001s
im_detect: 1936/4952 0.148s 0.001s
im_detect: 1937/4952 0.148s 0.001s
im_detect: 1938/4952 0.148s 0.001s
im_detect: 1939/4952 0.148s 0.001s
im_detect: 1940/4952 0.148s 0.001s
im_detect: 1941/4952 0.148s 0.001s
im_detect: 1942/4952 0.148s 0.001s
im_detect: 1943/4952 0.148s 0.001s
im_detect: 1944/4952 0.148s 0.001s
im_detect: 1945/4952 0.148s 0.001s
im_detect: 1946/4952 0.148s 0.001s
im_detect: 1947/4952 0.148s 0.001s
im_detect: 1948/4952 0.148s 0.001s
im_detect: 1949/4952 0.148s 0.001s
im_detect: 1950/4952 0.148s 0.001s
im_detect: 1951/4952 0.148s 0.001s
im_detect: 1952/4952 0.148s 0.001s
im_detect: 1953/4952 0.148s 0.001s
im_detect: 1954/4952 0.148s 0.001s
im_detect: 1955/4952 0.148s 0.001s
im_detect: 1956/4952 0.148s 0.001s
im_detect: 1957/4952 0.148s 0.001s
im_detect: 1958/4952 0.148s 0.001s
im_detect: 1959/4952 0.148s 0.001s
im_detect: 1960/4952 0.148s 0.001s
im_detect: 1961/4952 0.148s 0.001s
im_detect: 1962/4952 0.148s 0.001s
im_detect: 1963/4952 0.148s 0.001s
im_detect: 1964/4952 0.148s 0.001s
im_detect: 1965/4952 0.148s 0.001s
im_detect: 1966/4952 0.148s 0.001s
im_detect: 1967/4952 0.148s 0.001s
im_detect: 1968/4952 0.148s 0.001s
im_detect: 1969/4952 0.148s 0.001s
im_detect: 1970/4952 0.148s 0.001s
im_detect: 1971/4952 0.148s 0.001s
im_detect: 1972/4952 0.148s 0.001s
im_detect: 1973/4952 0.148s 0.001s
im_detect: 1974/4952 0.148s 0.001s
im_detect: 1975/4952 0.148s 0.001s
im_detect: 1976/4952 0.148s 0.001s
im_detect: 1977/4952 0.148s 0.001s
im_detect: 1978/4952 0.148s 0.001s
im_detect: 1979/4952 0.148s 0.001s
im_detect: 1980/4952 0.148s 0.001s
im_detect: 1981/4952 0.148s 0.001s
im_detect: 1982/4952 0.148s 0.001s
im_detect: 1983/4952 0.148s 0.001s
im_detect: 1984/4952 0.148s 0.001s
im_detect: 1985/4952 0.148s 0.001s
im_detect: 1986/4952 0.148s 0.001s
im_detect: 1987/4952 0.148s 0.001s
im_detect: 1988/4952 0.148s 0.001s
im_detect: 1989/4952 0.148s 0.001s
im_detect: 1990/4952 0.148s 0.001s
im_detect: 1991/4952 0.148s 0.001s
im_detect: 1992/4952 0.148s 0.001s
im_detect: 1993/4952 0.148s 0.001s
im_detect: 1994/4952 0.148s 0.001s
im_detect: 1995/4952 0.148s 0.001s
im_detect: 1996/4952 0.148s 0.001s
im_detect: 1997/4952 0.148s 0.001s
im_detect: 1998/4952 0.148s 0.001s
im_detect: 1999/4952 0.148s 0.001s
im_detect: 2000/4952 0.148s 0.001s
im_detect: 2001/4952 0.148s 0.001s
im_detect: 2002/4952 0.148s 0.001s
im_detect: 2003/4952 0.148s 0.001s
im_detect: 2004/4952 0.148s 0.001s
im_detect: 2005/4952 0.148s 0.001s
im_detect: 2006/4952 0.148s 0.001s
im_detect: 2007/4952 0.148s 0.001s
im_detect: 2008/4952 0.148s 0.001s
im_detect: 2009/4952 0.148s 0.001s
im_detect: 2010/4952 0.148s 0.001s
im_detect: 2011/4952 0.148s 0.001s
im_detect: 2012/4952 0.148s 0.001s
im_detect: 2013/4952 0.148s 0.001s
im_detect: 2014/4952 0.148s 0.001s
im_detect: 2015/4952 0.148s 0.001s
im_detect: 2016/4952 0.148s 0.001s
im_detect: 2017/4952 0.148s 0.001s
im_detect: 2018/4952 0.148s 0.001s
im_detect: 2019/4952 0.148s 0.001s
im_detect: 2020/4952 0.148s 0.001s
im_detect: 2021/4952 0.148s 0.001s
im_detect: 2022/4952 0.148s 0.001s
im_detect: 2023/4952 0.148s 0.001s
im_detect: 2024/4952 0.148s 0.001s
im_detect: 2025/4952 0.148s 0.001s
im_detect: 2026/4952 0.148s 0.001s
im_detect: 2027/4952 0.148s 0.001s
im_detect: 2028/4952 0.148s 0.001s
im_detect: 2029/4952 0.148s 0.001s
im_detect: 2030/4952 0.148s 0.001s
im_detect: 2031/4952 0.148s 0.001s
im_detect: 2032/4952 0.148s 0.001s
im_detect: 2033/4952 0.148s 0.001s
im_detect: 2034/4952 0.148s 0.001s
im_detect: 2035/4952 0.148s 0.001s
im_detect: 2036/4952 0.148s 0.001s
im_detect: 2037/4952 0.148s 0.001s
im_detect: 2038/4952 0.148s 0.001s
im_detect: 2039/4952 0.148s 0.001s
im_detect: 2040/4952 0.148s 0.001s
im_detect: 2041/4952 0.148s 0.001s
im_detect: 2042/4952 0.148s 0.001s
im_detect: 2043/4952 0.148s 0.001s
im_detect: 2044/4952 0.148s 0.001s
im_detect: 2045/4952 0.148s 0.001s
im_detect: 2046/4952 0.148s 0.001s
im_detect: 2047/4952 0.148s 0.001s
im_detect: 2048/4952 0.148s 0.001s
im_detect: 2049/4952 0.148s 0.001s
im_detect: 2050/4952 0.148s 0.001s
im_detect: 2051/4952 0.148s 0.001s
im_detect: 2052/4952 0.148s 0.001s
im_detect: 2053/4952 0.148s 0.001s
im_detect: 2054/4952 0.148s 0.001s
im_detect: 2055/4952 0.148s 0.001s
im_detect: 2056/4952 0.148s 0.001s
im_detect: 2057/4952 0.148s 0.001s
im_detect: 2058/4952 0.148s 0.001s
im_detect: 2059/4952 0.148s 0.001s
im_detect: 2060/4952 0.148s 0.001s
im_detect: 2061/4952 0.148s 0.001s
im_detect: 2062/4952 0.148s 0.001s
im_detect: 2063/4952 0.148s 0.001s
im_detect: 2064/4952 0.148s 0.001s
im_detect: 2065/4952 0.148s 0.001s
im_detect: 2066/4952 0.148s 0.001s
im_detect: 2067/4952 0.148s 0.001s
im_detect: 2068/4952 0.148s 0.001s
im_detect: 2069/4952 0.148s 0.001s
im_detect: 2070/4952 0.148s 0.001s
im_detect: 2071/4952 0.148s 0.001s
im_detect: 2072/4952 0.148s 0.001s
im_detect: 2073/4952 0.148s 0.001s
im_detect: 2074/4952 0.148s 0.001s
im_detect: 2075/4952 0.148s 0.001s
im_detect: 2076/4952 0.148s 0.001s
im_detect: 2077/4952 0.148s 0.001s
im_detect: 2078/4952 0.148s 0.001s
im_detect: 2079/4952 0.148s 0.001s
im_detect: 2080/4952 0.148s 0.001s
im_detect: 2081/4952 0.148s 0.001s
im_detect: 2082/4952 0.148s 0.001s
im_detect: 2083/4952 0.148s 0.001s
im_detect: 2084/4952 0.148s 0.001s
im_detect: 2085/4952 0.148s 0.001s
im_detect: 2086/4952 0.148s 0.001s
im_detect: 2087/4952 0.148s 0.001s
im_detect: 2088/4952 0.148s 0.001s
im_detect: 2089/4952 0.148s 0.001s
im_detect: 2090/4952 0.148s 0.001s
im_detect: 2091/4952 0.148s 0.001s
im_detect: 2092/4952 0.148s 0.001s
im_detect: 2093/4952 0.148s 0.001s
im_detect: 2094/4952 0.148s 0.001s
im_detect: 2095/4952 0.148s 0.001s
im_detect: 2096/4952 0.148s 0.001s
im_detect: 2097/4952 0.148s 0.001s
im_detect: 2098/4952 0.148s 0.001s
im_detect: 2099/4952 0.148s 0.001s
im_detect: 2100/4952 0.148s 0.001s
im_detect: 2101/4952 0.148s 0.001s
im_detect: 2102/4952 0.148s 0.001s
im_detect: 2103/4952 0.148s 0.001s
im_detect: 2104/4952 0.148s 0.001s
im_detect: 2105/4952 0.148s 0.001s
im_detect: 2106/4952 0.148s 0.001s
im_detect: 2107/4952 0.148s 0.001s
im_detect: 2108/4952 0.148s 0.001s
im_detect: 2109/4952 0.148s 0.001s
im_detect: 2110/4952 0.148s 0.001s
im_detect: 2111/4952 0.148s 0.001s
im_detect: 2112/4952 0.148s 0.001s
im_detect: 2113/4952 0.148s 0.001s
im_detect: 2114/4952 0.148s 0.001s
im_detect: 2115/4952 0.148s 0.001s
im_detect: 2116/4952 0.148s 0.001s
im_detect: 2117/4952 0.148s 0.001s
im_detect: 2118/4952 0.148s 0.001s
im_detect: 2119/4952 0.148s 0.001s
im_detect: 2120/4952 0.148s 0.001s
im_detect: 2121/4952 0.148s 0.001s
im_detect: 2122/4952 0.148s 0.001s
im_detect: 2123/4952 0.148s 0.001s
im_detect: 2124/4952 0.148s 0.001s
im_detect: 2125/4952 0.148s 0.001s
im_detect: 2126/4952 0.148s 0.001s
im_detect: 2127/4952 0.148s 0.001s
im_detect: 2128/4952 0.148s 0.001s
im_detect: 2129/4952 0.148s 0.001s
im_detect: 2130/4952 0.148s 0.001s
im_detect: 2131/4952 0.148s 0.001s
im_detect: 2132/4952 0.148s 0.001s
im_detect: 2133/4952 0.148s 0.001s
im_detect: 2134/4952 0.148s 0.001s
im_detect: 2135/4952 0.148s 0.001s
im_detect: 2136/4952 0.148s 0.001s
im_detect: 2137/4952 0.148s 0.001s
im_detect: 2138/4952 0.148s 0.001s
im_detect: 2139/4952 0.148s 0.001s
im_detect: 2140/4952 0.148s 0.001s
im_detect: 2141/4952 0.148s 0.001s
im_detect: 2142/4952 0.148s 0.001s
im_detect: 2143/4952 0.148s 0.001s
im_detect: 2144/4952 0.148s 0.001s
im_detect: 2145/4952 0.148s 0.001s
im_detect: 2146/4952 0.148s 0.001s
im_detect: 2147/4952 0.148s 0.001s
im_detect: 2148/4952 0.148s 0.001s
im_detect: 2149/4952 0.148s 0.001s
im_detect: 2150/4952 0.148s 0.001s
im_detect: 2151/4952 0.148s 0.001s
im_detect: 2152/4952 0.148s 0.001s
im_detect: 2153/4952 0.148s 0.001s
im_detect: 2154/4952 0.148s 0.001s
im_detect: 2155/4952 0.148s 0.001s
im_detect: 2156/4952 0.148s 0.001s
im_detect: 2157/4952 0.148s 0.001s
im_detect: 2158/4952 0.148s 0.001s
im_detect: 2159/4952 0.148s 0.001s
im_detect: 2160/4952 0.148s 0.001s
im_detect: 2161/4952 0.148s 0.001s
im_detect: 2162/4952 0.148s 0.001s
im_detect: 2163/4952 0.148s 0.001s
im_detect: 2164/4952 0.148s 0.001s
im_detect: 2165/4952 0.148s 0.001s
im_detect: 2166/4952 0.148s 0.001s
im_detect: 2167/4952 0.148s 0.001s
im_detect: 2168/4952 0.148s 0.001s
im_detect: 2169/4952 0.148s 0.001s
im_detect: 2170/4952 0.148s 0.001s
im_detect: 2171/4952 0.148s 0.001s
im_detect: 2172/4952 0.148s 0.001s
im_detect: 2173/4952 0.148s 0.001s
im_detect: 2174/4952 0.148s 0.001s
im_detect: 2175/4952 0.148s 0.001s
im_detect: 2176/4952 0.148s 0.001s
im_detect: 2177/4952 0.148s 0.001s
im_detect: 2178/4952 0.148s 0.001s
im_detect: 2179/4952 0.148s 0.001s
im_detect: 2180/4952 0.148s 0.001s
im_detect: 2181/4952 0.148s 0.001s
im_detect: 2182/4952 0.148s 0.001s
im_detect: 2183/4952 0.148s 0.001s
im_detect: 2184/4952 0.148s 0.001s
im_detect: 2185/4952 0.148s 0.001s
im_detect: 2186/4952 0.148s 0.001s
im_detect: 2187/4952 0.148s 0.001s
im_detect: 2188/4952 0.148s 0.001s
im_detect: 2189/4952 0.148s 0.001s
im_detect: 2190/4952 0.148s 0.001s
im_detect: 2191/4952 0.148s 0.001s
im_detect: 2192/4952 0.148s 0.001s
im_detect: 2193/4952 0.148s 0.001s
im_detect: 2194/4952 0.148s 0.002s
im_detect: 2195/4952 0.148s 0.002s
im_detect: 2196/4952 0.148s 0.002s
im_detect: 2197/4952 0.148s 0.002s
im_detect: 2198/4952 0.148s 0.002s
im_detect: 2199/4952 0.148s 0.002s
im_detect: 2200/4952 0.148s 0.002s
im_detect: 2201/4952 0.148s 0.002s
im_detect: 2202/4952 0.148s 0.002s
im_detect: 2203/4952 0.148s 0.002s
im_detect: 2204/4952 0.148s 0.002s
im_detect: 2205/4952 0.148s 0.002s
im_detect: 2206/4952 0.148s 0.002s
im_detect: 2207/4952 0.148s 0.002s
im_detect: 2208/4952 0.148s 0.002s
im_detect: 2209/4952 0.148s 0.002s
im_detect: 2210/4952 0.148s 0.002s
im_detect: 2211/4952 0.148s 0.002s
im_detect: 2212/4952 0.148s 0.002s
im_detect: 2213/4952 0.148s 0.002s
im_detect: 2214/4952 0.148s 0.002s
im_detect: 2215/4952 0.148s 0.002s
im_detect: 2216/4952 0.148s 0.002s
im_detect: 2217/4952 0.148s 0.002s
im_detect: 2218/4952 0.148s 0.002s
im_detect: 2219/4952 0.148s 0.002s
im_detect: 2220/4952 0.148s 0.002s
im_detect: 2221/4952 0.148s 0.002s
im_detect: 2222/4952 0.148s 0.002s
im_detect: 2223/4952 0.148s 0.002s
im_detect: 2224/4952 0.148s 0.002s
im_detect: 2225/4952 0.148s 0.002s
im_detect: 2226/4952 0.148s 0.002s
im_detect: 2227/4952 0.148s 0.002s
im_detect: 2228/4952 0.148s 0.002s
im_detect: 2229/4952 0.148s 0.002s
im_detect: 2230/4952 0.148s 0.002s
im_detect: 2231/4952 0.148s 0.002s
im_detect: 2232/4952 0.148s 0.002s
im_detect: 2233/4952 0.148s 0.002s
im_detect: 2234/4952 0.148s 0.002s
im_detect: 2235/4952 0.148s 0.002s
im_detect: 2236/4952 0.148s 0.002s
im_detect: 2237/4952 0.148s 0.002s
im_detect: 2238/4952 0.148s 0.002s
im_detect: 2239/4952 0.148s 0.002s
im_detect: 2240/4952 0.148s 0.002s
im_detect: 2241/4952 0.148s 0.002s
im_detect: 2242/4952 0.148s 0.002s
im_detect: 2243/4952 0.148s 0.002s
im_detect: 2244/4952 0.148s 0.002s
im_detect: 2245/4952 0.148s 0.002s
im_detect: 2246/4952 0.148s 0.002s
im_detect: 2247/4952 0.148s 0.002s
im_detect: 2248/4952 0.148s 0.002s
im_detect: 2249/4952 0.148s 0.002s
im_detect: 2250/4952 0.148s 0.002s
im_detect: 2251/4952 0.148s 0.002s
im_detect: 2252/4952 0.148s 0.002s
im_detect: 2253/4952 0.148s 0.002s
im_detect: 2254/4952 0.148s 0.002s
im_detect: 2255/4952 0.148s 0.002s
im_detect: 2256/4952 0.148s 0.002s
im_detect: 2257/4952 0.148s 0.002s
im_detect: 2258/4952 0.148s 0.002s
im_detect: 2259/4952 0.148s 0.002s
im_detect: 2260/4952 0.148s 0.002s
im_detect: 2261/4952 0.148s 0.002s
im_detect: 2262/4952 0.148s 0.002s
im_detect: 2263/4952 0.148s 0.002s
im_detect: 2264/4952 0.148s 0.002s
im_detect: 2265/4952 0.148s 0.002s
im_detect: 2266/4952 0.148s 0.002s
im_detect: 2267/4952 0.148s 0.002s
im_detect: 2268/4952 0.148s 0.002s
im_detect: 2269/4952 0.148s 0.002s
im_detect: 2270/4952 0.148s 0.002s
im_detect: 2271/4952 0.148s 0.002s
im_detect: 2272/4952 0.148s 0.002s
im_detect: 2273/4952 0.148s 0.002s
im_detect: 2274/4952 0.148s 0.002s
im_detect: 2275/4952 0.148s 0.002s
im_detect: 2276/4952 0.148s 0.002s
im_detect: 2277/4952 0.148s 0.002s
im_detect: 2278/4952 0.148s 0.002s
im_detect: 2279/4952 0.148s 0.002s
im_detect: 2280/4952 0.148s 0.002s
im_detect: 2281/4952 0.148s 0.002s
im_detect: 2282/4952 0.148s 0.002s
im_detect: 2283/4952 0.148s 0.002s
im_detect: 2284/4952 0.148s 0.002s
im_detect: 2285/4952 0.148s 0.002s
im_detect: 2286/4952 0.148s 0.002s
im_detect: 2287/4952 0.148s 0.002s
im_detect: 2288/4952 0.148s 0.002s
im_detect: 2289/4952 0.148s 0.002s
im_detect: 2290/4952 0.148s 0.002s
im_detect: 2291/4952 0.148s 0.002s
im_detect: 2292/4952 0.148s 0.002s
im_detect: 2293/4952 0.148s 0.002s
im_detect: 2294/4952 0.148s 0.002s
im_detect: 2295/4952 0.148s 0.002s
im_detect: 2296/4952 0.148s 0.002s
im_detect: 2297/4952 0.148s 0.002s
im_detect: 2298/4952 0.148s 0.002s
im_detect: 2299/4952 0.148s 0.002s
im_detect: 2300/4952 0.148s 0.002s
im_detect: 2301/4952 0.148s 0.002s
im_detect: 2302/4952 0.148s 0.002s
im_detect: 2303/4952 0.148s 0.002s
im_detect: 2304/4952 0.148s 0.002s
im_detect: 2305/4952 0.148s 0.002s
im_detect: 2306/4952 0.148s 0.002s
im_detect: 2307/4952 0.148s 0.002s
im_detect: 2308/4952 0.148s 0.002s
im_detect: 2309/4952 0.148s 0.002s
im_detect: 2310/4952 0.148s 0.002s
im_detect: 2311/4952 0.148s 0.002s
im_detect: 2312/4952 0.148s 0.002s
im_detect: 2313/4952 0.148s 0.002s
im_detect: 2314/4952 0.148s 0.002s
im_detect: 2315/4952 0.148s 0.002s
im_detect: 2316/4952 0.148s 0.002s
im_detect: 2317/4952 0.148s 0.002s
im_detect: 2318/4952 0.148s 0.002s
im_detect: 2319/4952 0.148s 0.002s
im_detect: 2320/4952 0.148s 0.002s
im_detect: 2321/4952 0.148s 0.002s
im_detect: 2322/4952 0.148s 0.002s
im_detect: 2323/4952 0.148s 0.002s
im_detect: 2324/4952 0.148s 0.002s
im_detect: 2325/4952 0.148s 0.002s
im_detect: 2326/4952 0.148s 0.002s
im_detect: 2327/4952 0.148s 0.002s
im_detect: 2328/4952 0.148s 0.002s
im_detect: 2329/4952 0.148s 0.002s
im_detect: 2330/4952 0.148s 0.002s
im_detect: 2331/4952 0.148s 0.002s
im_detect: 2332/4952 0.148s 0.002s
im_detect: 2333/4952 0.148s 0.002s
im_detect: 2334/4952 0.148s 0.002s
im_detect: 2335/4952 0.148s 0.002s
im_detect: 2336/4952 0.148s 0.002s
im_detect: 2337/4952 0.148s 0.002s
im_detect: 2338/4952 0.148s 0.002s
im_detect: 2339/4952 0.148s 0.002s
im_detect: 2340/4952 0.148s 0.002s
im_detect: 2341/4952 0.148s 0.002s
im_detect: 2342/4952 0.148s 0.002s
im_detect: 2343/4952 0.148s 0.002s
im_detect: 2344/4952 0.148s 0.002s
im_detect: 2345/4952 0.148s 0.002s
im_detect: 2346/4952 0.148s 0.002s
im_detect: 2347/4952 0.148s 0.002s
im_detect: 2348/4952 0.148s 0.002s
im_detect: 2349/4952 0.148s 0.002s
im_detect: 2350/4952 0.148s 0.002s
im_detect: 2351/4952 0.148s 0.002s
im_detect: 2352/4952 0.148s 0.002s
im_detect: 2353/4952 0.148s 0.002s
im_detect: 2354/4952 0.148s 0.002s
im_detect: 2355/4952 0.148s 0.002s
im_detect: 2356/4952 0.148s 0.002s
im_detect: 2357/4952 0.148s 0.002s
im_detect: 2358/4952 0.148s 0.002s
im_detect: 2359/4952 0.148s 0.002s
im_detect: 2360/4952 0.148s 0.002s
im_detect: 2361/4952 0.148s 0.002s
im_detect: 2362/4952 0.148s 0.002s
im_detect: 2363/4952 0.148s 0.002s
im_detect: 2364/4952 0.148s 0.002s
im_detect: 2365/4952 0.148s 0.002s
im_detect: 2366/4952 0.148s 0.002s
im_detect: 2367/4952 0.148s 0.002s
im_detect: 2368/4952 0.148s 0.002s
im_detect: 2369/4952 0.148s 0.002s
im_detect: 2370/4952 0.148s 0.002s
im_detect: 2371/4952 0.148s 0.002s
im_detect: 2372/4952 0.148s 0.002s
im_detect: 2373/4952 0.148s 0.002s
im_detect: 2374/4952 0.148s 0.002s
im_detect: 2375/4952 0.148s 0.002s
im_detect: 2376/4952 0.148s 0.002s
im_detect: 2377/4952 0.148s 0.002s
im_detect: 2378/4952 0.148s 0.002s
im_detect: 2379/4952 0.148s 0.002s
im_detect: 2380/4952 0.148s 0.002s
im_detect: 2381/4952 0.148s 0.002s
im_detect: 2382/4952 0.148s 0.002s
im_detect: 2383/4952 0.148s 0.002s
im_detect: 2384/4952 0.148s 0.002s
im_detect: 2385/4952 0.148s 0.002s
im_detect: 2386/4952 0.148s 0.002s
im_detect: 2387/4952 0.148s 0.002s
im_detect: 2388/4952 0.148s 0.002s
im_detect: 2389/4952 0.148s 0.002s
im_detect: 2390/4952 0.148s 0.002s
im_detect: 2391/4952 0.148s 0.002s
im_detect: 2392/4952 0.148s 0.002s
im_detect: 2393/4952 0.148s 0.002s
im_detect: 2394/4952 0.148s 0.002s
im_detect: 2395/4952 0.148s 0.002s
im_detect: 2396/4952 0.148s 0.002s
im_detect: 2397/4952 0.148s 0.002s
im_detect: 2398/4952 0.148s 0.002s
im_detect: 2399/4952 0.148s 0.002s
im_detect: 2400/4952 0.148s 0.002s
im_detect: 2401/4952 0.148s 0.002s
im_detect: 2402/4952 0.148s 0.002s
im_detect: 2403/4952 0.148s 0.002s
im_detect: 2404/4952 0.148s 0.002s
im_detect: 2405/4952 0.148s 0.002s
im_detect: 2406/4952 0.148s 0.002s
im_detect: 2407/4952 0.148s 0.002s
im_detect: 2408/4952 0.148s 0.002s
im_detect: 2409/4952 0.148s 0.002s
im_detect: 2410/4952 0.148s 0.002s
im_detect: 2411/4952 0.148s 0.002s
im_detect: 2412/4952 0.148s 0.002s
im_detect: 2413/4952 0.148s 0.002s
im_detect: 2414/4952 0.148s 0.002s
im_detect: 2415/4952 0.148s 0.002s
im_detect: 2416/4952 0.148s 0.002s
im_detect: 2417/4952 0.148s 0.002s
im_detect: 2418/4952 0.148s 0.002s
im_detect: 2419/4952 0.148s 0.002s
im_detect: 2420/4952 0.148s 0.002s
im_detect: 2421/4952 0.148s 0.002s
im_detect: 2422/4952 0.148s 0.002s
im_detect: 2423/4952 0.148s 0.002s
im_detect: 2424/4952 0.148s 0.002s
im_detect: 2425/4952 0.148s 0.002s
im_detect: 2426/4952 0.148s 0.002s
im_detect: 2427/4952 0.148s 0.002s
im_detect: 2428/4952 0.148s 0.002s
im_detect: 2429/4952 0.148s 0.002s
im_detect: 2430/4952 0.148s 0.002s
im_detect: 2431/4952 0.148s 0.002s
im_detect: 2432/4952 0.148s 0.002s
im_detect: 2433/4952 0.148s 0.002s
im_detect: 2434/4952 0.148s 0.002s
im_detect: 2435/4952 0.148s 0.002s
im_detect: 2436/4952 0.148s 0.002s
im_detect: 2437/4952 0.148s 0.002s
im_detect: 2438/4952 0.148s 0.002s
im_detect: 2439/4952 0.148s 0.002s
im_detect: 2440/4952 0.148s 0.002s
im_detect: 2441/4952 0.148s 0.002s
im_detect: 2442/4952 0.148s 0.002s
im_detect: 2443/4952 0.148s 0.002s
im_detect: 2444/4952 0.148s 0.002s
im_detect: 2445/4952 0.148s 0.002s
im_detect: 2446/4952 0.148s 0.002s
im_detect: 2447/4952 0.148s 0.002s
im_detect: 2448/4952 0.148s 0.002s
im_detect: 2449/4952 0.148s 0.002s
im_detect: 2450/4952 0.148s 0.002s
im_detect: 2451/4952 0.148s 0.002s
im_detect: 2452/4952 0.148s 0.002s
im_detect: 2453/4952 0.148s 0.002s
im_detect: 2454/4952 0.148s 0.002s
im_detect: 2455/4952 0.148s 0.002s
im_detect: 2456/4952 0.148s 0.002s
im_detect: 2457/4952 0.148s 0.002s
im_detect: 2458/4952 0.148s 0.002s
im_detect: 2459/4952 0.148s 0.002s
im_detect: 2460/4952 0.148s 0.002s
im_detect: 2461/4952 0.148s 0.002s
im_detect: 2462/4952 0.148s 0.002s
im_detect: 2463/4952 0.148s 0.002s
im_detect: 2464/4952 0.148s 0.002s
im_detect: 2465/4952 0.148s 0.002s
im_detect: 2466/4952 0.148s 0.002s
im_detect: 2467/4952 0.148s 0.002s
im_detect: 2468/4952 0.148s 0.002s
im_detect: 2469/4952 0.148s 0.002s
im_detect: 2470/4952 0.148s 0.002s
im_detect: 2471/4952 0.148s 0.002s
im_detect: 2472/4952 0.148s 0.002s
im_detect: 2473/4952 0.148s 0.002s
im_detect: 2474/4952 0.148s 0.002s
im_detect: 2475/4952 0.148s 0.002s
im_detect: 2476/4952 0.148s 0.002s
im_detect: 2477/4952 0.148s 0.002s
im_detect: 2478/4952 0.148s 0.002s
im_detect: 2479/4952 0.148s 0.002s
im_detect: 2480/4952 0.148s 0.002s
im_detect: 2481/4952 0.148s 0.002s
im_detect: 2482/4952 0.148s 0.002s
im_detect: 2483/4952 0.148s 0.002s
im_detect: 2484/4952 0.148s 0.002s
im_detect: 2485/4952 0.148s 0.002s
im_detect: 2486/4952 0.148s 0.002s
im_detect: 2487/4952 0.148s 0.002s
im_detect: 2488/4952 0.148s 0.002s
im_detect: 2489/4952 0.148s 0.002s
im_detect: 2490/4952 0.148s 0.002s
im_detect: 2491/4952 0.148s 0.002s
im_detect: 2492/4952 0.148s 0.002s
im_detect: 2493/4952 0.148s 0.002s
im_detect: 2494/4952 0.148s 0.002s
im_detect: 2495/4952 0.148s 0.002s
im_detect: 2496/4952 0.148s 0.002s
im_detect: 2497/4952 0.148s 0.002s
im_detect: 2498/4952 0.148s 0.002s
im_detect: 2499/4952 0.148s 0.002s
im_detect: 2500/4952 0.148s 0.002s
im_detect: 2501/4952 0.148s 0.002s
im_detect: 2502/4952 0.148s 0.002s
im_detect: 2503/4952 0.148s 0.002s
im_detect: 2504/4952 0.148s 0.002s
im_detect: 2505/4952 0.148s 0.002s
im_detect: 2506/4952 0.148s 0.002s
im_detect: 2507/4952 0.148s 0.002s
im_detect: 2508/4952 0.148s 0.002s
im_detect: 2509/4952 0.148s 0.002s
im_detect: 2510/4952 0.148s 0.002s
im_detect: 2511/4952 0.148s 0.002s
im_detect: 2512/4952 0.148s 0.002s
im_detect: 2513/4952 0.148s 0.002s
im_detect: 2514/4952 0.148s 0.002s
im_detect: 2515/4952 0.148s 0.002s
im_detect: 2516/4952 0.148s 0.002s
im_detect: 2517/4952 0.148s 0.002s
im_detect: 2518/4952 0.148s 0.002s
im_detect: 2519/4952 0.148s 0.002s
im_detect: 2520/4952 0.148s 0.002s
im_detect: 2521/4952 0.148s 0.002s
im_detect: 2522/4952 0.148s 0.002s
im_detect: 2523/4952 0.148s 0.002s
im_detect: 2524/4952 0.148s 0.002s
im_detect: 2525/4952 0.148s 0.002s
im_detect: 2526/4952 0.148s 0.002s
im_detect: 2527/4952 0.148s 0.002s
im_detect: 2528/4952 0.148s 0.002s
im_detect: 2529/4952 0.148s 0.002s
im_detect: 2530/4952 0.148s 0.002s
im_detect: 2531/4952 0.148s 0.002s
im_detect: 2532/4952 0.148s 0.002s
im_detect: 2533/4952 0.148s 0.002s
im_detect: 2534/4952 0.148s 0.002s
im_detect: 2535/4952 0.148s 0.002s
im_detect: 2536/4952 0.148s 0.002s
im_detect: 2537/4952 0.148s 0.002s
im_detect: 2538/4952 0.148s 0.002s
im_detect: 2539/4952 0.148s 0.002s
im_detect: 2540/4952 0.148s 0.002s
im_detect: 2541/4952 0.148s 0.002s
im_detect: 2542/4952 0.148s 0.002s
im_detect: 2543/4952 0.148s 0.002s
im_detect: 2544/4952 0.148s 0.002s
im_detect: 2545/4952 0.148s 0.002s
im_detect: 2546/4952 0.148s 0.002s
im_detect: 2547/4952 0.148s 0.002s
im_detect: 2548/4952 0.148s 0.002s
im_detect: 2549/4952 0.148s 0.002s
im_detect: 2550/4952 0.148s 0.002s
im_detect: 2551/4952 0.148s 0.002s
im_detect: 2552/4952 0.148s 0.002s
im_detect: 2553/4952 0.148s 0.002s
im_detect: 2554/4952 0.148s 0.002s
im_detect: 2555/4952 0.148s 0.002s
im_detect: 2556/4952 0.148s 0.002s
im_detect: 2557/4952 0.148s 0.002s
im_detect: 2558/4952 0.148s 0.002s
im_detect: 2559/4952 0.148s 0.002s
im_detect: 2560/4952 0.148s 0.002s
im_detect: 2561/4952 0.148s 0.002s
im_detect: 2562/4952 0.148s 0.002s
im_detect: 2563/4952 0.148s 0.002s
im_detect: 2564/4952 0.148s 0.002s
im_detect: 2565/4952 0.148s 0.002s
im_detect: 2566/4952 0.148s 0.002s
im_detect: 2567/4952 0.148s 0.002s
im_detect: 2568/4952 0.148s 0.002s
im_detect: 2569/4952 0.148s 0.002s
im_detect: 2570/4952 0.148s 0.002s
im_detect: 2571/4952 0.148s 0.002s
im_detect: 2572/4952 0.148s 0.002s
im_detect: 2573/4952 0.148s 0.002s
im_detect: 2574/4952 0.148s 0.002s
im_detect: 2575/4952 0.148s 0.002s
im_detect: 2576/4952 0.148s 0.002s
im_detect: 2577/4952 0.148s 0.002s
im_detect: 2578/4952 0.148s 0.002s
im_detect: 2579/4952 0.148s 0.002s
im_detect: 2580/4952 0.148s 0.002s
im_detect: 2581/4952 0.148s 0.002s
im_detect: 2582/4952 0.148s 0.002s
im_detect: 2583/4952 0.148s 0.002s
im_detect: 2584/4952 0.148s 0.002s
im_detect: 2585/4952 0.148s 0.002s
im_detect: 2586/4952 0.148s 0.002s
im_detect: 2587/4952 0.148s 0.002s
im_detect: 2588/4952 0.148s 0.002s
im_detect: 2589/4952 0.148s 0.002s
im_detect: 2590/4952 0.148s 0.002s
im_detect: 2591/4952 0.148s 0.002s
im_detect: 2592/4952 0.148s 0.002s
im_detect: 2593/4952 0.148s 0.002s
im_detect: 2594/4952 0.148s 0.002s
im_detect: 2595/4952 0.148s 0.002s
im_detect: 2596/4952 0.148s 0.002s
im_detect: 2597/4952 0.148s 0.002s
im_detect: 2598/4952 0.148s 0.002s
im_detect: 2599/4952 0.148s 0.002s
im_detect: 2600/4952 0.148s 0.002s
im_detect: 2601/4952 0.148s 0.002s
im_detect: 2602/4952 0.148s 0.002s
im_detect: 2603/4952 0.148s 0.002s
im_detect: 2604/4952 0.148s 0.002s
im_detect: 2605/4952 0.148s 0.002s
im_detect: 2606/4952 0.148s 0.002s
im_detect: 2607/4952 0.148s 0.002s
im_detect: 2608/4952 0.148s 0.002s
im_detect: 2609/4952 0.148s 0.002s
im_detect: 2610/4952 0.148s 0.002s
im_detect: 2611/4952 0.148s 0.002s
im_detect: 2612/4952 0.148s 0.002s
im_detect: 2613/4952 0.148s 0.002s
im_detect: 2614/4952 0.148s 0.002s
im_detect: 2615/4952 0.148s 0.002s
im_detect: 2616/4952 0.148s 0.002s
im_detect: 2617/4952 0.148s 0.002s
im_detect: 2618/4952 0.148s 0.002s
im_detect: 2619/4952 0.148s 0.002s
im_detect: 2620/4952 0.148s 0.002s
im_detect: 2621/4952 0.148s 0.002s
im_detect: 2622/4952 0.148s 0.002s
im_detect: 2623/4952 0.148s 0.002s
im_detect: 2624/4952 0.148s 0.002s
im_detect: 2625/4952 0.148s 0.002s
im_detect: 2626/4952 0.148s 0.002s
im_detect: 2627/4952 0.149s 0.002s
im_detect: 2628/4952 0.149s 0.002s
im_detect: 2629/4952 0.149s 0.002s
im_detect: 2630/4952 0.149s 0.002s
im_detect: 2631/4952 0.149s 0.002s
im_detect: 2632/4952 0.149s 0.002s
im_detect: 2633/4952 0.149s 0.002s
im_detect: 2634/4952 0.149s 0.002s
im_detect: 2635/4952 0.149s 0.002s
im_detect: 2636/4952 0.149s 0.002s
im_detect: 2637/4952 0.149s 0.002s
im_detect: 2638/4952 0.149s 0.002s
im_detect: 2639/4952 0.149s 0.002s
im_detect: 2640/4952 0.149s 0.002s
im_detect: 2641/4952 0.149s 0.002s
im_detect: 2642/4952 0.149s 0.002s
im_detect: 2643/4952 0.149s 0.002s
im_detect: 2644/4952 0.149s 0.002s
im_detect: 2645/4952 0.149s 0.002s
im_detect: 2646/4952 0.149s 0.002s
im_detect: 2647/4952 0.149s 0.002s
im_detect: 2648/4952 0.149s 0.002s
im_detect: 2649/4952 0.149s 0.002s
im_detect: 2650/4952 0.149s 0.002s
im_detect: 2651/4952 0.149s 0.002s
im_detect: 2652/4952 0.149s 0.002s
im_detect: 2653/4952 0.149s 0.002s
im_detect: 2654/4952 0.149s 0.002s
im_detect: 2655/4952 0.149s 0.002s
im_detect: 2656/4952 0.149s 0.002s
im_detect: 2657/4952 0.149s 0.002s
im_detect: 2658/4952 0.149s 0.002s
im_detect: 2659/4952 0.149s 0.002s
im_detect: 2660/4952 0.149s 0.002s
im_detect: 2661/4952 0.149s 0.002s
im_detect: 2662/4952 0.149s 0.002s
im_detect: 2663/4952 0.149s 0.002s
im_detect: 2664/4952 0.149s 0.002s
im_detect: 2665/4952 0.149s 0.002s
im_detect: 2666/4952 0.149s 0.002s
im_detect: 2667/4952 0.149s 0.002s
im_detect: 2668/4952 0.149s 0.002s
im_detect: 2669/4952 0.149s 0.002s
im_detect: 2670/4952 0.149s 0.002s
im_detect: 2671/4952 0.149s 0.002s
im_detect: 2672/4952 0.149s 0.002s
im_detect: 2673/4952 0.149s 0.002s
im_detect: 2674/4952 0.149s 0.002s
im_detect: 2675/4952 0.149s 0.002s
im_detect: 2676/4952 0.149s 0.002s
im_detect: 2677/4952 0.149s 0.002s
im_detect: 2678/4952 0.149s 0.002s
im_detect: 2679/4952 0.149s 0.002s
im_detect: 2680/4952 0.149s 0.002s
im_detect: 2681/4952 0.149s 0.002s
im_detect: 2682/4952 0.149s 0.002s
im_detect: 2683/4952 0.149s 0.002s
im_detect: 2684/4952 0.149s 0.002s
im_detect: 2685/4952 0.149s 0.002s
im_detect: 2686/4952 0.149s 0.002s
im_detect: 2687/4952 0.149s 0.002s
im_detect: 2688/4952 0.149s 0.002s
im_detect: 2689/4952 0.149s 0.002s
im_detect: 2690/4952 0.149s 0.002s
im_detect: 2691/4952 0.149s 0.002s
im_detect: 2692/4952 0.149s 0.002s
im_detect: 2693/4952 0.149s 0.002s
im_detect: 2694/4952 0.149s 0.002s
im_detect: 2695/4952 0.149s 0.002s
im_detect: 2696/4952 0.149s 0.002s
im_detect: 2697/4952 0.149s 0.002s
im_detect: 2698/4952 0.149s 0.002s
im_detect: 2699/4952 0.149s 0.002s
im_detect: 2700/4952 0.149s 0.002s
im_detect: 2701/4952 0.149s 0.002s
im_detect: 2702/4952 0.149s 0.002s
im_detect: 2703/4952 0.149s 0.002s
im_detect: 2704/4952 0.149s 0.002s
im_detect: 2705/4952 0.149s 0.002s
im_detect: 2706/4952 0.149s 0.002s
im_detect: 2707/4952 0.149s 0.002s
im_detect: 2708/4952 0.149s 0.002s
im_detect: 2709/4952 0.149s 0.002s
im_detect: 2710/4952 0.149s 0.002s
im_detect: 2711/4952 0.149s 0.002s
im_detect: 2712/4952 0.149s 0.002s
im_detect: 2713/4952 0.149s 0.002s
im_detect: 2714/4952 0.149s 0.002s
im_detect: 2715/4952 0.149s 0.002s
im_detect: 2716/4952 0.149s 0.002s
im_detect: 2717/4952 0.149s 0.002s
im_detect: 2718/4952 0.149s 0.002s
im_detect: 2719/4952 0.149s 0.002s
im_detect: 2720/4952 0.149s 0.002s
im_detect: 2721/4952 0.149s 0.002s
im_detect: 2722/4952 0.149s 0.002s
im_detect: 2723/4952 0.149s 0.002s
im_detect: 2724/4952 0.149s 0.002s
im_detect: 2725/4952 0.149s 0.002s
im_detect: 2726/4952 0.149s 0.002s
im_detect: 2727/4952 0.149s 0.002s
im_detect: 2728/4952 0.149s 0.002s
im_detect: 2729/4952 0.149s 0.002s
im_detect: 2730/4952 0.149s 0.002s
im_detect: 2731/4952 0.149s 0.002s
im_detect: 2732/4952 0.149s 0.002s
im_detect: 2733/4952 0.149s 0.002s
im_detect: 2734/4952 0.149s 0.002s
im_detect: 2735/4952 0.149s 0.002s
im_detect: 2736/4952 0.149s 0.002s
im_detect: 2737/4952 0.149s 0.002s
im_detect: 2738/4952 0.149s 0.002s
im_detect: 2739/4952 0.149s 0.002s
im_detect: 2740/4952 0.149s 0.002s
im_detect: 2741/4952 0.149s 0.002s
im_detect: 2742/4952 0.149s 0.002s
im_detect: 2743/4952 0.149s 0.002s
im_detect: 2744/4952 0.149s 0.002s
im_detect: 2745/4952 0.149s 0.002s
im_detect: 2746/4952 0.149s 0.002s
im_detect: 2747/4952 0.149s 0.002s
im_detect: 2748/4952 0.149s 0.002s
im_detect: 2749/4952 0.149s 0.002s
im_detect: 2750/4952 0.149s 0.002s
im_detect: 2751/4952 0.149s 0.002s
im_detect: 2752/4952 0.149s 0.002s
im_detect: 2753/4952 0.149s 0.002s
im_detect: 2754/4952 0.149s 0.002s
im_detect: 2755/4952 0.149s 0.002s
im_detect: 2756/4952 0.149s 0.002s
im_detect: 2757/4952 0.149s 0.002s
im_detect: 2758/4952 0.149s 0.002s
im_detect: 2759/4952 0.149s 0.002s
im_detect: 2760/4952 0.149s 0.002s
im_detect: 2761/4952 0.149s 0.002s
im_detect: 2762/4952 0.149s 0.002s
im_detect: 2763/4952 0.149s 0.002s
im_detect: 2764/4952 0.149s 0.002s
im_detect: 2765/4952 0.149s 0.002s
im_detect: 2766/4952 0.149s 0.002s
im_detect: 2767/4952 0.149s 0.002s
im_detect: 2768/4952 0.149s 0.002s
im_detect: 2769/4952 0.149s 0.002s
im_detect: 2770/4952 0.149s 0.002s
im_detect: 2771/4952 0.149s 0.002s
im_detect: 2772/4952 0.149s 0.002s
im_detect: 2773/4952 0.149s 0.002s
im_detect: 2774/4952 0.149s 0.002s
im_detect: 2775/4952 0.149s 0.002s
im_detect: 2776/4952 0.149s 0.002s
im_detect: 2777/4952 0.149s 0.002s
im_detect: 2778/4952 0.149s 0.002s
im_detect: 2779/4952 0.149s 0.002s
im_detect: 2780/4952 0.149s 0.002s
im_detect: 2781/4952 0.149s 0.002s
im_detect: 2782/4952 0.149s 0.002s
im_detect: 2783/4952 0.149s 0.002s
im_detect: 2784/4952 0.149s 0.002s
im_detect: 2785/4952 0.149s 0.002s
im_detect: 2786/4952 0.149s 0.002s
im_detect: 2787/4952 0.149s 0.002s
im_detect: 2788/4952 0.149s 0.002s
im_detect: 2789/4952 0.149s 0.002s
im_detect: 2790/4952 0.149s 0.002s
im_detect: 2791/4952 0.149s 0.002s
im_detect: 2792/4952 0.149s 0.002s
im_detect: 2793/4952 0.149s 0.002s
im_detect: 2794/4952 0.149s 0.002s
im_detect: 2795/4952 0.149s 0.002s
im_detect: 2796/4952 0.149s 0.002s
im_detect: 2797/4952 0.149s 0.002s
im_detect: 2798/4952 0.149s 0.002s
im_detect: 2799/4952 0.149s 0.002s
im_detect: 2800/4952 0.149s 0.002s
im_detect: 2801/4952 0.149s 0.002s
im_detect: 2802/4952 0.149s 0.002s
im_detect: 2803/4952 0.149s 0.002s
im_detect: 2804/4952 0.149s 0.002s
im_detect: 2805/4952 0.149s 0.002s
im_detect: 2806/4952 0.149s 0.002s
im_detect: 2807/4952 0.149s 0.002s
im_detect: 2808/4952 0.149s 0.002s
im_detect: 2809/4952 0.149s 0.002s
im_detect: 2810/4952 0.149s 0.002s
im_detect: 2811/4952 0.149s 0.002s
im_detect: 2812/4952 0.149s 0.002s
im_detect: 2813/4952 0.149s 0.002s
im_detect: 2814/4952 0.149s 0.002s
im_detect: 2815/4952 0.149s 0.002s
im_detect: 2816/4952 0.149s 0.002s
im_detect: 2817/4952 0.149s 0.002s
im_detect: 2818/4952 0.149s 0.002s
im_detect: 2819/4952 0.149s 0.002s
im_detect: 2820/4952 0.149s 0.002s
im_detect: 2821/4952 0.149s 0.002s
im_detect: 2822/4952 0.149s 0.002s
im_detect: 2823/4952 0.149s 0.002s
im_detect: 2824/4952 0.149s 0.002s
im_detect: 2825/4952 0.149s 0.002s
im_detect: 2826/4952 0.149s 0.002s
im_detect: 2827/4952 0.149s 0.002s
im_detect: 2828/4952 0.149s 0.002s
im_detect: 2829/4952 0.149s 0.002s
im_detect: 2830/4952 0.149s 0.002s
im_detect: 2831/4952 0.149s 0.002s
im_detect: 2832/4952 0.149s 0.002s
im_detect: 2833/4952 0.149s 0.002s
im_detect: 2834/4952 0.149s 0.002s
im_detect: 2835/4952 0.149s 0.002s
im_detect: 2836/4952 0.149s 0.002s
im_detect: 2837/4952 0.149s 0.002s
im_detect: 2838/4952 0.149s 0.002s
im_detect: 2839/4952 0.149s 0.002s
im_detect: 2840/4952 0.149s 0.002s
im_detect: 2841/4952 0.149s 0.002s
im_detect: 2842/4952 0.149s 0.002s
im_detect: 2843/4952 0.149s 0.002s
im_detect: 2844/4952 0.149s 0.002s
im_detect: 2845/4952 0.149s 0.002s
im_detect: 2846/4952 0.149s 0.002s
im_detect: 2847/4952 0.149s 0.002s
im_detect: 2848/4952 0.149s 0.002s
im_detect: 2849/4952 0.149s 0.002s
im_detect: 2850/4952 0.149s 0.002s
im_detect: 2851/4952 0.149s 0.002s
im_detect: 2852/4952 0.149s 0.002s
im_detect: 2853/4952 0.149s 0.002s
im_detect: 2854/4952 0.149s 0.002s
im_detect: 2855/4952 0.149s 0.002s
im_detect: 2856/4952 0.149s 0.002s
im_detect: 2857/4952 0.149s 0.002s
im_detect: 2858/4952 0.149s 0.002s
im_detect: 2859/4952 0.149s 0.002s
im_detect: 2860/4952 0.149s 0.002s
im_detect: 2861/4952 0.149s 0.002s
im_detect: 2862/4952 0.149s 0.002s
im_detect: 2863/4952 0.149s 0.002s
im_detect: 2864/4952 0.149s 0.002s
im_detect: 2865/4952 0.149s 0.002s
im_detect: 2866/4952 0.149s 0.002s
im_detect: 2867/4952 0.149s 0.002s
im_detect: 2868/4952 0.149s 0.002s
im_detect: 2869/4952 0.149s 0.002s
im_detect: 2870/4952 0.149s 0.002s
im_detect: 2871/4952 0.149s 0.002s
im_detect: 2872/4952 0.149s 0.002s
im_detect: 2873/4952 0.149s 0.002s
im_detect: 2874/4952 0.149s 0.002s
im_detect: 2875/4952 0.149s 0.002s
im_detect: 2876/4952 0.149s 0.002s
im_detect: 2877/4952 0.149s 0.002s
im_detect: 2878/4952 0.149s 0.002s
im_detect: 2879/4952 0.149s 0.002s
im_detect: 2880/4952 0.149s 0.002s
im_detect: 2881/4952 0.149s 0.002s
im_detect: 2882/4952 0.149s 0.002s
im_detect: 2883/4952 0.149s 0.002s
im_detect: 2884/4952 0.149s 0.002s
im_detect: 2885/4952 0.149s 0.002s
im_detect: 2886/4952 0.149s 0.002s
im_detect: 2887/4952 0.149s 0.002s
im_detect: 2888/4952 0.149s 0.002s
im_detect: 2889/4952 0.149s 0.002s
im_detect: 2890/4952 0.149s 0.002s
im_detect: 2891/4952 0.149s 0.002s
im_detect: 2892/4952 0.149s 0.002s
im_detect: 2893/4952 0.149s 0.002s
im_detect: 2894/4952 0.149s 0.002s
im_detect: 2895/4952 0.149s 0.002s
im_detect: 2896/4952 0.149s 0.002s
im_detect: 2897/4952 0.149s 0.002s
im_detect: 2898/4952 0.149s 0.002s
im_detect: 2899/4952 0.149s 0.002s
im_detect: 2900/4952 0.149s 0.002s
im_detect: 2901/4952 0.149s 0.002s
im_detect: 2902/4952 0.149s 0.002s
im_detect: 2903/4952 0.149s 0.002s
im_detect: 2904/4952 0.149s 0.002s
im_detect: 2905/4952 0.149s 0.002s
im_detect: 2906/4952 0.149s 0.002s
im_detect: 2907/4952 0.149s 0.002s
im_detect: 2908/4952 0.149s 0.002s
im_detect: 2909/4952 0.149s 0.002s
im_detect: 2910/4952 0.149s 0.002s
im_detect: 2911/4952 0.149s 0.002s
im_detect: 2912/4952 0.149s 0.002s
im_detect: 2913/4952 0.149s 0.002s
im_detect: 2914/4952 0.149s 0.002s
im_detect: 2915/4952 0.149s 0.002s
im_detect: 2916/4952 0.149s 0.002s
im_detect: 2917/4952 0.149s 0.002s
im_detect: 2918/4952 0.149s 0.002s
im_detect: 2919/4952 0.149s 0.002s
im_detect: 2920/4952 0.149s 0.002s
im_detect: 2921/4952 0.149s 0.002s
im_detect: 2922/4952 0.149s 0.002s
im_detect: 2923/4952 0.149s 0.002s
im_detect: 2924/4952 0.149s 0.002s
im_detect: 2925/4952 0.149s 0.002s
im_detect: 2926/4952 0.149s 0.002s
im_detect: 2927/4952 0.149s 0.002s
im_detect: 2928/4952 0.149s 0.002s
im_detect: 2929/4952 0.149s 0.002s
im_detect: 2930/4952 0.149s 0.002s
im_detect: 2931/4952 0.149s 0.002s
im_detect: 2932/4952 0.149s 0.002s
im_detect: 2933/4952 0.149s 0.002s
im_detect: 2934/4952 0.149s 0.002s
im_detect: 2935/4952 0.149s 0.002s
im_detect: 2936/4952 0.149s 0.002s
im_detect: 2937/4952 0.149s 0.002s
im_detect: 2938/4952 0.149s 0.002s
im_detect: 2939/4952 0.149s 0.002s
im_detect: 2940/4952 0.149s 0.002s
im_detect: 2941/4952 0.149s 0.002s
im_detect: 2942/4952 0.149s 0.002s
im_detect: 2943/4952 0.149s 0.002s
im_detect: 2944/4952 0.149s 0.002s
im_detect: 2945/4952 0.149s 0.002s
im_detect: 2946/4952 0.149s 0.002s
im_detect: 2947/4952 0.149s 0.002s
im_detect: 2948/4952 0.149s 0.002s
im_detect: 2949/4952 0.149s 0.002s
im_detect: 2950/4952 0.149s 0.002s
im_detect: 2951/4952 0.149s 0.002s
im_detect: 2952/4952 0.149s 0.002s
im_detect: 2953/4952 0.149s 0.002s
im_detect: 2954/4952 0.149s 0.002s
im_detect: 2955/4952 0.149s 0.002s
im_detect: 2956/4952 0.149s 0.002s
im_detect: 2957/4952 0.149s 0.002s
im_detect: 2958/4952 0.149s 0.002s
im_detect: 2959/4952 0.149s 0.002s
im_detect: 2960/4952 0.149s 0.002s
im_detect: 2961/4952 0.149s 0.002s
im_detect: 2962/4952 0.149s 0.002s
im_detect: 2963/4952 0.149s 0.002s
im_detect: 2964/4952 0.149s 0.002s
im_detect: 2965/4952 0.149s 0.002s
im_detect: 2966/4952 0.149s 0.002s
im_detect: 2967/4952 0.149s 0.002s
im_detect: 2968/4952 0.149s 0.002s
im_detect: 2969/4952 0.149s 0.002s
im_detect: 2970/4952 0.149s 0.002s
im_detect: 2971/4952 0.149s 0.002s
im_detect: 2972/4952 0.149s 0.002s
im_detect: 2973/4952 0.149s 0.002s
im_detect: 2974/4952 0.149s 0.002s
im_detect: 2975/4952 0.149s 0.002s
im_detect: 2976/4952 0.149s 0.002s
im_detect: 2977/4952 0.149s 0.002s
im_detect: 2978/4952 0.149s 0.002s
im_detect: 2979/4952 0.149s 0.002s
im_detect: 2980/4952 0.149s 0.002s
im_detect: 2981/4952 0.149s 0.002s
im_detect: 2982/4952 0.149s 0.002s
im_detect: 2983/4952 0.149s 0.002s
im_detect: 2984/4952 0.149s 0.002s
im_detect: 2985/4952 0.149s 0.002s
im_detect: 2986/4952 0.149s 0.002s
im_detect: 2987/4952 0.149s 0.002s
im_detect: 2988/4952 0.149s 0.002s
im_detect: 2989/4952 0.149s 0.002s
im_detect: 2990/4952 0.149s 0.002s
im_detect: 2991/4952 0.149s 0.002s
im_detect: 2992/4952 0.149s 0.002s
im_detect: 2993/4952 0.149s 0.002s
im_detect: 2994/4952 0.149s 0.002s
im_detect: 2995/4952 0.149s 0.002s
im_detect: 2996/4952 0.149s 0.002s
im_detect: 2997/4952 0.149s 0.002s
im_detect: 2998/4952 0.149s 0.002s
im_detect: 2999/4952 0.149s 0.002s
im_detect: 3000/4952 0.149s 0.002s
im_detect: 3001/4952 0.149s 0.002s
im_detect: 3002/4952 0.149s 0.002s
im_detect: 3003/4952 0.149s 0.002s
im_detect: 3004/4952 0.149s 0.002s
im_detect: 3005/4952 0.149s 0.002s
im_detect: 3006/4952 0.149s 0.002s
im_detect: 3007/4952 0.149s 0.002s
im_detect: 3008/4952 0.149s 0.002s
im_detect: 3009/4952 0.149s 0.002s
im_detect: 3010/4952 0.149s 0.002s
im_detect: 3011/4952 0.149s 0.002s
im_detect: 3012/4952 0.149s 0.002s
im_detect: 3013/4952 0.149s 0.002s
im_detect: 3014/4952 0.149s 0.002s
im_detect: 3015/4952 0.149s 0.002s
im_detect: 3016/4952 0.149s 0.002s
im_detect: 3017/4952 0.149s 0.002s
im_detect: 3018/4952 0.149s 0.002s
im_detect: 3019/4952 0.149s 0.002s
im_detect: 3020/4952 0.149s 0.002s
im_detect: 3021/4952 0.149s 0.002s
im_detect: 3022/4952 0.149s 0.002s
im_detect: 3023/4952 0.149s 0.002s
im_detect: 3024/4952 0.149s 0.002s
im_detect: 3025/4952 0.149s 0.002s
im_detect: 3026/4952 0.149s 0.002s
im_detect: 3027/4952 0.149s 0.002s
im_detect: 3028/4952 0.149s 0.002s
im_detect: 3029/4952 0.149s 0.002s
im_detect: 3030/4952 0.149s 0.002s
im_detect: 3031/4952 0.149s 0.002s
im_detect: 3032/4952 0.149s 0.002s
im_detect: 3033/4952 0.149s 0.002s
im_detect: 3034/4952 0.149s 0.002s
im_detect: 3035/4952 0.149s 0.002s
im_detect: 3036/4952 0.149s 0.002s
im_detect: 3037/4952 0.149s 0.002s
im_detect: 3038/4952 0.149s 0.002s
im_detect: 3039/4952 0.149s 0.002s
im_detect: 3040/4952 0.149s 0.002s
im_detect: 3041/4952 0.149s 0.002s
im_detect: 3042/4952 0.149s 0.002s
im_detect: 3043/4952 0.149s 0.002s
im_detect: 3044/4952 0.149s 0.002s
im_detect: 3045/4952 0.149s 0.002s
im_detect: 3046/4952 0.149s 0.003s
im_detect: 3047/4952 0.149s 0.003s
im_detect: 3048/4952 0.149s 0.003s
im_detect: 3049/4952 0.149s 0.003s
im_detect: 3050/4952 0.149s 0.003s
im_detect: 3051/4952 0.149s 0.003s
im_detect: 3052/4952 0.149s 0.003s
im_detect: 3053/4952 0.149s 0.003s
im_detect: 3054/4952 0.149s 0.003s
im_detect: 3055/4952 0.149s 0.003s
im_detect: 3056/4952 0.149s 0.003s
im_detect: 3057/4952 0.149s 0.003s
im_detect: 3058/4952 0.149s 0.003s
im_detect: 3059/4952 0.149s 0.003s
im_detect: 3060/4952 0.149s 0.003s
im_detect: 3061/4952 0.149s 0.003s
im_detect: 3062/4952 0.149s 0.003s
im_detect: 3063/4952 0.149s 0.003s
im_detect: 3064/4952 0.149s 0.003s
im_detect: 3065/4952 0.149s 0.003s
im_detect: 3066/4952 0.149s 0.003s
im_detect: 3067/4952 0.149s 0.003s
im_detect: 3068/4952 0.149s 0.003s
im_detect: 3069/4952 0.149s 0.003s
im_detect: 3070/4952 0.149s 0.003s
im_detect: 3071/4952 0.149s 0.003s
im_detect: 3072/4952 0.149s 0.003s
im_detect: 3073/4952 0.149s 0.003s
im_detect: 3074/4952 0.149s 0.003s
im_detect: 3075/4952 0.149s 0.003s
im_detect: 3076/4952 0.149s 0.003s
im_detect: 3077/4952 0.149s 0.003s
im_detect: 3078/4952 0.149s 0.003s
im_detect: 3079/4952 0.149s 0.003s
im_detect: 3080/4952 0.149s 0.003s
im_detect: 3081/4952 0.149s 0.003s
im_detect: 3082/4952 0.149s 0.003s
im_detect: 3083/4952 0.149s 0.003s
im_detect: 3084/4952 0.149s 0.003s
im_detect: 3085/4952 0.149s 0.003s
im_detect: 3086/4952 0.149s 0.003s
im_detect: 3087/4952 0.149s 0.003s
im_detect: 3088/4952 0.149s 0.003s
im_detect: 3089/4952 0.149s 0.003s
im_detect: 3090/4952 0.149s 0.003s
im_detect: 3091/4952 0.149s 0.003s
im_detect: 3092/4952 0.149s 0.003s
im_detect: 3093/4952 0.149s 0.003s
im_detect: 3094/4952 0.149s 0.003s
im_detect: 3095/4952 0.149s 0.003s
im_detect: 3096/4952 0.149s 0.003s
im_detect: 3097/4952 0.149s 0.003s
im_detect: 3098/4952 0.149s 0.003s
im_detect: 3099/4952 0.149s 0.003s
im_detect: 3100/4952 0.149s 0.003s
im_detect: 3101/4952 0.149s 0.003s
im_detect: 3102/4952 0.149s 0.003s
im_detect: 3103/4952 0.149s 0.003s
im_detect: 3104/4952 0.149s 0.003s
im_detect: 3105/4952 0.149s 0.003s
im_detect: 3106/4952 0.149s 0.003s
im_detect: 3107/4952 0.149s 0.003s
im_detect: 3108/4952 0.149s 0.003s
im_detect: 3109/4952 0.149s 0.003s
im_detect: 3110/4952 0.149s 0.003s
im_detect: 3111/4952 0.149s 0.003s
im_detect: 3112/4952 0.149s 0.003s
im_detect: 3113/4952 0.149s 0.003s
im_detect: 3114/4952 0.149s 0.003s
im_detect: 3115/4952 0.149s 0.003s
im_detect: 3116/4952 0.149s 0.003s
im_detect: 3117/4952 0.149s 0.003s
im_detect: 3118/4952 0.149s 0.003s
im_detect: 3119/4952 0.149s 0.003s
im_detect: 3120/4952 0.149s 0.003s
im_detect: 3121/4952 0.149s 0.003s
im_detect: 3122/4952 0.149s 0.003s
im_detect: 3123/4952 0.149s 0.003s
im_detect: 3124/4952 0.149s 0.003s
im_detect: 3125/4952 0.149s 0.003s
im_detect: 3126/4952 0.149s 0.003s
im_detect: 3127/4952 0.149s 0.003s
im_detect: 3128/4952 0.149s 0.003s
im_detect: 3129/4952 0.149s 0.003s
im_detect: 3130/4952 0.149s 0.003s
im_detect: 3131/4952 0.149s 0.003s
im_detect: 3132/4952 0.149s 0.003s
im_detect: 3133/4952 0.149s 0.003s
im_detect: 3134/4952 0.149s 0.003s
im_detect: 3135/4952 0.149s 0.003s
im_detect: 3136/4952 0.149s 0.003s
im_detect: 3137/4952 0.149s 0.003s
im_detect: 3138/4952 0.149s 0.003s
im_detect: 3139/4952 0.149s 0.003s
im_detect: 3140/4952 0.149s 0.003s
im_detect: 3141/4952 0.149s 0.003s
im_detect: 3142/4952 0.149s 0.003s
im_detect: 3143/4952 0.149s 0.003s
im_detect: 3144/4952 0.149s 0.003s
im_detect: 3145/4952 0.149s 0.003s
im_detect: 3146/4952 0.149s 0.003s
im_detect: 3147/4952 0.149s 0.003s
im_detect: 3148/4952 0.149s 0.003s
im_detect: 3149/4952 0.149s 0.003s
im_detect: 3150/4952 0.149s 0.003s
im_detect: 3151/4952 0.149s 0.003s
im_detect: 3152/4952 0.149s 0.003s
im_detect: 3153/4952 0.149s 0.003s
im_detect: 3154/4952 0.149s 0.003s
im_detect: 3155/4952 0.149s 0.003s
im_detect: 3156/4952 0.149s 0.003s
im_detect: 3157/4952 0.149s 0.003s
im_detect: 3158/4952 0.149s 0.003s
im_detect: 3159/4952 0.149s 0.003s
im_detect: 3160/4952 0.149s 0.003s
im_detect: 3161/4952 0.149s 0.003s
im_detect: 3162/4952 0.149s 0.003s
im_detect: 3163/4952 0.149s 0.003s
im_detect: 3164/4952 0.149s 0.003s
im_detect: 3165/4952 0.149s 0.003s
im_detect: 3166/4952 0.149s 0.003s
im_detect: 3167/4952 0.149s 0.003s
im_detect: 3168/4952 0.149s 0.003s
im_detect: 3169/4952 0.149s 0.003s
im_detect: 3170/4952 0.149s 0.003s
im_detect: 3171/4952 0.149s 0.003s
im_detect: 3172/4952 0.149s 0.003s
im_detect: 3173/4952 0.149s 0.003s
im_detect: 3174/4952 0.149s 0.003s
im_detect: 3175/4952 0.149s 0.003s
im_detect: 3176/4952 0.149s 0.003s
im_detect: 3177/4952 0.149s 0.003s
im_detect: 3178/4952 0.149s 0.003s
im_detect: 3179/4952 0.149s 0.003s
im_detect: 3180/4952 0.149s 0.003s
im_detect: 3181/4952 0.149s 0.003s
im_detect: 3182/4952 0.149s 0.003s
im_detect: 3183/4952 0.149s 0.003s
im_detect: 3184/4952 0.149s 0.003s
im_detect: 3185/4952 0.149s 0.003s
im_detect: 3186/4952 0.149s 0.003s
im_detect: 3187/4952 0.149s 0.003s
im_detect: 3188/4952 0.149s 0.003s
im_detect: 3189/4952 0.149s 0.003s
im_detect: 3190/4952 0.149s 0.003s
im_detect: 3191/4952 0.149s 0.003s
im_detect: 3192/4952 0.149s 0.003s
im_detect: 3193/4952 0.149s 0.003s
im_detect: 3194/4952 0.149s 0.003s
im_detect: 3195/4952 0.149s 0.003s
im_detect: 3196/4952 0.149s 0.003s
im_detect: 3197/4952 0.149s 0.003s
im_detect: 3198/4952 0.149s 0.003s
im_detect: 3199/4952 0.149s 0.003s
im_detect: 3200/4952 0.149s 0.003s
im_detect: 3201/4952 0.149s 0.003s
im_detect: 3202/4952 0.149s 0.003s
im_detect: 3203/4952 0.149s 0.003s
im_detect: 3204/4952 0.149s 0.003s
im_detect: 3205/4952 0.149s 0.003s
im_detect: 3206/4952 0.149s 0.003s
im_detect: 3207/4952 0.149s 0.003s
im_detect: 3208/4952 0.149s 0.003s
im_detect: 3209/4952 0.149s 0.003s
im_detect: 3210/4952 0.149s 0.003s
im_detect: 3211/4952 0.149s 0.003s
im_detect: 3212/4952 0.149s 0.003s
im_detect: 3213/4952 0.149s 0.003s
im_detect: 3214/4952 0.149s 0.003s
im_detect: 3215/4952 0.149s 0.003s
im_detect: 3216/4952 0.149s 0.003s
im_detect: 3217/4952 0.149s 0.003s
im_detect: 3218/4952 0.149s 0.003s
im_detect: 3219/4952 0.149s 0.003s
im_detect: 3220/4952 0.149s 0.003s
im_detect: 3221/4952 0.149s 0.003s
im_detect: 3222/4952 0.149s 0.003s
im_detect: 3223/4952 0.149s 0.003s
im_detect: 3224/4952 0.149s 0.003s
im_detect: 3225/4952 0.149s 0.003s
im_detect: 3226/4952 0.149s 0.003s
im_detect: 3227/4952 0.149s 0.003s
im_detect: 3228/4952 0.149s 0.003s
im_detect: 3229/4952 0.149s 0.003s
im_detect: 3230/4952 0.149s 0.003s
im_detect: 3231/4952 0.149s 0.003s
im_detect: 3232/4952 0.149s 0.003s
im_detect: 3233/4952 0.149s 0.003s
im_detect: 3234/4952 0.149s 0.003s
im_detect: 3235/4952 0.149s 0.003s
im_detect: 3236/4952 0.149s 0.003s
im_detect: 3237/4952 0.149s 0.003s
im_detect: 3238/4952 0.149s 0.003s
im_detect: 3239/4952 0.149s 0.003s
im_detect: 3240/4952 0.149s 0.003s
im_detect: 3241/4952 0.149s 0.003s
im_detect: 3242/4952 0.149s 0.003s
im_detect: 3243/4952 0.149s 0.003s
im_detect: 3244/4952 0.149s 0.003s
im_detect: 3245/4952 0.149s 0.003s
im_detect: 3246/4952 0.149s 0.003s
im_detect: 3247/4952 0.149s 0.003s
im_detect: 3248/4952 0.149s 0.003s
im_detect: 3249/4952 0.149s 0.003s
im_detect: 3250/4952 0.149s 0.003s
im_detect: 3251/4952 0.149s 0.003s
im_detect: 3252/4952 0.149s 0.003s
im_detect: 3253/4952 0.149s 0.003s
im_detect: 3254/4952 0.149s 0.003s
im_detect: 3255/4952 0.149s 0.003s
im_detect: 3256/4952 0.149s 0.003s
im_detect: 3257/4952 0.149s 0.003s
im_detect: 3258/4952 0.149s 0.003s
im_detect: 3259/4952 0.149s 0.003s
im_detect: 3260/4952 0.149s 0.003s
im_detect: 3261/4952 0.149s 0.003s
im_detect: 3262/4952 0.149s 0.003s
im_detect: 3263/4952 0.149s 0.003s
im_detect: 3264/4952 0.149s 0.003s
im_detect: 3265/4952 0.149s 0.003s
im_detect: 3266/4952 0.149s 0.003s
im_detect: 3267/4952 0.149s 0.003s
im_detect: 3268/4952 0.149s 0.003s
im_detect: 3269/4952 0.149s 0.003s
im_detect: 3270/4952 0.149s 0.003s
im_detect: 3271/4952 0.149s 0.003s
im_detect: 3272/4952 0.149s 0.003s
im_detect: 3273/4952 0.149s 0.003s
im_detect: 3274/4952 0.149s 0.003s
im_detect: 3275/4952 0.149s 0.003s
im_detect: 3276/4952 0.149s 0.003s
im_detect: 3277/4952 0.149s 0.003s
im_detect: 3278/4952 0.149s 0.003s
im_detect: 3279/4952 0.149s 0.003s
im_detect: 3280/4952 0.149s 0.003s
im_detect: 3281/4952 0.149s 0.003s
im_detect: 3282/4952 0.149s 0.003s
im_detect: 3283/4952 0.149s 0.003s
im_detect: 3284/4952 0.149s 0.003s
im_detect: 3285/4952 0.149s 0.003s
im_detect: 3286/4952 0.149s 0.003s
im_detect: 3287/4952 0.149s 0.003s
im_detect: 3288/4952 0.149s 0.003s
im_detect: 3289/4952 0.149s 0.003s
im_detect: 3290/4952 0.149s 0.003s
im_detect: 3291/4952 0.149s 0.003s
im_detect: 3292/4952 0.149s 0.003s
im_detect: 3293/4952 0.149s 0.003s
im_detect: 3294/4952 0.149s 0.003s
im_detect: 3295/4952 0.149s 0.003s
im_detect: 3296/4952 0.149s 0.003s
im_detect: 3297/4952 0.149s 0.003s
im_detect: 3298/4952 0.149s 0.003s
im_detect: 3299/4952 0.149s 0.003s
im_detect: 3300/4952 0.149s 0.003s
im_detect: 3301/4952 0.149s 0.003s
im_detect: 3302/4952 0.149s 0.003s
im_detect: 3303/4952 0.149s 0.003s
im_detect: 3304/4952 0.149s 0.003s
im_detect: 3305/4952 0.149s 0.003s
im_detect: 3306/4952 0.149s 0.003s
im_detect: 3307/4952 0.149s 0.003s
im_detect: 3308/4952 0.149s 0.003s
im_detect: 3309/4952 0.149s 0.003s
im_detect: 3310/4952 0.149s 0.003s
im_detect: 3311/4952 0.149s 0.003s
im_detect: 3312/4952 0.149s 0.003s
im_detect: 3313/4952 0.149s 0.003s
im_detect: 3314/4952 0.149s 0.003s
im_detect: 3315/4952 0.149s 0.003s
im_detect: 3316/4952 0.149s 0.003s
im_detect: 3317/4952 0.149s 0.003s
im_detect: 3318/4952 0.149s 0.003s
im_detect: 3319/4952 0.149s 0.003s
im_detect: 3320/4952 0.149s 0.003s
im_detect: 3321/4952 0.149s 0.003s
im_detect: 3322/4952 0.149s 0.003s
im_detect: 3323/4952 0.149s 0.003s
im_detect: 3324/4952 0.149s 0.003s
im_detect: 3325/4952 0.149s 0.003s
im_detect: 3326/4952 0.149s 0.003s
im_detect: 3327/4952 0.149s 0.003s
im_detect: 3328/4952 0.149s 0.003s
im_detect: 3329/4952 0.149s 0.003s
im_detect: 3330/4952 0.149s 0.003s
im_detect: 3331/4952 0.149s 0.003s
im_detect: 3332/4952 0.149s 0.003s
im_detect: 3333/4952 0.149s 0.003s
im_detect: 3334/4952 0.149s 0.003s
im_detect: 3335/4952 0.149s 0.003s
im_detect: 3336/4952 0.149s 0.003s
im_detect: 3337/4952 0.149s 0.003s
im_detect: 3338/4952 0.149s 0.003s
im_detect: 3339/4952 0.149s 0.003s
im_detect: 3340/4952 0.149s 0.003s
im_detect: 3341/4952 0.149s 0.003s
im_detect: 3342/4952 0.149s 0.003s
im_detect: 3343/4952 0.149s 0.003s
im_detect: 3344/4952 0.149s 0.003s
im_detect: 3345/4952 0.149s 0.003s
im_detect: 3346/4952 0.149s 0.003s
im_detect: 3347/4952 0.149s 0.003s
im_detect: 3348/4952 0.149s 0.003s
im_detect: 3349/4952 0.149s 0.003s
im_detect: 3350/4952 0.149s 0.003s
im_detect: 3351/4952 0.149s 0.003s
im_detect: 3352/4952 0.149s 0.003s
im_detect: 3353/4952 0.149s 0.003s
im_detect: 3354/4952 0.149s 0.003s
im_detect: 3355/4952 0.149s 0.003s
im_detect: 3356/4952 0.149s 0.003s
im_detect: 3357/4952 0.149s 0.003s
im_detect: 3358/4952 0.149s 0.003s
im_detect: 3359/4952 0.149s 0.003s
im_detect: 3360/4952 0.149s 0.003s
im_detect: 3361/4952 0.149s 0.003s
im_detect: 3362/4952 0.149s 0.003s
im_detect: 3363/4952 0.149s 0.003s
im_detect: 3364/4952 0.149s 0.003s
im_detect: 3365/4952 0.149s 0.003s
im_detect: 3366/4952 0.149s 0.003s
im_detect: 3367/4952 0.149s 0.003s
im_detect: 3368/4952 0.149s 0.003s
im_detect: 3369/4952 0.149s 0.003s
im_detect: 3370/4952 0.149s 0.003s
im_detect: 3371/4952 0.149s 0.003s
im_detect: 3372/4952 0.149s 0.003s
im_detect: 3373/4952 0.149s 0.003s
im_detect: 3374/4952 0.149s 0.003s
im_detect: 3375/4952 0.149s 0.003s
im_detect: 3376/4952 0.149s 0.003s
im_detect: 3377/4952 0.149s 0.003s
im_detect: 3378/4952 0.149s 0.003s
im_detect: 3379/4952 0.149s 0.003s
im_detect: 3380/4952 0.149s 0.003s
im_detect: 3381/4952 0.149s 0.003s
im_detect: 3382/4952 0.149s 0.003s
im_detect: 3383/4952 0.149s 0.003s
im_detect: 3384/4952 0.149s 0.003s
im_detect: 3385/4952 0.149s 0.003s
im_detect: 3386/4952 0.149s 0.003s
im_detect: 3387/4952 0.149s 0.003s
im_detect: 3388/4952 0.149s 0.003s
im_detect: 3389/4952 0.149s 0.003s
im_detect: 3390/4952 0.149s 0.003s
im_detect: 3391/4952 0.149s 0.003s
im_detect: 3392/4952 0.149s 0.003s
im_detect: 3393/4952 0.149s 0.003s
im_detect: 3394/4952 0.149s 0.003s
im_detect: 3395/4952 0.149s 0.003s
im_detect: 3396/4952 0.149s 0.003s
im_detect: 3397/4952 0.149s 0.003s
im_detect: 3398/4952 0.149s 0.003s
im_detect: 3399/4952 0.149s 0.003s
im_detect: 3400/4952 0.149s 0.003s
im_detect: 3401/4952 0.149s 0.003s
im_detect: 3402/4952 0.149s 0.003s
im_detect: 3403/4952 0.149s 0.003s
im_detect: 3404/4952 0.149s 0.003s
im_detect: 3405/4952 0.149s 0.003s
im_detect: 3406/4952 0.149s 0.003s
im_detect: 3407/4952 0.149s 0.003s
im_detect: 3408/4952 0.149s 0.003s
im_detect: 3409/4952 0.149s 0.003s
im_detect: 3410/4952 0.149s 0.003s
im_detect: 3411/4952 0.149s 0.003s
im_detect: 3412/4952 0.149s 0.003s
im_detect: 3413/4952 0.149s 0.003s
im_detect: 3414/4952 0.149s 0.003s
im_detect: 3415/4952 0.149s 0.003s
im_detect: 3416/4952 0.149s 0.003s
im_detect: 3417/4952 0.149s 0.003s
im_detect: 3418/4952 0.149s 0.003s
im_detect: 3419/4952 0.149s 0.003s
im_detect: 3420/4952 0.149s 0.003s
im_detect: 3421/4952 0.149s 0.003s
im_detect: 3422/4952 0.149s 0.003s
im_detect: 3423/4952 0.149s 0.003s
im_detect: 3424/4952 0.149s 0.003s
im_detect: 3425/4952 0.149s 0.003s
im_detect: 3426/4952 0.149s 0.003s
im_detect: 3427/4952 0.149s 0.003s
im_detect: 3428/4952 0.149s 0.003s
im_detect: 3429/4952 0.149s 0.003s
im_detect: 3430/4952 0.149s 0.003s
im_detect: 3431/4952 0.149s 0.003s
im_detect: 3432/4952 0.149s 0.003s
im_detect: 3433/4952 0.149s 0.003s
im_detect: 3434/4952 0.149s 0.003s
im_detect: 3435/4952 0.149s 0.003s
im_detect: 3436/4952 0.149s 0.003s
im_detect: 3437/4952 0.149s 0.003s
im_detect: 3438/4952 0.149s 0.003s
im_detect: 3439/4952 0.149s 0.003s
im_detect: 3440/4952 0.149s 0.003s
im_detect: 3441/4952 0.149s 0.003s
im_detect: 3442/4952 0.149s 0.003s
im_detect: 3443/4952 0.149s 0.003s
im_detect: 3444/4952 0.149s 0.003s
im_detect: 3445/4952 0.149s 0.003s
im_detect: 3446/4952 0.149s 0.003s
im_detect: 3447/4952 0.149s 0.003s
im_detect: 3448/4952 0.149s 0.003s
im_detect: 3449/4952 0.149s 0.003s
im_detect: 3450/4952 0.149s 0.003s
im_detect: 3451/4952 0.149s 0.003s
im_detect: 3452/4952 0.149s 0.003s
im_detect: 3453/4952 0.149s 0.003s
im_detect: 3454/4952 0.149s 0.003s
im_detect: 3455/4952 0.149s 0.003s
im_detect: 3456/4952 0.149s 0.003s
im_detect: 3457/4952 0.149s 0.003s
im_detect: 3458/4952 0.149s 0.003s
im_detect: 3459/4952 0.149s 0.003s
im_detect: 3460/4952 0.149s 0.003s
im_detect: 3461/4952 0.149s 0.003s
im_detect: 3462/4952 0.149s 0.003s
im_detect: 3463/4952 0.149s 0.003s
im_detect: 3464/4952 0.149s 0.003s
im_detect: 3465/4952 0.149s 0.003s
im_detect: 3466/4952 0.149s 0.003s
im_detect: 3467/4952 0.149s 0.003s
im_detect: 3468/4952 0.149s 0.003s
im_detect: 3469/4952 0.149s 0.003s
im_detect: 3470/4952 0.149s 0.003s
im_detect: 3471/4952 0.149s 0.003s
im_detect: 3472/4952 0.149s 0.003s
im_detect: 3473/4952 0.149s 0.003s
im_detect: 3474/4952 0.149s 0.003s
im_detect: 3475/4952 0.149s 0.003s
im_detect: 3476/4952 0.149s 0.003s
im_detect: 3477/4952 0.149s 0.003s
im_detect: 3478/4952 0.149s 0.003s
im_detect: 3479/4952 0.149s 0.003s
im_detect: 3480/4952 0.149s 0.003s
im_detect: 3481/4952 0.149s 0.003s
im_detect: 3482/4952 0.149s 0.003s
im_detect: 3483/4952 0.149s 0.003s
im_detect: 3484/4952 0.149s 0.003s
im_detect: 3485/4952 0.149s 0.003s
im_detect: 3486/4952 0.149s 0.003s
im_detect: 3487/4952 0.149s 0.003s
im_detect: 3488/4952 0.149s 0.003s
im_detect: 3489/4952 0.149s 0.003s
im_detect: 3490/4952 0.149s 0.003s
im_detect: 3491/4952 0.149s 0.003s
im_detect: 3492/4952 0.149s 0.003s
im_detect: 3493/4952 0.149s 0.003s
im_detect: 3494/4952 0.149s 0.003s
im_detect: 3495/4952 0.149s 0.003s
im_detect: 3496/4952 0.149s 0.003s
im_detect: 3497/4952 0.149s 0.003s
im_detect: 3498/4952 0.149s 0.003s
im_detect: 3499/4952 0.149s 0.003s
im_detect: 3500/4952 0.149s 0.003s
im_detect: 3501/4952 0.149s 0.003s
im_detect: 3502/4952 0.149s 0.003s
im_detect: 3503/4952 0.149s 0.003s
im_detect: 3504/4952 0.149s 0.003s
im_detect: 3505/4952 0.149s 0.003s
im_detect: 3506/4952 0.149s 0.003s
im_detect: 3507/4952 0.149s 0.003s
im_detect: 3508/4952 0.149s 0.003s
im_detect: 3509/4952 0.149s 0.003s
im_detect: 3510/4952 0.149s 0.003s
im_detect: 3511/4952 0.149s 0.003s
im_detect: 3512/4952 0.149s 0.003s
im_detect: 3513/4952 0.149s 0.003s
im_detect: 3514/4952 0.149s 0.003s
im_detect: 3515/4952 0.149s 0.003s
im_detect: 3516/4952 0.149s 0.003s
im_detect: 3517/4952 0.149s 0.003s
im_detect: 3518/4952 0.149s 0.003s
im_detect: 3519/4952 0.149s 0.003s
im_detect: 3520/4952 0.149s 0.003s
im_detect: 3521/4952 0.149s 0.003s
im_detect: 3522/4952 0.149s 0.003s
im_detect: 3523/4952 0.149s 0.003s
im_detect: 3524/4952 0.149s 0.003s
im_detect: 3525/4952 0.149s 0.003s
im_detect: 3526/4952 0.149s 0.003s
im_detect: 3527/4952 0.149s 0.003s
im_detect: 3528/4952 0.149s 0.003s
im_detect: 3529/4952 0.149s 0.003s
im_detect: 3530/4952 0.149s 0.003s
im_detect: 3531/4952 0.149s 0.003s
im_detect: 3532/4952 0.149s 0.003s
im_detect: 3533/4952 0.149s 0.003s
im_detect: 3534/4952 0.149s 0.003s
im_detect: 3535/4952 0.149s 0.003s
im_detect: 3536/4952 0.149s 0.003s
im_detect: 3537/4952 0.149s 0.003s
im_detect: 3538/4952 0.149s 0.003s
im_detect: 3539/4952 0.149s 0.003s
im_detect: 3540/4952 0.149s 0.003s
im_detect: 3541/4952 0.149s 0.003s
im_detect: 3542/4952 0.149s 0.003s
im_detect: 3543/4952 0.149s 0.003s
im_detect: 3544/4952 0.149s 0.003s
im_detect: 3545/4952 0.149s 0.003s
im_detect: 3546/4952 0.149s 0.003s
im_detect: 3547/4952 0.149s 0.003s
im_detect: 3548/4952 0.149s 0.003s
im_detect: 3549/4952 0.149s 0.003s
im_detect: 3550/4952 0.149s 0.003s
im_detect: 3551/4952 0.149s 0.003s
im_detect: 3552/4952 0.149s 0.003s
im_detect: 3553/4952 0.149s 0.003s
im_detect: 3554/4952 0.149s 0.003s
im_detect: 3555/4952 0.149s 0.003s
im_detect: 3556/4952 0.149s 0.003s
im_detect: 3557/4952 0.149s 0.003s
im_detect: 3558/4952 0.149s 0.003s
im_detect: 3559/4952 0.149s 0.003s
im_detect: 3560/4952 0.149s 0.003s
im_detect: 3561/4952 0.149s 0.003s
im_detect: 3562/4952 0.149s 0.003s
im_detect: 3563/4952 0.149s 0.003s
im_detect: 3564/4952 0.149s 0.003s
im_detect: 3565/4952 0.149s 0.003s
im_detect: 3566/4952 0.149s 0.003s
im_detect: 3567/4952 0.149s 0.003s
im_detect: 3568/4952 0.149s 0.003s
im_detect: 3569/4952 0.149s 0.003s
im_detect: 3570/4952 0.149s 0.003s
im_detect: 3571/4952 0.149s 0.003s
im_detect: 3572/4952 0.149s 0.003s
im_detect: 3573/4952 0.149s 0.003s
im_detect: 3574/4952 0.149s 0.003s
im_detect: 3575/4952 0.149s 0.003s
im_detect: 3576/4952 0.149s 0.003s
im_detect: 3577/4952 0.149s 0.003s
im_detect: 3578/4952 0.149s 0.003s
im_detect: 3579/4952 0.149s 0.003s
im_detect: 3580/4952 0.149s 0.003s
im_detect: 3581/4952 0.149s 0.003s
im_detect: 3582/4952 0.149s 0.003s
im_detect: 3583/4952 0.149s 0.003s
im_detect: 3584/4952 0.149s 0.003s
im_detect: 3585/4952 0.149s 0.003s
im_detect: 3586/4952 0.149s 0.003s
im_detect: 3587/4952 0.149s 0.003s
im_detect: 3588/4952 0.149s 0.003s
im_detect: 3589/4952 0.149s 0.003s
im_detect: 3590/4952 0.149s 0.003s
im_detect: 3591/4952 0.149s 0.003s
im_detect: 3592/4952 0.149s 0.003s
im_detect: 3593/4952 0.149s 0.003s
im_detect: 3594/4952 0.149s 0.003s
im_detect: 3595/4952 0.149s 0.003s
im_detect: 3596/4952 0.149s 0.003s
im_detect: 3597/4952 0.149s 0.003s
im_detect: 3598/4952 0.149s 0.003s
im_detect: 3599/4952 0.149s 0.003s
im_detect: 3600/4952 0.149s 0.003s
im_detect: 3601/4952 0.149s 0.003s
im_detect: 3602/4952 0.149s 0.003s
im_detect: 3603/4952 0.149s 0.003s
im_detect: 3604/4952 0.149s 0.003s
im_detect: 3605/4952 0.149s 0.003s
im_detect: 3606/4952 0.149s 0.003s
im_detect: 3607/4952 0.149s 0.003s
im_detect: 3608/4952 0.149s 0.003s
im_detect: 3609/4952 0.149s 0.003s
im_detect: 3610/4952 0.149s 0.003s
im_detect: 3611/4952 0.149s 0.003s
im_detect: 3612/4952 0.149s 0.003s
im_detect: 3613/4952 0.149s 0.003s
im_detect: 3614/4952 0.149s 0.003s
im_detect: 3615/4952 0.149s 0.003s
im_detect: 3616/4952 0.149s 0.003s
im_detect: 3617/4952 0.149s 0.003s
im_detect: 3618/4952 0.149s 0.003s
im_detect: 3619/4952 0.149s 0.003s
im_detect: 3620/4952 0.149s 0.003s
im_detect: 3621/4952 0.149s 0.003s
im_detect: 3622/4952 0.149s 0.003s
im_detect: 3623/4952 0.149s 0.003s
im_detect: 3624/4952 0.149s 0.003s
im_detect: 3625/4952 0.149s 0.003s
im_detect: 3626/4952 0.149s 0.003s
im_detect: 3627/4952 0.149s 0.003s
im_detect: 3628/4952 0.149s 0.003s
im_detect: 3629/4952 0.149s 0.003s
im_detect: 3630/4952 0.149s 0.003s
im_detect: 3631/4952 0.149s 0.003s
im_detect: 3632/4952 0.149s 0.003s
im_detect: 3633/4952 0.149s 0.003s
im_detect: 3634/4952 0.149s 0.003s
im_detect: 3635/4952 0.149s 0.003s
im_detect: 3636/4952 0.149s 0.003s
im_detect: 3637/4952 0.149s 0.003s
im_detect: 3638/4952 0.149s 0.003s
im_detect: 3639/4952 0.149s 0.003s
im_detect: 3640/4952 0.149s 0.003s
im_detect: 3641/4952 0.149s 0.003s
im_detect: 3642/4952 0.149s 0.003s
im_detect: 3643/4952 0.149s 0.003s
im_detect: 3644/4952 0.149s 0.003s
im_detect: 3645/4952 0.149s 0.003s
im_detect: 3646/4952 0.149s 0.003s
im_detect: 3647/4952 0.149s 0.003s
im_detect: 3648/4952 0.149s 0.003s
im_detect: 3649/4952 0.149s 0.003s
im_detect: 3650/4952 0.149s 0.003s
im_detect: 3651/4952 0.149s 0.003s
im_detect: 3652/4952 0.149s 0.003s
im_detect: 3653/4952 0.149s 0.003s
im_detect: 3654/4952 0.149s 0.003s
im_detect: 3655/4952 0.149s 0.003s
im_detect: 3656/4952 0.149s 0.003s
im_detect: 3657/4952 0.149s 0.003s
im_detect: 3658/4952 0.149s 0.003s
im_detect: 3659/4952 0.149s 0.003s
im_detect: 3660/4952 0.149s 0.003s
im_detect: 3661/4952 0.149s 0.003s
im_detect: 3662/4952 0.149s 0.003s
im_detect: 3663/4952 0.149s 0.003s
im_detect: 3664/4952 0.149s 0.003s
im_detect: 3665/4952 0.149s 0.003s
im_detect: 3666/4952 0.149s 0.003s
im_detect: 3667/4952 0.149s 0.003s
im_detect: 3668/4952 0.149s 0.003s
im_detect: 3669/4952 0.149s 0.003s
im_detect: 3670/4952 0.149s 0.003s
im_detect: 3671/4952 0.149s 0.003s
im_detect: 3672/4952 0.149s 0.003s
im_detect: 3673/4952 0.149s 0.003s
im_detect: 3674/4952 0.149s 0.003s
im_detect: 3675/4952 0.149s 0.003s
im_detect: 3676/4952 0.149s 0.003s
im_detect: 3677/4952 0.149s 0.003s
im_detect: 3678/4952 0.149s 0.003s
im_detect: 3679/4952 0.149s 0.003s
im_detect: 3680/4952 0.149s 0.003s
im_detect: 3681/4952 0.149s 0.003s
im_detect: 3682/4952 0.149s 0.003s
im_detect: 3683/4952 0.149s 0.003s
im_detect: 3684/4952 0.149s 0.003s
im_detect: 3685/4952 0.149s 0.003s
im_detect: 3686/4952 0.149s 0.003s
im_detect: 3687/4952 0.149s 0.003s
im_detect: 3688/4952 0.149s 0.003s
im_detect: 3689/4952 0.149s 0.003s
im_detect: 3690/4952 0.149s 0.003s
im_detect: 3691/4952 0.149s 0.003s
im_detect: 3692/4952 0.149s 0.003s
im_detect: 3693/4952 0.149s 0.003s
im_detect: 3694/4952 0.149s 0.003s
im_detect: 3695/4952 0.149s 0.003s
im_detect: 3696/4952 0.149s 0.003s
im_detect: 3697/4952 0.149s 0.003s
im_detect: 3698/4952 0.149s 0.003s
im_detect: 3699/4952 0.149s 0.003s
im_detect: 3700/4952 0.149s 0.003s
im_detect: 3701/4952 0.149s 0.003s
im_detect: 3702/4952 0.149s 0.003s
im_detect: 3703/4952 0.149s 0.003s
im_detect: 3704/4952 0.149s 0.003s
im_detect: 3705/4952 0.149s 0.003s
im_detect: 3706/4952 0.149s 0.003s
im_detect: 3707/4952 0.149s 0.003s
im_detect: 3708/4952 0.149s 0.003s
im_detect: 3709/4952 0.149s 0.003s
im_detect: 3710/4952 0.149s 0.003s
im_detect: 3711/4952 0.149s 0.003s
im_detect: 3712/4952 0.149s 0.003s
im_detect: 3713/4952 0.149s 0.003s
im_detect: 3714/4952 0.149s 0.003s
im_detect: 3715/4952 0.149s 0.003s
im_detect: 3716/4952 0.149s 0.003s
im_detect: 3717/4952 0.149s 0.003s
im_detect: 3718/4952 0.149s 0.003s
im_detect: 3719/4952 0.149s 0.003s
im_detect: 3720/4952 0.149s 0.003s
im_detect: 3721/4952 0.149s 0.003s
im_detect: 3722/4952 0.149s 0.003s
im_detect: 3723/4952 0.149s 0.003s
im_detect: 3724/4952 0.149s 0.003s
im_detect: 3725/4952 0.149s 0.003s
im_detect: 3726/4952 0.149s 0.003s
im_detect: 3727/4952 0.149s 0.003s
im_detect: 3728/4952 0.149s 0.003s
im_detect: 3729/4952 0.149s 0.003s
im_detect: 3730/4952 0.149s 0.003s
im_detect: 3731/4952 0.149s 0.003s
im_detect: 3732/4952 0.149s 0.003s
im_detect: 3733/4952 0.149s 0.003s
im_detect: 3734/4952 0.149s 0.003s
im_detect: 3735/4952 0.149s 0.003s
im_detect: 3736/4952 0.149s 0.003s
im_detect: 3737/4952 0.149s 0.003s
im_detect: 3738/4952 0.149s 0.003s
im_detect: 3739/4952 0.149s 0.003s
im_detect: 3740/4952 0.149s 0.003s
im_detect: 3741/4952 0.149s 0.003s
im_detect: 3742/4952 0.149s 0.003s
im_detect: 3743/4952 0.149s 0.003s
im_detect: 3744/4952 0.149s 0.003s
im_detect: 3745/4952 0.149s 0.003s
im_detect: 3746/4952 0.149s 0.003s
im_detect: 3747/4952 0.149s 0.003s
im_detect: 3748/4952 0.149s 0.003s
im_detect: 3749/4952 0.149s 0.003s
im_detect: 3750/4952 0.149s 0.003s
im_detect: 3751/4952 0.149s 0.003s
im_detect: 3752/4952 0.149s 0.003s
im_detect: 3753/4952 0.149s 0.003s
im_detect: 3754/4952 0.149s 0.003s
im_detect: 3755/4952 0.149s 0.003s
im_detect: 3756/4952 0.149s 0.003s
im_detect: 3757/4952 0.149s 0.003s
im_detect: 3758/4952 0.149s 0.003s
im_detect: 3759/4952 0.149s 0.003s
im_detect: 3760/4952 0.149s 0.003s
im_detect: 3761/4952 0.149s 0.003s
im_detect: 3762/4952 0.149s 0.003s
im_detect: 3763/4952 0.149s 0.003s
im_detect: 3764/4952 0.149s 0.003s
im_detect: 3765/4952 0.149s 0.003s
im_detect: 3766/4952 0.149s 0.003s
im_detect: 3767/4952 0.149s 0.003s
im_detect: 3768/4952 0.149s 0.003s
im_detect: 3769/4952 0.149s 0.003s
im_detect: 3770/4952 0.149s 0.003s
im_detect: 3771/4952 0.149s 0.003s
im_detect: 3772/4952 0.149s 0.003s
im_detect: 3773/4952 0.149s 0.003s
im_detect: 3774/4952 0.149s 0.003s
im_detect: 3775/4952 0.149s 0.003s
im_detect: 3776/4952 0.149s 0.003s
im_detect: 3777/4952 0.149s 0.003s
im_detect: 3778/4952 0.149s 0.003s
im_detect: 3779/4952 0.149s 0.003s
im_detect: 3780/4952 0.149s 0.003s
im_detect: 3781/4952 0.149s 0.003s
im_detect: 3782/4952 0.149s 0.003s
im_detect: 3783/4952 0.149s 0.003s
im_detect: 3784/4952 0.149s 0.003s
im_detect: 3785/4952 0.149s 0.003s
im_detect: 3786/4952 0.149s 0.003s
im_detect: 3787/4952 0.149s 0.003s
im_detect: 3788/4952 0.149s 0.003s
im_detect: 3789/4952 0.149s 0.003s
im_detect: 3790/4952 0.149s 0.003s
im_detect: 3791/4952 0.149s 0.003s
im_detect: 3792/4952 0.149s 0.003s
im_detect: 3793/4952 0.149s 0.003s
im_detect: 3794/4952 0.149s 0.003s
im_detect: 3795/4952 0.149s 0.003s
im_detect: 3796/4952 0.149s 0.003s
im_detect: 3797/4952 0.149s 0.003s
im_detect: 3798/4952 0.149s 0.003s
im_detect: 3799/4952 0.149s 0.003s
im_detect: 3800/4952 0.149s 0.003s
im_detect: 3801/4952 0.149s 0.003s
im_detect: 3802/4952 0.149s 0.003s
im_detect: 3803/4952 0.149s 0.003s
im_detect: 3804/4952 0.149s 0.003s
im_detect: 3805/4952 0.149s 0.003s
im_detect: 3806/4952 0.149s 0.003s
im_detect: 3807/4952 0.149s 0.003s
im_detect: 3808/4952 0.149s 0.003s
im_detect: 3809/4952 0.149s 0.003s
im_detect: 3810/4952 0.149s 0.003s
im_detect: 3811/4952 0.149s 0.003s
im_detect: 3812/4952 0.149s 0.003s
im_detect: 3813/4952 0.149s 0.003s
im_detect: 3814/4952 0.149s 0.003s
im_detect: 3815/4952 0.149s 0.003s
im_detect: 3816/4952 0.149s 0.003s
im_detect: 3817/4952 0.149s 0.003s
im_detect: 3818/4952 0.149s 0.003s
im_detect: 3819/4952 0.149s 0.003s
im_detect: 3820/4952 0.149s 0.003s
im_detect: 3821/4952 0.149s 0.003s
im_detect: 3822/4952 0.149s 0.003s
im_detect: 3823/4952 0.149s 0.003s
im_detect: 3824/4952 0.149s 0.003s
im_detect: 3825/4952 0.149s 0.003s
im_detect: 3826/4952 0.149s 0.003s
im_detect: 3827/4952 0.149s 0.003s
im_detect: 3828/4952 0.149s 0.003s
im_detect: 3829/4952 0.149s 0.003s
im_detect: 3830/4952 0.149s 0.003s
im_detect: 3831/4952 0.149s 0.003s
im_detect: 3832/4952 0.149s 0.003s
im_detect: 3833/4952 0.149s 0.003s
im_detect: 3834/4952 0.149s 0.003s
im_detect: 3835/4952 0.149s 0.003s
im_detect: 3836/4952 0.149s 0.003s
im_detect: 3837/4952 0.149s 0.003s
im_detect: 3838/4952 0.149s 0.003s
im_detect: 3839/4952 0.149s 0.003s
im_detect: 3840/4952 0.149s 0.003s
im_detect: 3841/4952 0.149s 0.003s
im_detect: 3842/4952 0.149s 0.003s
im_detect: 3843/4952 0.149s 0.003s
im_detect: 3844/4952 0.149s 0.003s
im_detect: 3845/4952 0.149s 0.003s
im_detect: 3846/4952 0.149s 0.003s
im_detect: 3847/4952 0.149s 0.003s
im_detect: 3848/4952 0.149s 0.003s
im_detect: 3849/4952 0.149s 0.003s
im_detect: 3850/4952 0.149s 0.003s
im_detect: 3851/4952 0.149s 0.003s
im_detect: 3852/4952 0.149s 0.003s
im_detect: 3853/4952 0.149s 0.003s
im_detect: 3854/4952 0.149s 0.003s
im_detect: 3855/4952 0.149s 0.003s
im_detect: 3856/4952 0.149s 0.003s
im_detect: 3857/4952 0.149s 0.003s
im_detect: 3858/4952 0.149s 0.003s
im_detect: 3859/4952 0.149s 0.003s
im_detect: 3860/4952 0.149s 0.003s
im_detect: 3861/4952 0.149s 0.003s
im_detect: 3862/4952 0.149s 0.003s
im_detect: 3863/4952 0.149s 0.003s
im_detect: 3864/4952 0.149s 0.003s
im_detect: 3865/4952 0.149s 0.003s
im_detect: 3866/4952 0.149s 0.003s
im_detect: 3867/4952 0.149s 0.003s
im_detect: 3868/4952 0.149s 0.003s
im_detect: 3869/4952 0.149s 0.003s
im_detect: 3870/4952 0.149s 0.003s
im_detect: 3871/4952 0.149s 0.003s
im_detect: 3872/4952 0.149s 0.003s
im_detect: 3873/4952 0.149s 0.003s
im_detect: 3874/4952 0.149s 0.003s
im_detect: 3875/4952 0.149s 0.003s
im_detect: 3876/4952 0.149s 0.003s
im_detect: 3877/4952 0.149s 0.003s
im_detect: 3878/4952 0.149s 0.003s
im_detect: 3879/4952 0.149s 0.003s
im_detect: 3880/4952 0.149s 0.003s
im_detect: 3881/4952 0.149s 0.003s
im_detect: 3882/4952 0.149s 0.003s
im_detect: 3883/4952 0.149s 0.003s
im_detect: 3884/4952 0.149s 0.003s
im_detect: 3885/4952 0.149s 0.003s
im_detect: 3886/4952 0.149s 0.003s
im_detect: 3887/4952 0.149s 0.003s
im_detect: 3888/4952 0.149s 0.003s
im_detect: 3889/4952 0.149s 0.003s
im_detect: 3890/4952 0.149s 0.003s
im_detect: 3891/4952 0.149s 0.003s
im_detect: 3892/4952 0.149s 0.003s
im_detect: 3893/4952 0.149s 0.003s
im_detect: 3894/4952 0.149s 0.003s
im_detect: 3895/4952 0.149s 0.003s
im_detect: 3896/4952 0.149s 0.003s
im_detect: 3897/4952 0.149s 0.003s
im_detect: 3898/4952 0.149s 0.003s
im_detect: 3899/4952 0.149s 0.003s
im_detect: 3900/4952 0.149s 0.003s
im_detect: 3901/4952 0.149s 0.003s
im_detect: 3902/4952 0.149s 0.003s
im_detect: 3903/4952 0.149s 0.003s
im_detect: 3904/4952 0.149s 0.003s
im_detect: 3905/4952 0.149s 0.003s
im_detect: 3906/4952 0.149s 0.003s
im_detect: 3907/4952 0.149s 0.003s
im_detect: 3908/4952 0.149s 0.003s
im_detect: 3909/4952 0.149s 0.003s
im_detect: 3910/4952 0.149s 0.003s
im_detect: 3911/4952 0.149s 0.003s
im_detect: 3912/4952 0.149s 0.003s
im_detect: 3913/4952 0.149s 0.003s
im_detect: 3914/4952 0.149s 0.003s
im_detect: 3915/4952 0.149s 0.003s
im_detect: 3916/4952 0.149s 0.003s
im_detect: 3917/4952 0.149s 0.003s
im_detect: 3918/4952 0.149s 0.003s
im_detect: 3919/4952 0.149s 0.003s
im_detect: 3920/4952 0.149s 0.003s
im_detect: 3921/4952 0.149s 0.003s
im_detect: 3922/4952 0.149s 0.003s
im_detect: 3923/4952 0.149s 0.003s
im_detect: 3924/4952 0.149s 0.003s
im_detect: 3925/4952 0.149s 0.003s
im_detect: 3926/4952 0.149s 0.003s
im_detect: 3927/4952 0.149s 0.003s
im_detect: 3928/4952 0.149s 0.003s
im_detect: 3929/4952 0.149s 0.003s
im_detect: 3930/4952 0.149s 0.003s
im_detect: 3931/4952 0.149s 0.003s
im_detect: 3932/4952 0.149s 0.003s
im_detect: 3933/4952 0.149s 0.003s
im_detect: 3934/4952 0.149s 0.003s
im_detect: 3935/4952 0.149s 0.003s
im_detect: 3936/4952 0.149s 0.003s
im_detect: 3937/4952 0.149s 0.003s
im_detect: 3938/4952 0.149s 0.003s
im_detect: 3939/4952 0.149s 0.003s
im_detect: 3940/4952 0.149s 0.003s
im_detect: 3941/4952 0.149s 0.003s
im_detect: 3942/4952 0.149s 0.003s
im_detect: 3943/4952 0.149s 0.003s
im_detect: 3944/4952 0.149s 0.003s
im_detect: 3945/4952 0.149s 0.003s
im_detect: 3946/4952 0.149s 0.003s
im_detect: 3947/4952 0.149s 0.003s
im_detect: 3948/4952 0.149s 0.003s
im_detect: 3949/4952 0.149s 0.003s
im_detect: 3950/4952 0.149s 0.003s
im_detect: 3951/4952 0.149s 0.003s
im_detect: 3952/4952 0.149s 0.003s
im_detect: 3953/4952 0.149s 0.003s
im_detect: 3954/4952 0.149s 0.003s
im_detect: 3955/4952 0.149s 0.003s
im_detect: 3956/4952 0.149s 0.003s
im_detect: 3957/4952 0.149s 0.003s
im_detect: 3958/4952 0.149s 0.003s
im_detect: 3959/4952 0.149s 0.003s
im_detect: 3960/4952 0.149s 0.003s
im_detect: 3961/4952 0.149s 0.003s
im_detect: 3962/4952 0.149s 0.003s
im_detect: 3963/4952 0.149s 0.003s
im_detect: 3964/4952 0.149s 0.003s
im_detect: 3965/4952 0.149s 0.003s
im_detect: 3966/4952 0.149s 0.003s
im_detect: 3967/4952 0.149s 0.003s
im_detect: 3968/4952 0.149s 0.003s
im_detect: 3969/4952 0.149s 0.003s
im_detect: 3970/4952 0.149s 0.003s
im_detect: 3971/4952 0.149s 0.003s
im_detect: 3972/4952 0.149s 0.003s
im_detect: 3973/4952 0.149s 0.003s
im_detect: 3974/4952 0.149s 0.003s
im_detect: 3975/4952 0.149s 0.003s
im_detect: 3976/4952 0.149s 0.003s
im_detect: 3977/4952 0.149s 0.003s
im_detect: 3978/4952 0.149s 0.003s
im_detect: 3979/4952 0.149s 0.003s
im_detect: 3980/4952 0.149s 0.003s
im_detect: 3981/4952 0.149s 0.003s
im_detect: 3982/4952 0.149s 0.003s
im_detect: 3983/4952 0.149s 0.003s
im_detect: 3984/4952 0.149s 0.003s
im_detect: 3985/4952 0.149s 0.003s
im_detect: 3986/4952 0.149s 0.003s
im_detect: 3987/4952 0.149s 0.003s
im_detect: 3988/4952 0.149s 0.003s
im_detect: 3989/4952 0.149s 0.003s
im_detect: 3990/4952 0.149s 0.003s
im_detect: 3991/4952 0.149s 0.003s
im_detect: 3992/4952 0.149s 0.003s
im_detect: 3993/4952 0.149s 0.003s
im_detect: 3994/4952 0.149s 0.003s
im_detect: 3995/4952 0.149s 0.003s
im_detect: 3996/4952 0.149s 0.003s
im_detect: 3997/4952 0.149s 0.003s
im_detect: 3998/4952 0.149s 0.003s
im_detect: 3999/4952 0.149s 0.003s
im_detect: 4000/4952 0.149s 0.003s
im_detect: 4001/4952 0.149s 0.003s
im_detect: 4002/4952 0.149s 0.003s
im_detect: 4003/4952 0.149s 0.003s
im_detect: 4004/4952 0.149s 0.003s
im_detect: 4005/4952 0.149s 0.003s
im_detect: 4006/4952 0.149s 0.003s
im_detect: 4007/4952 0.149s 0.003s
im_detect: 4008/4952 0.149s 0.003s
im_detect: 4009/4952 0.149s 0.003s
im_detect: 4010/4952 0.149s 0.003s
im_detect: 4011/4952 0.149s 0.003s
im_detect: 4012/4952 0.149s 0.003s
im_detect: 4013/4952 0.149s 0.003s
im_detect: 4014/4952 0.149s 0.003s
im_detect: 4015/4952 0.149s 0.003s
im_detect: 4016/4952 0.149s 0.003s
im_detect: 4017/4952 0.149s 0.003s
im_detect: 4018/4952 0.149s 0.003s
im_detect: 4019/4952 0.149s 0.003s
im_detect: 4020/4952 0.149s 0.003s
im_detect: 4021/4952 0.149s 0.003s
im_detect: 4022/4952 0.149s 0.003s
im_detect: 4023/4952 0.149s 0.003s
im_detect: 4024/4952 0.149s 0.003s
im_detect: 4025/4952 0.149s 0.003s
im_detect: 4026/4952 0.149s 0.003s
im_detect: 4027/4952 0.149s 0.003s
im_detect: 4028/4952 0.149s 0.003s
im_detect: 4029/4952 0.149s 0.003s
im_detect: 4030/4952 0.149s 0.003s
im_detect: 4031/4952 0.149s 0.003s
im_detect: 4032/4952 0.149s 0.003s
im_detect: 4033/4952 0.149s 0.003s
im_detect: 4034/4952 0.149s 0.003s
im_detect: 4035/4952 0.149s 0.003s
im_detect: 4036/4952 0.149s 0.003s
im_detect: 4037/4952 0.149s 0.003s
im_detect: 4038/4952 0.149s 0.003s
im_detect: 4039/4952 0.149s 0.003s
im_detect: 4040/4952 0.149s 0.003s
im_detect: 4041/4952 0.149s 0.003s
im_detect: 4042/4952 0.149s 0.003s
im_detect: 4043/4952 0.149s 0.003s
im_detect: 4044/4952 0.149s 0.003s
im_detect: 4045/4952 0.149s 0.003s
im_detect: 4046/4952 0.149s 0.003s
im_detect: 4047/4952 0.149s 0.003s
im_detect: 4048/4952 0.149s 0.003s
im_detect: 4049/4952 0.149s 0.003s
im_detect: 4050/4952 0.149s 0.003s
im_detect: 4051/4952 0.149s 0.003s
im_detect: 4052/4952 0.149s 0.003s
im_detect: 4053/4952 0.149s 0.003s
im_detect: 4054/4952 0.149s 0.003s
im_detect: 4055/4952 0.149s 0.003s
im_detect: 4056/4952 0.149s 0.003s
im_detect: 4057/4952 0.149s 0.003s
im_detect: 4058/4952 0.149s 0.003s
im_detect: 4059/4952 0.149s 0.003s
im_detect: 4060/4952 0.149s 0.003s
im_detect: 4061/4952 0.149s 0.003s
im_detect: 4062/4952 0.149s 0.003s
im_detect: 4063/4952 0.149s 0.003s
im_detect: 4064/4952 0.149s 0.003s
im_detect: 4065/4952 0.149s 0.003s
im_detect: 4066/4952 0.149s 0.003s
im_detect: 4067/4952 0.149s 0.003s
im_detect: 4068/4952 0.149s 0.003s
im_detect: 4069/4952 0.149s 0.003s
im_detect: 4070/4952 0.149s 0.003s
im_detect: 4071/4952 0.149s 0.003s
im_detect: 4072/4952 0.149s 0.003s
im_detect: 4073/4952 0.149s 0.003s
im_detect: 4074/4952 0.149s 0.003s
im_detect: 4075/4952 0.149s 0.003s
im_detect: 4076/4952 0.149s 0.003s
im_detect: 4077/4952 0.149s 0.003s
im_detect: 4078/4952 0.149s 0.003s
im_detect: 4079/4952 0.149s 0.003s
im_detect: 4080/4952 0.149s 0.003s
im_detect: 4081/4952 0.149s 0.003s
im_detect: 4082/4952 0.149s 0.003s
im_detect: 4083/4952 0.149s 0.003s
im_detect: 4084/4952 0.149s 0.003s
im_detect: 4085/4952 0.149s 0.003s
im_detect: 4086/4952 0.149s 0.003s
im_detect: 4087/4952 0.149s 0.003s
im_detect: 4088/4952 0.149s 0.003s
im_detect: 4089/4952 0.149s 0.003s
im_detect: 4090/4952 0.149s 0.003s
im_detect: 4091/4952 0.149s 0.003s
im_detect: 4092/4952 0.149s 0.003s
im_detect: 4093/4952 0.149s 0.003s
im_detect: 4094/4952 0.149s 0.003s
im_detect: 4095/4952 0.149s 0.003s
im_detect: 4096/4952 0.149s 0.003s
im_detect: 4097/4952 0.149s 0.003s
im_detect: 4098/4952 0.149s 0.003s
im_detect: 4099/4952 0.149s 0.003s
im_detect: 4100/4952 0.149s 0.003s
im_detect: 4101/4952 0.149s 0.003s
im_detect: 4102/4952 0.149s 0.003s
im_detect: 4103/4952 0.149s 0.003s
im_detect: 4104/4952 0.149s 0.003s
im_detect: 4105/4952 0.149s 0.003s
im_detect: 4106/4952 0.149s 0.003s
im_detect: 4107/4952 0.149s 0.003s
im_detect: 4108/4952 0.149s 0.003s
im_detect: 4109/4952 0.149s 0.003s
im_detect: 4110/4952 0.149s 0.003s
im_detect: 4111/4952 0.149s 0.003s
im_detect: 4112/4952 0.149s 0.003s
im_detect: 4113/4952 0.149s 0.003s
im_detect: 4114/4952 0.149s 0.003s
im_detect: 4115/4952 0.149s 0.003s
im_detect: 4116/4952 0.149s 0.003s
im_detect: 4117/4952 0.149s 0.003s
im_detect: 4118/4952 0.149s 0.003s
im_detect: 4119/4952 0.149s 0.003s
im_detect: 4120/4952 0.149s 0.003s
im_detect: 4121/4952 0.149s 0.003s
im_detect: 4122/4952 0.149s 0.003s
im_detect: 4123/4952 0.149s 0.003s
im_detect: 4124/4952 0.149s 0.003s
im_detect: 4125/4952 0.149s 0.003s
im_detect: 4126/4952 0.149s 0.003s
im_detect: 4127/4952 0.149s 0.003s
im_detect: 4128/4952 0.149s 0.003s
im_detect: 4129/4952 0.149s 0.003s
im_detect: 4130/4952 0.149s 0.003s
im_detect: 4131/4952 0.149s 0.003s
im_detect: 4132/4952 0.149s 0.003s
im_detect: 4133/4952 0.149s 0.003s
im_detect: 4134/4952 0.149s 0.003s
im_detect: 4135/4952 0.149s 0.003s
im_detect: 4136/4952 0.149s 0.003s
im_detect: 4137/4952 0.149s 0.003s
im_detect: 4138/4952 0.149s 0.003s
im_detect: 4139/4952 0.149s 0.003s
im_detect: 4140/4952 0.149s 0.003s
im_detect: 4141/4952 0.149s 0.003s
im_detect: 4142/4952 0.149s 0.003s
im_detect: 4143/4952 0.149s 0.003s
im_detect: 4144/4952 0.149s 0.003s
im_detect: 4145/4952 0.149s 0.003s
im_detect: 4146/4952 0.149s 0.003s
im_detect: 4147/4952 0.149s 0.003s
im_detect: 4148/4952 0.149s 0.003s
im_detect: 4149/4952 0.149s 0.003s
im_detect: 4150/4952 0.149s 0.003s
im_detect: 4151/4952 0.149s 0.003s
im_detect: 4152/4952 0.149s 0.003s
im_detect: 4153/4952 0.149s 0.003s
im_detect: 4154/4952 0.149s 0.003s
im_detect: 4155/4952 0.149s 0.003s
im_detect: 4156/4952 0.149s 0.003s
im_detect: 4157/4952 0.149s 0.003s
im_detect: 4158/4952 0.149s 0.003s
im_detect: 4159/4952 0.149s 0.003s
im_detect: 4160/4952 0.149s 0.003s
im_detect: 4161/4952 0.149s 0.003s
im_detect: 4162/4952 0.149s 0.003s
im_detect: 4163/4952 0.149s 0.003s
im_detect: 4164/4952 0.149s 0.003s
im_detect: 4165/4952 0.149s 0.003s
im_detect: 4166/4952 0.149s 0.003s
im_detect: 4167/4952 0.149s 0.003s
im_detect: 4168/4952 0.149s 0.003s
im_detect: 4169/4952 0.149s 0.003s
im_detect: 4170/4952 0.149s 0.003s
im_detect: 4171/4952 0.149s 0.003s
im_detect: 4172/4952 0.149s 0.003s
im_detect: 4173/4952 0.149s 0.003s
im_detect: 4174/4952 0.149s 0.003s
im_detect: 4175/4952 0.149s 0.003s
im_detect: 4176/4952 0.149s 0.003s
im_detect: 4177/4952 0.149s 0.003s
im_detect: 4178/4952 0.149s 0.003s
im_detect: 4179/4952 0.149s 0.003s
im_detect: 4180/4952 0.149s 0.003s
im_detect: 4181/4952 0.149s 0.003s
im_detect: 4182/4952 0.149s 0.003s
im_detect: 4183/4952 0.149s 0.003s
im_detect: 4184/4952 0.149s 0.003s
im_detect: 4185/4952 0.149s 0.003s
im_detect: 4186/4952 0.149s 0.003s
im_detect: 4187/4952 0.149s 0.003s
im_detect: 4188/4952 0.149s 0.003s
im_detect: 4189/4952 0.149s 0.003s
im_detect: 4190/4952 0.149s 0.003s
im_detect: 4191/4952 0.149s 0.003s
im_detect: 4192/4952 0.149s 0.003s
im_detect: 4193/4952 0.149s 0.003s
im_detect: 4194/4952 0.149s 0.003s
im_detect: 4195/4952 0.149s 0.003s
im_detect: 4196/4952 0.149s 0.003s
im_detect: 4197/4952 0.149s 0.003s
im_detect: 4198/4952 0.149s 0.003s
im_detect: 4199/4952 0.149s 0.003s
im_detect: 4200/4952 0.149s 0.003s
im_detect: 4201/4952 0.149s 0.003s
im_detect: 4202/4952 0.149s 0.003s
im_detect: 4203/4952 0.149s 0.003s
im_detect: 4204/4952 0.149s 0.003s
im_detect: 4205/4952 0.149s 0.003s
im_detect: 4206/4952 0.149s 0.003s
im_detect: 4207/4952 0.149s 0.003s
im_detect: 4208/4952 0.149s 0.003s
im_detect: 4209/4952 0.149s 0.003s
im_detect: 4210/4952 0.149s 0.003s
im_detect: 4211/4952 0.149s 0.003s
im_detect: 4212/4952 0.149s 0.003s
im_detect: 4213/4952 0.149s 0.003s
im_detect: 4214/4952 0.149s 0.003s
im_detect: 4215/4952 0.149s 0.003s
im_detect: 4216/4952 0.149s 0.003s
im_detect: 4217/4952 0.149s 0.003s
im_detect: 4218/4952 0.149s 0.003s
im_detect: 4219/4952 0.149s 0.003s
im_detect: 4220/4952 0.149s 0.003s
im_detect: 4221/4952 0.149s 0.003s
im_detect: 4222/4952 0.149s 0.003s
im_detect: 4223/4952 0.149s 0.003s
im_detect: 4224/4952 0.149s 0.003s
im_detect: 4225/4952 0.149s 0.003s
im_detect: 4226/4952 0.149s 0.003s
im_detect: 4227/4952 0.149s 0.003s
im_detect: 4228/4952 0.149s 0.003s
im_detect: 4229/4952 0.149s 0.003s
im_detect: 4230/4952 0.149s 0.003s
im_detect: 4231/4952 0.149s 0.003s
im_detect: 4232/4952 0.149s 0.003s
im_detect: 4233/4952 0.149s 0.003s
im_detect: 4234/4952 0.149s 0.003s
im_detect: 4235/4952 0.149s 0.003s
im_detect: 4236/4952 0.149s 0.003s
im_detect: 4237/4952 0.149s 0.003s
im_detect: 4238/4952 0.149s 0.003s
im_detect: 4239/4952 0.149s 0.003s
im_detect: 4240/4952 0.149s 0.003s
im_detect: 4241/4952 0.149s 0.003s
im_detect: 4242/4952 0.149s 0.003s
im_detect: 4243/4952 0.149s 0.003s
im_detect: 4244/4952 0.149s 0.003s
im_detect: 4245/4952 0.149s 0.003s
im_detect: 4246/4952 0.149s 0.003s
im_detect: 4247/4952 0.149s 0.003s
im_detect: 4248/4952 0.149s 0.003s
im_detect: 4249/4952 0.149s 0.003s
im_detect: 4250/4952 0.149s 0.003s
im_detect: 4251/4952 0.149s 0.003s
im_detect: 4252/4952 0.149s 0.003s
im_detect: 4253/4952 0.149s 0.003s
im_detect: 4254/4952 0.149s 0.003s
im_detect: 4255/4952 0.149s 0.003s
im_detect: 4256/4952 0.149s 0.003s
im_detect: 4257/4952 0.149s 0.003s
im_detect: 4258/4952 0.149s 0.003s
im_detect: 4259/4952 0.149s 0.003s
im_detect: 4260/4952 0.149s 0.003s
im_detect: 4261/4952 0.149s 0.003s
im_detect: 4262/4952 0.149s 0.003s
im_detect: 4263/4952 0.149s 0.003s
im_detect: 4264/4952 0.149s 0.003s
im_detect: 4265/4952 0.149s 0.003s
im_detect: 4266/4952 0.149s 0.003s
im_detect: 4267/4952 0.149s 0.003s
im_detect: 4268/4952 0.149s 0.003s
im_detect: 4269/4952 0.149s 0.003s
im_detect: 4270/4952 0.149s 0.003s
im_detect: 4271/4952 0.149s 0.003s
im_detect: 4272/4952 0.149s 0.003s
im_detect: 4273/4952 0.149s 0.003s
im_detect: 4274/4952 0.149s 0.003s
im_detect: 4275/4952 0.149s 0.003s
im_detect: 4276/4952 0.149s 0.003s
im_detect: 4277/4952 0.149s 0.003s
im_detect: 4278/4952 0.149s 0.003s
im_detect: 4279/4952 0.149s 0.003s
im_detect: 4280/4952 0.149s 0.003s
im_detect: 4281/4952 0.149s 0.003s
im_detect: 4282/4952 0.149s 0.003s
im_detect: 4283/4952 0.149s 0.003s
im_detect: 4284/4952 0.149s 0.003s
im_detect: 4285/4952 0.149s 0.003s
im_detect: 4286/4952 0.149s 0.003s
im_detect: 4287/4952 0.149s 0.003s
im_detect: 4288/4952 0.149s 0.003s
im_detect: 4289/4952 0.149s 0.003s
im_detect: 4290/4952 0.149s 0.003s
im_detect: 4291/4952 0.149s 0.003s
im_detect: 4292/4952 0.149s 0.003s
im_detect: 4293/4952 0.149s 0.003s
im_detect: 4294/4952 0.149s 0.003s
im_detect: 4295/4952 0.149s 0.003s
im_detect: 4296/4952 0.149s 0.003s
im_detect: 4297/4952 0.149s 0.003s
im_detect: 4298/4952 0.149s 0.003s
im_detect: 4299/4952 0.149s 0.003s
im_detect: 4300/4952 0.149s 0.003s
im_detect: 4301/4952 0.149s 0.003s
im_detect: 4302/4952 0.149s 0.003s
im_detect: 4303/4952 0.149s 0.003s
im_detect: 4304/4952 0.149s 0.003s
im_detect: 4305/4952 0.149s 0.003s
im_detect: 4306/4952 0.149s 0.003s
im_detect: 4307/4952 0.149s 0.003s
im_detect: 4308/4952 0.149s 0.003s
im_detect: 4309/4952 0.149s 0.003s
im_detect: 4310/4952 0.149s 0.003s
im_detect: 4311/4952 0.149s 0.003s
im_detect: 4312/4952 0.149s 0.003s
im_detect: 4313/4952 0.149s 0.003s
im_detect: 4314/4952 0.149s 0.003s
im_detect: 4315/4952 0.149s 0.003s
im_detect: 4316/4952 0.149s 0.003s
im_detect: 4317/4952 0.149s 0.003s
im_detect: 4318/4952 0.149s 0.003s
im_detect: 4319/4952 0.149s 0.003s
im_detect: 4320/4952 0.149s 0.003s
im_detect: 4321/4952 0.149s 0.003s
im_detect: 4322/4952 0.149s 0.003s
im_detect: 4323/4952 0.149s 0.003s
im_detect: 4324/4952 0.149s 0.003s
im_detect: 4325/4952 0.149s 0.003s
im_detect: 4326/4952 0.149s 0.003s
im_detect: 4327/4952 0.149s 0.003s
im_detect: 4328/4952 0.149s 0.003s
im_detect: 4329/4952 0.149s 0.003s
im_detect: 4330/4952 0.149s 0.003s
im_detect: 4331/4952 0.149s 0.003s
im_detect: 4332/4952 0.149s 0.003s
im_detect: 4333/4952 0.149s 0.003s
im_detect: 4334/4952 0.149s 0.003s
im_detect: 4335/4952 0.149s 0.003s
im_detect: 4336/4952 0.149s 0.003s
im_detect: 4337/4952 0.149s 0.003s
im_detect: 4338/4952 0.149s 0.003s
im_detect: 4339/4952 0.149s 0.003s
im_detect: 4340/4952 0.149s 0.003s
im_detect: 4341/4952 0.149s 0.003s
im_detect: 4342/4952 0.149s 0.003s
im_detect: 4343/4952 0.149s 0.003s
im_detect: 4344/4952 0.149s 0.003s
im_detect: 4345/4952 0.149s 0.003s
im_detect: 4346/4952 0.149s 0.003s
im_detect: 4347/4952 0.149s 0.003s
im_detect: 4348/4952 0.149s 0.003s
im_detect: 4349/4952 0.149s 0.003s
im_detect: 4350/4952 0.149s 0.003s
im_detect: 4351/4952 0.149s 0.003s
im_detect: 4352/4952 0.149s 0.003s
im_detect: 4353/4952 0.149s 0.003s
im_detect: 4354/4952 0.149s 0.003s
im_detect: 4355/4952 0.149s 0.003s
im_detect: 4356/4952 0.149s 0.003s
im_detect: 4357/4952 0.149s 0.003s
im_detect: 4358/4952 0.149s 0.003s
im_detect: 4359/4952 0.149s 0.003s
im_detect: 4360/4952 0.149s 0.003s
im_detect: 4361/4952 0.149s 0.003s
im_detect: 4362/4952 0.149s 0.003s
im_detect: 4363/4952 0.149s 0.003s
im_detect: 4364/4952 0.149s 0.003s
im_detect: 4365/4952 0.149s 0.003s
im_detect: 4366/4952 0.149s 0.003s
im_detect: 4367/4952 0.149s 0.003s
im_detect: 4368/4952 0.149s 0.003s
im_detect: 4369/4952 0.149s 0.003s
im_detect: 4370/4952 0.149s 0.003s
im_detect: 4371/4952 0.149s 0.003s
im_detect: 4372/4952 0.149s 0.003s
im_detect: 4373/4952 0.149s 0.003s
im_detect: 4374/4952 0.149s 0.003s
im_detect: 4375/4952 0.149s 0.003s
im_detect: 4376/4952 0.149s 0.003s
im_detect: 4377/4952 0.149s 0.003s
im_detect: 4378/4952 0.149s 0.003s
im_detect: 4379/4952 0.149s 0.003s
im_detect: 4380/4952 0.149s 0.003s
im_detect: 4381/4952 0.149s 0.003s
im_detect: 4382/4952 0.149s 0.003s
im_detect: 4383/4952 0.149s 0.003s
im_detect: 4384/4952 0.149s 0.003s
im_detect: 4385/4952 0.149s 0.003s
im_detect: 4386/4952 0.149s 0.003s
im_detect: 4387/4952 0.149s 0.003s
im_detect: 4388/4952 0.149s 0.003s
im_detect: 4389/4952 0.149s 0.003s
im_detect: 4390/4952 0.149s 0.003s
im_detect: 4391/4952 0.149s 0.003s
im_detect: 4392/4952 0.149s 0.003s
im_detect: 4393/4952 0.149s 0.003s
im_detect: 4394/4952 0.149s 0.003s
im_detect: 4395/4952 0.149s 0.003s
im_detect: 4396/4952 0.149s 0.003s
im_detect: 4397/4952 0.149s 0.003s
im_detect: 4398/4952 0.149s 0.003s
im_detect: 4399/4952 0.149s 0.003s
im_detect: 4400/4952 0.149s 0.003s
im_detect: 4401/4952 0.149s 0.003s
im_detect: 4402/4952 0.149s 0.003s
im_detect: 4403/4952 0.149s 0.003s
im_detect: 4404/4952 0.149s 0.003s
im_detect: 4405/4952 0.149s 0.003s
im_detect: 4406/4952 0.149s 0.003s
im_detect: 4407/4952 0.149s 0.003s
im_detect: 4408/4952 0.149s 0.003s
im_detect: 4409/4952 0.149s 0.003s
im_detect: 4410/4952 0.149s 0.003s
im_detect: 4411/4952 0.149s 0.003s
im_detect: 4412/4952 0.149s 0.003s
im_detect: 4413/4952 0.149s 0.003s
im_detect: 4414/4952 0.149s 0.003s
im_detect: 4415/4952 0.149s 0.003s
im_detect: 4416/4952 0.149s 0.003s
im_detect: 4417/4952 0.149s 0.003s
im_detect: 4418/4952 0.149s 0.003s
im_detect: 4419/4952 0.149s 0.003s
im_detect: 4420/4952 0.149s 0.003s
im_detect: 4421/4952 0.149s 0.003s
im_detect: 4422/4952 0.149s 0.003s
im_detect: 4423/4952 0.149s 0.003s
im_detect: 4424/4952 0.149s 0.003s
im_detect: 4425/4952 0.149s 0.003s
im_detect: 4426/4952 0.149s 0.003s
im_detect: 4427/4952 0.149s 0.003s
im_detect: 4428/4952 0.149s 0.003s
im_detect: 4429/4952 0.149s 0.003s
im_detect: 4430/4952 0.149s 0.003s
im_detect: 4431/4952 0.149s 0.003s
im_detect: 4432/4952 0.149s 0.003s
im_detect: 4433/4952 0.149s 0.003s
im_detect: 4434/4952 0.149s 0.003s
im_detect: 4435/4952 0.149s 0.003s
im_detect: 4436/4952 0.149s 0.003s
im_detect: 4437/4952 0.149s 0.003s
im_detect: 4438/4952 0.149s 0.003s
im_detect: 4439/4952 0.149s 0.003s
im_detect: 4440/4952 0.149s 0.003s
im_detect: 4441/4952 0.149s 0.003s
im_detect: 4442/4952 0.149s 0.003s
im_detect: 4443/4952 0.149s 0.003s
im_detect: 4444/4952 0.149s 0.003s
im_detect: 4445/4952 0.149s 0.003s
im_detect: 4446/4952 0.149s 0.003s
im_detect: 4447/4952 0.149s 0.003s
im_detect: 4448/4952 0.149s 0.003s
im_detect: 4449/4952 0.149s 0.003s
im_detect: 4450/4952 0.149s 0.003s
im_detect: 4451/4952 0.149s 0.003s
im_detect: 4452/4952 0.149s 0.003s
im_detect: 4453/4952 0.149s 0.003s
im_detect: 4454/4952 0.149s 0.003s
im_detect: 4455/4952 0.149s 0.003s
im_detect: 4456/4952 0.149s 0.003s
im_detect: 4457/4952 0.149s 0.003s
im_detect: 4458/4952 0.149s 0.003s
im_detect: 4459/4952 0.149s 0.003s
im_detect: 4460/4952 0.149s 0.003s
im_detect: 4461/4952 0.149s 0.003s
im_detect: 4462/4952 0.149s 0.003s
im_detect: 4463/4952 0.149s 0.003s
im_detect: 4464/4952 0.149s 0.003s
im_detect: 4465/4952 0.149s 0.003s
im_detect: 4466/4952 0.149s 0.003s
im_detect: 4467/4952 0.149s 0.003s
im_detect: 4468/4952 0.149s 0.003s
im_detect: 4469/4952 0.149s 0.003s
im_detect: 4470/4952 0.149s 0.003s
im_detect: 4471/4952 0.149s 0.003s
im_detect: 4472/4952 0.149s 0.003s
im_detect: 4473/4952 0.149s 0.003s
im_detect: 4474/4952 0.149s 0.003s
im_detect: 4475/4952 0.149s 0.003s
im_detect: 4476/4952 0.149s 0.003s
im_detect: 4477/4952 0.149s 0.003s
im_detect: 4478/4952 0.149s 0.003s
im_detect: 4479/4952 0.149s 0.003s
im_detect: 4480/4952 0.149s 0.003s
im_detect: 4481/4952 0.149s 0.003s
im_detect: 4482/4952 0.149s 0.003s
im_detect: 4483/4952 0.149s 0.003s
im_detect: 4484/4952 0.149s 0.003s
im_detect: 4485/4952 0.149s 0.003s
im_detect: 4486/4952 0.149s 0.003s
im_detect: 4487/4952 0.149s 0.003s
im_detect: 4488/4952 0.149s 0.003s
im_detect: 4489/4952 0.149s 0.003s
im_detect: 4490/4952 0.149s 0.003s
im_detect: 4491/4952 0.149s 0.003s
im_detect: 4492/4952 0.149s 0.003s
im_detect: 4493/4952 0.149s 0.003s
im_detect: 4494/4952 0.149s 0.003s
im_detect: 4495/4952 0.149s 0.003s
im_detect: 4496/4952 0.149s 0.003s
im_detect: 4497/4952 0.149s 0.003s
im_detect: 4498/4952 0.149s 0.003s
im_detect: 4499/4952 0.149s 0.003s
im_detect: 4500/4952 0.149s 0.003s
im_detect: 4501/4952 0.149s 0.003s
im_detect: 4502/4952 0.149s 0.003s
im_detect: 4503/4952 0.149s 0.003s
im_detect: 4504/4952 0.149s 0.003s
im_detect: 4505/4952 0.149s 0.003s
im_detect: 4506/4952 0.149s 0.003s
im_detect: 4507/4952 0.149s 0.003s
im_detect: 4508/4952 0.149s 0.003s
im_detect: 4509/4952 0.149s 0.003s
im_detect: 4510/4952 0.149s 0.003s
im_detect: 4511/4952 0.149s 0.003s
im_detect: 4512/4952 0.149s 0.003s
im_detect: 4513/4952 0.149s 0.003s
im_detect: 4514/4952 0.149s 0.003s
im_detect: 4515/4952 0.149s 0.003s
im_detect: 4516/4952 0.149s 0.003s
im_detect: 4517/4952 0.149s 0.003s
im_detect: 4518/4952 0.149s 0.003s
im_detect: 4519/4952 0.149s 0.003s
im_detect: 4520/4952 0.149s 0.003s
im_detect: 4521/4952 0.149s 0.003s
im_detect: 4522/4952 0.149s 0.003s
im_detect: 4523/4952 0.149s 0.003s
im_detect: 4524/4952 0.149s 0.003s
im_detect: 4525/4952 0.149s 0.003s
im_detect: 4526/4952 0.149s 0.003s
im_detect: 4527/4952 0.149s 0.003s
im_detect: 4528/4952 0.149s 0.003s
im_detect: 4529/4952 0.149s 0.003s
im_detect: 4530/4952 0.149s 0.003s
im_detect: 4531/4952 0.149s 0.003s
im_detect: 4532/4952 0.149s 0.003s
im_detect: 4533/4952 0.149s 0.003s
im_detect: 4534/4952 0.149s 0.003s
im_detect: 4535/4952 0.149s 0.003s
im_detect: 4536/4952 0.149s 0.003s
im_detect: 4537/4952 0.149s 0.003s
im_detect: 4538/4952 0.149s 0.003s
im_detect: 4539/4952 0.149s 0.003s
im_detect: 4540/4952 0.149s 0.003s
im_detect: 4541/4952 0.149s 0.003s
im_detect: 4542/4952 0.149s 0.003s
im_detect: 4543/4952 0.149s 0.003s
im_detect: 4544/4952 0.149s 0.003s
im_detect: 4545/4952 0.149s 0.003s
im_detect: 4546/4952 0.149s 0.003s
im_detect: 4547/4952 0.149s 0.003s
im_detect: 4548/4952 0.149s 0.003s
im_detect: 4549/4952 0.149s 0.003s
im_detect: 4550/4952 0.149s 0.003s
im_detect: 4551/4952 0.149s 0.003s
im_detect: 4552/4952 0.149s 0.003s
im_detect: 4553/4952 0.149s 0.003s
im_detect: 4554/4952 0.149s 0.003s
im_detect: 4555/4952 0.149s 0.003s
im_detect: 4556/4952 0.149s 0.003s
im_detect: 4557/4952 0.149s 0.003s
im_detect: 4558/4952 0.149s 0.003s
im_detect: 4559/4952 0.149s 0.003s
im_detect: 4560/4952 0.149s 0.003s
im_detect: 4561/4952 0.149s 0.003s
im_detect: 4562/4952 0.149s 0.003s
im_detect: 4563/4952 0.149s 0.003s
im_detect: 4564/4952 0.149s 0.003s
im_detect: 4565/4952 0.149s 0.003s
im_detect: 4566/4952 0.149s 0.003s
im_detect: 4567/4952 0.149s 0.003s
im_detect: 4568/4952 0.149s 0.003s
im_detect: 4569/4952 0.149s 0.003s
im_detect: 4570/4952 0.149s 0.003s
im_detect: 4571/4952 0.149s 0.003s
im_detect: 4572/4952 0.149s 0.003s
im_detect: 4573/4952 0.149s 0.003s
im_detect: 4574/4952 0.149s 0.003s
im_detect: 4575/4952 0.149s 0.003s
im_detect: 4576/4952 0.149s 0.003s
im_detect: 4577/4952 0.149s 0.003s
im_detect: 4578/4952 0.149s 0.003s
im_detect: 4579/4952 0.149s 0.003s
im_detect: 4580/4952 0.149s 0.003s
im_detect: 4581/4952 0.149s 0.003s
im_detect: 4582/4952 0.149s 0.003s
im_detect: 4583/4952 0.149s 0.003s
im_detect: 4584/4952 0.149s 0.003s
im_detect: 4585/4952 0.149s 0.003s
im_detect: 4586/4952 0.149s 0.003s
im_detect: 4587/4952 0.149s 0.003s
im_detect: 4588/4952 0.149s 0.003s
im_detect: 4589/4952 0.149s 0.003s
im_detect: 4590/4952 0.149s 0.003s
im_detect: 4591/4952 0.149s 0.003s
im_detect: 4592/4952 0.149s 0.003s
im_detect: 4593/4952 0.149s 0.003s
im_detect: 4594/4952 0.149s 0.003s
im_detect: 4595/4952 0.149s 0.003s
im_detect: 4596/4952 0.149s 0.003s
im_detect: 4597/4952 0.149s 0.003s
im_detect: 4598/4952 0.149s 0.003s
im_detect: 4599/4952 0.149s 0.003s
im_detect: 4600/4952 0.149s 0.003s
im_detect: 4601/4952 0.149s 0.003s
im_detect: 4602/4952 0.149s 0.003s
im_detect: 4603/4952 0.149s 0.003s
im_detect: 4604/4952 0.149s 0.003s
im_detect: 4605/4952 0.149s 0.003s
im_detect: 4606/4952 0.149s 0.003s
im_detect: 4607/4952 0.149s 0.003s
im_detect: 4608/4952 0.149s 0.003s
im_detect: 4609/4952 0.149s 0.003s
im_detect: 4610/4952 0.149s 0.003s
im_detect: 4611/4952 0.149s 0.003s
im_detect: 4612/4952 0.149s 0.003s
im_detect: 4613/4952 0.149s 0.003s
im_detect: 4614/4952 0.149s 0.003s
im_detect: 4615/4952 0.149s 0.003s
im_detect: 4616/4952 0.149s 0.003s
im_detect: 4617/4952 0.149s 0.003s
im_detect: 4618/4952 0.149s 0.003s
im_detect: 4619/4952 0.149s 0.003s
im_detect: 4620/4952 0.149s 0.003s
im_detect: 4621/4952 0.149s 0.003s
im_detect: 4622/4952 0.149s 0.003s
im_detect: 4623/4952 0.149s 0.003s
im_detect: 4624/4952 0.149s 0.003s
im_detect: 4625/4952 0.149s 0.003s
im_detect: 4626/4952 0.149s 0.003s
im_detect: 4627/4952 0.149s 0.003s
im_detect: 4628/4952 0.149s 0.003s
im_detect: 4629/4952 0.149s 0.003s
im_detect: 4630/4952 0.149s 0.003s
im_detect: 4631/4952 0.149s 0.003s
im_detect: 4632/4952 0.149s 0.003s
im_detect: 4633/4952 0.149s 0.003s
im_detect: 4634/4952 0.149s 0.003s
im_detect: 4635/4952 0.149s 0.003s
im_detect: 4636/4952 0.149s 0.003s
im_detect: 4637/4952 0.149s 0.003s
im_detect: 4638/4952 0.149s 0.003s
im_detect: 4639/4952 0.149s 0.003s
im_detect: 4640/4952 0.149s 0.003s
im_detect: 4641/4952 0.149s 0.003s
im_detect: 4642/4952 0.149s 0.003s
im_detect: 4643/4952 0.149s 0.003s
im_detect: 4644/4952 0.149s 0.003s
im_detect: 4645/4952 0.149s 0.003s
im_detect: 4646/4952 0.149s 0.003s
im_detect: 4647/4952 0.149s 0.003s
im_detect: 4648/4952 0.149s 0.003s
im_detect: 4649/4952 0.149s 0.003s
im_detect: 4650/4952 0.149s 0.003s
im_detect: 4651/4952 0.149s 0.003s
im_detect: 4652/4952 0.149s 0.003s
im_detect: 4653/4952 0.149s 0.003s
im_detect: 4654/4952 0.149s 0.003s
im_detect: 4655/4952 0.149s 0.003s
im_detect: 4656/4952 0.149s 0.003s
im_detect: 4657/4952 0.149s 0.003s
im_detect: 4658/4952 0.149s 0.003s
im_detect: 4659/4952 0.149s 0.003s
im_detect: 4660/4952 0.149s 0.003s
im_detect: 4661/4952 0.149s 0.003s
im_detect: 4662/4952 0.149s 0.003s
im_detect: 4663/4952 0.149s 0.003s
im_detect: 4664/4952 0.149s 0.003s
im_detect: 4665/4952 0.149s 0.003s
im_detect: 4666/4952 0.149s 0.003s
im_detect: 4667/4952 0.149s 0.003s
im_detect: 4668/4952 0.149s 0.003s
im_detect: 4669/4952 0.149s 0.003s
im_detect: 4670/4952 0.149s 0.003s
im_detect: 4671/4952 0.149s 0.003s
im_detect: 4672/4952 0.149s 0.003s
im_detect: 4673/4952 0.149s 0.003s
im_detect: 4674/4952 0.149s 0.003s
im_detect: 4675/4952 0.149s 0.003s
im_detect: 4676/4952 0.149s 0.003s
im_detect: 4677/4952 0.149s 0.003s
im_detect: 4678/4952 0.149s 0.003s
im_detect: 4679/4952 0.149s 0.003s
im_detect: 4680/4952 0.149s 0.003s
im_detect: 4681/4952 0.149s 0.003s
im_detect: 4682/4952 0.149s 0.003s
im_detect: 4683/4952 0.149s 0.003s
im_detect: 4684/4952 0.149s 0.003s
im_detect: 4685/4952 0.149s 0.003s
im_detect: 4686/4952 0.149s 0.003s
im_detect: 4687/4952 0.149s 0.003s
im_detect: 4688/4952 0.149s 0.003s
im_detect: 4689/4952 0.149s 0.003s
im_detect: 4690/4952 0.149s 0.003s
im_detect: 4691/4952 0.149s 0.003s
im_detect: 4692/4952 0.149s 0.003s
im_detect: 4693/4952 0.149s 0.003s
im_detect: 4694/4952 0.149s 0.003s
im_detect: 4695/4952 0.149s 0.003s
im_detect: 4696/4952 0.149s 0.003s
im_detect: 4697/4952 0.149s 0.003s
im_detect: 4698/4952 0.149s 0.003s
im_detect: 4699/4952 0.149s 0.003s
im_detect: 4700/4952 0.149s 0.003s
im_detect: 4701/4952 0.149s 0.003s
im_detect: 4702/4952 0.149s 0.003s
im_detect: 4703/4952 0.149s 0.003s
im_detect: 4704/4952 0.149s 0.003s
im_detect: 4705/4952 0.149s 0.003s
im_detect: 4706/4952 0.149s 0.003s
im_detect: 4707/4952 0.149s 0.003s
im_detect: 4708/4952 0.149s 0.003s
im_detect: 4709/4952 0.149s 0.003s
im_detect: 4710/4952 0.149s 0.003s
im_detect: 4711/4952 0.149s 0.003s
im_detect: 4712/4952 0.149s 0.003s
im_detect: 4713/4952 0.149s 0.003s
im_detect: 4714/4952 0.149s 0.003s
im_detect: 4715/4952 0.149s 0.003s
im_detect: 4716/4952 0.149s 0.003s
im_detect: 4717/4952 0.149s 0.003s
im_detect: 4718/4952 0.149s 0.003s
im_detect: 4719/4952 0.149s 0.003s
im_detect: 4720/4952 0.149s 0.003s
im_detect: 4721/4952 0.149s 0.003s
im_detect: 4722/4952 0.149s 0.003s
im_detect: 4723/4952 0.149s 0.003s
im_detect: 4724/4952 0.149s 0.003s
im_detect: 4725/4952 0.149s 0.003s
im_detect: 4726/4952 0.149s 0.003s
im_detect: 4727/4952 0.149s 0.003s
im_detect: 4728/4952 0.149s 0.003s
im_detect: 4729/4952 0.149s 0.003s
im_detect: 4730/4952 0.149s 0.003s
im_detect: 4731/4952 0.149s 0.003s
im_detect: 4732/4952 0.149s 0.003s
im_detect: 4733/4952 0.149s 0.003s
im_detect: 4734/4952 0.149s 0.003s
im_detect: 4735/4952 0.149s 0.003s
im_detect: 4736/4952 0.149s 0.003s
im_detect: 4737/4952 0.149s 0.003s
im_detect: 4738/4952 0.149s 0.003s
im_detect: 4739/4952 0.149s 0.003s
im_detect: 4740/4952 0.149s 0.003s
im_detect: 4741/4952 0.149s 0.003s
im_detect: 4742/4952 0.149s 0.003s
im_detect: 4743/4952 0.149s 0.003s
im_detect: 4744/4952 0.149s 0.003s
im_detect: 4745/4952 0.149s 0.003s
im_detect: 4746/4952 0.149s 0.003s
im_detect: 4747/4952 0.149s 0.003s
im_detect: 4748/4952 0.149s 0.003s
im_detect: 4749/4952 0.149s 0.003s
im_detect: 4750/4952 0.149s 0.003s
im_detect: 4751/4952 0.150s 0.003s
im_detect: 4752/4952 0.149s 0.003s
im_detect: 4753/4952 0.150s 0.003s
im_detect: 4754/4952 0.150s 0.003s
im_detect: 4755/4952 0.150s 0.003s
im_detect: 4756/4952 0.150s 0.003s
im_detect: 4757/4952 0.150s 0.003s
im_detect: 4758/4952 0.150s 0.003s
im_detect: 4759/4952 0.150s 0.003s
im_detect: 4760/4952 0.150s 0.003s
im_detect: 4761/4952 0.150s 0.003s
im_detect: 4762/4952 0.150s 0.003s
im_detect: 4763/4952 0.150s 0.003s
im_detect: 4764/4952 0.150s 0.003s
im_detect: 4765/4952 0.150s 0.003s
im_detect: 4766/4952 0.150s 0.003s
im_detect: 4767/4952 0.150s 0.003s
im_detect: 4768/4952 0.150s 0.003s
im_detect: 4769/4952 0.150s 0.003s
im_detect: 4770/4952 0.150s 0.003s
im_detect: 4771/4952 0.150s 0.003s
im_detect: 4772/4952 0.150s 0.003s
im_detect: 4773/4952 0.150s 0.003s
im_detect: 4774/4952 0.150s 0.003s
im_detect: 4775/4952 0.150s 0.003s
im_detect: 4776/4952 0.150s 0.003s
im_detect: 4777/4952 0.150s 0.003s
im_detect: 4778/4952 0.150s 0.003s
im_detect: 4779/4952 0.150s 0.003s
im_detect: 4780/4952 0.150s 0.003s
im_detect: 4781/4952 0.150s 0.003s
im_detect: 4782/4952 0.150s 0.003s
im_detect: 4783/4952 0.150s 0.003s
im_detect: 4784/4952 0.150s 0.003s
im_detect: 4785/4952 0.150s 0.003s
im_detect: 4786/4952 0.150s 0.003s
im_detect: 4787/4952 0.150s 0.003s
im_detect: 4788/4952 0.150s 0.003s
im_detect: 4789/4952 0.150s 0.003s
im_detect: 4790/4952 0.150s 0.003s
im_detect: 4791/4952 0.150s 0.003s
im_detect: 4792/4952 0.150s 0.003s
im_detect: 4793/4952 0.150s 0.003s
im_detect: 4794/4952 0.150s 0.003s
im_detect: 4795/4952 0.150s 0.003s
im_detect: 4796/4952 0.150s 0.003s
im_detect: 4797/4952 0.150s 0.003s
im_detect: 4798/4952 0.150s 0.003s
im_detect: 4799/4952 0.150s 0.003s
im_detect: 4800/4952 0.150s 0.003s
im_detect: 4801/4952 0.150s 0.003s
im_detect: 4802/4952 0.150s 0.003s
im_detect: 4803/4952 0.150s 0.003s
im_detect: 4804/4952 0.150s 0.003s
im_detect: 4805/4952 0.150s 0.003s
im_detect: 4806/4952 0.150s 0.003s
im_detect: 4807/4952 0.150s 0.003s
im_detect: 4808/4952 0.150s 0.003s
im_detect: 4809/4952 0.150s 0.003s
im_detect: 4810/4952 0.150s 0.003s
im_detect: 4811/4952 0.150s 0.003s
im_detect: 4812/4952 0.150s 0.003s
im_detect: 4813/4952 0.150s 0.003s
im_detect: 4814/4952 0.150s 0.003s
im_detect: 4815/4952 0.150s 0.003s
im_detect: 4816/4952 0.150s 0.003s
im_detect: 4817/4952 0.150s 0.003s
im_detect: 4818/4952 0.150s 0.003s
im_detect: 4819/4952 0.150s 0.003s
im_detect: 4820/4952 0.150s 0.003s
im_detect: 4821/4952 0.150s 0.003s
im_detect: 4822/4952 0.150s 0.003s
im_detect: 4823/4952 0.150s 0.003s
im_detect: 4824/4952 0.150s 0.003s
im_detect: 4825/4952 0.150s 0.003s
im_detect: 4826/4952 0.150s 0.003s
im_detect: 4827/4952 0.150s 0.003s
im_detect: 4828/4952 0.150s 0.003s
im_detect: 4829/4952 0.150s 0.003s
im_detect: 4830/4952 0.150s 0.003s
im_detect: 4831/4952 0.150s 0.003s
im_detect: 4832/4952 0.150s 0.003s
im_detect: 4833/4952 0.150s 0.003s
im_detect: 4834/4952 0.150s 0.003s
im_detect: 4835/4952 0.150s 0.003s
im_detect: 4836/4952 0.150s 0.003s
im_detect: 4837/4952 0.150s 0.003s
im_detect: 4838/4952 0.150s 0.003s
im_detect: 4839/4952 0.150s 0.003s
im_detect: 4840/4952 0.150s 0.003s
im_detect: 4841/4952 0.150s 0.003s
im_detect: 4842/4952 0.150s 0.003s
im_detect: 4843/4952 0.150s 0.003s
im_detect: 4844/4952 0.150s 0.003s
im_detect: 4845/4952 0.150s 0.003s
im_detect: 4846/4952 0.150s 0.003s
im_detect: 4847/4952 0.150s 0.003s
im_detect: 4848/4952 0.150s 0.003s
im_detect: 4849/4952 0.150s 0.003s
im_detect: 4850/4952 0.150s 0.003s
im_detect: 4851/4952 0.150s 0.003s
im_detect: 4852/4952 0.150s 0.003s
im_detect: 4853/4952 0.150s 0.003s
im_detect: 4854/4952 0.150s 0.003s
im_detect: 4855/4952 0.150s 0.003s
im_detect: 4856/4952 0.150s 0.003s
im_detect: 4857/4952 0.150s 0.003s
im_detect: 4858/4952 0.150s 0.003s
im_detect: 4859/4952 0.150s 0.003s
im_detect: 4860/4952 0.150s 0.003s
im_detect: 4861/4952 0.150s 0.003s
im_detect: 4862/4952 0.150s 0.003s
im_detect: 4863/4952 0.150s 0.003s
im_detect: 4864/4952 0.150s 0.003s
im_detect: 4865/4952 0.150s 0.003s
im_detect: 4866/4952 0.150s 0.003s
im_detect: 4867/4952 0.150s 0.003s
im_detect: 4868/4952 0.150s 0.003s
im_detect: 4869/4952 0.150s 0.003s
im_detect: 4870/4952 0.150s 0.003s
im_detect: 4871/4952 0.150s 0.003s
im_detect: 4872/4952 0.150s 0.003s
im_detect: 4873/4952 0.150s 0.003s
im_detect: 4874/4952 0.150s 0.003s
im_detect: 4875/4952 0.150s 0.003s
im_detect: 4876/4952 0.150s 0.003s
im_detect: 4877/4952 0.150s 0.003s
im_detect: 4878/4952 0.150s 0.003s
im_detect: 4879/4952 0.150s 0.003s
im_detect: 4880/4952 0.150s 0.003s
im_detect: 4881/4952 0.150s 0.003s
im_detect: 4882/4952 0.150s 0.003s
im_detect: 4883/4952 0.150s 0.003s
im_detect: 4884/4952 0.150s 0.003s
im_detect: 4885/4952 0.150s 0.003s
im_detect: 4886/4952 0.150s 0.003s
im_detect: 4887/4952 0.150s 0.003s
im_detect: 4888/4952 0.150s 0.003s
im_detect: 4889/4952 0.150s 0.003s
im_detect: 4890/4952 0.150s 0.003s
im_detect: 4891/4952 0.150s 0.003s
im_detect: 4892/4952 0.150s 0.003s
im_detect: 4893/4952 0.150s 0.003s
im_detect: 4894/4952 0.150s 0.003s
im_detect: 4895/4952 0.150s 0.003s
im_detect: 4896/4952 0.150s 0.003s
im_detect: 4897/4952 0.150s 0.003s
im_detect: 4898/4952 0.150s 0.003s
im_detect: 4899/4952 0.150s 0.003s
im_detect: 4900/4952 0.150s 0.003s
im_detect: 4901/4952 0.150s 0.003s
im_detect: 4902/4952 0.150s 0.003s
im_detect: 4903/4952 0.150s 0.003s
im_detect: 4904/4952 0.150s 0.003s
im_detect: 4905/4952 0.150s 0.003s
im_detect: 4906/4952 0.150s 0.003s
im_detect: 4907/4952 0.150s 0.003s
im_detect: 4908/4952 0.150s 0.003s
im_detect: 4909/4952 0.150s 0.003s
im_detect: 4910/4952 0.150s 0.003s
im_detect: 4911/4952 0.150s 0.003s
im_detect: 4912/4952 0.150s 0.003s
im_detect: 4913/4952 0.150s 0.003s
im_detect: 4914/4952 0.150s 0.003s
im_detect: 4915/4952 0.150s 0.003s
im_detect: 4916/4952 0.150s 0.003s
im_detect: 4917/4952 0.150s 0.003s
im_detect: 4918/4952 0.150s 0.003s
im_detect: 4919/4952 0.150s 0.003s
im_detect: 4920/4952 0.150s 0.003s
im_detect: 4921/4952 0.150s 0.003s
im_detect: 4922/4952 0.150s 0.003s
im_detect: 4923/4952 0.150s 0.003s
im_detect: 4924/4952 0.150s 0.003s
im_detect: 4925/4952 0.150s 0.003s
im_detect: 4926/4952 0.150s 0.003s
im_detect: 4927/4952 0.150s 0.003s
im_detect: 4928/4952 0.150s 0.003s
im_detect: 4929/4952 0.150s 0.003s
im_detect: 4930/4952 0.150s 0.003s
im_detect: 4931/4952 0.150s 0.003s
im_detect: 4932/4952 0.150s 0.003s
im_detect: 4933/4952 0.150s 0.003s
im_detect: 4934/4952 0.150s 0.003s
im_detect: 4935/4952 0.150s 0.003s
im_detect: 4936/4952 0.150s 0.003s
im_detect: 4937/4952 0.150s 0.003s
im_detect: 4938/4952 0.150s 0.003s
im_detect: 4939/4952 0.150s 0.003s
im_detect: 4940/4952 0.150s 0.003s
im_detect: 4941/4952 0.150s 0.003s
im_detect: 4942/4952 0.150s 0.003s
im_detect: 4943/4952 0.150s 0.003s
im_detect: 4944/4952 0.150s 0.003s
im_detect: 4945/4952 0.150s 0.003s
im_detect: 4946/4952 0.150s 0.003s
im_detect: 4947/4952 0.150s 0.003s
im_detect: 4948/4952 0.150s 0.003s
im_detect: 4949/4952 0.150s 0.003s
im_detect: 4950/4952 0.150s 0.003s
im_detect: 4951/4952 0.150s 0.003s
im_detect: 4952/4952 0.150s 0.003s
Applying NMS to all detections
Evaluating detections
Writing aeroplane VOC results file
Writing bicycle VOC results file
Writing bird VOC results file
Writing boat VOC results file
Writing bottle VOC results file
Writing bus VOC results file
Writing car VOC results file
Writing cat VOC results file
Writing chair VOC results file
Writing cow VOC results file
Writing diningtable VOC results file
Writing dog VOC results file
Writing horse VOC results file
Writing motorbike VOC results file
Writing person VOC results file
Writing pottedplant VOC results file
Writing sheep VOC results file
Writing sofa VOC results file
Writing train VOC results file
Writing tvmonitor VOC results file
Running:
cd /home/bsl/py-faster-rcnn-master/tools/../lib/datasets/VOCdevkit-matlab-wrapper && matlab -nodisplay -nodesktop -r "dbstop if error; voc_eval('/home/bsl/py-faster-rcnn-master/tools/../lib/datasets/../../data/VOCdevkit2007','comp4-12584','test','/home/bsl/py-faster-rcnn-master/output/faster_rcnn_alt_opt/voc_2007_test/VGG16_faster_rcnn_final',1); quit;"

                            < M A T L A B (R) >
                  Copyright 1984-2014 The MathWorks, Inc.
                    R2014a (8.3.0.532) 64-bit (glnxa64)
                             February 11, 2014

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 
aeroplane: pr: load: 169/4952
aeroplane: pr: load: 434/4952
aeroplane: pr: load: 709/4952
aeroplane: pr: load: 977/4952
aeroplane: pr: load: 1000/4952
aeroplane: pr: load: 1281/4952
aeroplane: pr: load: 1544/4952
aeroplane: pr: load: 1806/4952
aeroplane: pr: load: 2074/4952
aeroplane: pr: load: 2171/4952
aeroplane: pr: load: 2181/4952
aeroplane: pr: load: 2187/4952
aeroplane: pr: load: 2328/4952
aeroplane: pr: load: 2601/4952
aeroplane: pr: load: 2851/4952
aeroplane: pr: load: 3103/4952
aeroplane: pr: load: 3354/4952
aeroplane: pr: load: 3623/4952
aeroplane: pr: load: 3867/4952
aeroplane: pr: load: 4115/4952
aeroplane: pr: load: 4385/4952
aeroplane: pr: load: 4652/4952
aeroplane: pr: load: 4905/4952
aeroplane: pr: compute: 2427/17618
aeroplane: pr: compute: 4860/17618
aeroplane: pr: compute: 7194/17618
aeroplane: pr: compute: 9593/17618
aeroplane: pr: compute: 11982/17618
aeroplane: pr: compute: 14425/17618
aeroplane: pr: compute: 16841/17618
!!! aeroplane : 0.7193 0.7418
bicycle: pr: load: 276/4952
bicycle: pr: load: 588/4952
bicycle: pr: load: 864/4952
bicycle: pr: load: 1149/4952
bicycle: pr: load: 1421/4952
bicycle: pr: load: 1699/4952
bicycle: pr: load: 1970/4952
bicycle: pr: load: 2241/4952
bicycle: pr: load: 2536/4952
bicycle: pr: load: 2817/4952
bicycle: pr: load: 3074/4952
bicycle: pr: load: 3329/4952
bicycle: pr: load: 3610/4952
bicycle: pr: load: 3875/4952
bicycle: pr: load: 4154/4952
bicycle: pr: load: 4423/4952
bicycle: pr: load: 4693/4952
bicycle: pr: compute: 2420/20567
bicycle: pr: compute: 4840/20567
bicycle: pr: compute: 7265/20567
bicycle: pr: compute: 9708/20567
bicycle: pr: compute: 12160/20567
bicycle: pr: compute: 14604/20567
bicycle: pr: compute: 17035/20567
bicycle: pr: compute: 19480/20567
!!! bicycle : 0.7954 0.8384
bird: pr: load: 276/4952
bird: pr: load: 586/4952
bird: pr: load: 863/4952
bird: pr: load: 1151/4952
bird: pr: load: 1418/4952
bird: pr: load: 1692/4952
bird: pr: load: 1959/4952
bird: pr: load: 2227/4952
bird: pr: load: 2516/4952
bird: pr: load: 2796/4952
bird: pr: load: 3055/4952
bird: pr: load: 3299/4952
bird: pr: load: 3567/4952
bird: pr: load: 3839/4952
bird: pr: load: 4101/4952
bird: pr: load: 4377/4952
bird: pr: load: 4648/4952
bird: pr: load: 4905/4952
bird: pr: compute: 2429/20935
bird: pr: compute: 4858/20935
bird: pr: compute: 7312/20935
bird: pr: compute: 9744/20935
bird: pr: compute: 12162/20935
bird: pr: compute: 14597/20935
bird: pr: compute: 17051/20935
bird: pr: compute: 19449/20935
!!! bird : 0.6822 0.7031
boat: pr: load: 276/4952
boat: pr: load: 580/4952
boat: pr: load: 857/4952
boat: pr: load: 1138/4952
boat: pr: load: 1411/4952
boat: pr: load: 1687/4952
boat: pr: load: 1958/4952
boat: pr: load: 2223/4952
boat: pr: load: 2513/4952
boat: pr: load: 2797/4952
boat: pr: load: 3060/4952
boat: pr: load: 3309/4952
boat: pr: load: 3581/4952
boat: pr: load: 3846/4952
boat: pr: load: 4114/4952
boat: pr: load: 4393/4952
boat: pr: load: 4666/4952
boat: pr: load: 4924/4952
boat: pr: compute: 2390/20515
boat: pr: compute: 4822/20515
boat: pr: compute: 7274/20515
boat: pr: compute: 9725/20515
boat: pr: compute: 12178/20515
boat: pr: compute: 14632/20515
boat: pr: compute: 17089/20515
boat: pr: compute: 19543/20515
!!! boat : 0.5691 0.5758
bottle: pr: load: 277/4952
bottle: pr: load: 580/4952
bottle: pr: load: 855/4952
bottle: pr: load: 1135/4952
bottle: pr: load: 1404/4952
bottle: pr: load: 1681/4952
bottle: pr: load: 1952/4952
bottle: pr: load: 2225/4952
bottle: pr: load: 2515/4952
bottle: pr: load: 2783/4952
bottle: pr: load: 3042/4952
bottle: pr: load: 3292/4952
bottle: pr: load: 3567/4952
bottle: pr: load: 3839/4952
bottle: pr: load: 4102/4952
bottle: pr: load: 4383/4952
bottle: pr: load: 4657/4952
bottle: pr: load: 4919/4952
bottle: pr: compute: 2423/28052
bottle: pr: compute: 4839/28052
bottle: pr: compute: 7263/28052
bottle: pr: compute: 9708/28052
bottle: pr: compute: 12144/28052
bottle: pr: compute: 14574/28052
bottle: pr: compute: 17027/28052
bottle: pr: compute: 19476/28052
bottle: pr: compute: 21928/28052
bottle: pr: compute: 24376/28052
bottle: pr: compute: 26812/28052
!!! bottle : 0.5320 0.5400
bus: pr: load: 276/4952
bus: pr: load: 580/4952
bus: pr: load: 854/4952
bus: pr: load: 1141/4952
bus: pr: load: 1413/4952
bus: pr: load: 1689/4952
bus: pr: load: 1958/4952
bus: pr: load: 2227/4952
bus: pr: load: 2518/4952
bus: pr: load: 2801/4952
bus: pr: load: 3061/4952
bus: pr: load: 3315/4952
bus: pr: load: 3590/4952
bus: pr: load: 3856/4952
bus: pr: load: 4130/4952
bus: pr: load: 4412/4952
bus: pr: load: 4688/4952
bus: pr: load: 4951/4952
bus: pr: compute: 2447/19172
bus: pr: compute: 4891/19172
bus: pr: compute: 7335/19172
bus: pr: compute: 9770/19172
bus: pr: compute: 12207/19172
bus: pr: compute: 14635/19172
bus: pr: compute: 17072/19172
!!! bus : 0.7805 0.8063
car: pr: load: 276/4952
car: pr: load: 584/4952
car: pr: load: 850/4952
car: pr: load: 1137/4952
car: pr: load: 1407/4952
car: pr: load: 1681/4952
car: pr: load: 1953/4952
car: pr: load: 2224/4952
car: pr: load: 2511/4952
car: pr: load: 2791/4952
car: pr: load: 3049/4952
car: pr: load: 3295/4952
car: pr: load: 3568/4952
car: pr: load: 3839/4952
car: pr: load: 4105/4952
car: pr: load: 4386/4952
car: pr: load: 4661/4952
car: pr: load: 4923/4952
car: pr: compute: 2414/18104
car: pr: compute: 4791/18104
car: pr: compute: 7241/18104
car: pr: compute: 9693/18104
car: pr: compute: 12147/18104
car: pr: compute: 14595/18104
car: pr: compute: 17044/18104
!!! car : 0.8001 0.8459
cat: pr: load: 278/4952
cat: pr: load: 580/4952
cat: pr: load: 852/4952
cat: pr: load: 1133/4952
cat: pr: load: 1399/4952
cat: pr: load: 1668/4952
cat: pr: load: 1933/4952
cat: pr: load: 2210/4952
cat: pr: load: 2481/4952
cat: pr: load: 2763/4952
cat: pr: load: 3019/4952
cat: pr: load: 3267/4952
cat: pr: load: 3539/4952
cat: pr: load: 3807/4952
cat: pr: load: 4059/4952
cat: pr: load: 4330/4952
cat: pr: load: 4601/4952
cat: pr: load: 4868/4952
cat: pr: compute: 2397/20234
cat: pr: compute: 4842/20234
cat: pr: compute: 7295/20234
cat: pr: compute: 9744/20234
cat: pr: compute: 12201/20234
cat: pr: compute: 14655/20234
cat: pr: compute: 17111/20234
cat: pr: compute: 19565/20234
!!! cat : 0.8142 0.8443
chair: pr: load: 276/4952
chair: pr: load: 584/4952
chair: pr: load: 860/4952
chair: pr: load: 1149/4952
chair: pr: load: 1421/4952
chair: pr: load: 1694/4952
chair: pr: load: 1960/4952
chair: pr: load: 2227/4952
chair: pr: load: 2518/4952
chair: pr: load: 2798/4952
chair: pr: load: 3058/4952
chair: pr: load: 3308/4952
chair: pr: load: 3580/4952
chair: pr: load: 3849/4952
chair: pr: load: 4119/4952
chair: pr: load: 4399/4952
chair: pr: load: 4672/4952
chair: pr: load: 4937/4952
chair: pr: compute: 2434/19970
chair: pr: compute: 4855/19970
chair: pr: compute: 7274/19970
chair: pr: compute: 9699/19970
chair: pr: compute: 12152/19970
chair: pr: compute: 14591/19970
chair: pr: compute: 17036/19970
chair: pr: compute: 19472/19970
!!! chair : 0.5159 0.5224
cow: pr: load: 278/4952
cow: pr: load: 588/4952
cow: pr: load: 867/4952
cow: pr: load: 1157/4952
cow: pr: load: 1428/4952
cow: pr: load: 1704/4952
cow: pr: load: 1973/4952
cow: pr: load: 2241/4952
cow: pr: load: 2533/4952
cow: pr: load: 2814/4952
cow: pr: load: 3071/4952
cow: pr: load: 3326/4952
cow: pr: load: 3601/4952
cow: pr: load: 3865/4952
cow: pr: load: 4142/4952
cow: pr: load: 4421/4952
cow: pr: load: 4697/4952
cow: pr: compute: 2453/18865
cow: pr: compute: 4912/18865
cow: pr: compute: 7369/18865
cow: pr: compute: 9826/18865
cow: pr: compute: 12285/18865
cow: pr: compute: 14744/18865
cow: pr: compute: 17204/18865
!!! cow : 0.7823 0.8049
diningtable: pr: load: 279/4952
diningtable: pr: load: 590/4952
diningtable: pr: load: 870/4952
diningtable: pr: load: 1162/4952
diningtable: pr: load: 1432/4952
diningtable: pr: load: 1709/4952
diningtable: pr: load: 1982/4952
diningtable: pr: load: 2254/4952
diningtable: pr: load: 2546/4952
diningtable: pr: load: 2823/4952
diningtable: pr: load: 3085/4952
diningtable: pr: load: 3343/4952
diningtable: pr: load: 3622/4952
diningtable: pr: load: 3885/4952
diningtable: pr: load: 4162/4952
diningtable: pr: load: 4440/4952
diningtable: pr: load: 4715/4952
diningtable: pr: compute: 2449/18842
diningtable: pr: compute: 4900/18842
diningtable: pr: compute: 7353/18842
diningtable: pr: compute: 9807/18842
diningtable: pr: compute: 12262/18842
diningtable: pr: compute: 14717/18842
diningtable: pr: compute: 17173/18842
!!! diningtable : 0.6624 0.6804
dog: pr: load: 277/4952
dog: pr: load: 588/4952
dog: pr: load: 867/4952
dog: pr: load: 1157/4952
dog: pr: load: 1428/4952
dog: pr: load: 1705/4952
dog: pr: load: 1975/4952
dog: pr: load: 2244/4952
dog: pr: load: 2537/4952
dog: pr: load: 2819/4952
dog: pr: load: 3075/4952
dog: pr: load: 3332/4952
dog: pr: load: 3611/4952
dog: pr: load: 3876/4952
dog: pr: load: 4153/4952
dog: pr: load: 4428/4952
dog: pr: load: 4703/4952
dog: pr: compute: 2448/17371
dog: pr: compute: 4897/17371
dog: pr: compute: 7352/17371
dog: pr: compute: 9801/17371
dog: pr: compute: 12257/17371
dog: pr: compute: 14713/17371
dog: pr: compute: 17158/17371
!!! dog : 0.8045 0.8281
horse: pr: load: 276/4952
horse: pr: load: 587/4952
horse: pr: load: 865/4952
horse: pr: load: 1152/4952
horse: pr: load: 1424/4952
horse: pr: load: 1701/4952
horse: pr: load: 1971/4952
horse: pr: load: 2238/4952
horse: pr: load: 2532/4952
horse: pr: load: 2815/4952
horse: pr: load: 3071/4952
horse: pr: load: 3325/4952
horse: pr: load: 3601/4952
horse: pr: load: 3866/4952
horse: pr: load: 4135/4952
horse: pr: load: 4417/4952
horse: pr: load: 4690/4952
horse: pr: compute: 2443/16092
horse: pr: compute: 4850/16092
horse: pr: compute: 7270/16092
horse: pr: compute: 9697/16092
horse: pr: compute: 12119/16092
horse: pr: compute: 14512/16092
!!! horse : 0.8218 0.8577
motorbike: pr: load: 272/4952
motorbike: pr: load: 577/4952
motorbike: pr: load: 849/4952
motorbike: pr: load: 1139/4952
motorbike: pr: load: 1413/4952
motorbike: pr: load: 1689/4952
motorbike: pr: load: 1962/4952
motorbike: pr: load: 2233/4952
motorbike: pr: load: 2526/4952
motorbike: pr: load: 2808/4952
motorbike: pr: load: 3066/4952
motorbike: pr: load: 3315/4952
motorbike: pr: load: 3580/4952
motorbike: pr: load: 3841/4952
motorbike: pr: load: 4109/4952
motorbike: pr: load: 4392/4952
motorbike: pr: load: 4668/4952
motorbike: pr: load: 4933/4952
motorbike: pr: compute: 2376/17202
motorbike: pr: compute: 4761/17202
motorbike: pr: compute: 7141/17202
motorbike: pr: compute: 9513/17202
motorbike: pr: compute: 11889/17202
motorbike: pr: compute: 14286/17202
motorbike: pr: compute: 16722/17202
!!! motorbike : 0.7740 0.8055
person: pr: load: 274/4952
person: pr: load: 575/4952
person: pr: load: 843/4952
person: pr: load: 1129/4952
person: pr: load: 1402/4952
person: pr: load: 1681/4952
person: pr: load: 1954/4952
person: pr: load: 2225/4952
person: pr: load: 2516/4952
person: pr: load: 2800/4952
person: pr: load: 3061/4952
person: pr: load: 3315/4952
person: pr: load: 3587/4952
person: pr: load: 3855/4952
person: pr: load: 4127/4952
person: pr: load: 4407/4952
person: pr: load: 4680/4952
person: pr: load: 4943/4952
person: pr: compute: 2411/13979
person: pr: compute: 4815/13979
person: pr: compute: 7249/13979
person: pr: compute: 9676/13979
person: pr: compute: 12123/13979
!!! person : 0.7686 0.7871
pottedplant: pr: load: 276/4952
pottedplant: pr: load: 587/4952
pottedplant: pr: load: 863/4952
pottedplant: pr: load: 1152/4952
pottedplant: pr: load: 1424/4952
pottedplant: pr: load: 1701/4952
pottedplant: pr: load: 1972/4952
pottedplant: pr: load: 2243/4952
pottedplant: pr: load: 2537/4952
pottedplant: pr: load: 2819/4952
pottedplant: pr: load: 3075/4952
pottedplant: pr: load: 3329/4952
pottedplant: pr: load: 3606/4952
pottedplant: pr: load: 3869/4952
pottedplant: pr: load: 4144/4952
pottedplant: pr: load: 4422/4952
pottedplant: pr: load: 4697/4952
pottedplant: pr: compute: 2433/26256
pottedplant: pr: compute: 4880/26256
pottedplant: pr: compute: 7335/26256
pottedplant: pr: compute: 9778/26256
pottedplant: pr: compute: 12202/26256
pottedplant: pr: compute: 14656/26256
pottedplant: pr: compute: 17097/26256
pottedplant: pr: compute: 19534/26256
pottedplant: pr: compute: 21985/26256
pottedplant: pr: compute: 24426/26256
!!! pottedplant : 0.4100 0.4013
sheep: pr: load: 276/4952
sheep: pr: load: 586/4952
sheep: pr: load: 864/4952
sheep: pr: load: 1155/4952
sheep: pr: load: 1426/4952
sheep: pr: load: 1703/4952
sheep: pr: load: 1974/4952
sheep: pr: load: 2246/4952
sheep: pr: load: 2537/4952
sheep: pr: load: 2818/4952
sheep: pr: load: 3074/4952
sheep: pr: load: 3329/4952
sheep: pr: load: 3603/4952
sheep: pr: load: 3866/4952
sheep: pr: load: 4140/4952
sheep: pr: load: 4419/4952
sheep: pr: load: 4687/4952
sheep: pr: load: 4948/4952
sheep: pr: compute: 2450/21605
sheep: pr: compute: 4896/21605
sheep: pr: compute: 7347/21605
sheep: pr: compute: 9802/21605
sheep: pr: compute: 12254/21605
sheep: pr: compute: 14701/21605
sheep: pr: compute: 17159/21605
sheep: pr: compute: 19573/21605
!!! sheep : 0.6895 0.7063
sofa: pr: load: 276/4952
sofa: pr: load: 585/4952
sofa: pr: load: 859/4952
sofa: pr: load: 1141/4952
sofa: pr: load: 1409/4952
sofa: pr: load: 1683/4952
sofa: pr: load: 1958/4952
sofa: pr: load: 2230/4952
sofa: pr: load: 2522/4952
sofa: pr: load: 2805/4952
sofa: pr: load: 3064/4952
sofa: pr: load: 3320/4952
sofa: pr: load: 3593/4952
sofa: pr: load: 3856/4952
sofa: pr: load: 4127/4952
sofa: pr: load: 4405/4952
sofa: pr: load: 4679/4952
sofa: pr: load: 4944/4952
sofa: pr: compute: 2448/17433
sofa: pr: compute: 4902/17433
sofa: pr: compute: 7356/17433
sofa: pr: compute: 9811/17433
sofa: pr: compute: 12267/17433
sofa: pr: compute: 14720/17433
sofa: pr: compute: 17177/17433
!!! sofa : 0.6620 0.6753
train: pr: load: 276/4952
train: pr: load: 582/4952
train: pr: load: 852/4952
train: pr: load: 1140/4952
train: pr: load: 1413/4952
train: pr: load: 1691/4952
train: pr: load: 1962/4952
train: pr: load: 2233/4952
train: pr: load: 2527/4952
train: pr: load: 2810/4952
train: pr: load: 3070/4952
train: pr: load: 3327/4952
train: pr: load: 3606/4952
train: pr: load: 3872/4952
train: pr: load: 4149/4952
train: pr: load: 4425/4952
train: pr: load: 4702/4952
train: pr: compute: 2449/18207
train: pr: compute: 4904/18207
train: pr: compute: 7362/18207
train: pr: compute: 9819/18207
train: pr: compute: 12274/18207
train: pr: compute: 14732/18207
train: pr: compute: 17190/18207
!!! train : 0.7664 0.7937
tvmonitor: pr: load: 277/4952
tvmonitor: pr: load: 582/4952
tvmonitor: pr: load: 862/4952
tvmonitor: pr: load: 1152/4952
tvmonitor: pr: load: 1424/4952
tvmonitor: pr: load: 1701/4952
tvmonitor: pr: load: 1971/4952
tvmonitor: pr: load: 2241/4952
tvmonitor: pr: load: 2537/4952
tvmonitor: pr: load: 2820/4952
tvmonitor: pr: load: 3077/4952
tvmonitor: pr: load: 3334/4952
tvmonitor: pr: load: 3614/4952
tvmonitor: pr: load: 3878/4952
tvmonitor: pr: load: 4155/4952
tvmonitor: pr: load: 4433/4952
tvmonitor: pr: load: 4707/4952
tvmonitor: pr: compute: 2445/25610
tvmonitor: pr: compute: 4897/25610
tvmonitor: pr: compute: 7349/25610
tvmonitor: pr: compute: 9801/25610
tvmonitor: pr: compute: 12253/25610
tvmonitor: pr: compute: 14703/25610
tvmonitor: pr: compute: 17149/25610
tvmonitor: pr: compute: 19603/25610
tvmonitor: pr: compute: 22058/25610
tvmonitor: pr: compute: 24512/25610
!!! tvmonitor : 0.7078 0.7267

~~~~~~~~~~~~~~~~~~~~
Results:
71.9
79.5
68.2
56.9
53.2
78.0
80.0
81.4
51.6
78.2
66.2
80.4
82.2
77.4
76.9
41.0
68.9
66.2
76.6
70.8
70.3
~~~~~~~~~~~~~~~~~~~~
